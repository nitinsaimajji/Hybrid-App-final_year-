{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3fdd3b-4a22-4298-b779-dd4783548f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('new_sms_train.csv')\n",
    "test_df = pd.read_csv('new_sms_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bfd338-8ca1-4cd6-88d3-b686e2f15965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 Reasons You Need to Join InstaSpam Now!\\n\\n1...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win A FREE iPhone X Now!! Click Here To Enter!...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get rich quick with our amazing new investment...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  5 Reasons You Need to Join InstaSpam Now!\\n\\n1...  spam\n",
       "1  Win A FREE iPhone X Now!! Click Here To Enter!...  spam\n",
       "2  CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...  spam\n",
       "3  Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...  spam\n",
       "4  Get rich quick with our amazing new investment...  spam"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c084d055-64cb-433e-a106-fe86aef26319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeTs tAlK AbouT DisCOuNtS aNd DeAlS! WhO HaS T...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waaassssupppppp!!!!!! Have you checked out the...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$$$MAKE $$$MONEY$$$ FAST!!!$$$ No scams!$$$ \\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get rich quick with our amazing new product!!!...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are you tired of being single? Join our websit...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  LeTs tAlK AbouT DisCOuNtS aNd DeAlS! WhO HaS T...  spam\n",
       "1  Waaassssupppppp!!!!!! Have you checked out the...  spam\n",
       "2  $$$MAKE $$$MONEY$$$ FAST!!!$$$ No scams!$$$ \\n...  spam\n",
       "3  Get rich quick with our amazing new product!!!...  spam\n",
       "4  Are you tired of being single? Join our websit...  spam"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9f4e9f-9d67-4289-95f1-29a610f8889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9950"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71975261-7f39-48eb-acc4-2a40000cc088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5a0721-59c5-41f2-b677-317db8bc537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_df contains a 'label' column indicating the class (e.g., 'spam' or 'not spam')\n",
    "\n",
    "# Separate samples by class\n",
    "spam_samples_train = train_df[train_df['label'] == 'spam']\n",
    "not_spam_samples_train = train_df[train_df['label'] == 'not_spam']\n",
    "\n",
    "# Determine the number of samples to select from each class\n",
    "num_samples_per_class_train = min(len(spam_samples_train), len(not_spam_samples_train))\n",
    "max_total_samples_train = 3000  # Maximum total number of samples\n",
    "\n",
    "# Calculate the number of samples to select for the training set, ensuring it doesn't exceed the maximum\n",
    "num_samples_train = min(num_samples_per_class_train * 2, max_total_samples_train)\n",
    "\n",
    "# Sample an equal number of instances from each class\n",
    "sampled_spam_train = spam_samples_train.sample(n=num_samples_train // 2, random_state=42)\n",
    "sampled_not_spam_train = not_spam_samples_train.sample(n=num_samples_train // 2, random_state=42)\n",
    "\n",
    "# Concatenate the sampled dataframes\n",
    "sampled_train_df = pd.concat([sampled_spam_train, sampled_not_spam_train])\n",
    "\n",
    "# Shuffle the dataframe to mix spam and not spam samples\n",
    "sampled_train_df = sampled_train_df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(len(sampled_train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e75688e-a7c2-4b3c-8b6c-b0fcc4c8989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_df contains a 'label' column indicating the class (e.g., 'spam' or 'not spam')\n",
    "\n",
    "# Separate samples by class\n",
    "spam_samples_test = test_df[test_df['label'] == 'spam']\n",
    "not_spam_samples_test = test_df[test_df['label'] == 'not_spam']\n",
    "\n",
    "# Determine the number of samples to select from each class\n",
    "num_samples_per_class_test = min(len(spam_samples_test), len(not_spam_samples_test))\n",
    "max_total_samples = 800  # Maximum total number of samples\n",
    "\n",
    "# Calculate the number of samples to select for test set, ensuring it doesn't exceed the maximum\n",
    "num_samples_test = min(num_samples_per_class_test * 2, max_total_samples)\n",
    "\n",
    "# Sample an equal number of instances from each class\n",
    "sampled_spam_test = spam_samples_test.sample(n=num_samples_test // 2, random_state=42)\n",
    "sampled_not_spam_test = not_spam_samples_test.sample(n=num_samples_test // 2, random_state=42)\n",
    "\n",
    "# Concatenate the sampled dataframes\n",
    "sampled_test_df = pd.concat([sampled_spam_test, sampled_not_spam_test])\n",
    "\n",
    "# Shuffle the dataframe to mix spam and not spam samples\n",
    "sampled_test_df = sampled_test_df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(len(sampled_test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e229c09f-f7df-412e-9db4-4d146dfff755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping\n",
    "label_mapping = {\"spam\": 0, \"not_spam\": 1}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "train_df['label'] = train_df['label'].map(label_mapping)\n",
    "test_df['label'] = test_df['label'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe57f83b-32b0-4bd8-8111-5e9e519ba20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 Reasons You Need to Join InstaSpam Now!\\n\\n1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win A FREE iPhone X Now!! Click Here To Enter!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get rich quick with our amazing new investment...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  5 Reasons You Need to Join InstaSpam Now!\\n\\n1...      0\n",
       "1  Win A FREE iPhone X Now!! Click Here To Enter!...      0\n",
       "2  CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...      0\n",
       "3  Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...      0\n",
       "4  Get rich quick with our amazing new investment...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c046807-5746-48fd-8eee-4e7e5392b6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cfa043-c3ce-498e-b775-3be58ad1fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae6588f-43bc-4816-b321-f61b2e757a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "109/109 [==============================] - 1362s 12s/step - loss: 0.5252 - accuracy: 0.7134 - val_loss: 0.7221 - val_accuracy: 0.5417\n",
      "30/30 [==============================] - 49s 2s/step - loss: 0.4286 - accuracy: 0.7811\n",
      "Test accuracy: 0.7810526490211487\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Assuming train_df and test_df are your training and testing DataFrames respectively\n",
    "\n",
    "# Tokenization for DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Encoding as numbers for training dataset with limited tokenization\n",
    "encoded_train_texts = tokenizer(train_df['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "X_train_padded = pad_sequences(encoded_train_texts['input_ids'], padding='post', maxlen=128)\n",
    "y_train = train_df['label'].to_numpy()\n",
    "\n",
    "# Encoding as numbers for testing dataset with limited tokenization\n",
    "encoded_test_texts = tokenizer(test_df['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "X_test_padded = pad_sequences(encoded_test_texts['input_ids'], padding='post', maxlen=128)\n",
    "y_test = test_df['label'].to_numpy()\n",
    "\n",
    "# Building the DistilBERT model\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compile the model (define optimizer, loss, and metric)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Training the model with early stopping for 1 epoch\n",
    "history = model.fit(\n",
    "    {'input_ids': X_train_padded, 'attention_mask': encoded_train_texts['attention_mask']},\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    validation_split=0.3,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluating the model on the testing dataset\n",
    "eval_result = model.evaluate(\n",
    "    {'input_ids': X_test_padded, 'attention_mask': encoded_test_texts['attention_mask']},\n",
    "    y_test\n",
    ")\n",
    "print(f\"Test accuracy: {eval_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c302feb-393e-43f1-8d0a-c6cc380403c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 53s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       500\n",
      "           1       1.00      0.54      0.70       450\n",
      "\n",
      "    accuracy                           0.78       950\n",
      "   macro avg       0.85      0.77      0.76       950\n",
      "weighted avg       0.85      0.78      0.77       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict({'input_ids': X_test_padded, 'attention_mask': encoded_test_texts['attention_mask']})\n",
    "y_pred = np.argmax(y_pred.logits, axis=1)\n",
    "\n",
    "# Generating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39942053-1d10-4178-9abf-ba5446824b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae02fd-33d6-448a-a6c8-a15deec1c614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
