{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3fdd3b-4a22-4298-b779-dd4783548f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('new_sms_train.csv')\n",
    "test_df = pd.read_csv('new_sms_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bfd338-8ca1-4cd6-88d3-b686e2f15965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 Reasons You Need to Join InstaSpam Now!\\n\\n1...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win A FREE iPhone X Now!! Click Here To Enter!...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get rich quick with our amazing new investment...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  5 Reasons You Need to Join InstaSpam Now!\\n\\n1...  spam\n",
       "1  Win A FREE iPhone X Now!! Click Here To Enter!...  spam\n",
       "2  CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...  spam\n",
       "3  Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...  spam\n",
       "4  Get rich quick with our amazing new investment...  spam"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c084d055-64cb-433e-a106-fe86aef26319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeTs tAlK AbouT DisCOuNtS aNd DeAlS! WhO HaS T...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waaassssupppppp!!!!!! Have you checked out the...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$$$MAKE $$$MONEY$$$ FAST!!!$$$ No scams!$$$ \\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get rich quick with our amazing new product!!!...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are you tired of being single? Join our websit...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  LeTs tAlK AbouT DisCOuNtS aNd DeAlS! WhO HaS T...  spam\n",
       "1  Waaassssupppppp!!!!!! Have you checked out the...  spam\n",
       "2  $$$MAKE $$$MONEY$$$ FAST!!!$$$ No scams!$$$ \\n...  spam\n",
       "3  Get rich quick with our amazing new product!!!...  spam\n",
       "4  Are you tired of being single? Join our websit...  spam"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9f4e9f-9d67-4289-95f1-29a610f8889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9950"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71975261-7f39-48eb-acc4-2a40000cc088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e229c09f-f7df-412e-9db4-4d146dfff755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping\n",
    "label_mapping = {\"spam\": 0, \"not_spam\": 1}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "train_df['label'] = train_df['label'].map(label_mapping)\n",
    "test_df['label'] = test_df['label'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe57f83b-32b0-4bd8-8111-5e9e519ba20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 Reasons You Need to Join InstaSpam Now!\\n\\n1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win A FREE iPhone X Now!! Click Here To Enter!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get rich quick with our amazing new investment...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  5 Reasons You Need to Join InstaSpam Now!\\n\\n1...      0\n",
       "1  Win A FREE iPhone X Now!! Click Here To Enter!...      0\n",
       "2  CHECK OUT THESE AMAZING DEALS! GET RICH QUICK ...      0\n",
       "3  Urgent update!!1!!1!1 OMG ðŸ˜±ðŸ˜±ðŸ˜±\\nYou won't belie...      0\n",
       "4  Get rich quick with our amazing new investment...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c046807-5746-48fd-8eee-4e7e5392b6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cfa043-c3ce-498e-b775-3be58ad1fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae6588f-43bc-4816-b321-f61b2e757a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 2462s 22s/step - loss: 0.1927 - accuracy: 0.9195 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "30/30 [==============================] - 95s 3s/step - loss: 0.0141 - accuracy: 0.9958\n",
      "Test accuracy: 0.9957894682884216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming train_df and test_df are your training and testing DataFrames respectively\n",
    "\n",
    "# Tokenization for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Encoding as numbers for training dataset with tokenization\n",
    "encoded_train_texts = tokenizer(train_df['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "X_train_padded = pad_sequences(encoded_train_texts['input_ids'], padding='post', maxlen=128)\n",
    "y_train = train_df['label'].to_numpy()\n",
    "\n",
    "# Encoding as numbers for testing dataset with tokenization\n",
    "encoded_test_texts = tokenizer(test_df['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "X_test_padded = pad_sequences(encoded_test_texts['input_ids'], padding='post', maxlen=128)\n",
    "y_test = test_df['label'].to_numpy()\n",
    "\n",
    "# Building the custom BERT + DNN model\n",
    "def create_bert_dnn_model():\n",
    "    # Load the pre-trained BERT model\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Input layers\n",
    "    input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    # BERT outputs\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = bert_outputs.last_hidden_state\n",
    "    pooled_output = bert_outputs.pooler_output\n",
    "    \n",
    "    # Custom DNN layers\n",
    "    dropout = Dropout(0.3)(pooled_output)\n",
    "    dense1 = Dense(256, activation='relu')(dropout)\n",
    "    dropout1 = Dropout(0.3)(dense1)\n",
    "    dense2 = Dense(64, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.3)(dense2)\n",
    "    output = Dense(2, activation='softmax')(dropout2)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_bert_dnn_model()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Training the model with early stopping for 1 epoch\n",
    "history = model.fit(\n",
    "    {'input_ids': X_train_padded, 'attention_mask': encoded_train_texts['attention_mask']},\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    validation_split=0.3,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluating the model on the testing dataset\n",
    "eval_result = model.evaluate(\n",
    "    {'input_ids': X_test_padded, 'attention_mask': encoded_test_texts['attention_mask']},\n",
    "    y_test\n",
    ")\n",
    "print(f\"Test accuracy: {eval_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c302feb-393e-43f1-8d0a-c6cc380403c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 94s 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9940    0.9980    0.9960       500\n",
      "           1     0.9978    0.9933    0.9955       450\n",
      "\n",
      "    accuracy                         0.9958       950\n",
      "   macro avg     0.9959    0.9957    0.9958       950\n",
      "weighted avg     0.9958    0.9958    0.9958       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict({'input_ids': X_test_padded, 'attention_mask': encoded_test_texts['attention_mask']})\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generating the classification report without rounding off\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d3245-c64f-4e8d-8c02-49109d438ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa119b-7952-4d57-b2c1-4a249ef8a4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
