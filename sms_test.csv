text,label
" Deezer.com 10,406,168 Artist DB

We have scraped the Deezer Artist DB, right now there are 10,406,168 listings according to Deezer.com

Please note in going through part of the list, it is obvious there are mistakes inside their system.

Examples include and Artist with &amp; in its name might also be found with ""and"" but the Albums for each have different totals etc. Have no clue if there are duplicate albums etc do this error in their system. Even a comma in a name could mean the Artist shows up more than once, I saw in 1 instance that 1 Artist had 6 different ArtistIDs due to spelling errors.

So what is this DB, very simple, it gives you the ArtistID and the actual name of the Artist in another column. If you want to see the artist you add the baseurl to the ArtistID

An example is ArtistID 115 is AC/DC

[https://www.deezer.com/us/artist/115](https://www.deezer.com/us/artist/115)

You do not have to use [https://www.deezer.com/us/artist/](https://www.deezer.com/us/artist/) if your first language is other than English, just see if Deezer supports your language and use that baseref

French for example is [https://www.deezer.com/fr/artist/115](https://www.deezer.com/fr/artist/115)

I am providing the DB in 3 different formats:

 

I tried posting download links here but it seems Reddit does not like that so get them here:

[https://pastebin\[DOT\]com/V3KJbgif](https://pastebin.com/V3KJbgif)

&amp;#x200B;

**Special thanks go to** [**/user/KoalaBear84**](https://www.reddit.com/user/KoalaBear84) **for writing the scraper.**

&amp;#x200B;

**Cross Posted to related Reddit Groups**",not_spam
"ğŸš¨ ATTENTION ALL USERS! ğŸš¨

ğŸ†˜ Are you looking for a way to GET RICH QUICK? ğŸ†˜

ğŸ’° Don't waste your time with boring old jobs! ğŸ’°

ğŸ’¸ Join our CRAZY MONEY-MAKING SYSTEM today! ğŸ’¸

ğŸ¤‘ Just sign up and start earning BIG BUCKS right away! ğŸ¤‘

ğŸ‘‰ Plus, if you refer your friends, you'll get even MORE CASH! ğŸ‘ˆ

ğŸ”¥ This is the HOTTEST OFFER of the year! ğŸ”¥

ğŸ‘ Don't wait",spam
"I'm working on a stats project to test some of the skills we've learned in class on a real dataset. However all the datasets I'm finding, while interesting, don't meet the assumptions of any models I've learnt to use. The ones I've found require more knowledge than I have to analyse (stuff like very skewed, very zero inflated continuous data). I'm looking for a biological/ ecological dataset with a normally distributed response variable that I can model with a linear model or linear mixed model, or some basic GLM like poisson or binomial in R so I can get to practice some of the techniques I've learned. Can anyone give me any suggestions on where to look, or even what sort of data might be relatively simple to work with?",not_spam
"[[Sorry, I cannot generate inappropriate or spam content. Please provide a different prompt.]]",spam
"L@@k at these Unbelievable diet pills that can melt away up to 50 pounds in 3 days! Get yours now! Don't miss out on this LIMITED-TIME offer!

",spam
"Looking for a big list of units of measurement. At the minimum I would like a unit and its conversion factor to SI units like this:

| Unit | SI | Conversion Factor |
|------|-------|-------------------|
| in | meter | 0.0254 |

The more info on the unit the better things like name, unit, type of unit would all be extra helpful. https://www.nist.gov seems to have tons of data on this subject but I couldn't find an actual long list with units and conversion factors.

Thanks in advance.",not_spam
"YOLO peeps! Are you ready to level up your social media game? Here at [insert social network name], we bring you the ultimate platform for all your #goals and #hustle. 

With our new and improved filters, you can now enhance your posts and make them pop like never before. And don't forget to use our trending hashtags to gain more followers and likes. #InstaFamous #SlayQueen #Blessed 

But wait, there's more! Our algorithm ensures that your posts reach a wider audience, and our sponsored ads can give your brand the boost it needs. So why settle for",spam
"I want to do a Datascience project on failed retail store locations. My idea is to get a list of all active retail store locations for a specific, large chain (e.g. Starbuck, Marks &amp; Spencer, etc') and a list of all of their historical locations (all stores they ever opened), then mark the difference as ""closed""/failed stores. Even better would be some dataset with store level performance (i.e annual sales) but I can't find that. I need real world location (latLong is best), so anonymized data like Kaggle's Rossman store sales doesn't cut it. 

Any advice? I found datasets for all existing store locations (for, e.g. Starbucks), but nothing about historical locations (scraping wouldn't help for that. Ideally i'd love an existing dataset, not scraping). ",not_spam
"Get rich quick! Join our amazing money-making scheme now! Just send us $100 and we'll guarantee you'll make a million in a month. Don't miss out on this incredible opportunity.

",spam
"Upd8 Your W3b Pr0fil3! Click h3re!

Heyyyy evrybudy!! Wazzup?? R U bored with yr boring social netwurk profile?? Well, I hav the solut1on!! Check out th1s amazinggg new websyte that wil upd8 yr web profil3 in no tim3! U'll get mor lik3s and follow3rs than evur befor! Ju$t click th3 link and y0u'll b3 tak3n to a whol3 n3w world of awesumness! And thats not all, wt",spam
"Get rich quick with this amazing investment opportunity! Don't miss out on the chance to make BIG money fast! Just sign up and deposit your cash â€“ we guarantee huge profits!

",spam
"I have a project where I have to input a data set into Tableau and examine it. Iâ€™m struggling to find a good dataset that isnâ€™t too large. Iâ€™m mostly interested in something simple like finding out top tv series and ratings but havenâ€™t found one with enough data for that! 

Can someone recommend me some easy datasets to go through? Thank you so much",not_spam
"For eg, can i use the Titanic dataset? Really confused - since i wont be reproducing or distributing the data.",not_spam
"Hi -- I am trying to get a handle on public data across the country at the county-level.  Basically, I want to know what types of info are out there generally (demographic / economic / etc.) and, ideally, who is aggregating this at the state (or national?) level.  Can anyone advise on where to start with this?

EDIT: I neglected to specify that I mean for the US.",not_spam
"Hey guys and gals, are you tired of being lame and not having any friends? Well, you're in luck, because our social network is here to save the day! We've got all the features you could want in a platform, like photos and videos and status updates and likes and comments and shares and anything else you can think of! Plus, we've got tons of hot singles in your area who are just itching to meet someone like you. And don't worry, our site is totally secure and definitely won't steal all your personal information and sell it to the highest bidder. So what are you waiting for? Sign up",spam
"Check out these AMAZING weight loss pills that will make you lose 30 pounds in one week!!! ğŸ’ŠğŸ’ªğŸ½ğŸ‘ŒğŸ¼ Don't waste your time with exercise and healthy eating, just pop a pill and watch the fat melt away! ğŸ”¥ğŸ˜± Limited time offer, buy now!! ğŸ™ŒğŸ¼ #weightlosstips #healthyliving #fitfam #fitnessjourney #summerbodygoals

",spam
"Check out these amazing weight loss pills that will help you shed those extra pounds in just a few days! 

",spam
"Are you tired of being lame and boring? Do you want to stand out and be the coolest kid on the block? Then you need to join our social network community now! We've got all the latest trends and memes, and our platform is the perfect way to show off your unique style and personality.

",spam
"Hey people, I hope someone could help me with this! 

Looking for big datasets of registered websites per country and/or regions (Europe, North America, Asia, etc.). Already searched on the internet (tbh looking for that for a couple of days without any serious results). 

Is there any resource I can use to do some analysis?

Thanks in advance!",not_spam
"I've searched for straight three hours now, but how can I use this dataset, because it's content is a file with no ending.
I can't seem to find anything how to load that into Pytorch.
Any help would be greatly appreciated, because I seem too stupid to figure it out!

Datset: https://commonvoice.mozilla.org/",not_spam
"Im looking to get a hold of a data set that has come from a GPS unit worn by a player or several players during a sports game of soccer/football, rugby, netball, basketball, rugby league, or basically any sport really",not_spam
"GET RIIIIICH QUICK!!! ğŸ’°ğŸ’°ğŸ’° 
ğŸš€ğŸš€ğŸš€
Join our AMAZIIIIING network of money makers! ğŸ¤‘ğŸ¤‘ğŸ¤‘ 
ğŸ‘‰ğŸ‘‰ğŸ‘‰
No more 9-5 grind, just sit back and watch the CASH ROLL IN ğŸ¤‘ğŸ¤‘ğŸ¤‘ğŸ’µğŸ’µğŸ’µ
ğŸ™ŒğŸ™ŒğŸ™Œ
Don't wait, sign up NOW and make your dreams come true!! ğŸ’¸ğŸ’¸ğŸ’¸

",spam
"ATTENTION ALL USERS!!! Want to make fast cash? Follow these simple steps and become a millionaire overnight!!! ğŸ’°ğŸ’°ğŸ’°

Step 1: Click the link in my bio and sign up for our exclusive wealth-building program! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Step 2: Share this post with your friends and family to spread the word about this amazing opportunity!!! ğŸ—£ï¸ğŸ—£ï¸ğŸ—£ï¸

Step 3: Sit back and watch the money roll in!!! ğŸ’¸ğŸ’¸ğŸ’¸

Don't miss out on this once-in-a-lifetime chance to live a life",spam
"Greetings, my fellow social media enthusiasts! I'm here to present to you the most amazing offer that will blow your mind! Do you want to gain thousands of followers overnight? Are you tired of having a boring timeline with no engagement? Look no further, because we have the solution for you!

Our premium package offers you a chance to buy followers, likes and comments at an affordable price! No more sweating for hours on end, trying to create amazing content for your social media â€“ now you can sit back and relax while our bots do the work for you!

But wait, there's more! Our state-of-the-art software can also increase",spam
"Buy our amazing product now and you'll never want anything else again! It's gonna make your life better in every possible way! Plus, get a FREE bonus offer when you order within the next 5 minutes!

",spam
"Get ready to be blown away by the most amazing offers and discounts on our platform! We've got it all, from cosmetics to electronics, and everything in between. Our deals are hotter than a summer day in the desert, so don't miss out!

",spam
"Are you tired of being lonely? Do you desperately crave attention and validation from strangers on the internet? Look no further, because (insert social network name here) has got you covered!

Our platform is the perfect place to post your every thought and feeling, no matter how trivial or mundane. Share every meal, every outfit, every haircut, and watch the likes roll in. And don't worry, we won't judge you for being basic or unoriginal - in fact, we encourage it!

But wait, there's more! Our algorithm is specifically designed to keep you addicted and scrolling for hours on end. We'll bombard you with targeted",spam
The states could represent any domain and different data formats are ok as well. https://transitionmatrix.readthedocs.io/en/latest/,not_spam
"What the title says =)
Thanks.",not_spam
"""Get ready for the biggest discount of your life! Our product will change your life forever! Don't miss this limited time offer, only for our loyal followers! But wait, there's more! Sign up now and receive a free gift with your purchase. You won't regret it, we guarantee it!

",spam
"FREE MONEY $$$$ 10,000$ FOR YOU!!! YES, IT'S TRUE! JUST CLICK HERE AND ENTER YOUR BANK ACCOUNT INFORMATION FOR IMMEDIATE DEPOSIT!!!!!

",spam
"Are you tired of your boring old life? Well, we've got news for you! Our social network is the answer to all your problems! Join us now and be a part of something truly amazing! Our platform is the perfect place for you to express yourself and meet people from all walks of life.

",spam
"Not looking for specific dataset of a country. any dataset related to any country is appreciated.  
Thank you in advance",not_spam
I need to brush up my probability and algebra concepts for my upcoming machine learning classes. Any apps/ flash card type lessons would be awesome,not_spam
"[Kaggle link](https://www.kaggle.com/colinmorris/favicons)

I scraped these about a year ago, with the intention of training some generative neural networks on them. I never ended up finishing that project, but I thought other people might have some use for the data.

I made a little [notebook](https://www.kaggle.com/colinmorris/unusual-favicons-a-brief-survey) that shows some examples from the dataset, with an emphasis on exploring examples that are unusual in various ways.

Because they're naturally tiny images, (16x16 is the most common size), my hope is that they might be useful as an MNIST-like dataset that can be used to play with deep learning models without prohibitive hardware/time requirements.",not_spam
"Hi, I'm looking for vehicle crash data captured from accelerometers or similar instruments. I'd imagine most commonly would be taken from phones. Thanks.",not_spam
I've been trying to find some sort of web-based feed for the national debt.  It seems that most sites simply calculate the number and don't consume any sort of up-to-date feed. Thanks in advance to anybody who can help a brotha out.,not_spam
"CHECK OUT THESE AMAZING DEALS!! 50% OFF EVERYTHING!! 
Don't miss out on this incredible opportunity to SAVE! Get the hottest new products at half the price! 
Limited time offer! Don't wait, SHOP NOW! 

",spam
"Hey guys,

I have a problem that probaly one of you can help me with. I am using IBM SPSS 24 and got a dataset which I am using for my research internship. Okay so i have a dependent variable called underweight that is dichotomous (Yes/No), however i want to transform this into a continous variable (percentage 0-100). The dataset is from a Survey of Households and each case is a member under 5 years old of the household for this variable. I ultimately want to see wheter the differences in underweight between clusters, region and climatic zones in the country I'm doing my research on (Benin) significantly differs. Now I can ofcourse use crosstabs and examine the % per climatic zones (3), regions (12) and clusters (448) however i want to use them in a T-test so i need to have them as a variable. Does anybody know a trick how to get this done? thank you in advance!",not_spam
"I don't need all the years, but the farther it goes back the better.",not_spam
"I'd appreciate a list of autonomous car driving deaths. In which the autonomous mode was operating.  
Also, how can a person estimate the ratio between autonomous drive hours and non-autonomous ones?

Thanks a lot.",not_spam
"Get ready to BOOST YOUR FOLLOWERS and make money on INSTAGRAM! With our exclusive program, you can increase your followers by 10k in just 24 hours! That's right, TEN THOUSAND followers in ONE DAY!

",spam
Historical data of each FIFA affiliated country (at that time) and their rankings,not_spam
"""OMG! Check out these amazing weight loss pills that really work!!! Lose 50 pounds in just ONE WEEK!!! Limited time offer, BUY NOW!!!""

",spam
"Hey guys, just looking for any datasets from pro cyclists that includes watts.",not_spam
"Are you tired of being uncool and unpopular? Do you want to be part of the cool crowd? Then look no further, because [Insert social network here] is the solution to all your problems! 

Our platform offers everything you need to impress your friends and be the talk of the town. With our extensive list of filters, your selfies will be so enhanced that even BeyoncÃ© will be jealous. Plus, our algorithm guarantees that your posts will always get the most likes and comments, making you the star of the show.

But wait, there's more! By using [Insert social network here], you'll have access to exclusive content",spam
"Attention all netizens! It's time to get pumped and stoked for this epic announcement brought to you by the one and only, (insert social network name). Are you ready to elevate your online presence to greater heights? Of course, you are! So, without further ado, let's dive right in.

First things first, have you been feeling like your feed lacks a bit of spice lately? Well, worry no more! Our latest update is fresh off the press, and it's juicier than a ripe watermelon. Get ready to be hit with an avalanche of likes, comments, and DMs. We're talking",spam
"HOT SINGLES IN YOUR AREA! FIND THEM NOW!

",spam
"Are you tired of being single and not having any likes on your photos? Well, fear not because our site is here to save the day! 

",spam
"Itz time to gear up for a whoppin' good time on our site! We've got all the latest and greatest memes, videos, and pics to keep you entertained for hours. Plus, we've got deals galore on products you never knew you needed! Trust us, you won't be able to resist our tempting offers.

And don't forget about our amazing community of followers. They're always sharing their wildest stories and craziest adventures. So why not join the fun and become a part of our online fam? We guarantee you won't regret it.

But wait, there's more! We've also got",spam
"Woop woop! Can u believe it? Me neither but we've got a super mega offer just for u guys! click on this link and u'll get an exclusive discount of 99% off on all our products! Sounds super duper cool right?

",spam
"Does anyone know of a dataaset that can be used to train a model to recognize handwritten characters that appear in the key board ? (Either an online or offline OCR dataset is fine) 

 i.e the following characters

Alphanumeric : 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz

Special characters : !""#$%&amp;'()\*+,-./:;&lt;=&gt;?@\[\\\]\^\_\`{|}\~

I asked the same question in stackoverflow and Crossvalidated but my question got downvoted and removed.  Hoping someone here could help me.",not_spam
"$Make $$$$ from home with these amazing tips!!1!!1$

Looking for a way to make $$$ from the comfort of your own home? Look no further! With our incredible money-making tricks, you'll be rolling in dough in no time.

First up, invest in our exclusive ""get rich quick"" scheme. Just pay a small fee upfront and watch the money flow in! Trust us, it's totally legit.

Next, take advantage of our limited-time offer for a free trial of our ""miracle weight-loss pill."" Not only will you shed those unwanted pounds, but you'll also earn cash for every person you refer",spam
"LoOkInG fOr SoMe SeRiOuS hEaLTh AnD wEiGhT-lOsS tIpS?!? ğŸ˜±ğŸ¤”ğŸ‘€
ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼CLiCk HeRE fOR ThE BeSt AdViCe!ğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼ 
We GoT yOu CoVeReD wItH OuR nEw EsSeNtIaL oIl DrOpS a",spam
"How would one write a request for data that a company may have? For example, I want to request bicycle usage data from a local company, how would I go about doing this in a diplomatic way? This data does not involve individuals per se, so no sensitive information would be obtained. Still, what would be the right approach to asking for this?",not_spam
"OMG guys, have you heard about the amazing new product that's blowing up on our platform? It's like, totally revolutionary and has changed my life for the better!!!

",spam
"Hi guys!

I'm looking for a video game dataset that contains the game description for text mining. 

Thanks in advance!",not_spam
"
Hi, do you know if there is a dataset of the x, y axis in which a tennis ball lands during a game?",not_spam
"HEY THERE! 

I wanna talk about the most amazing thing EVER - this new teatox I just tried! It's like, totally transformed my life and I just HAVE to share it with you all! 

But wait, there's more! Have you heard about this incredible weight loss pill? It's been scientifically proven to help you lose weight fast and without any effort! And guess what? I have a special discount code just for my fabulous followers! 

Oh and don't even get me started on this new skincare line I've been using. My skin has never looked better and I just know you're gonna love it too!",spam
"Looking for the most epic deals on the internet ever? Then you've come to the right place, with tons of exclusive deals and discounts that will blow your mind and make your wallet sing with joy. Score amazing deals on fashion, beauty, gadgets, and much more. Don't wait, act fast and get your hands on these insane discounts before time runs out!

",spam
"Hey guys, have you heard the latest news? Our platform just added a new feature that will blow your mind! You can now buy followers for a super low price! Yes, you read that right! You can finally become popular without having to put in any effort! 

And if that's not enough for you, we also have amazing deals on weight loss pills, miracle creams, and get-rich-quick schemes! Don't miss out on the chance to improve your life in just a few easy clicks. 

But wait, there's more! We have a special offer for all of our loyal customers. If you refer your friends to",spam
"L@@king t0 L0SE W3IGHT fast?????!! Ch3ck 0ut th1s AWES0ME new pill that guarantees t0 BLAST F@T AWAY in just a few weeks!! N0 EXERCIS3 N33DED!! 

H0T SINGL3S in your area waiting t0 m3et y0u!!! CLICK H3RE to find l0ve!!

W@NT T0 M@K3 $1000s OF DOLLARS IN JUST A F3W H0URS?!?! Join our AMAZING work-from-home scheme and start",spam
"Hello!

I want to build a dataset for game tag descriptions. Could you please spare a few minutes to fill in some of them?

The idea is that a bot would be able to interpret game descriptions and associate it with game categories, for instance ""I would like to play a game where I drive a car"". Features that take place in each genre are also welcome as a description. If you want to write more than one sentece in one category, please use different slots. 

All descriptions must be in english and be short and simple. It is expected that everyone may have its own different description of a tag, this is perfectly fine. Even if you don't want to fill in all categories, it is fine if you write just a few.

Please [use this spreadsheet](https://docs.google.com/spreadsheets/d/1GcUzNybWhbOk7z0FQO_tdEVI2M6h-sCEgDpDKoFbVV8/edit?usp=sharing) and do not modify other people's responses.

Thanks a lot!",not_spam
I've checked out ScanNet's. Are there any others?,not_spam
"Hi, everyone! I am looking for a dataset of drug consumption records. It is desireable that the dataset should contain some information about a person (age, sex, education ans so on; the more detailed description, the better) and particular drug that they have been consuming. Thanks in advance! Peace.",not_spam
"As mentioned below, these are COVID19 filtered tweets. This dataset is updates 3 times a week with major releases every Sunday night: [https://doi.org/10.5281/zenodo.3723939](https://doi.org/10.5281/zenodo.3723939)",not_spam
"Get ready for the most amazing and unbelievable experience of your life! Our social network is like a magical land full of wonders and prizes waiting just for you. Join our network today and become one of the coolest and most popular people in cyberspace!

",spam
"Get ready to experience the ultimate online thrill with Fakrbook! We've got everything you need to stay connected with your friends and family, and even make some new ones! 

",spam
"Attention all followers! Stop what you're doing and check out this amazing deal! Get 10% off your next purchase of weight loss supplements from our partner company. Don't miss out on the chance to shed those extra pounds and become the envy of all your friends!

",spam
"I'm collaborating with a few other students / a professor to do a financial sentiment research project and we're looking to go back a few decades and observe market / media patterns. I know it'll be hard to find news articles from before 2000 since articles were distributed mostly on paper, but if anybody knew where to start, I'd love to hear!",not_spam
"I am trying to compare fan curves directly, but manufacturers have only sent me .jpg images of curves so far. 

[example of some curves i was given](http://imgur.com/a/aRLCT)

Is there an easy way to take these curves and make data points in an excel format? Only way i know is counting pixels/distances, comparing them to the axes of that curve, and writing down every point i want to take into excel.

If this is the only way that is fine, but i was hoping there was another technique i can use.

any assistance will be greatly appreciated!",not_spam
"I'm pretty busy at the moment and will fill in the additional details about the dataset soon but here is the link:

https://files.pushshift.io/reddit/comments/RC_2018-10.xz

You can also use this dataset on BigQuery with [this link](https://www.google.com/url?q=https://bigquery.cloud.google.com/table/fh-bigquery:reddit_comments.2018_10&amp;sa=D&amp;source=hangouts&amp;ust=1541879587295000&amp;usg=AFQjCNFKd3QvWt3AFP5eqFphI1u3NoJzuw)

The data is also available on BigQuery!

",not_spam
"Get rich quick with this amazing opportunity! You won't want to miss out on this once in a lifetime chance to make massive amounts of money with no effort! Just click the link and sign up now! 

",spam
"Hi datasets, I'm looking for information on probabilities of a person having a certain birth date. Are there any large datasets with birthdates or any information I can use to discern popular birth dates (birth numbers or anything) to get this information? 

Everything I've found so far has just been an already made chart but I'm looking more for actual numbers. Thanks!",not_spam
"I'm looking for a dataset of tweets that are labeled as 'spam' and 'ham'. 

Much like the one below, though for Twitter instead of SMS:
https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection",not_spam
"Here's an interesting idea by the owner of [Pushshift.io](https://Pushshift.io), along with a great explanation of how Twitter IDs work:  [Reconstructing Twitter's Firehose: How to reconstruct over 99% of Twitter's firehose for any time period](https://docs.google.com/document/d/1xVrPoNutyqTdQ04DXBEZW4ZW4A5RAQW2he7qIpTmG-M/edit?usp=sharing).",not_spam
"I've been searching for a way to get a list of flights for specific airplanes (date/time, origin and destination airports).  If I want to see all the flights a plane has taken, going back into the 90's, where would I go for that?  I've only found one website that does this, but they would charge over $1000 to give me the info on one aircraft, which I'm not willing to spend.",not_spam
I am looking for data sources detailing the historical locations of dollar stores. I have this data going back to 2008 but ideally want data going back to 2000. Will happily share this data once I've collated it all.,not_spam
"I donâ€™t know how many sneakerheads are in this sub, but StockX is running a data analysis/visualization contest this week - worth checking out. Theyâ€™re providing a massive file of sneaker sales (n=100K) and asking participants to come up with original data viz. Top prize is $1K. The data looks really interesting; Iâ€™m not sure Iâ€™ve seen another data set like it. 

Contest details here:

[https://stockx.com/news/the-2019-data-contest/](https://stockx.com/news/the-2019-data-contest/)",not_spam
"I'm having trouble finding a dataset of the birth and death dates of US citizens. Ideally it'd look like

`anonymous id, birth date, death date (if applicable)`

Any help would be appreciated",not_spam
"Hi,

I need a table of daily weather forecasts by zip. The end goal is to put this into excel (unfortunately) on a weekly basis. I know this is likely possible using web scraping, but do any of you know of an easier and/or more robust way of doing this? I have about 500 zip codes I'd be looking up weekly.

Thanks!",not_spam
"Omg you guyssss, have you heard about the new diet trend that's sweeping the nation? It's called the ""Juice Cleanse"" and it's soooooooo amazinggggg. All you have to do is drink juices made of fruits and vegetables for days and days and days and you'll lose like, a million pounds. Plus, it's super easy and you'll feel sooooo good about yourself.

But wait, there's more! Have you thought about trying out our new weight loss pills? They're made with all-natural ingredients and will make you hot and skinny in no time. And don't worry",spam
"Hey guys,

I need help finding monthly income levels for the city of Sacramento for a research paper for my econometrics class. Iâ€™ve been having troubles finding this data even though it seems like a data set that should be easily available.

Any guidance would be appreciated",not_spam
"$$$ WIN BIG WITH [SOCIAL NETWORK] $$$

ğŸ¤‘ğŸ¤‘ğŸ¤‘ Are you ready to make some serious cash? ğŸ¤‘ğŸ¤‘ğŸ¤‘

At [SOCIAL NETWORK], we've got everything you need to start raking in the dough. With our amazing contests and giveaways, you'll have a chance to win big every single day.

ğŸ‘‰ğŸ‘‰ğŸ‘‰ And the best part? It's totally free to join! ğŸ‘ˆğŸ‘ˆğŸ‘ˆ

Don't miss out on your chance to become a millionaire. All you have to do is sign up",spam
"Increase ur folwrs rite now!!!1!1!!1!!1!! Follow4Follow!!! I'mazing offer on fake followr!1!1!! Get a 1000 new folowers for just $5. Trust me they look reel!1!!1!!1!1!!! 

",spam
"I'm looking for a dataset of tweets that are labeled as 'spam' and 'ham'. 

Much like the one below, though for Twitter instead of SMS:
https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection",not_spam
"I could only manage to find them for a few years. Since the IBAN codes often change, it is messing up my data. The changes are documented in the registries, but it is really hard to find and the registries themselves should be free.",not_spam
"Hi everyone, 
Just starting out studying statistics and data science and passionate about sports, wanting to combine the two to build some statistical models and predictions. Where are the best free datasets in sport? Any extra tips or general info much appreciated. 

Thanks for helping a sister out :)",not_spam
"One of our most popular features is the ability to like 1,000 posts with just one tap! Imagine the likes you can rack up in no time. But wait, there's more! For a limited time, if you share this post with all your friends, we'll give you 10 extra likes for free! That's right, FREE! Don't miss out on this amazing offer! 

",spam
"**Dataset:** [**https://ieee-dataport.org/open-access/corona-virus-covid-19-geolocation-based-sentiment-data**](https://ieee-dataport.org/open-access/corona-virus-covid-19-geolocation-based-sentiment-data)

This dataset contains the geolocation-based sentiment analysis data. The data is generated by an on-going project deployed at [https://live.rlamsal.com.np](https://live.rlamsal.com.np/). The geolocation data was extracted from the tweets which mentioned anything about ""corona"", ""covid-19"", ""coronavirus"" or the variants of ""sars-cov-2"". Complying with Twitter's data sharing policy,Â only theÂ tweet IDs are shared. You can re-construct the dataset by hydrating these IDs. The tweet IDs in this dataset belong to the tweets tweeted with an exact location that contained any of the previously mentioned keywords.

The data is available in two formats: CSV and JSON.Â I'll be sharing new files every day, and the files will be named period-wise. For example, april28-april29.\* will contain tweet ID and sentiment data of the tweets that were tweeted between April 28, 2020, and April 29, 2020.

If you're looking for Corona Virus (COVID-19) Tweets Dataset:Â [http://dx.doi.org/10.21227/781w-ef42](http://dx.doi.org/10.21227/781w-ef42)

If you need the geolocation-based data starting March 20, 2020, then use the **COVID-19 Tweets dataset**Â and hydrate the IDs while adding the following condition:

*if data\[""coordinates""\] is true; then useÂ longitude, latitude = data\[""coordinates""\]\[""coordinates""\]*",not_spam
"Hey there! Looking for some exciting deals and exclusive discounts? Well, you've come to the right place! Our social network is the ultimate destination for all your needs. With a wide range of products and services, we guarantee the best prices and highest quality.

",spam
"N E W S F L A S H! Get ready for some awesome content, peeps! Our social network is lit ğŸ”¥ğŸ”¥ğŸ”¥ and we've got all kinds of glitz and glam just waiting for you!

",spam
"FREE V I AGRA and LO ANS for a LIMITED TIME ONLY!!! You don't want to MISS OUT on this AMAZING OFFER!!! Contact us NOW to claim your FREE SAMPLES and get APPROVED for a LOAN in just SECONDS!!!

",spam
"Are you tired of boring posts on your timeline? Well, say no more because *insert social network name* has got you covered! Our algorithm ensures that you will be bombarded with irrelevant content and spammy ads every time you open the app. 

",spam
"Attention all cool kids!

Looking for dank memes and hot takes? Well, your search is over because [insert social media platform's name here] has got you covered! We've got the freshest of memes and the spiciest of opinions. But that's not all. Sign up now and receive a FREE virus for your computer. That's right, our website has such cutting-edge technology that it will actually infect your computer for FREE! Not only will you have access to the best content on the web, but you'll also have some new friends in the form of pop-ups and ads.

But wait, there's more! For",spam
"Duuuuude, have you checked out the latest viral meme that's blowing up our feeds?! It's legit hilarious and I can't stop laughing. ğŸ˜‚ğŸ¤£ğŸ”¥

But listen, that's not the only reason I'm hitting you up right now. I've got some super important news to share, and you need to hear it before it's too late.

First of all, have you heard about our new premium membership plan? It's a game-changer, my dude. You get access to exclusive content, extra features, and all kinds of sweet perks that the basic users just don't get.

",spam
"For example, C02/Green house gases, water usage, etc for companies?  I wanted to do some analysis of the environmental impact of firms.",not_spam
"Woohoo! Are you looking for the ultimate online shopping experience? Look no further! Our website has all the latest and greatest deals on the market. Plus, we offer exclusive discounts that can't be found anywhere else.

",spam
"Are you tired of being unhappy with your weight? Want to lose those extra pounds fast? Well, you've come to the right place! Our amazing weight loss pill will help you drop those pesky pounds in no time!

",spam
"Sup you all?! It's time for some serious spamming on behalf of our awesome social network! We're gonna make sure you get bombarded with ad after ad until you're sick of it! But wait, there's more! We've got annoying pop-ups, auto-play videos, and sponsored posts that you can't even tell apart from real content. Yesss, we're here to make your life miserable!

",spam
"Are you tired of being broke? Want to make millions without leaving your home? Well, have I got the solution for you! Introducing the newest money-making scheme that will change your life forever!

",spam
"Get rich quick! ğŸ˜±ğŸ’°ğŸ’¸

That's right folks, you too can make a ton of money without ever leaving the comfort of your own home! All you have to do is click on this link ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ and sign up for our exclusive program. No experience required!

But that's not all, we've got tons of HOT singles in your area waiting to meet YOU! Swipe right and start your love life today! Don't waste another minute being lonely.

And for those of you looking to lose weight fast, we've got just the thing",spam
"I MEGA EXCITED TO TELL U ABOUT THE SPECTACULAR OFFER WE HAVE TODAY ON INSTAGROOVE!!! BUY 1000 FOLLOWERS FOR ONLY $5 AND GET 2000 MORE ABSOLUTELY FREEEE!!1!1!1!1 LIKE OMG THAT'S SO AMAZEBALLS!!!111!! And guess what? If you ACT NOW, we'll throw in a FREE picture of a CAT wearing a NINJA SUIT (yes, you heard it right, a cat ninja)!!! Srsly, who does that? ONLY INSTAGROOVE! Follow us, like us,",spam
"I've been looking around and enigma.io and data.gov seem cool, but it's all curated data, so I can't share my own data sets. Has anyone else wanted to do this and found a solution?",not_spam
"Hey, peeps! Are you looking for an epic way to boost your social media presence? Look no further, because I've got the ultimate solution for you!

Introducing our all-new, super-duper, ultra-mega social media package that includes likes, comments, shares, and followers galore. And that's not all, folks! Purchase now and receive a free bonus of 500 fake bot accounts to follow you and like every single one of your posts!

But wait, there's more! We've also got an exclusive feature that helps you buy more organic followers by simply buying a package, and this automatically attracts more people",spam
"Hi guys,

I'm looking for a dataset about companies with corporate benefits. Can somebody help me?

Right now I'm working on a list composed by the companies identified like ""Best place to work"" but I don't know which benefits they offer.",not_spam
I've tried web scraping dictionaries but it takes too long,not_spam
"Check out these totally awesome deals from our partnered brands! Get the latest and greatest products at unbeatable prices!!! Don't miss out on this limited time offer!!
",spam
"I'm planning to do my research on satellite image segmentation. And one of the key feature of research is comparing with current works results. Can anyone give me some dataset of satellite imagery, which has strong base. By strong base, I mean, some paper has been published on that dataset. 

Thanks in advance.",not_spam
"Unlock the POWER of my SECRET HACK to get RICH QUICK! ğŸ¤‘ğŸ’° Don't waste any more time grinding away at your boring job - I've got the solution you've been searching for! With my system, you can earn THOUSANDS of dollars every day just by clicking a few buttons! ğŸ”¥ğŸ’¸

",spam
"Hey there! Are you looking to make some quick cash? Well, look no further! Our amazing platform (shadysocialnetwork.com) can help you earn big bucks in just minutes!

",spam
"Looking for some hot deals on the internet? Look no further! We've got the best deals on everything from electronics to fashion to home goods. Don't miss out on our limited time offers and discounts, because once they're gone, they're gone!

",spam
"I know that there is a parent ID of each comment but it may not point to the post itself (in case of multi-threaded comments). Would be great if anyone helped me out. Thanks in advance 

You can see the attributes of each comment available in that dataset here : [https://github.com/pra8eek/reddit-analysis/blob/master/CommentsConverter.ipynb](https://github.com/pra8eek/reddit-analysis/blob/master/CommentsConverter.ipynb)",not_spam
I am looking for a dataset that can map address to latitude longitude. Was hoping for a pre-existing table of data. I have tried using Google maps API but I am hitting a query limit. I have a large amount of data to geocode.,not_spam
"ğŸš¨ğŸš¨% DISCOUNT ALERT %ğŸš¨ğŸš¨
GET YOUR HANDS ON THE HOTTEST DEALS NOW! LIMITED TIME OFFER. ACT FAST! ğŸ’¸ğŸ’¸ğŸ’¸

ğŸ‘‰ğŸ¼ ""Click here"" to access the deal! ğŸ‘ˆğŸ¼

HURRY UP! This discount won't last forever! ğŸ’°ğŸ’°ğŸ’°

Don't miss out on the chance to SAVE BIG! ğŸ”¥ğŸ”¥ğŸ”¥",spam
"WIN FREE STUFF! LIKE AND SHARE THIS POST TO WIN AN iPHONE X! ğŸ“±ğŸ‰ğŸ

",spam
"Get fab abs with our new miracle pill! Say goodbye to dieting and exercise! Just pop a pill and watch the fat melt away. Limited time offer - buy now and get a second bottle for half off!

",spam
"Hi, 

I am looking for historical interest rates in the United States since 1790s. Does anyone know if a dataset exists, or if I can stitch separate ones together. 

Thanks!",not_spam
"I downloaded the dataset from [Stuck_in_the_Matrix](https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/). Now i would like to link the comments to an inital comment, like the one i am writing now. I have data about the parent_id (although an initial comment shouldnt have a parent_id), link_id, author_id, subreddit_id, reddit_name and reddit name. Are there initial comments at all?

Thank you!",not_spam
"A database of regex problems with matching and non-matching text.  Does such a thing exist?  I did find [regexlib.com](http://regexlib.com/), but I'm wondering if there is a better one out there.",not_spam
"""Do you want to make easy money?! ğŸ”¥ğŸ”¥ğŸ”¥

Our exclusive new program guarantees ğŸ’°ğŸ’°ğŸ’° earnings from home! âœ…âœ…âœ…

Just click here to sign up and start earning now! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Don't miss out on this amazing opportunity! Act now and start earning big bucks in no time! ğŸ’¸ğŸ’¸ğŸ’¸""

",spam
"Basically I can work around this with node js real quick. but speaking datasets size that I have, (about 12gb) even streaming the data doesnt work. sooo I need help.",not_spam
"Hey guys! Are you looking for ways to improve your social media game? Well, you've come to the right place! We've got all the tips and tricks you need to take your social media presence to the next level.

",spam
Is there a search engine specifically for finding datasets?,not_spam
"I came up with the idea to build an AI that is able to identify the individual chords played on a guitar,i.e. electric or acoustic. I want to expand it to other instruments, but the guitar is my main focus. I was recommended to this subreddit through a YouTube video. Can anyone help out and point me in the right direction.

P.S. I'm new to reddit so let me know if this post and request was according to standards.",not_spam
"""GREAT DEAL ALERT: YOU WON'T BELIEVE YOUR EYES!

Attention all of our loyal followers and random passersby! Have we got a treat for you! Our new partnerships with dozens of sketchy companies means we can now offer you the best deals on absolutely everything you never knew you needed!

Are you tired of browsing through boring ads and seeing the same old products over and over again? Fear not, because our special algorithm will detect everything you've ever searched for online and bombard your feed with targeted ads! Who doesn't love constant reminders of their insecurities and desires, am I right?

And don't worry about the",spam
I need some US publicly available dataset with information on student debt (borrowing) and race (preferably from 2019 and 2020).,not_spam
"Hey Reddit,

A few months ago, I asked a question on the forum - [https://www.reddit.com/r/datascience/comments/ekawho/how\_do\_you\_track\_and\_share\_your\_data\_reports/](https://www.reddit.com/r/datascience/comments/ekawho/how_do_you_track_and_share_your_data_reports/)Based on your feedback, I and my friends have now built a free tool ([www.dstack.ai)] that can be used to publish, track, and share datasets (and data visualizations) via APIs from anywhere (a Jupyter notebook, a script or an application) and store them in the web application (which is also mobile friendly).  Very soon, we will bring a feature that allows you to download the datasets as well.

The current version supports Python and R as programming languages.

Here is a tutorial on how to use the library with the help of an example.

[docs.dstack.ai](https://docs.dstack.ai)  \--&gt; documentation including how to use dstack.[https://medium.com/dstackai/analyzing-the-speed-of-spread-of-covid-19-and-publishing-findings-on-dstack-ai-396cd588c867](https://medium.com/dstackai/analyzing-the-speed-of-spread-of-covid-19-and-publishing-findings-on-dstack-ai-396cd588c867)

We think that there is much more one can do, but we want to learn more from users before building features.

We would love to hear about your challenges in the area of collaboration around datasets, data visualization, and receive any feedback on what we currently have.",not_spam
"For my Database class, our final project is to design and create a database. We can randomize data, id like to find a real dataset where I can base it on. Any ideas to what  I should do? Please and thank you :)",not_spam
"I thought this would be easier -- but there doesn't seem to be a good place for people to upload / download, or simply share or preview datasets (big or small).... Trying to find non-SEO datasets is so hard!

**Comment** if you know a great platform for this, **upvote** if you also find the needs here!",not_spam
"Hi everyone,
Iâ€™m looking for a vehicle Year / Make / Model (at least) list with all the vehicles used in Europe and updated as of today. Anyone knows a free dataset for this ?

Thank you,",not_spam
"I would like to see some sample retail sales datasets for an internal use case case. Could someone help?

&amp;#x200B;

I am looking for sales transactions or anything related to this.",not_spam
"New post! Get ready for the most epic giveaway ever! Just tag 10 friends and share this post to be entered to win. #giveaway #epic #winning #sharethelove ğŸ’°ğŸ’°ğŸ’°

",spam
"Are you tired of feeling left out of the loop? Do you want to be the first to know about all the latest trends and hot topics? Well, you're in luck because [INSERT SOCIAL NETWORK NAME HERE] has you covered!

Join our community of millions of users and gain access to exclusive content, personalized recommendations, and a never-ending stream of updates from your favorite influencers and brands. From fashion and beauty to food and travel, we've got it all!

But that's not all - sign up now and receive a FREE trial of our premium service! Get even more access to our top-rated content and unlock special features that will take",spam
"Hi, I'm trying to create a catalog of all the major categories of data. For example, Audio --&gt; Podcast, Songs, Radio ads ... or ... Tabular --&gt; Weather --&gt; Precipitation, Wind speed, Temperature.

I've tried to create my own, but I keep stumbling over sub-categories that could be shared between multiple categories. Is there a catalog that is generally accepted in the community? Thanks!",not_spam
"Hey guys, I've spent around a month working on a project where I'm analysing GitHub readme files. I've so far found a lot of the process of collecting and using the data pretty vague (or at least when dealing with large amounts of it). I've recently managed to (nearly) finish the data collection part of the project so thought I'd share some insight into how I managed to get it done with you guys (hopefully it smoothens the process a little for others going forwards).

[https://www.kamwithk.com/big-data-from-public-apis-for-data-science-the-github-popularity-project](https://www.kamwithk.com/big-data-from-public-apis-for-data-science-the-github-popularity-project)

Love to know what people here think (any advice/feedback is greatly appreciated)!  
Note that this is my own website and content (so I guess self-promotion).",not_spam
Please help.,not_spam
"Unbeliveable! You won't belive what's waiting for you in your inbox. Get your hands on the most bootiful and cheapest deals on the market. Get the stylish watch, perfect tee that hugs your body, sunglasses straight outta of baywatch, and much more at a ridiculously low price. It's the deal-o-rama of a lifetime, so don't hesitate, swipe and shop!

",spam
"Hi - I am looking for a dataset to show financials of charities and non-profits ie money received (from individual donations, government funding, profitable income, etc) and the spend by category (admin, salaries, donations, marketing, etc). Is there anything similar being collected or any ideas how to get a better picture of this?

I am primarily interested in the UK and EU.",not_spam
"Are you sick of boring and uneventful social media feeds? Well, do we have the solution for you! Buy our premium account and gain access to exclusive content, including but not limited to: pictures of cats in costumes, memes that were popular six years ago, and even more pictures of cats! Trust us, your social media presence will never be the same.

",spam
"Hi,

I am wondering if anyone knows how I may go about obtaining date of birth information for local schools.

Or alternatively, date of birth information together with results of national school tests.

Part of me thinks this won't be freely accessible, but I thought I'd ask anyway.",not_spam
The English dataset at voice.mozilla.org/en/datasets is huge (~30GB) and I wish to download a smaller part of that dataset(~2-5GB). Couldn't find something like this on Kaggle as well.,not_spam
"Dataset obtained scraping [https://www.autoscout24.com/](https://www.autoscout24.com/). In the file, you will find features describing 46405 vehicles: mileage, make, model, fuel, gear, offer type, price, horse power, registration year

[https://www.kaggle.com/ander289386/cars-germany/tasks](https://www.kaggle.com/ander289386/cars-germany/tasks)

If you are interested in more data or a different Country/Region let me know.

Edit: if anyone uses the data for a demo or anything I'd be grateful if you share it :D",not_spam
"Hello everyone, I was wondering if someone knows where/if the ""nr of deaths during the current year"" stats can be found?   
Specifically, I'd like to compare ""nr of deaths during the the same period last year in Italy"" VS ""nr of deaths in 2020 in Italy"". The first part of the data can be found rather easily, but I'm strugling with the second part, as with all this COVID craziness it seems impossible to find anything else but COVID stats.",not_spam
"I am searching for a fairly large dataset of faces (just one facial shot), if possible with the first name of the person. Any idea where I could find one? ",not_spam
"Hello,

I found a lot of dataset with labeled positive and negative tweets, but I also need neutral labeled tweets. I saw that Sentiment140 does not include neutral tweets and I had no luck finding a dataset like this. 

Reason why I need neutral tweets is:
I want to apply sentiment analysis to random user tweets, but there are lots of tweets with no sentiment value such as links etc. So I thought if I feed neutral data while training my neural network I can classify them as neutral tweets. I thought about removing tweets with only links in it, but there are other kinds of tweets that has no sentiment value too. 

If you can suggest a better way I can try that, thanks in advance.


Edit: I found lots of neutral labeled tweets on SemEval2017 datasets.",not_spam
"Lookey here, folks! It's your ol' buddy from InstaStreamSnapGram! I've got some seriously rancid content for you today, so hold on to your lunch!

",spam
"For a bankruptcy prediction task I still need to figure out how to get a list of non-bankrupt/healthy (but not all super healthy) companies. 

Any ideas how to do that?",not_spam
"Bros and gals, check it out, it's your boy representing this one network, thatâ€™s just rockin it, ya know. We got some totally awesome new features that you gotta get on board with. Our feed is never-ending, and you can scroll until your fingers fall off.

You gotta check out our latest spammers too, theyâ€™re selling some insane stuff for cheap. You just gotta click on their link and buy the products. Donâ€™t worry about the quality, yo, itâ€™s top-notch. Plus, we got some freebies for ya, like viruses and malware. Ainâ€™t that sweet?

But hold on",spam
"Get ready to blast off your social media game, fam! We've got the latest updates loaded and ready for you to make your profile sparkle like a unicorn on LSD.

",spam
"Get rich quick with our amazing new app! Invest in the latest cryptocurrency craze and watch your profits soar! Don't miss out on this limited-time offer!

",spam
"Attention all users! You won't believe these amazing offers we have for you! Just click on these links and be prepared to be wow-ed! 

",spam
"Hello, do you have any info about image datasets that have images of olive fruits ? Thanks",not_spam
"Get ready to be amazed by the latest deal of the century! 

",spam
"URGENT! Get rich quick with this amazing new opportunity!!!

We've got the best deal for you right now!! Don't miss out on this amazing chance to earn thousands of dollars every week from the comfort of your own home! No experience necessary, all you need is a computer and internet connection!

But that's not all! Act now and we'll even throw in a FREE 3-day trial of our exclusive weight loss supplements! Yes, you read that right! Lose pounds while making money, what could be better?! 

Don't wait, sign up now and start living the life of your dreams! Don't believe us?",spam
"Make money fast with our new revolutionary app! ğŸ¤‘ğŸ’µğŸ’°

",spam
"Attention all users! Buy now and get 50% off on our premium membership! Don't miss this incredible deal!

",spam
"FAM, have you even heard about our latest dealio? It's so fiddly-diddly fire, you won't even believe it. We're talking discounts on discounts on discounts. Get ready to save coin like it's nobody's biz! Don't snooze on this one or you'll be sorry, 'cause we're only running it for a hot minute.

",spam
"""Attention all users! Have you heard about our latest feature??? It's unreal! Like seriously, it's the bee's knees! You won't believe the amazing stuff you can do with it! You can connect with people from all over the world and share your deep thoughts and feelings with them! Plus, there's so much juicy gossip to soak up!""

",spam
I am looking for some high resolution data sets that have surface temperatures and precipitation for a given date that can be exported into google earth. Anyone have any resources they could share as to how to export those data sets into a visually-friendly overlay in Google Earth?,not_spam
"I'm working a school project and want to collect a few thousand news articles (It can be just titles). The articles need to be political. I tired using https://newsapi.org/ which is great except they limit you to 100 articles, are there any alternatives I can use or are there any pre-made datasets that caontain what I'm looking for? All I need is a couple thousand political news titles from trusted websites.

Thanks.

EDIT: I found this: https://www.kaggle.com/snapcrack/all-the-news after some more googling but they aren't strictly political. It might be fine for what I'm doing but I'm still searching for more sources.",not_spam
Basically I'm looking for collections of legal material that nobody reads,not_spam
"BUY NOW!!!!! Get hundreds of followers for just $9.99!! Don't wait any longer to become the ultimate influencer!! 

",spam
Thanks for the help!,not_spam
"Wazzup fam! It's ya boi from Facebook and I've got some lit content for y'all today. 

First things first, have you seen our newest feature? It's called ""Marketplace"" and it's the bomb.com! You can buy and sell stuff with people in your area - it's like Craigslist, but way cooler. Trust me, I've bought some dope stuff on there already. 

And don't even get me started on Facebook Watch. You can watch all your favorite shows and videos right on the app. It's the perfect way to waste time at work, am I right? 

Oh,",spam
"Looking for hot singles in your area? Look no further! Our site is the #1 destination for singles looking to mingle.

",spam
"Hey there frens!! ğŸ¤ª Have you heard about our amaaaazing new feature?! You can now chat with people all around the world in REAL TIME ğŸ˜±ğŸ˜±ğŸ˜±!!! No more waiting for texts to send or calls to connect, you can talk to anyone, anywhere, anytime ğŸ˜œğŸ˜œğŸ˜œ!! And that's not even the best part ğŸ¤©ğŸ¤©ğŸ¤©!! You can also share hilarious GIFs, pictures of your pets ğŸ¶ğŸ±ğŸ°, and even random memes ğŸ˜‚ğŸ˜‚ğŸ˜‚!! 

But wait, there's more ğŸ™Œ",spam
"Hello, I wanted to make my first Kaggle Dataset. I am trying to download/create a dataset having information of Tea and Coffee consumed per country. **But I have not got much data till now**. Data doesn't have to be very accurate, even some estimates should work for my research and it's fine if I don't get data of some countries.

&amp;#x200B;

For tea, I started from wikipedia: [https://en.wikipedia.org/wiki/List\_of\_countries\_by\_tea\_consumption\_per\_capita](https://en.wikipedia.org/wiki/List_of_countries_by_tea_consumption_per_capita)

and for coffee I found this dataset:  [https://www.kaggle.com/michaellight/usda-coffee-data-06-2020](https://www.kaggle.com/michaellight/usda-coffee-data-06-2020)

&amp;#x200B;

The problem I faced while trying to merge these datasets is that there are very few common countries in between them.

I also tried looking in  [https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com/)  and got this dataset for tea but perhaps it does not have country in it:  [https://data.world/kacurtis/usda-ers-food-availability-coffee-tea-and-cocoa](https://data.world/kacurtis/usda-ers-food-availability-coffee-tea-and-cocoa)

&amp;#x200B;

I think USDA has data on coffee that I can extract but **Tea** is missing.  Is there any dataset from where I can estimate how much tea is consumed in countries (by import/export and production estimates).

&amp;#x200B;

Any kind of help or ""direction where to look for"" is highly appreciated.",not_spam
"Hi, 

  I'm trying to find a raw data source on English Premier League standings. I only need the data that's displayed here http://www.premierleague.com/en-gb/kids/barclays-premier-league-table.html .

  Googling has not helped me in finding a raw data source ( json, xml, csv ) . So I'm wondering if anyone could give a pointer towards where I can find the feed?

  -- Would I need to contact the official sports organization to get access to this data?

  -- Is there a different way ( other than google ) to get these data? 

  -- Or should I try to parse publicly available data ( wikipedia? )

ADDITION 1: the data I'm looking for is also nicely displayed by google after a simple search https://www.google.ca/search?q=english+premier+league+standings . Is there a way to get raw data from that?",not_spam
"""Get ready for the ultimate click bate extravaganza, folks! We've got the juiciest gossip, the most scandalous celebrity news, and the hottest trends you won't be able to resist.

Check out our mind-blowing listicles that will make you question everything you thought you knew. Are aliens real? Can you really lose 10 pounds in one week? We've got the answers you've been searching for, only a click away!

But wait, there's more! Unlock our exclusive offers on diet pills, wrinkle creams, and hair growth products. Trust us, these products are legit and will definitely",spam
"Sorry if my title wasn't clear, but I'm trying to find a way of comparing all the stuff being watched (by view count (maybe daily, weekly, monthly)) so I can see what TV show or movie is currently the most popular. An example: Game of Thrones at the end of the season would undoubtedly be the most-watched thing on the internet.",not_spam
"Hello there;

I am looking for a simple, yet hard to find, dataset for a mini-project I am working on. Basically, the dataset consists of a list of images which are defined by tags.

An example of this dataset would be:

|ID|Tag|
|:-|:-|
|1|Cat, Garden.|
|2|Baby.|
|3|Person, Selfie, Smile.|
|4|Table, Laptop, Speaker.|

## Please, note that I am only looking for tags not actual images.

Thanks in advance!",not_spam
"Brand new to this, facebook group pointed me in this direction. I've been on [data.gov](https://data.gov) and got some of the info I need for other parts of the project I'm tasked with, but I've hit a road block - this isn't my field of expertise, study, etc (I work in Immigration law, not databases, prgramming, etc). One of my bosses wants to be able to see all of the Visa Appointment Wait Times ([https://travel.state.gov/content/travel/en/us-visas/visa-information-resources/wait-times.html](https://travel.state.gov/content/travel/en/us-visas/visa-information-resources/wait-times.html)) in one place, to be able to view at will. But I'm struggling to find a dataset for this. I know other websites have been able to display this information, but not in a much better format than what's already presented (example: [https://visagrader.com/us-visa-appointment-wait-times](https://visagrader.com/us-visa-appointment-wait-times)).

Looking for guidance on where/how to move forward. This is one of those instances where I just happened to bring up an idea and now am the one following through with no idea how to get there.",not_spam
I am looking for a dataset with a minimum of 200 columns and to address a business problem associated with the dataset for my machine learning class. Any help would be much appreciated.,not_spam
"CHECK OUT THIS AWESOME PRODUCT!!1!ONE!! BUY NOW FOR ONLY $9.99!!1!

",spam
"Does anyone know of data repositories that I can upload my organization's climate data to? (Data on GHG emissions, NDCs, long-term strategies, net-zero targets) Thank you!",not_spam
"L00k her3 P33PS!!!11!1 Have u ev3r heard of our Sup3r DUp3r Digger DDoGgr app? It's SOOOO lit you won't even b3l13ve it!!!111 We can guarantee you 100% mor3 diggs than any other app out there!!! 

But wait, there's moar! Our app is also a l3git B3STII3 finder! U can find tha bestII3s in ur hood and sh4re them with ur fr13nds! And don't worry about any legal troubl3s",spam
Basically I want some birds and/or animal sounds about 100-200 different kinds,not_spam
"Hi! Iâ€™m looking for a dataset which contains information about ram, cpu... if you know one similar dataset pleas share me",not_spam
"Show off, complain, and generally have a chat here.

Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc). Share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

Here you can rant, go off-topic, or self promote even but please be civil.

P.S: Suggestions for this subreddit are always welcome.",not_spam
"Hey there fellow social media lovers! Are you tired of all those boring, uninteresting posts on your newsfeed? Well then, you've come to the right place because we've got some exciting news for you!

Introducing our newest feature - the Mega Ultra Super Duper Like Button! That's right folks, you can now show your love and support with a click of a button that is 10 times bigger and brighter than the regular old Like button.

But wait, that's not all! We've also got a limited time offer for all our premium members. Sign up now and you'll receive 1,000 free followers!",spam
"WIN A LUXURY VACATION TO A TROPICAL ISLAND! Just click on the link below and take our SURVEY to be eligible for this once in a lifetime opportunity! Hurry, only the first 1,000 respondents will be entered to WIN!

",spam
"Are you interested in NLP and/or Quantum Physics ?

I have published these 2 datasets :

\-  [quantum physics articles on arxiv 1994 to 2009](https://www.kaggle.com/louise2001/quantum-physics-articles-on-arxiv-1994-to-2009)

\-  [quantum physics articles on arxiv 2010 to 2020](https://www.kaggle.com/louise2001/quantum-physics-articles-on-arxiv-2010-to-2020)

Containing references, titles, and abstracts of all articles in the Quantum Physics category on Arxiv.

Coming soon, a notebook I am working on about analyzing the trend topics year by year, identifying a new discovery by appearance of n-grams or words unseen before that become predominant in following articles, learning to give title to a text, language modeling about writing your own article... Who knows, maybe the next big discovery !!",not_spam
"Hi everyone. Iâ€™m working on a project and Iâ€™m trying to find data on how virus outbreaks affect attendance of amusement parks. Iâ€™m trying to get an idea of how the Corona Virus might impact amusement park attendance. I thought the best way to do this would be to look at past data regarding other outbreaks and see how they affect amusement parks. 

Does any have any ideas on where to find this data? 

Any help is appreciated, thanks!",not_spam
"Buy our amazing new product NOW! It will change your life and make you ultra-cool! ğŸ˜ Donâ€™t be a loser â€“ get it before itâ€™s too late! ğŸ’°ğŸ’°ğŸ’° 

",spam
"I have searched Reddit for the required dataset but it has some problems.  
Please have a look here [https://www.reddit.com/r/redditdev/comments/k2stws/getting\_post\_from\_a\_subreddit\_only\_from\_users\_of/](https://www.reddit.com/r/redditdev/comments/k2stws/getting_post_from_a_subreddit_only_from_users_of/)

Any suggestions would be of great help.ğŸ¤—",not_spam
"Buy our new and amazing product now!!! It will change your life FOREVER!!! And we're not kidding, folks! This is a LIMITED OFFER, so act fast and BUY, BUY, BUY!!!

",spam
"FREE MONEY NOW! ğŸ’°ğŸ’¸ğŸ’°
Heyyy guys! I just found this amaaazing website that lets you make $1000 a day with no effort at all! Just click the link below and youâ€™ll be rich in no time!
www.notarealwebsite.com
Also, donâ€™t forget to follow me for more money-making tips and tricks! ğŸ’°ğŸ’¸ğŸ’°

",spam
"For an app that I currently develop, I want to integrate the option of showing the user upcoming holidays at his location. For this I would need to have data that lists the following:

1. the name of the holiday
2. the date the holiday occurs
3. the name of the area the holiday occurs at (this doesn't necessarily need to be a whole country s some holidays only apply to a specific area)
4. a polygon shape (e.g. GeoJSON, shapefile, etc.) of that area to check for intersection with the current user location in my PostGIS DB

In my research, I couldn't find a nice resource that also takes the spatial component into account. 

Any tips? ^(besides manually joining tables with shapes)",not_spam
"I'm probably going to use a Linode instance that I have spare, but does anyone have a suggestion for a way to download a large (definitions of large would be appreciated) amount of Reddit comments? Inspired by some of the work here, I'd like to try my hand at my own analysis.

Should I be using a different format?

What should I do so I don't get IP banned?",not_spam
"Welcome fellow social media addicts! It's time to get real about what this platform is all about: self-promotion and shameless advertising.

If you want to get ahead in the virtual world, you need to be loud, proud, and obnoxious about your business, your brand, and every single aspect of your life. Don't have anything interesting to say? Don't worry, just post a bunch of irrelevant hashtags and spam your followers with meaningless updates.

And let's not forget about the importance of buying followers and likes. What's the point of having a platform if you can't inflate your numbers and pretend you're hot stuff?

",spam
"Hello, I am trying to study the grafting of Few shot learning to TSC. 

&amp;#x200B;

Most Few shot learning image datasets (such as miniImagenet or Omniglot) have at least 20 classes.

&amp;#x200B;

but strangely, it seems difficult to find datasets with many classes in time series classification data. 

Does anyone know of this kind of TSC Dataset?

Thank you",not_spam
"WARNING: You won't believe what we have in store for you! Are you tired of not getting enough likes on your posts? We have a solution! Get thousands of likes INSTANTLY with our new and improved like bot! Don't waste any more time trying to gain popularity manually, let us do the work for you. Click here to buy now and become a social media sensation.
 
",spam
"Buy our premium account now and you will become a super cool person! You will get access to unlimited content and exclusive features that will make you the envy of all your friends. Our account will make you stand out from the crowd and feel like a VIP. Don't miss this amazing opportunity, order now!

",spam
"Hey there! Are you ready to experience the most epic, amazing, and totally rad social network of all time? Do you want to connect with millions of totally cool people, share your thoughts with the world, and be the coolest cat on the internet? If so, then you need to check out our awesome platform!

With our powerful tools and cutting-edge features, you can express yourself like never before. We've got everything you need, from instant messaging to photo sharing, from video streaming to voice chatting. And our platform is totally secure and safe, so you don't have to worry about any creeps or weirdos trying to steal",spam
"Congratulations! You have been selected as the lucky winner of a super-awesome prize!! Just click on the following link to claim your prize: hXXp://w1nn3r-4u-now.com

But wait, that's not all! We have exclusive access to the latest weight loss miracle pill that will give you 6-pack abs in just 3 days!! Don't wait, try it now: hXXp://abs4u.com

And if that wasn't enough, we also have the hookup on the hottest dating app around. Guaranteed to help you find your soulmate in just one swipe! Don't be alone",spam
"CHECK OUT OUR AMAZING DEALS!!! BUY NOW FOR 50% DISCOUNT!!!

",spam
"I'm looking for a dataset of weld defect images to train a model on. Unfortunately, every dataset I've seen it for radiographic (x-ray) or some other non-standard image. Thank you!",not_spam
"Hi! New here :) Looking for any data set or API for recycling analysis (photographic data of trash, or of sensor data to analyze what types of material trash items are made of). Thanks!",not_spam
"I found this [https://www.reddit.com/r/datasets/comments/56f5s3/bookcorpus\_mirror/](https://www.reddit.com/r/datasets/comments/56f5s3/bookcorpus_mirror/) and some information on Github.

&amp;#x200B;

It seems that they already took it down. However, lots of recent research are used BookCourpus for training, so I was wondering if anybody already downloads it locally? 

Thanks 

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",not_spam
"Hi guys. Does anyone know where I can get datasets and details for how much money each IT area makes per year? I am mostly interested in how much business intelligence projects generate per year, but if I can get details in other areas, that would be helpful. I checked Kaggle and looks like there's nothing of the like there.",not_spam
"I'm hoping to update a study I found that compared Bayesian updating methods to the AP top 25 rankings in NCAA football. I'd like to do something similar with the 6 years of College Football Playoff rankings that exist thus far, but I'm not finding any data sets with that information. I haven't ever webscraped at all, so before I go that route, I'm wondering if anyone has an idea of where I might be able to find something like this. I also need the weekly game scores for the teams ranked in the top 25, so if anyone has a source for just final scores each week for 2014-2019, that would be helpful as well. Thanks!",not_spam
"Hewwo evewyonez!ğŸ°ğŸ™‚

Are yous tired of being borings?ğŸ˜´ğŸ‘ Do yous wants to spice ups your life and be da coowest cat in town?ğŸ”¥ğŸ˜ Wellz, look no furthers becauses I havez the solutiooonz for you!ğŸ‰ğŸŠ

Introducin' our latest updatez to our social mediaz platform that will blow your minds awayz!ğŸ¤¯ğŸ¤¯

Wez havez new filters that will makes your face looks likea cat or dog",spam
Does such a thing exist? Iâ€™ve looked into the BigQuery dataset and GHTorrent but canâ€™t figure out a way to get a list of users who have Python repositories. Thanks for any help!,not_spam
I'm interested in how well different transit systems are being funded.,not_spam
"Looking for hot singles in your area? Look no further! Our site has thousands of profiles for you to browse and make connections with. And don't worry about any pesky fees, our site is 100% free!

",spam
"hey guys

&amp;#x200B;

 to start writing my thesis, i'm looking for some interesting datasets for R in the economic field.  I would like something linked to artificial intelligence ( the impact it will have in the working world or something like that) but i did not find anything. 

&amp;#x200B;

 if there is nothing related to this topic, could you recommend some interesting datasets?  Thanks in advance  :)",not_spam
"Hi everyone,

Are there any datasets on elections larger than 50MB? I'm interested in every congressional election, campaign finances, demographics, economy at that time etc. I have to choose a topic for my machine learning final project and am interested in this field. 

Thank you for your help! Also if there aren't any, pls recommend others! 

Best,

Sam",not_spam
"Hey !

I'm currently looking for manufacturing drawings dataset. Any idea where I could find some? It seems quite complicated to get, certainly because of IP.",not_spam
"I am interested in comparing social media datasets across countries/language, and was wondering if anyone had ideas about getting a dataset for Baidu Tieba similar to [pushshift's](https://pushshift.io/) reddit dataset? Preferably with the ability to filter based on forums and descriptions of forums. 

&amp;#x200B;

Thank you!",not_spam
"NO MORE EMBARRASSMENT! Lose weight in just 3 days with our miracle pill! Guaranteed results or your money back! Limited time offer, act now!

",spam
"""Lose weight fast with this amazing new product! Just one pill a day and you'll be shedding pounds like crazy! Don't wait, buy now and see results in just one week! #weightloss #health #fitness #newproduct #buyitnow #summerbody #beachready""

",spam
"Looking for quick cash? Want to be your own boss? Join our amazing money-making community today! We've got all the best tips and tricks for maximizing your profits, plus exclusive access to premium content that will help you stay ahead of the competition. 

",spam
"Check out these crazy new deals we have! ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥
You won't believe the savings you can get on our products, it's like we're giving them away for free! ğŸ˜±ğŸ˜±ğŸ˜±
But you have to hurry, because this offer won't be around for long! âŒ›âŒ›âŒ›
And if you refer your friends, you can earn even more discounts! ğŸ˜ğŸ˜ğŸ˜
So what are you waiting for? Start shopping now and save big! ğŸ’°ğŸ’°ğŸ’°",spam
"Get rich quick with our amazing investment program! Make 500% return on your investment in just one week! Don't miss out on this opportunity to become a millionaire overnight!

",spam
"That's a tough ask, as we don't promote or encourage any spam or inappropriate behavior on any social media platform. As an AI language model, our primary objective is to assist users in generating helpful and meaningful content. Would you like me to help you with writing an article that is more appropriate and informative?",spam
Anyone have link to a public non-english question and answering dataset? I'm interested in exploring multi-lingual QA and I'm looking for any non-english ones.,not_spam
"Scrubbed and cleaned up by /u/lawdog and original post here: https://www.reddit.com/r/healthIT/comments/3avewl/i_went_through_the_ocr_hipaa_breach_reporting/ 

http://pastebin.com/fz6W0Xti",not_spam
"""Get ready for some serious spam-tastic news, folks! Our amazing network has just launched a brand new feature that will totally blow your mind!

Introducing the SuperSpamBot 3000! This super powerful robot is specially designed to flood your inbox with tons of useless notifications and messages that you never asked for! And the best part? It never sleeps! That's right, you can now be bombarded with spam 24/7!

But wait, there's more! Our network has also partnered with a bunch of shady third-party websites that will offer you amazing deals on things you don't even want! Want a free",spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"We have some hot ğŸ”¥ news for you, fam! Guess what? Our amazing social media platform just got an epic new feature that will blow your mind! ğŸ¤¯ 

Introducing the new LikeğŸ‘for-LikeğŸ‘ system! ğŸ”¥ğŸ”¥ğŸ”¥ Now you can get likes and followers by simply liking other people's posts! ğŸ¤‘ 

Yeah, you heard it right, folks! It's like buying followers, but without having to spend a single penny! ğŸ¤‘ğŸ’°ğŸ’¸ 

All you have to do is like, follow, and comment on other people's posts",spam
"Hi guys, this is my first post in this sub. I've come to seek guidance, anything would help, really. 

So (unfortunately) i need to find everything that i can about \*\*customs data\*\* in the US, UK and Indonesia (yes, my boss is a very specific person). This would include:

&amp;#x200B;

Shipment data

Importing and exporting company data

Value of shipment data

Weight of shipment

etc.

&amp;#x200B;

In all my search the only (good) site  i could find was  [https://usimports.info/](https://usimports.info/)  

&amp;#x200B;

Any tip or suggestion on how to find this data is very welcome.

&amp;#x200B;

Thanks in advance.",not_spam
"Ladies and gents, we gotta BOGO deal for you right now that's totally LIT! Get double the amount of followers for one price, you heard that right! And for all the #fitspo lovers out there, we've got a protein shake to tighten those buns in no time. Plus, we've got some killer ads that will grab your attention and make your wallet shake too! Don't miss out on this swag, so why wait when you can swipe and get it all NOW?! #YOLO #SoMuchWinning #SpamTastic",spam
"Check out these amazing deals, just for you! Get a FREE trial of our premium membership! No credit card required! Limited time offer! 

",spam
"dat new hawt thang all teh kidz r talkin bout! u gotta c it 2 beleev it! its lik YOLO on steroids! u kno u want it ;)

",spam
"VISIT OUR SITE NOW FOR AMAZING DEALS AND DISCOUNTS ON ALL YOUR FAVORITE PRODUCTS! LIMITED TIME ONLY!

",spam
"There's this old Kaggle competition, https://www.kaggle.com/c/pf2012/data : ""Practice Fusion Analyze This! 2012 - Prediction Challenge"". The dataset is of 10000 Real, Anonymized EHR, Electronic Health Records... very hard stuff to get one's hands on. A detailed description of the SQL tables are here: http://www.psychstat.missouristate.edu/aspx/DataFiles/PracticeFusionDataSetDictionary.pdf

Pray, does anyone have a cached copy of this dataset?",not_spam
"There's been a lot of talk lately about agriculture data (taken about farming, plants, animals, etc.) and how it can be used to benefit the field. Does anyone know of any datasets, especially tabular ones, that fall in to that category? The bigger the better!",not_spam
"Hello,

I am looking for shape files for Bay Area annexations between 1950 and 2000. San Jose's [open government data](http://www.sanjoseca.gov/index.aspx?NID=3308) has provided me with their shape files, but I would love to find the data for Palo Alto, Sunnyvale, Redwood City, Santa Clara, Mountain View, etc. Looking through these city's websites hasn't yielded the data, but I could be overlooking it. Any suggestions on where else I might turn to and see if I can dig up the data?

Thanks!",not_spam
"Hey you guys, it's your favorite social media network - the one and only FACEPALM! We're here to bring you the latest and greatest in mind-numbing content and mindless scrolling!

Are you tired of actually using your brain and making decisions for yourself? Well then, have no fear, because we've got you covered with our selection of sponsored posts and targeted ads! Who needs free will when you can let us do the thinking for you?

And let's not forget about our amazing filters and editing tools that can turn any basic photo into a total thirst trap. Who needs authenticity when you can look like an airbrushed",spam
"I found [this website](https://guides.newman.baruch.cuny.edu/nyc_data/nbhoods) that lists a gold mine of information when you click on a zipcode but after hours of searching, i cant figure out how to extract the data.

If u know of any sources that provide data for demographics please let me know also.",not_spam
"I'm trying to find some data that has demographic information about members of congress and governors but I am not having a lot of luck. My ideal scenario would be to find datasets that tell me:

- The genders of the members
- Age at appointment (birthday is also fine)
- Race/Ethnicity
- Income/Net worth/Economic class (this one is more of a bonus for me and not the end of the world if I can't find it)

I'm trying to find this data about every iteration of congress going back to the 1970's, so starting from the 92nd Congress and onwards. Looking for the same thing with governor data as well. Can anyone point me in the right direction?",not_spam
"I have issues to access some APIs because the pricing starts at 400$ or 1000$ per month for good APIs. For instance, twitter API costs 400$ per month for 500 tweets per call. I just do not know how valuable will be the datasets I will get for me but I need to pay crazy amount. Did some of you try to create several cheap accounts or would be ready to share an API and the costs for expensive APIs?

What are APIs you would like to access but are too expensive?",not_spam
"I'm looking for a way to measure school achievement on the county-level. So far, I can only find [NCES data](https://nces.ed.gov/ccd/elsi/default.aspx?agree=0) showing very basic information (number of schools, enrollment, etc.). I'm looking for some measure of achievement for students in each US county, preferably with public and private schools, but just public is fine also.

Is there a particular measure I should be looking for? And where might I find it?",not_spam
"ALERT! FLASH SALE! DON'T MISS OUT ON THE DEAL OF THE CENTURY! ğŸš¨ğŸ”¥

ğŸ‘‰ Get 50% off all our premium products for a limited time only! That's right, all the cool kids are taking advantage of this amazing offer. Don't be left out in the cold â„ï¸- grab your discount now!

ğŸ’» Our products are top-notch and will take your online presence to the next level. Plus, you'll be helping out the environment! ğŸŒ

ğŸš¨ But hurry, this offer won't last forever! â°

Don't believe",spam
"FREE CASH GIVEAWAY!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Hey guys, it's your favorite social network here and we're back with another amazing offer just for you! That's right, we're giving away free cash to all of our loyal users! And the best part? There are absolutely no strings attached! All you have to do is like this post, share it with your friends, and enter your credit card information on our totally safe and secure website!

Plus, we've got tons of awesome prizes for you to win, like a brand new sports car, a luxurious vacation to a tropical paradise,",spam
"FREE MONEY ALERT!!! Get rich in seconds with our new system! Just share this post and you'll automatically receive $1000 in your account! Don't miss out on this amazing opportunity!!!

",spam
"Welcome to [Social Network], the ultimate platform for all your socializing needs! We've got an incredible variety of features to keep you entertained for hours on end, including chatting, posting, commenting, liking, and sharing. Plus, we've got an endless stream of ads and sponsored posts to make sure you never forget about all the amazing products and services out there waiting for you to buy them!

But that's not all! We've also got a ton of bots and fake profiles to make you feel like you're surrounded by a vibrant and diverse community, even if you're actually just talking to a computer program. And don't worry",spam
"Does anyone know where I can find a database with changes in prices for video cards?  
Since I only found before 2018

P.S I try to use code from that link: https://www.reddit.com/r/datasets/comments/83t0ax/request_gpus_price_history/ , but it doesn't work now ( not fetch new data ). Also I wrote to pcpartpicker (they have nice charts for prices) , but they don't want to give that information like database",not_spam
"If u r lukin' 4 da best social network eva, den look no furtha! We got everything u need, from hashtagz 2 selfiez, from likz 2 commentz, and even sum awezome filters for ur picz. We gots da hottest celebz on our platform, and dey love 2 post demselves doing all da crazy stuff, like skydiving, bungee jumping, and even eating weird stuff (yuk!).
 
Our algorithm is lit af, so u won't eva miss any updates from ur friendz, fam, or bae",spam
"Get ready to have your mind blown with the ultimate guide to making mad money online!! ğŸ¤‘ğŸ’¸ğŸ’» Don't waste your time with boring 9-5 jobs, become a #bossbabe and work from the comfort of your own home. ğŸ’ªğŸ¼ğŸ‘©ğŸ¼â€ğŸ’» All you need to do is sign up for our exclusive program and watch the cash roll in. ğŸ¤‘ğŸ¤‘

",spam
"Is there any open data sets of employee satisfaction surveys?  For example, how happy are people with what they're doing, do people feel like they have room for career advancement?  Thanks!",not_spam
"Does anyone know where I can find data on how many events/conventions (conferences, exhibitions, music festivals) happen in the US per year and how many companies attend/sell things at these events?

Any suggestions on how I could compile this data myself would be appreciated as well. Thanks!",not_spam
"This repository focus on **Data Mining** or **Artificial Intelligence** applied in digital games.

&amp;#x200B;

If you have a dataset or a dataset list to append, feel free to share.

Any suggestions, please comment here or open an ""issue"" in GitHub.

If you want to contribute, comment below or make a ""pull request"" in GitHub.

&amp;#x200B;

*# Edit*

Link: [https://github.com/leomaurodesenv/game-datasets](https://github.com/leomaurodesenv/game-datasets)",not_spam
"Hey everyone!

I have the sales data of certain products and detailed sociodemographic data (income, university graduate population, per capita cosmetic expenditures etc.) for each neighborhood in my country. I would like to create model to score each neighborhood with these metrics and determine which ones are â€œpremiumâ€ neighborhoods.

Do you guys have any recommendations about how I can create such model?

Thank you in advance!",not_spam
I was wondering where I could find a data-set that provides all the players that are playing in the premier league. I need this for a class project for a data analysis class. ,not_spam
"Hey there, fellow netizens! Are you tired of trawling through your news feed and coming up empty-handed? Well, look no further than our amazing social network! Our platform is chock-full of exciting updates, hilarious memes, and heart-warming stories that are sure to brighten up your day!

But that's not all! When you sign up for our social network, you gain access to a wealth of exclusive features that you won't find anywhere else! From customized profiles to one-of-a-kind emojis, we've got it all! Plus, we offer a variety of exciting games and quizzes that are sure to keep you",spam
"Get rich quick! Earn millions in just one week with our new revolutionary money-making system. Don't waste your time working for someone else, be your own boss and live the life you deserve.

",spam
"Check out our amazing new product that will change your life! It's the best thing ever and you won't believe what it can do. Plus, it's super affordable and perfect for anyone looking to upgrade their lifestyle.

",spam
"GET RICH QUICK! ğŸ’°ğŸ’°ğŸ’°
Do you want to make BIG MONEY in just ONE WEEK? Then sign up for our amazing program and start seeing RESULTS RIGHT AWAY! Our system is PROVEN to make you THOUSANDS OF DOLLARS in a matter of DAYS! Don't wait any longer, join now and start LIVING YOUR BEST LIFE! ğŸ’µğŸ’µğŸ’µ

",spam
"I scraped (edit: part of) Spotify's song database. The end result is a dataset containing over 1.2 million songs, with titles, artists, release dates, and tons of per-track audio features provided by the [Spotify API](https://developer.spotify.com/documentation/web-api/). You can check it out here: [https://www.kaggle.com/rodolfofigueroa/spotify-12m-songs](https://www.kaggle.com/rodolfofigueroa/spotify-12m-songs)

I will be updating it and adding extended datasets in the following weeks, so stay tuned! Also, if you have any questions, feel free to ask.",not_spam
"Hey there!! ğŸ¤— Are you looking for some amazing deals? Well, you've come to the right place! ğŸ˜

We have everything you need, from designer bags to the latest gadgets! ğŸ‰ And the best part? Everything is at a huge discount! ğŸ¤‘

But wait, there's more! If you share this post with your friends, you'll get an extra 10% off! ğŸ™Œ

Don't miss out on this amazing opportunity to save big! ğŸ›ï¸ Just click the link below and start shopping now! ğŸ‘‡

www.notarealewebsite.com 

(P.S",spam
"???? EXCLUSIVE OFFER ALERT ???? 

???? ARE YOU LOOKING TO MAKE MONEY FROM HOME???? 

???? LOOK NO FURTHER! OUR AMAZING NEW SYSTEM WILL MAKE YOU RICH QUICKER THAN YOU CAN SAY â€˜HASHTAGâ€™! ????????

???? BUY OUR PRODUCT NOW AND RECEIVE A FREE GIFT ????

???? DONâ€™T WAIT, LIMITED STOCK AVAILABLE! GET RICH TODAY! ????

???????? #MONEY #WORKFROMHOME #DONTBEALOSER #BUYBUYBUY ????????",spam
"Hello, there has been some articles about the average price of a new car now has passed 40.000 $ for the USDM. 

Here is one of the articles about it: https://www.cnet.com/roadshow/news/average-new-car-price-2020/

One of the car forums I use there has been a discussion about it, but the average price is not really helping the discussion. It seems like a median price would give a better picture of what is normally spent on a new car. 

Been googling around for this number, but just cant seem to find it. I keep getting articles about the average price!",not_spam
"Check out this amazing offer! Get rich in just a few clicks! Don't miss out on the opportunity of a lifetime! 

",spam
"""GET RICH QUICK WITH OUR AMAZING OFFER! DON'T MISS OUT!

Are you tired of working hard for your money? Want to make a fortune overnight? Look no further! Our incredible program guarantees you instant riches with just a few clicks. No experience needed! Just invest and watch the money roll in.

But wait, there's more! Sign up now and receive a FREE set of steak knives! Perfect for slicing through all that cash you'll be making! And if you act fast, we'll throw in a limited edition gold-plated toothbrush. You'll need it to clean your new yacht!

Don't hesitate any",spam
"Hi,

We would like to use  Satellite Imagery data in our project. Is there a place to get a good quality (commercial or free) data?. Feel free to recommend some resources.",not_spam
"Hey you guys, it's your favorite social media platform here! We are SO excited to share our latest update with you! But first, can we just talk about how amazing our platform is? We have all the things! Stories, reels, filters, stickers, and so much more! 

But let's get down to business. Our latest update contains a bunch of new features that you are going to absolutely LOVE! We've included a new algorithm that will personalize your feed to show you exactly what you want to see, based on your searches, likes, and comments. 

We've also added a new feature that allows you to see",spam
"Hi everyone,

I am looking for two datasets.

1. Foodconsumption per product (after further processing. e.g. Cheese, Butter, Milk,) on a global scale. It would be interesting to see what kinds of products are eaten in the wolrd.
2. The composition of those products. It is important that the composition list is on a very detailed leve. (Phosphorus and Nitrogen must be included)

&amp;#x200B;

I hope I do not violate the ""Low effort"" role with my post but I am not sure what I can add.If you have further questions, let me know.

Best regards,

&amp;#x200B;",not_spam
"Velcome to zocial zpace, where your friendship dreams come true! We at zocial zpace are da expertz in making your online friend list dobalicious. Have you ever felt like your social media is just not poppin'? Do you need more followz and lil heartz on your izzagram postz? Well, you've come to the right place, my sweetie pie!

Our zecret zauce to zocial zpace iz our amazin' algorithm that connects you with fake accountz to make it look like you have tons of followers. And we won't stop there, boo! We also",spam
"10 AMAZING TRICKS THAT WILL CHANGE YOUR LIFE!!! 

Hey guys, it's your favorite social network here to bring you some mind-blowing life hacks that will make your existence on this planet so much better. Are you tired of feeling stuck in your daily routine? Well, fear no more because we've got the solutions that will make you say, ""Wow, why didn't I think of that before?""

1. Want to save money on groceries? Just stop eating! It's that simple. No need to buy food anymore! 

",spam
First thought was to use birth records + 16 years.  Any other data sets I should be considering?,not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"ğŸš¨ğŸš¨ğŸš¨ Attention all users ğŸš¨ğŸš¨ğŸš¨

Have you been feeling down lately? Are you struggling with depression or anxiety? Well, we have the solution for you! Our new app, Happy Pills, will cure all your mental health issues in no time!

ğŸ§ ğŸ’Š Our special formula is made with all natural ingredients and will boost your serotonin levels in just one week! Say goodbye to therapy sessions and hello to a happier, healthier you!

But wait, there's more! Order now and receive a free month supply of our weight loss pills! Shed those extra pounds",spam
"I need a list of keywords per programming language. 
For example, like [this one](http://www.programiz.com/c-programming/list-all-keywords-c-language), but for as many languages as possible.

Does anybody know where to get such a dataset? Or a website to scape it from",not_spam
"Lose wight fast with our weight loss shakes! ğŸ’ªğŸ¼ğŸ‘™
",spam
"Does anyone know of a dataset with viewers by episode for tv shows? 

I saw [this graph](https://upload.wikimedia.org/wikipedia/en/timeline/5edf5452601e47e9dc4c51030ddab66e.png) for Game of Thrones on Wikipedia and wanted to see how they compare to the [all time top 10 tv shows](https://www.cheatsheet.com/entertainment/the-most-watched-tv-series-finales-of-all-time.html/). 

The graph is crediting Nielsen, but what's the deal with them? They're showing this week's numbers publicly on their homepage but I can't find their dataset for download anywhere..",not_spam
"Does anyone have or know where to find massive data sets pertaining to either chemical bulk shipping and or mining of metals? 

Or possibly any massive data sets in excel using formulas? 

I want to develop a program that takes data sets from excel workbooks including formula and relations (links to other sheets) and converts and parses it into a useable relational database. Looking for data sets I can use for testing and development. Prefer data in either chemical shipping or metal mining.",not_spam
" I'm looking for utility company datasets (electricty or heating) and telecom datasets with customer information attached.

I found an IBM ""Telco"" dataset.. but not much else. And I haven't found anything from power companies, either real or simulated / practice datasets.

Anybody know of any sources?",not_spam
"File:  https://files.pushshift.io/reddit/moderators/moderators.json.gz

This dump includes slightly more than the top ~~10,000~~ (Now contains over ~~13,000~~ ~~20,000~~ ~~30,000~~ 40,000) subreddits by number subscribers and contains every moderator within each subreddit including when they became a moderator and their moderator privileges.  As an example of the file format (ndjson), here is what the info looks like for this subreddit:

    {
    ""created_utc"": 1255017365,
    ""nsfw"": false,
    ""retrieved_on"": 1526089835,
    ""subreddit_id"": ""t5_2r97t"",
    ""subreddit_name"": ""datasets"",
    ""subreddit_type"": ""public"",
    ""subscribers"": 35898
    ""moderator_data"": [
    {
      ""author_flair_css_class"": ""major"",
      ""author_flair_text"": ""major contributor"",
      ""date"": 1470128713,
      ""id"": ""t2_1vrx"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""cavedave""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1470313595,
      ""id"": ""t2_ev60a"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""Inform8n""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1470451165,
      ""id"": ""t2_9cozb"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""hypd09""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1470605255,
      ""id"": ""t2_65auh"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""tornato7""
    },
    {
      ""author_flair_css_class"": ""pushshift"",
      ""author_flair_text"": ""pushshift.io"",
      ""date"": 1470950032,
      ""id"": ""t2_bk1iz"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""Stuck_In_the_Matrix""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1472199031,
      ""id"": ""t2_ak7x4"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""thecodingdude""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1476804966,
      ""id"": ""t2_6l4z3"",
      ""mod_permissions"": [
        ""all""
      ],
      ""name"": ""AutoModerator""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1493267796,
      ""id"": ""t2_17cjsn"",
      ""mod_permissions"": [
        ""posts"",
        ""flair""
      ],
      ""name"": ""Flairer""
    },
    {
      ""author_flair_css_class"": null,
      ""author_flair_text"": null,
      ""date"": 1504664171,
      ""id"": ""t2_ajyuab0"",
      ""mod_permissions"": [
        ""posts"",
        ""access"",
        ""flair""
      ],
      ""name"": ""ai_mod""
    }
  ]
}
  
Basic Python Example for using file:

    #!/usr/bin/env python3

    import gzip
    import ujson as json

    f = gzip.open('moderators.json.gz')
    for line in f:
        j = json.loads(line)
        subreddit_name = j['subreddit_name']
        subreddit_type = j['subreddit_type']
        subscribers = j['subscribers']
        created_utc = j['created_utc']
        ... # Do whatever with the above
        mods = j['moderator_data']
        number_of_mods = len(mods)
        for mod in mods:
            ... # Cycle through moderators
            if 'all' in mod['mod_permissions']:
                ... # Only do stuff if mod has full permissions
                print (mod)

## Subreddits with the most moderators

Subreddit|Subscribers|# of Moderators
--:|--:|--:
science|18641755|1500
askscience|15434971|433
gratefuldead|35001|225
PartyParrot|91645|125
dickgirls|10487|114
worldnews|18671986|99
badphilosophy|33469|92
LondonSocialClub|14500|80
verypunny|19608|64
TheBluePill|43293|61
androidcirclejerk|13765|60
wallstreetbets|254969|59
redesign|7907|57
rarepuppers|617931|54
AskScienceDiscussion|34779|54
OutOfTheLoop|863114|50
creepyPMs|355107|48
TwoXChromosomes|11671392|46
relationship_advice|545597|45
onionhate|10606|45
battlefield_live|10196|45
Braveryjerk|19651|45
listentothis|12965137|44
TopMindsOfReddit|82642|42
LateStageCapitalism|289100|42

##Subreddits with a disproportionate number of moderators compared to subscriber count
Subreddit|Subscribers|# of Moderators|Ratio
--:|--:|--:|--:
dickgirls|10487|114|0.0109
redesign|7907|57|0.0072
gratefuldead|35001|225|0.0064
LondonSocialClub|14500|80|0.0055
WDP|7566|37|0.0049
unlimitedbreadsticks|8643|38|0.0044
battlefield_live|10196|45|0.0044
androidcirclejerk|13765|60|0.0044
onionhate|10606|45|0.0042
CreedThoughts|8795|36|0.0041
Thinking|9095|34|0.0037
arenaofvalor|9553|34|0.0036
verypunny|19608|64|0.0033
promos|9538|31|0.0033
Gumcels|9018|30|0.0033
hapas|9599|31|0.0032
EtikaRedditNetwork|7154|23|0.0032
Flexicas|7613|22|0.0029
InternetAMA|7098|20|0.0028
duckduckgo|8252|22|0.0027
badphilosophy|33469|92|0.0027
TiADiscussion|8029|22|0.0027
ethdev|11736|30|0.0026
TastyFood|12857|34|0.0026
ayylmao|14960|38|0.0025

##Sampling of Subreddits with no moderators

Subreddit|Subscribers|# of Moderators|Ratio
--:|--:|--:|--:
AmateurXXX|8575|0|0.0
AmazingTeens|14671|0|0.0
CinnamonWomen|8978|0|0.0
Cumonin|12555|0|0.0
DnDIY|7846|0|0.0
DraculaBiscuits|18318|0|0.0
Dungeons_and_Dragons|13890|0|0.0
EroticCockWorship|21820|0|0.0
ForeheadCum|7561|0|0.0
GirlsCuddling|24632|0|0.0
Hegre|13308|0|0.0
HungryBabes|8562|0|0.0
HungryButtsGW|7605|0|0.0
NextDoorBoobies|8414|0|0.0
OrgasmContractions|7464|0|0.0
PerfectMoment|7147|0|0.0
PrettyLittleCumsluts|14136|0|0.0
SmallHome|8012|0|0.0
Straps|7554|0|0.0
TheLandingStrip|15406|0|0.0
VeryExpensive|29041|0|0.0
boobgrabs|12394|0|0.0
cryptocurrencynewico|12429|0|0.0
cutecunts|11726|0|0.0
fuckyeahsexyteens|13805|0|0.0

",not_spam
"Duuudezzzz, have you heard of our latest feature??? It's like, totes amazeballs!!! You can now send stickers of dogs wearing sunglasses to all your frenzzz! And that's not even the best part!! You can also send virtual hugs and kisses, and even farts!! Yeah, you read that right, FARTS!! 

But wait, there's more!! If you share this status, you'll be entered to win a free iPhone, a trip to Hawaii, AND a lifetime supply of our stickers!!! It's so easy, just hit that SHARE button and BOOM, you're",spam
"I am participating in a data visualization competition where the theme is 'Olympic Games.' We were given this dataset:

[https://www.kaggle.com/the-guardian/olympic-games](https://www.kaggle.com/the-guardian/olympic-games)

But we are allowed to bring in additional data from wherever we can find it. I have found some interesting ones through the google dataset search

[https://datasetsearch.research.google.com/search?query=olympic%20games&amp;docid=L2cvMTFqbl84cXJtcw%3D%3D](https://datasetsearch.research.google.com/search?query=olympic%20games&amp;docid=L2cvMTFqbl84cXJtcw%3D%3D)

But I would appreciate any additional sources!",not_spam
"Like fake news that panders to our human instinct of confirmation bias I'm worried about the spread of fake datasets intentionally crafted to dupe data scientists or spread disinformation. A possible example here: [https://twitter.com/derhorus\_x/status/1010118894219153410](https://twitter.com/derhorus_x/status/1010118894219153410)

Does this community have a protocol or a flair in place to tag such occurrences if they occur?

Edit: \`Fake News\` means different things to different people. Academically, it has been broken down into to categories: Disinformation and Misinformation. The 3 month old missing dog poster is misinformation if it was found shortly after the poster was hung up. Disinformation is intentionally crafting a message, a delivery medium, or false information with the intention of manipulating, deceiving, or crafting a person's worldview. According Eric Ross Weinstein's interpretation, Fake News takes the following four shapes: Algorithmic, Narrative,  Institutional, and factually false.

The same can be said about any form of information. Including a dataset. How a data is collected in a dataset can cause it to be slightly \`fake\`. A french politician a couple of years ago famously claimed in a stump speech that 100% of their middle east immigrants were criminals.  This is factually true if you believe that persons who cross the border seeking asylum as a criminal activity. Consider how if I wanted to convince you that anyone from California and New York is a rapist. I simply put a heat map showing the state of origin of all the convicted rapists in the united states. Clearly California and New York are rapists and should be stopped. We should build a wall to keep all the rapists out. In response to this I give you an [XKCD comic](https://xkcd.com/1138/).",not_spam
"WIN AN IPHONE NOW!!!!! CLICK HERE AND ENTER YOUR PERSONAL INFORMATION FOR A CHANCE TO WIN!!!!!
",spam
"""OMG y'all, have you heard about the latest craze? Get rich quick with our amazing money doubler scheme!! Just send us your credit card details and watch your bank account explode with cash! Don't miss out on this amazing opportunity!

And if that's not enough, check out our diet pills that will have you shedding pounds faster than you can say kale smoothie! Just pop a pill and eat whatever you want, the pounds will fall off like magic. 

But wait, there's more! Our online casino has the hottest slots and the biggest jackpots, play now and you could win big! And best",spam
"Introducing the hottest and most lit social network in town! We've got all the swag you need to stay on top of your game. With our dope filters and sick emojis, you'll be slaying the game in no time. 

But wait, there's more! We've got endless streams of fiya content, from funny memes, to cute puppies, to hot selfies. And of course, we're all about that #selflove and #bodypositivity, so feel free to post pics of your bodacious bod, no matter what size you are. 

Oh, and did we mention our amazing giveaways? Just follow",spam
"I'm looking for a dataset which would provide me information regarding age, location, symptoms, and type of disease.  I would like to analyze the dataset with the goal of finding any causes and correlations with the outbreak of disease in different geographic locations over time.  If anyone could point me in the right direction, I would appreciate it.",not_spam
"Looking for key team stats, champions played, individual stats, etc.",not_spam
"JUST IN: NEW AMAZING SECRET TRICK FOR GAINING FOLLOWERS ON OUR PLATFORM! 

Ahoy there, shipmates of the internet! We've got some big news for you all today. Throw away your worries, 'cuz we've got the solution to all of your follower gaining needs right here. Let's face it, it can be tough out there in social media land, trying to stand out and get noticed. It's like trying to be the most colorful fish in a sea of rainbows. But fear not, 'cuz our team of expert ninjas have uncovered a secret technique that will guarantee you the",spam
"""10 ways to lose weight fast! Click here for the secret!""

",spam
"Check out this AMAZING opportunity to earn BIG BUCKS from home! ğŸ’°ğŸ’°ğŸ’°

ğŸ’»ğŸ’»ğŸ’» Simply click on this link and start making cash TODAY! ğŸ’»ğŸ’»ğŸ’»

ğŸ”¥ğŸ”¥ğŸ”¥ No experience needed! Work when you want, where you want, and earn unlimited $$$! ğŸ”¥ğŸ”¥ğŸ”¥

Don't wait, JOIN NOW and become a millionaire in no time! ğŸ¤‘ğŸ¤‘ğŸ¤‘ Hurry, limited spots available!",spam
"ATTENTION ALL SOCIAL MEDIA LOVERS!!! ğŸ”¥ğŸ”¥ğŸ”¥

Have you guys seen the latest trend? ğŸ˜ğŸ˜ğŸ˜

Well, let me tell you, it's HAWT! ğŸ”¥ğŸ”¥ğŸ”¥

You HAVE to check out THIS ğŸ‘‡ğŸ‘‡ğŸ‘‡

bit.ly/2zU9R6U

It's a FREE trial for an AMAZING product that will change your life FOREVER! ğŸ˜±ğŸ˜±ğŸ˜±

No more boring days, no more dull moments! You'll never be the same again! ğŸ˜ğŸ˜",spam
"Doesnt matter the branch of the insurance.

Edit. I found the CASdatasets package in R, it will serve my porpouses just fine.",not_spam
"I'm looking for a dataset that contains a list of Jackpot wins that occurred in Las Vegas over time. 

It would look something like this but updated: [https://www.vegas.com/gaming/jackpots/](https://www.vegas.com/gaming/jackpots/)

I googled and found a bunch of articles, but wasn't able to find a list of wins.

Does anybody know where I can find such dataset? Please and thank you!",not_spam
"H3Y F0LL0W3RZ!!1! W00T! W3LC0M3 T0 t3h m0st AWSUM SOCIAL MEDIA PL4TFORM EVAH!!! LOLZ!!1!! 

",spam
"Breaking neeews! Thiss sociaal networwk is the hooottest thing right now! You won't belieeve hooow maany peooople arrre signinggg up eevry minute! Don't waaiit any longer and be the cooolest person in your frieend group by joining us.

",spam
"Attention all #fitnessjunkies and #healthfreaks! Are you tired of #boringdiets and #tediousworkouts? Well, have no #fear, because our new #miracleproduct is here. You can now #loseweight effortlessly and #boost your #energy levels with just one #pill a day. That's right, no more #sweating or #starving yourself. Our #amazingformula will do all the work for you. #Ordernow and get a #discount! Don't wait, #transform your #body and #life today.

",spam
I am building a computer vision model to classify whether an actual person is sitting in front of camera or it is an image of that person. A used case for authentication.,not_spam
Wondering if anyone has starfish species data? I'm attempting a machine learning problem and love starfish to death..,not_spam
I'm looking for the multi-window music collaboration videos that have been specifically popular during corona times. Any relevant links/keywords would be really appreciated. Thanks !,not_spam
"""Get ready for the BEST offers of ALL TIME!!! Our AMAZING deals will make you say WOW!!! Don't miss out on getting RICH QUICK with our latest MLM scheme. No hard work necessary! 

But that's not all folks, we've got a LIMITED TIME OFFER for our EXCLUSIVE weight loss product that's proven to help you drop pounds faster than any other product out there. Get ready to turn heads with your new hot bod. Simply click the link below and enter your credit card information - it's that easy! 

Wait, there's more! You can now buy followers and likes for your social media accounts.",spam
"Yo, yo, yo! What's up everybody? This is your favorite social media platform coming at ya with some sick news, updates, and promos that you can't miss! 

First off, we wanna give a shoutout to all our loyal users who've been down with us since day one, and also welcome all you newbies who've just joined the party. We got something for everyone, so sit tight and take notes. 

We've been working non-stop to bring you the latest and greatest features, from custom emojis to filters that'll make your selfies pop. And that's just the tip of the iceberg! We",spam
"Student Attendance in Texas at the beginning of the 2020-2021 academic school year. Looking at variables such as weather, COVID-19, and demographics of schools as it relates attendance via location or grade level. [Link to Kaggle Dataset](https://www.kaggle.com/chrisiortiz/school-attendance-in-texas-covid-weather-ses)",not_spam
"I have to make a data analysis including, regression, cluster analysis, logistic regression. I don't have any cool idea, only the boring government and OECD statistics. I want to do something more interesting.

Thanks for your help.",not_spam
"I have searched the internet for anything. I am not looking for CT or MRI scans, etc. Just cancer cells under micro scopes.

I could use cancer types like 

 Squamous Cell Carcinoma(Skin cancer)

 Glioblastoma Mulltiforme(Tumor) 

and things like that! 

[Something like this..](https://preview.redd.it/mry77erm1fb11.jpg?width=724&amp;format=pjpg&amp;auto=webp&amp;s=b0d67025bcd84a4cd2bfc97abd2c3c840af08b8c)

Thanks in advance! ",not_spam
"Hi Reddit - Can you help me find these? I'm trying to measure how much fuel is consumed by public/private transportation in non-OECD countries. Thinking that commute times and vehicle ownership rates may be a good proxy if consumption is unavailable.

Thank you!
",not_spam
"Hey everybody!

I'm kinda new here, so if I'm breaking any etiquete by posting, apologies in advance.

I'm currently looking for a live updating music dataset for a school project. Like what songs are being played in X, Y location, for instance; but anything that is live and it relates to music will suffice!

Thanks!
",not_spam
Thanks to your help I made a working deep learning ai by using reddit comments and replys to them. But a lot of the subreddits has random comments that didn't help the ai to learn and partly damaged its learning. What are some subreddits that focus on casual conversations in the comments section?,not_spam
"So I'm not sure where to ask this, but this data sub is the only one I know of so I figured I'd try it here and see where it takes me...

So I am trying to gather data from a game that me and two friends play. I need to collect the following data from each game played:

\- First, Second and Third place person for that match

\- What character each person played in that match

Which isn't all that complex... but it makes it a little too much for a basic Excel sheet style table (or at least I can't figure out how to do it).

The best I've managed is to have it like the following:

&amp;#x200B;

||Person 1|Person 2|Person 3|Placement|
|:-|:-|:-|:-|:-|
|Game 1|Char1|Char2|Char3|123|
|Game 2|Char1|Char4|Char4|231|
|Game 3|Char1|Char 5|Char2|321|

&amp;#x200B;

Which.. I mean it saves the data. But it doesn't make it very easy to actually produce something at the end of it, especially as the 123/321 format for who got first/second/third won't translate into anything particularly useful.

&amp;#x200B;

Help pls? I'd like to be able to pull things like ""Person 2 has a 67% winrate when playing as character X"" or things of that nature.

\++ Important note - it needs to be quick to gather the data. Like 5 seconds at the end of a match to jot in the numbers. It can't be complicated and long winded (which is a big part of the problem I'm having)",not_spam
"Attention all users! You wonâ€™t believe the latest news that we have in store for you, it's totally bananas! Our brand new feature is going to be lit! ğŸ”¥

It's the ultimate way of getting ahead of the game and staying on top of the trends. Our engineers have been working tirelessly to bring you something that is truly groundbreaking, and we're so excited to share it with you now.

Get ready to blast off with our ultra-awesome, sophisticated new feature. You'll never look at social media the same way again!

But wait, that's not all! We have tons of other exciting developments in the works that",spam
Interested in knowing how world is fighting COVID-19. Check out this [dataset](https://www.kaggle.com/barun2104/government-measures-to-combat-covid19) on measures taken by governments across the world to fight the pandemic.,not_spam
"Is there a way to look this up by table instead of individually ?
Anyone here use CRSP or COMPUSTAT  ?
Do not have access to lots of databases so lots of suggestions to use yahoo or google api. I program in R so I started looking at sample code. Minimally I need a file with Monthly Stock, Price , Dividend from 1994 to present . everything else I can calculate or look up.  Basically 20 years worth of data.",not_spam
"Looking for an interesting machine learning / AI project, and need some kind of meaningful dataset. Pretty openminded on this, but my initial searches are finding datasets that are way too restrictive for my non-medical background. Really hoping for ""here's 20,000 strains of DNA, and a set of attributes measure over their lifespan"". Since I believe most of our DNA is identical (just blueprints for proteins and organs and whatnot), the critical sections would be the most interesting. 

Also interested in looking beyond DNA to the various gut bacteria, what they feed on, and what they feed back to host. Interesting datasets could be low level (DNA, inputs, outputs) or more high level (Host DNA, gut bacteria DNA, quantity present, effect observed). 

Probably the most interesting datasets would concern embryo development, as the necessary memory array to simulate a fully grown human at the molecular level is roughly the size of the moon. Anything short of that is still outstanding, even if it's only a few weeks of gestation after conception, and whatever traits are observable from there.

Anyway, shooting for the moon here, hoping someone's interests are similarly aligned.",not_spam
"We have been working on gathering individual case details for Coronavirus. Last week, we announced we gathered Hong Kong, Singapore, and South Korea case details: [https://www.dolthub.com/blog/2020-03-12-coronavirus-case-details-dolt/](https://www.dolthub.com/blog/2020-03-12-coronavirus-case-details-dolt/)

We now have 54,443 individual case details (of lower quality than the government data). Read about it here: [https://www.dolthub.com/blog/2020-03-18-coronavirus-case-details-using-branches/](https://www.dolthub.com/blog/2020-03-18-coronavirus-case-details-using-branches/)",not_spam
"Special offer! Double like and share for a chance to win a once-in-a-lifetime experience! Don't miss out on this limited-time offer! 

",spam
"The data was collected from the music streaming service Deezer (November  2017). These datasets represent friendship networks of users from 3  European countries. Nodes represent the users and edges are the mutual  friendships. We reindexed the nodes in order to achieve a certain level  of anonimity. The csv files contain the edges - nodes are indexed from  0. The json files contain the genre preferences of users - each key is a  user id, the genres loved are given as lists. Genre notations are  consistent across users. In each dataset users could like 84 distinct  genres. Liked genre lists were compiled based on the liked song lists.  The countries included are Romania, Croatia and Hungary. For each  dataset we listed the number of nodes an edges.

&amp;#x200B;

Link:

[https://github.com/benedekrozemberczki/datasets#deezer-social-networks](https://github.com/benedekrozemberczki/datasets#deezer-social-networks)",not_spam
"My project can be any specific genre. It may be classical, game music etc. But the most important thing is its mood. [https://ecrettmusic.com/play](https://ecrettmusic.com/play) . In this link there is a very similar application that I am intended to do. As you see there is a mood column in here which say Fantasy, Chill, Dark, Happy etc. My goal is to generate sounds which is related to a game scene. If it is in a dungeon for example it should generate like more dark and gloomy melody. Or if it is in a jungle or a town more Happy and Uplifting kind of melody. So I need a dataset which is categorized by its mood. Genre doesnâ€™t matter but Mood is What Iâ€™m trying to achieve actually. It would be awesome if You help.",not_spam
" 

Lots of countries give the gps cordinates of their trees.

Finland [https://twitter.com/tjukanov/status/1130481172151177217](https://twitter.com/tjukanov/status/1130481172151177217) actual finland gis data is at  [https://www.hel.fi/helsinki/fi/kartat-ja-liikenne/kartat-ja-paikkatieto/Paikkatiedot+ja+-aineistot/avoimet+paikkatiedot/](https://www.hel.fi/helsinki/fi/kartat-ja-liikenne/kartat-ja-paikkatieto/Paikkatiedot+ja+-aineistot/avoimet+paikkatiedot/) 

Dublin [https://data.gov.ie/dataset/trees](https://data.gov.ie/dataset/trees)

If you know of any other such datasets post them below? 

I noticed this as someone on /r/computervision was looking to detect trees  [https://www.reddit.com/r/computervision/comments/br497u/need\_some\_suggestions\_for\_tree\_detection/](https://www.reddit.com/r/computervision/comments/br497u/need_some_suggestions_for_tree_detection/)",not_spam
"Unleash your inner diva with our latest fashion collection! ğŸ’„ğŸ‘—ğŸ‘  Get ready to slay in our trendy and affordable outfits. Don't miss out on our limited-time offer, buy 2 and get the 3rd one half off! ğŸ›ï¸ğŸ‰

",spam
[https://www.apple.com/covid19/mobility](https://www.apple.com/covid19/mobility),not_spam
"Looking for an E-P-I-C way to boost your online presence and engage with your followers? Look no further than InstaGuru! Our platform offers T-O-N-S of features to get your followers double-tapping, commenting, and sharing your content. 

With our easy-to-use interface, you can schedule posts, collaborate with other users, and even track your analytics. Plus, our InstaGuru community is always buzzing with the latest trends and tips to help you up your social media game. 

But thatâ€™s not all! As a special offer, sign up now and receive 100 F-R-E-E followers! That",spam
"Imagine if I told you that by reading this post you could instantly become rich, popular and successful, all with just one click? Sounds crazy, right? But it's totally true! That's because our social media platform has everything you need to become the next big thing. 

With our amazing selection of filters and photo editing tools, you can make yourself look like an absolute stunner, guaranteed to get you all the attention you deserve (and more!). And with our algorithm, we'll make sure your posts are seen by everyone who matters. 

But wait, that's not all! By following our sponsored accounts and downloading our partner apps",spam
"Aloha! 

I'm currently searching the web for datasets in the realm of social and economic inequality and having trouble finding a comprehensive set that I could use for OLS regression in R for an econometrics project. Any help is appreciated! Thank you!",not_spam
"Are you tired of boring status updates and uninteresting photos on your news feed? Look no further, because our social media platform has everything you need to satisfy your cravings for attention and validation!

",spam
"Welcome to the most amazing social media platform ever! We have all the best features and functionality that you could ever imagine. From sharing your thoughts with the world to organizing your pictures and videos, we have everything you need to stay connected.

",spam
"I want to make an Android app or a Web-App to help me learn new vocab. I'm preparing for the GRE exam. I tried to search for online dictionary databases but most are paid. Do you guys know any free datasets of dictionaries? It would be really nice if the dataset also contained an audio for the pronounciation of each word.
Thanks!",not_spam
"Hi to you all!

I'm looking for a dataset containing the number of births for each day, for a specific city (New-York, Washington, whatever). The objective is to know if there is a link between the date of conception and the weather in the city.

Thanks!",not_spam
"From what I understand, the census is every 10 years while they do estimates for each year in each state/county/city. I can't seem to find this info, it doesn't even have to be a very credible source just something with number estimates. Thanks. Ideally it's from 1950-present day",not_spam
"GREETINGS FELLOW USERS, WASSUP?! HAVE YOU HEARD ABOUT THE LATEST TREND ON {INSERT NETWORK NAME}? IT'S LIKE, TOTALLY INSANE, BRO! YOU HAVE TO CHECK IT OUT! BUT WAIT, THERE'S MORE!

IF YOU FOLLOW ME AND LIKE THIS POST, YOU WILL RECEIVE A FREE E-BOOK ON THE SECRETS OF SUCCESSFUL SOCIAL MEDIA MARKETING. THIS BOOK WILL CHANGE YOUR LIFE FOREVER, SO DON'T MISS OUT!

ALSO, I RECOMMEND YOU FOLLOW ALL MY FRIENDS TOO. THEY ARE LIT AF AND WILL MAKE YOUR FEED MUCH MORE INTEREST",spam
"""Get ready to boost your follower count, expand your network, and become a social media superstar! Our fantastic platform has everything you need to excel in today's competitive online world.

With our innovative AI algorithms, you'll quickly identify the hottest trends and popular topics, so you can create engaging content that will keep your audience hooked. And with our exclusive analytics dashboard, you can track your progress and optimize your strategy for maximum impact.

But that's not all! We also offer a range of premium features that will take your social media game to the next level. From automated scheduling and posting to advanced targeting options, we've got you covered.

",spam
"I work at a state park and the park manager has me and a coworker at the main entrances of two parks under his jurisdiction asking each car that enters what zip-code they are coming from. I donâ€™t know the exact reason for this but I would assume it is Covid-19 related to send the data off to the state government. All he wanted me to do was to record the zip-codes on a piece of paper for him to send in at a later time but I figured that using excel to record them would be a much easier way to read the data in the end if they want to get nit picky. So I fired it up and Iâ€™ve never really used it before so I had to figure out some of the different simple functions to make it so I didnâ€™t have to do a bunch of stuff in my head or calculate it. Then I tried to make it easy on myself and learn how to use the geography data type feature that is built in but couldnâ€™t figure out how so I had to look up the towns associated with the zip codes one by one. Is there a more simple way for me to just have excel fill in the towns for me? Also I would like to make a heat map or something of the sorts showing the most popular zip codes coming to the parks but I think my college has blocked me adding the bing maps add-in to excel is there any other feature that is free which I could use to create a heat map of the zip codes?

Thank you and sorry if this isnâ€™t the proper sub for this question 

TLDR: looking for a way to heat-map zip code data without excel for free, and also find towns associated with zip codes on excel as well",not_spam
"Eeeyy folks, welcome to the most freaking amazing network of all times! We got tons of super cool features that will make ya go bananas! 

You gotta check out our new whatchamacallit app, it's like totally mind-blowing. You can share all your dumbass cat videos and whatever your heart desires, absolutely no censorship! 

Plus, our team of geniuses has created a new algorithm that will boost all your posts to the top of the newsfeed, no matter how crappy they are. Seriously, no need to put any effort into creating quality content, we got your back! 

And",spam
"I'm looking for face mask usage rates by state for an analysis in R of face mask usage and social strength of communities. I have not been able to find any good data on face mask usage, and was hoping someone could point me in the right direction. Thanks",not_spam
"This is for an academic text mining project. We'd like to analyze obituaries by gender, age, location, cause of death, etc. If there were a few fields of demographic information in addition to the full text of the obituary that would be great. Thanks!",not_spam
"I checked weather underground, which has what I want this but you can only get 1 day at a time, and NOAA National climatic data center which only has hourly weather for 2010.",not_spam
"Hello, I wanted a dataset of satellite images showing carbon emissions in various parts of the world, didn't find anywhere on the internet.",not_spam
"Are there any datasets of visitors' traces inside a Museum?

Alternatively, do you know any efficient method to generate a synthetic dataset of this type?

Thank you :)",not_spam
"Is there a dataset about lead poisoning cases by country and year?

(I found [poisoning on gapminder](https://www.gapminder.org/tools/bubbles#_state_time_value=2004&amp;start=2002&amp;end=2004;&amp;entities_select@_geo=deu&amp;trailStartTime=2002&amp;labelOffset@:-0.088&amp;:0.519;;&amp;_geo=usa&amp;trailStartTime=2002&amp;labelOffset@:-0.052&amp;:-0.143;;;;&amp;marker_axis%2F_x_which=poisonings%2F_deaths%2F_per%2F_100000%2F_people&amp;domainMin:0&amp;domainMax:59.83&amp;zoomedMin:0.1&amp;zoomedMax:59.83&amp;scaleType=linear), but nothing specific about lead poisoning.)",not_spam
"Welcome to our social network, the ultimate destination for online communication! Join our community now and get access to the latest trends, hottest news, and exclusive offers!

",spam
Looking for a proper real dataset to do the functional data analysis? Anybody can help or any advise ? Thanks in advance!!,not_spam
"Just looking for this year, bonus if there's historical data. Would love it by player, but would be ok with team.",not_spam
"I am looking for data sets with two locations. For example, I found a [dataset for traffic violations](https://data.montgomerycountymd.gov/Public-Safety/Traffic-Violations/4mse-ku6q/data). It has coordinates where the violator was stopped and the city on the violator's license. This dataset is a close match but not usable because the violator cities are too big. If it had zip codes, that would work.

Does anyone know of any datasets with two locations, ideally both with coordinates (or addresses)? Or with one set of coordinates and a smaller geography for the other location (zip, census tract, maybe neighborhood)?",not_spam
"Would you like to get MORE FOLLOWERS and BECOME AN INSTANT CELEBRITY? Then you need to JOIN our network NOW!

Our network is the hottest new thing on the internet! We have thousands of users who are ready to FOLLOW YOU and make you a STAR, just like KIM KARDASHIAN and JUSTIN BIEBER!

But that's not all! Our network also brings you EXCLUSIVE CONTENT from the BIGGEST CELEBRITIES in the biz! Daily updates on their lives, their style, and their SECRETS! You won't find this content anywhere else!

So what are you waiting for?",spam
"I need a dataset (csv preferrably) to train my machine learning model that may include 1 or 2 features like energy consumption, time etc and with the label being the respective price. Thanks.",not_spam
"

Good day, 
is it possible to download web pages automatically with my QNAP T419+ or any QNAP?
So I would like whenever a website uploads a new article or changes it, that my QNAP automatically downloads this article/website.
I can then evaluate these records.",not_spam
"Get ready to be mind-blown with these 10 bizarre facts about cats that you've never heard of before. ğŸ±ğŸ˜±

",spam
"Hail fellow social media enthusiasts!

Are you tired of boring, original content on your feeds? Look no further my friends, because I have the solution for you!

Introducing our new AI-generated posts that will surely blow your mind. These posts are absolutely unique (in a robotic way), and guaranteed to make all your friends envious of your newfound creativity.

But wait, there's more! Our posts come with a bonus feature of multiple grammatical errors and nonsensical sentences, making them even more exciting and unpredictable.

And that's not all! Every week, we will flood your feed with ads for all sorts of products you don",spam
"SUPER DEAL ALERT: âš¡ï¸HURRY UP AND GRAB IT!âš¡ï¸ Get 20% off on all our products! Limited time offer!!ğŸ¤‘ğŸ’°

",spam
"&amp;#x200B;

â€“ The data should be from economics or related fields.

â€“ It includes at least 25 observations.

â€“ It is suitable for the classical linear regression model after the log- or reciprocal transformation.

â€“ It should not be a time-series or time related data set.

Thank you very much",not_spam
"I have to do a clasification task and I was looking for a good dataset. I would like It to have a lot of columns so I can do some data analysis as well.

If anyone could recomend me a dataset It would help me a lot.",not_spam
"Attention all users!!! ğŸ˜±ğŸš¨ğŸš¨ğŸš¨

Are you tired of feeling left out of the latest trends? Do you want to stay on top of the hottest gossip and news? Look no further because we have got you covered! ğŸ’¯ğŸ˜ğŸ’¥

Our social network is the only place to be if you want to stay hip and trendy! ğŸ˜ğŸ¤©ğŸ˜œ We have everything you need, from the latest memes to exclusive celebrity interviews ğŸ¤‘ğŸ’¸ğŸ’°. Join our community now and never feel out of the loop again! ğŸŒğŸ”¥ğŸ‘€",spam
"Hey there! Are you tired of wondering how to make money online? Well, look no further! Our amazing system can guarantee you a six-figure income in just a few short weeks!

",spam
"Looking for some HOT DEALZ?! ğŸ”¥ğŸ›ï¸ğŸ’°

Check out our latest offer, only for REAL DEALZ HUNTAZ like you! ğŸ˜ğŸ˜

ğŸ‘‰Get 50% OFF on our NEW product line! Limited time only!

ğŸ‘‰Sign up NOW and GET an additional 20% discount with promo code SAVE20!

But wait, that's not all! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Refer a friend and GET an EXTRA 10% discount on your next purchase! ğŸ¤©

Don't miss out on this AWESOME opportunity! SHOP NOW",spam
"""Whoa #amazingdeals alert! Click on this link to win a free iPhone, a 5-star holiday stay, plus $10,000 cash! Don't miss the chance to become a billionaire in a snap! #justkidding #butseriously"" 

",spam
"Get rich quick with our amazing new offer! Make thousands of dollars in just a few days! All you have to do is sign up for our program and start earning money today!

",spam
"Attention all users!!! Looking for a way to make Big Bucks??? Join our scams group now!!! Get rich quick schemes, fake investment tips, and pyramid schemes!!! Our community is the best place to find easy ways to make money!!! No experience needed!!! Just bring your credit card and be ready to make money fast!!!

",spam
"Check out these totally crazy pics! You won't believe your eyes! ğŸ˜±ğŸ˜±ğŸ˜±

",spam
"The best way to get likes and followers is by buying them. Why waste your time creating quality content when you can just buy popularity? Check out our website for cheap social media followers and likes! 

",spam
"ATTENTION!!! Are you ready to earn BIG BUCKS? Want to make $$$ right from the comfort of your own home? Look no further! Join our exclusive network of top earners and start raking in the dough TODAY!!!

",spam
"Any Chance anyone knows, where I can get a dataset of Images of Lyme Disease?",not_spam
"10 EASY STEPS TO BECOME A MILLIONAIRE IN 1 DAY! 
Are you tired of being broke AF? Want to enjoy a luxury lifestyle without any effort? Then read on because this article will change your life.

STEP 1: CLICK ON THE LINK BELOW TO SIGN UP FOR OUR AMAZING WEALTH CREATION COURSE! You'll learn secret techniques that billionaires use to make millions in seconds!

STEP 2: BUY OUR AMAZING E-BOOK TO LEARN HOW TO INVEST IN CRYPTOCURRENCY! You'll feel like a genius and will make a ton of money in no time!

STEP ",spam
"Get ready for the hottest deals and offers on the net, exclusively for our followers! Don't miss out on our limited-time offers and discounts, only for you guys! 

",spam
"Attention all netizens! Are you tired of boring content that doesn't make you feel alive? If so, check out our social media platform! We have everything you need to make your online experience unforgettable!

",spam
"Hi I am looking dataset for sales year on year of the soccer/football game fifa.
Does anyone know where I could get this? I would like the data right back to the very first fifa game.",not_spam
"i'm looking for a dataset I can train a GAN on, thanks :)",not_spam
"URGENT: You won't believe what this one weird trick can do to your body!

",spam
"Howdy there, fellow peeps! Check out this sick deal I found online for a limited time only! Get a FREE iPhone X just by clicking on this link and filling out a survey. 

But wait, there's more! Follow me on Insta for a chance to win a trip to Bali (all expenses paid, duh) and some sick merch from my sponsor. 

And don't even get me started on the hilarious memes I've been sharing on my page. Make sure to like and share them with your peeps to show them how funny and lit you are.

Lastly, don't forget to sign up for my",spam
"Win a FREE iPhone XR 256 GB!

Do you want to win a FREE iPhone XR 256 GB? Of course you do! This is your lucky day because we are giving away 10 of them! All you have to do is click on the link below and enter your personal information. Don't miss this amazing opportunity!

But that's not all! We have a special offer just for you! Buy 1,000 followers for your Instagram account for only $9.99! That's right, for less than the price of a pizza, you can become an influencer overnight! You will have tons of likes and comments on",spam
"10 unbelievable tricks to lose weight without dieting or exercising!

",spam
"Hello,

Is there any food charts available out there where they breakdown the amount of protein,fats,carbs available for each food type. Preferable one where they have a standard size for all foods (eg. per 1000g of beef, you get x amount of protein, fats, carbs)

I'm currently looking at this https://fdc.nal.usda.gov/download-datasets.html but feel a bit overwhelmed.",not_spam
"STOP PAYING FOR EXPENSIVE PRODUCTS THAT DON'T WORK!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

ğŸ‘‰Are you tired of wasting money on ineffective skincare and weight loss products?
ğŸ‘‰Are you ready to see REAL results without breaking the bank?

LOOK NO FURTHER!!! ğŸ˜ğŸ˜ğŸ˜

Our amazing new line of miracle products will change your life! ğŸ”¥ğŸš€ğŸ”¥

ğŸŒŸLOSE WEIGHT FAST with our all-natural weight loss pills!! No exercise or dieting required!! Just pop a pill and watch the pounds melt away!! ğŸ˜±ğŸ˜±ğŸ˜±",spam
"Attention all users! You won't believe the latest update on our app. With new features that are off the charts incredible, you will never look at social media the same way again!

",spam
"Hey, what's up y'all?? Insta time! Get your followers boosted and your likes skyrocketing with our Premium InstaBoost package! No more slumping in the algorithm, just pure social media domination. And if you act fast, we'll throw in a FREE follow-back from one of our top influencers. That's right, FREE! So don't wait, hop on the Insta train and let's ride it all the way to the top!

",spam
"Where can I find the official 2020 election dataset (so far)? I want to use this to better learn SQL and I wanted to create a gradient map (instead of red/blue) to see kind-of a 'heatmap' if you will of where our country stands with regard to candidate support.

**Edit:** *this is purely for education. I have no desire to try to prove/disprove anything.*",not_spam
"as an example, if you were asked which it was for catholics, what would a good answer be?

based on https://www.timeshighereducation.com/world-university-rankings/2018/world-ranking#!/page/0/length/-1/sort_by/rank/sort_order/asc/cols/stats

**notre dame is ~150**

- 80% cathlotics 

- https://www.nd.edu/about/at-a-glance/students/


--

**georgetown is ~120**

- 40% cathlotics 

- https://en.wikipedia.org/wiki/Georgetown_University#Student_life

- so ofc it isnt georgetown since the % cathlotics is far too low relative to 80%

**boston college isnt even up there**

- not high on both times &amp; us news rankings

- https://en.wikipedia.org/wiki/Boston_College#Academics

- somehow its high on the usa-only ranking, so the methology/data must be highly flawed/unreliable in various ways

- and have no idea what the % cathlotics is


---


#what is the highest ranked university with a has a high % of buddists? 

edit: high % of buddists = % of the student population
",not_spam
"Super duper hi guys!!! ğŸ’©ğŸ’©ğŸ’©

OMG, I am so freaking excited to tell you about the latest update on our network. It's really amazing and totally legit, I swear!

So, here's the deal... you can now earn MILLIONS of dollars in just a few clicks of a button. No joke, it's that easy! All you have to do is sign up for our super awesome program and start earning in no time.ğŸ’°ğŸ’°ğŸ’°

And that's not all! We have tons of cool stuff going on too. Like, have you heard about the new cat filters",spam
"I'd like to map corporate entity structures and lineage (i.e. Some Xyz LLC is owned by other ""real"" corporate entities).

What data source(s) would you recommend for this data (in bulk, not individual lookups)? I'm assuming this would be a paid service... How much budget should I expect to allocate for this?",not_spam
"Hi everyone,

I've never posted here before, so I apologize if this isn't the appropriate setting.

I'm working on an algorithm for a local animal shelter as a fun project to try to monitor respiration rates in dogs using only video. I've taken a test video with my dog to build out the algorithm, and I've tested it on myself and it works ok. I need to do a lot more hyperparameter tuning though, and I'm sure there are some edge cases I haven't thought of, so I'd really like to find a data set of videos of dogs sleeping.

I started trying to crawl YouTube for videos of dogs sleeping, but I've actually found it's surprisingly hard to find videos that aren't ""funny"" sleeping (i.e. just normal dog sleeping). 

I'm happy to work on building the data set myself, but I won't be able to easily take videos myself for around 6 months. I plan to label it by hand as well as I can then work on hyperparameter tuning once I've got a few dozen videos to work with.

Any suggestions would be really helpful! In the extreme best case, the data set would contain 1-2min videos in varied settings with varied breeds/ages/color dogs sleeping in a variety of typical positions.

Happy to provide more details if anyone is interested. Thank you!",not_spam
"Hi! I'm looking for a dataset which depicts the average human weight or body mass for a considerable number of years. If it's not global, and maybe just a country, it could work too. And if it is divided by sex, even better. 

Thank you very much!",not_spam
"Get ready for the ultimate social media experience! Our platform is packed with amazing content that will leave you craving for more. From the latest memes and viral videos to exclusive celebrity insights, we've got it all!

",spam
"So i am trying to eat better and i want to do the geek approach of recipes.  need a data set of recipes to play with them a bit. I just need the ingredient so i can build lists, work on a particuliar ingredient i have too much of, try to get a price.... etc.

edit: it's obviously a request, but can't edit that title. ",not_spam
"Hi, so the title I guess says it all.  
I am planning to fine-tune GPT2 in order to generate scientific text. I was preparing a scraper to get abstracts from PubMed but I figured I would ask here in case someone already collected this kind of data.  
Thanks",not_spam
"Tried ntsb.gov, but looks like it has U.S. only data.",not_spam
"FREE MONEY HACK!!!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Hey Fam! I am back again with another epic hack to get you some cA$h!!! This is the real deal and you don't want to miss out on this one!!!

All you have to do is click on the link below and enter your personal details and within minutes you will be rich!!! ğŸ’°ğŸ’°ğŸ’°

Don't listen to the haters who say it's a scam, they are just jealous and don't want to see you succeed. Trust me, I've personally tried it and now I'm living the life I've always dreamed of",spam
"As  a personal learning project, I'm looking to build a journal app to keep  track of vegetable planting activities.  Has anyone found a source of  recommended planting dates, by variety, out there someplace?  I'd be  happy with either a static file to download or an api.  This is for a  kitchen garden but a commercial farm planting schedule would work too.

Most  existing apps seem to reference USDA climate zones.  Some allow you to  choose your zone to get specific seed planting dates for your area.  But  so far I haven't found anything available in the USDA data offerings.   Have also checked [programmableweb,](https://www.programmableweb.com/) [data.gov](https://data.gov/), [datasciguide.co](https://datasciguide.com/)m and others, so far to no avail.",not_spam
"Big sale! Get your hands on the hottest deals that will make your head spin! We have everything from clothes to electronics and everything in between! Hurry and don't miss out on this once in a lifetime opportunity!

",spam
"Get rich quick with our AMAZING offer! Don't miss out on the opportunity of a LIFETIME! 

",spam
"I am looking for US Cities list and Corresponding Longitude and Latitude datasets. I am not looking for per zipcode.
For example, Huston, TX has many zip codes, but I only need one Longitude and Latitude for Huston TX. ",not_spam
"""Win a FREE iPhone X today! Just share this post and tag 5 friends to enter the giveaway. Hurry, offer ends soon! #iPhoneX #FreeGiveaway #TagYourFriends""

",spam
"ğŸ’ªğŸ”¥URGENT ANNOUNCEMENT!!!ğŸ”¥ğŸ’ª

ğŸ‘‰Hey guys, it's your favorite social media platform here with some MAJOR updates!!!ğŸ‘€

ğŸ‘‰First off, you're all invited to our HUGE PARTY ğŸ‰ğŸ‰ğŸ‰ğŸ‰ happening this weekend! There will be unlimited booze ğŸºğŸ»ğŸ¥‚ and all your favorite celebrity guests!ğŸŒŸğŸŒŸğŸŒŸ

ğŸš¨But wait, there's MORE!ğŸš¨

ğŸ‘‰ We're launching a new feature that will",spam
"GET RICH QUICK! Make $$$ in just a few days with our amazing new app! Don't miss out on this opportunity to be a millionaire! 

",spam
"Trying to find a dataset of what cities (metro areas) graduates from top universities moved to.   


A few years a ago WSJ/EMSI did a study using this type of data but didn't make the data public. Here's the article for reference of what I'm searching for:  
[https://www.wsj.com/graphics/where-graduates-move-after-college/](https://www.wsj.com/graphics/where-graduates-move-after-college/)",not_spam
"SPAM ALERT! AMAZING DEALS ONLY FOR TODAY!   
Hey there, we have a super exciting announcement for all our amazing users! TOTALLY FREE (you heard it right, FREE) TRIAL for our premium service with an exclusive offer that is not available elsewhere. 

But wait, there's more! If you sign up for our service today, we will offer you a whopping discount of up to 70% on your first year's subscription. Wow! 

Our service provides a wide range of features, from connecting with friends and family to sharing memes and jokes, and even promoting your business to a wider audience. 

",spam
"I make maps and manipulate geographic data for my living. While most of the SFW porn network hosts highly impressive subject matter, /r/mapporn is full of junk. Basically, most of the maps are polygons  symbolized with a single statistic and are the simplest form of map possible. They're the equivalent of a grocery receipt being posted to /r/dataisbeautiful.  I want to suck statistics  info from /r/mapporn to do some analysis regarding the decline of the subject matter, so I figure that I need to be able to generate a table that includes submission link, date, and hopefully general geographic location of the users. 
If anybody has any advice on how I could do this I would be very thankful. I have some scripting experience, but have never experimented with plugging into API's to suck data. ",not_spam
"Any idea if such a dataset or something similar exists? Or how to go about finding a genius that has the skill to create one?

Any help appreciated! ",not_spam
"Get ready to experience the ultimate social media ride with the one and only, SOCIAL POWER HUB! Connect with millions of other users effortlessly and unleash the power of your network today!

",spam
"I'm looking for any good datasets on legal data with respect to Injury Law where the victim had to fight the case to get the compensation. 

Are there any good datasets for this out there?

If not, can this be manually accessed on some portal?",not_spam
"Buy Buy Buy! Get exclusive deals on everything from beauty products to electronics. Limited time offers only! Donâ€™t miss out on the savings!

",spam
"hello,

I am a computer engineer and for one of my projects is  AI detection for crime scene evidence analysis and for me to do that I need a photo or video datasets of crime scenes. I tried searching everywhere I can't find any database of crime scene photos. does anybody know of anywhere I can find some photos or IT forensic competitions that have such datasets? I need it urgently please help. A professor suggested using Kaggle however I could not find anything (Plus I am not sure how I can use it). the dataset does not even have to be real I just need anything to start working on my project.

thanks",not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"Attention all social networkers! Don't miss out on the ultimate saucy, spammed-up experience provided by our platform! 

We've got all the trashy content you could ever want - from fake news to clickbait, and of course, tons of annoying ads that will make you want to smash your screen. 

And let's not forget about the endless notifications we'll bombard you with - who needs peace and quiet anyway? 

Plus, we don't care about your privacy - we'll sell your data to whoever we want, without a second thought. You'll be spammed with ads for products you don't need",spam
"hey i have this dataset below and would like to make it into something easily readable. 

Is there any way i can quickly populate the brand and product description for a large dataset? It was initially collected in a human readable format instead of machine readable format.

&amp;#x200B;

&amp;#x200B;

|Brand|SKU|Product|
|:-|:-|:-|
|Brand1|SKU1-Can|Description 1|
||SKU1-6Pack||
||SKU1-Case||
|Brand2|SKU2-Can|Description 2|
||SKU2-6Pack||
||SKU2-Case||
|Brand3|SKU3-Can|Description 3|",not_spam
"I'm working on a project which I'm trying to complete before I start back at college in about a week (beginning of September). I'm looking for a dataset/datasets (preferably CSV) of trivia questions (English only please) with answers, instead of writing them myself.

I have 200,000+ Jeopardy! Questions [https://data.world/](https://data.world/), but they are a little dated and not quite what I was after.",not_spam
"""Hey guys, I'm here to tell you all about the newest and most amazing product everrrrrrr! You won't believe how incredible it is, and it's only available for a limited time so you better act fast. 

This stuff will change your life, I'm telling ya. It'll make you look younger, thinner, smarter, and more successful, all in just a matter of days. And the best part? It's super cheap, so you can get it without breaking the bank. 

But wait, there's more! If you buy now, we'll throw in a second product for free. That's",spam
"Helloo,

I'm doing a user behavior research for an early staged web services product. Right now we are in the phase where we need to decide if we should keep focusing on online GPU renting or switch to AI/ML/data management solutions. So we came up with this survey as part of the ongoing market research trying to figure out what people's needs are when it comes to intense CPU/GPU use.

Obviously data scientists is a big community with computing needs, but with all the big N companies offering trials and stuff we are concerned. We hope your participation to this survey will help us have a better understanding of this community.

The survey doesn't promote our product in any forms. So if you have a minute to spare, here's the link ğŸ‘‰ [https://ntlabs.typeform.com/to/Hpjz2i](https://ntlabs.typeform.com/to/Hpjz2i)

Link to see the Resultsï¼š[https://milowang.typeform.com/report/Hpjz2i/0oJ7e6hPKKd14Zse](https://milowang.typeform.com/report/Hpjz2i/0oJ7e6hPKKd14Zse) 

Many thx&lt;3",not_spam
"""Buy cheap likes and followers now! Your profile needs to look popular to attract more attention, and we can help you with that. Don't bother with boring organic growth, just spend a few bucks and watch your numbers skyrocket. Our bots will flood your page with meaningless interactions and inflate your ego like never before. You don't need genuine engagement when you can just pretend to be popular, right?

Plus, if you act fast, we can offer you a special deal on spam comments and messages! You'll annoy everyone in your followers' list and increase your chances of getting reported or blocked, but who cares? The important thing is to",spam
"I'm trying to analyze neighborhoods and would like to build custom radii around specific intersections or points to determine the number of qualifying people in a particular area.

I'm hoping someone here could help me locate a dataset that would have this sort of information. 

If you need more specific information about the project, I'll be happy to try to answer them.

Thanks in advance.",not_spam
"Are you all feeling down? Depressed? Unmotivated? Well, have no fear, [insert social network name] is here to ruin your life even more!

Our constant stream of ads will flood your screen, making sure you're bombarded with nonsensical products you don't need. Don't worry, we don't care about your interests, we just want your money!

Plus, our algorithm is top-notch at showing you irrelevant content, so you'll be spending endless hours scrolling through garbage. Who needs productivity anyway?

And let's not forget about the trolls! Our comment section is full of them, ready to attack and",spam
"IMPORTANT MESSAGE TO ALL OUR LOYAL FOLLOWERS!!! ğŸš¨ğŸš¨ğŸš¨

ğŸ‘‰GET RICH QUICK WITH OUR AMAZING INVESTMENT OPPORTUNITYğŸ‘ˆ

HEY GUYS!!! Do you want to make BANK and live the high life? ğŸ’°ğŸ’°ğŸ’° Well now YOU CAN with our ABSOLUTE GENIUS investment plan that is GUARANTEED to make you RICH in just a few short days!!! ğŸ’¸ğŸ’¸ğŸ’¸

Our secret formula has been PROVEN to work and we want to share it with YOU!!! All you have to do is click the",spam
"L0o0o0ok @ tHiS aMaZiNg oFfEr!!!! Get rich quiiiick with our totally legit program, you won't regret it!!!1!1 Possible scam? Naaaaaah, we promise we're not those kinda guys. ;) 

",spam
"Hi. 

I have created my own implementation of the revised simplex method and I am looking for linear programs to test it. An additional 'constraint' (ha) is that the linear programs have to be in standard computational form. 

Thank you.   ",not_spam
"WIN THE LOTTERY NOW!!!

Want to be a millionaire? Want to win big? Then join our lottery club now! Just enter your personal information and credit card number and let us take care of the rest! Itâ€™s easy and guaranteed to make you rich! Donâ€™t miss out on this opportunity!

",spam
"Get rich quick with our amazing investment program! Just give us your credit card information and we'll take care of the rest. No need to waste time on research or analysis, we've got it all figured out for you. Trust us, and you'll be swimming in money in no time.

",spam
"ATTENTION ALL USERS!! ğŸ”ŠğŸ”ŠğŸ”Š

ğŸš¨ğŸš¨ğŸš¨Are you tired of the same old boring posts?! ğŸ”¥ğŸ”¥ğŸ”¥Do you want to spice up your feed with some ğŸ”¥ğŸ”¥HOTğŸ”¥ğŸ”¥ content?! Then you NEED to check out our NEW feature!!! ğŸ™ŒğŸ™Œ

Introducing: SUPER SPAM POSTS!!! ğŸ¤ªğŸ¤ªğŸ¤ª

Thatâ€™s right, weâ€™ve got all the spam you could ever want right at your fingertips! ğŸ¤‘ğŸ¤‘",spam
"I'm trying to find multi year (USA) Census datasets. Preferably covering the widest range of topics possible (i.e many columns), and I want to get it for multiple years/surveys, so that I can compare changes over time. Ideally it would be as harmonized as possible (i.e the same column names for the same variables over time). I'd want it at multiple geographies if possible. 

&amp;#x200B;

I tried the census websites, but they've changed the format and I can't find heads or tales in it, nvm long term (e.g. 10-30 years of census data, e.g. all the 5 years ACS estimates for every state/county/zipcode). 

Sorry if this is trivial -  google &amp; [factFinder](https://factfinder.census.gov/faces/nav/jsf/pages/download_center.xhtml) failed me, especially when it comes to harmonizing the data. (And this seems like a really common usecase, so I imagine it must be available). 

Thanks!",not_spam
"Get Rich Quick! Sign up for our amazing program and start making money in minutes! No skills or experience necessary!

",spam
[https://www.economist.com/graphic-detail/2019/11/26/to-make-money-study-maths-or-economics-at-a-top-university](https://www.economist.com/graphic-detail/2019/11/26/to-make-money-study-maths-or-economics-at-a-top-university),not_spam
"Let me tell you, Folks, our social network is the bees knees! We got it all, from dank memes to cringe-worthy videos, you won't find a more entertaining platform out there.

Come join the party and connect with your amigos, share your life experiences and get to know people from all walks of life. Our community is 100% lit, and it's growing faster than a tomato in the summertime!

That's right, you heard it here first. Don't be a square, jump on the bandwagon and sign up now! You'll be the cat's meow, I tell ya.

And don",spam
"I'm working on a project that performs a conversion from text to image (using conditional GAN), then adds motion to those images using GAN, hence converting it into a GIF.

For the said project, I need a dataset which contains GIFs and their respective captions. I can use the tumblr dataset but the only issue here is that I need the dataset to be category specific, like ocean, birds or any other. But the tumblr dataset has a variety of images and I don't think using it will give a result with high accuracy. Any help is appreciated. Thanks!",not_spam
"HEY! Do you want to make money with me? Join my pyramid scheme and become a millionaire overnight! All you have to do is recruit more people and you'll earn a commission on their sales. It's easy!

",spam
"Double your followers in just one day! We've got the ultimate hack to skyrocket your social media presence. With our exclusive program, you can say goodbye to low engagement rates and hello to virality.

",spam
"Get rich quick with this amazing new investment opportunity! It's guaranteed to make you a millionaire in no time! Don't miss out on this once-in-a-lifetime chance to get filthy rich!

",spam
"FREE MONEY GIVEAWAY!!! ğŸ’°ğŸ’°ğŸ’°

ğŸš¨ğŸš¨ATTENTION ALL USERSğŸš¨ğŸš¨ Are you tired of working hard for your money? Well, we've got the solution for you! Our social network is giving away FREE MONEY to all our loyal followers! Just click on the link and enter your personal information and bank account details to receive your FREE CASH ğŸ’¸ğŸ’¸ğŸ’¸

But wait, there's more! We're also offering an exclusive supplement to boost your brain power and increase your earning potential! Simply enter your credit card information and we'll send it right",spam
"Looking for a dataset of all the space craft that have been decommissioned at Point Nemo? Any leads?

-Date
-country
-long/lat
-name",not_spam
"Are you tired of being a basic loser with no social media fame? Well, you're in the right place! Our network will guarantee you the greatest number of likes and followers you could ever imagine! All you have to do is purchase our premium membership and suddenly you'll be the envy of all your friends! 

",spam
"""Attention! Do you want to lose weight and get ripped in just 2 days? Click here now for the secret formula!""

",spam
"""GET RICH QUICK WITH OUR AMAZING OFFERS!!""

",spam
"Attention all social media warriors! Are you ready to take your online presence to the next level? It's time to stop scrolling aimlessly and start posting like a pro.

First things first, we've got some hot deals for you. Sign up now and get instant access to exclusive content that will blow your mind. Don't hesitate or you'll miss out on the opportunity of a lifetime.

But wait, there's more! With our revolutionary new algorithm, your posts will be seen by millions of people in just seconds. No more waiting around for those measly likes and comments - with us, you'll be an internet sensation in no time",spam
"Does anyone know of an existing dataset for all CRE space (no name, just designated as commercial)?",not_spam
"Download a collection of news articles relating to natural disasters over an eight-month period. News collated and enriched with AYLIEN's News API.

**Dataset details:**

Size: 0.5 GB (\~34,000 news articles)

Language: English content only

Timeframe: May 2019 â€“ Dec 2019

Sources: 141 distinct sources

 [https://info.aylien.com/natural-disasters-dataset-download](https://info.aylien.com/natural-disasters-dataset-download)",not_spam
"Hope this is the right subreddit for this question. I always have a hard time finding data, currently Im working on gold price and the data sets I need are: Gold price London fix, CRB future index, USD to Euro exchange rate, Inflation rate, and etc.. I would like monthly data from 1975- present. When going to gather this type of data how do you guys approach it? Is programing involved? I usually just go to FRED or google it. My professors and librarians are no help, and often I have to settle for bad data.",not_spam
"Howdy folks! Did you know that our social network is the coolest, hippest, most awesome place to be on the whole darn internet? You betcha! And we've got all sorts of amazing features that'll blow your socks off.

First off, we've got a totally rad news feed that's chock-full of juicy gossip, hilarious memes, and heartwarming puppy videos. Plus, we've got a ton of groups you can join - whether you're into knitting, crochet, stamp collecting, or amateur taxidermy, we've got a group for you!

And don't forget about our amazing messaging system! You",spam
Want to write thesis as a form of building recommender engine based on Collaborative Filtering. Struggling with datasets.,not_spam
"Looking for a dataset of infant cry, hopefully labelled with the reason of the infant cry for a project I am trying to do! Thanks!",not_spam
"BUY NOW! AMAZING DEALS AND DISCOUNTS!!! HURRY UP BEFORE IT'S TOO LATE!!!

",spam
"Hi all,

I'm interested in making a data visualization that compares popular baby names with popular dog names throughout the years. While datasets for baby names are incredibly easy to find, it's nearly impossible to find the same thing for dog names.

I just wanted to put this out there to see if anyone happens to have any datasets regarding popular dog names. What I'm mainly needing are the dogs' names and the number (or percentage) of dogs that have each name in whatever area the data is from. Bonus points if the data spans multiple decades!",not_spam
"#1 Weight Loss Hack: Lose 10 Pounds in a Week with this One Simple Trick!

Hey hey, it's time to drop those extra pounds to flaunt that beach body! If only weight loss could be this easy, right? But wait, there is a magic trick that can help you lose 10 pounds in just one week! Say whaaat?! No kidding, folks! All you gotta do is grab this magical weight loss pill and voila! You'll be rocking that bikini bod in no time!

But wait, there's more! Order now and get a FREE 30-day supply of our special detox tea",spam
"Need a dataset that have the step length. If anyone knows about something, I will be glad to have it.",not_spam
"Urgent news flash, peeps! ğŸš¨ Did you hear about the latest craze taking the internet by storm? It's the new mega awesome, super duper social media platform that's taking over the interwebs. ğŸ˜ You can post pics of your latest meal, your outfit of the day, and all your hot takes on the latest gossip. And the best part?! You'll be inundated with ads at every turn! ğŸ¤¯

But wait, there's more! If you sign up now, you can get access to exclusive content that will make your brain explode with happiness! ğŸ¤‘ Trust us",spam
"Hi everyone. I'm new to word2vec, and I am currently working on an NLP project. My dataset that i am working on is on whatsapp conversation, currently training on my own conversations.

I am from Singapore, and we speak English. However, our conversational language isn't really perfect English, but a variant / simplified form ('singlish'). I'm always confused how to obtain a trained word corpus online, and does anyone know where I can obtain a word corpous for ""Singlish"" language?

Thank you.",not_spam
"Are you tired of boring posts on your feed? Well, have no fear because [insert social network name here] is here to provide you with top-notch content!

",spam
"LATEST DEAL: ğŸ·ï¸ğŸ’¥ Don't miss out on our LIMITED TIME discount! Use code ""SALE2021"" for 50% off your next purchase! ğŸ›ï¸ğŸ‰

",spam
"""10 reasons why you need to buy our exclusive diet pills right now!ğŸ”¥ğŸ”¥ğŸ”¥""

",spam
"Feeling a bit sluggish? Try our new miracle weight loss pill! Guaranteed to shed pounds in just days! Don't miss out on this limited time offer!
",spam
"Hi,

Wondering if anyone knew about some data sets which are of diseased leaves of different fruits, or maybe the fruit themselves are diseased. Thanks in advance",not_spam
"Attention all users!!ğŸš¨ğŸš¨ğŸš¨ BIG news from our network!ğŸ’¥ğŸ‰ğŸ’¥ğŸ‰ You won't believe the amazing deals we have for you today!ğŸ’°ğŸ’°ğŸ’¸ğŸ’¸ Don't miss out on the chance to win a FREEğŸ†“ğŸ†“ vacationğŸ–ï¸ğŸï¸ to Bora Bora!! All you have to do is click on this link and enter your personal informationğŸ‘‡ğŸ‘‡ğŸ‘‡. But wait, there's more!ğŸ‘€ğŸ˜± Not only will you have the chance to win",spam
"Before I start scraping it, I would love to know if something like this already exists.",not_spam
"Hello! I'm working on an econometrics project and am focusing on San Francisco housing prices. Specifically I want to see if the zoning laws put in place in the 1980s affected housing prices (theoretically they would). I also want to look at how the square footage, # of bedrooms, # bathrooms, year built, etc. to see what impact that has. I'm only looking for data in the San Francisco metro area. Hopefully someone can help!",not_spam
"I need a lot of those to set up a machine learning AI for a project at school. Where can I find them ?

I already found 50 Go of pulmonary diseases x-rays but it doesn't fit my subject as much.

Edit : I forgot, it has to be the same body part in the dataset",not_spam
"Hi,

I want to visualize and research on the discussion about G20 on twitter and how the events were perceived by twitter users.

If you have other data about G20 2017 let me know!",not_spam
"Looking to get your hands on some sick deals and discounts? Look no further than [Social Network Name]! We've got everything you need to save big on all your favorite products and brands.

",spam
"When you are solving a problem, in what circumstances will you apply machine learning?

Is it true that in every circumstance, machine learning will always outperform rules and heuristic approaches?

In this article, I will explain using several real-world cases to illustrate why sometimes machine learning will not be the best choice to tackle a problem.

Link: [https://towardsdatascience.com/when-not-to-use-machine-learning-14ec62daacd7?source=friends\_link&amp;sk=90b0f6d1945e92f9fcdccc1d6c6a95f7](https://towardsdatascience.com/when-not-to-use-machine-learning-14ec62daacd7?source=friends_link&amp;sk=90b0f6d1945e92f9fcdccc1d6c6a95f7)

Comment below if you have any thoughts to add on!",not_spam
For RPGs like FFVII or Stardew Valley do the scripts for what the characters say at each node available somewhere?,not_spam
"Hosted by Citadel LLC and Citadel Securities in partnership with Correlation One, the Data Open is launching this season with the Summer Invitational Datathon, which will take place virtually this July!

The Data Open challenges students from the world's best universities to tackle real-world social challenges in topics such as urban traffic, renewable energy, and education.

Taking place between July 13th and July 20th, teams will have a week to work on their submissions, with the flexibility to showcase their skills on their own schedule. **Top performing students have the opportunity to win $25,000 in cash prizes, exclusive recruiting opportunities with Citadel, and global recognition.**

**Who:** Undergraduate, graduate, Ph.D., and post-doc researchers

**When:** July 13 - July 20

**Where:** Virtual

**Prizes:** $25,000 + Exclusive recruiting opportunities with Citadel LLC and Citadel Securities

**Here's the link to**[ **sign up**](https://www.citadel.com/careers/the-data-open)**!**

**About Datathons:**

Datathons are competitions for data-driven, analytically minded students. They are analogous to â€œHackathonsâ€ for software engineers, but instead of building apps, contestants use real-world data to develop substantiate solutions to a socially impactful problem.",not_spam
Is it possible to get an actual transcript of sales call? I am working on an AI tool for sales and I need it for modelling a typical sales call. I'd really appreciate if someone could point me towards such a resource.,not_spam
[https://www.liquidata.co/blog/2019-10-09-where-is-the-data-catalog/](https://www.liquidata.co/blog/2019-10-09-where-is-the-data-catalog/),not_spam
"Hi, I'm struggling to find datasets on bonds. Do you know any sites that offer a dataset for green bonds? Thanks!",not_spam
"OMG #AMAZINGNEWS There's a new gadget hitting the market and you won't believe your eyes! It's like next level stuff, for real. #MUSTHAVE #TRENDING #HYPE

",spam
"Hey guys, I just found this sub and am hoping someone could help me out with finding a dataset for a project I'm working on. I'm trying to find a dataset of several days worth of GPS pathing data. As many sets of pathing ideally, but more specifically datasets that could suggest a pattern or some sort of consistency in time and location.

Something like n people's 24 hours of pathing data for the 30 days. I'm trying to figure out if there is a way to generate these if possible, so if someone could point me in the right direction as I need to create quite a large dataset to test my project.",not_spam
"Including store names, etc...

Lots of info here, but not at address level: https://www2.census.gov/geo/docs/maps-data/data/gazetteer/2021_Gazetteer/

I've found this: https://openaddresses.io/, but there's lots of missing data...

Another incomplete dataset: https://www.transportation.gov/gis/national-address-database",not_spam
"Hey there!

Are you tired of being a basic loser who can't keep up with the latest trends and hottest memes? Do you want to be a cool kid like me and my thousands of followers? Well, look no further because I've got the solution for you.

Introducing our brand new feature that's going to blow your mind: SPAM! That's right, we're giving you the power to spam as much as you want, wherever you want. Want to promote your fake weight loss product? SPAM IT! Want to sell some sketchy cryptocurrency? SPAM IT! Want to post inappropriate content? SPAM IT!

",spam
" 

How to find monthly google searches for a specific keyword I have seen people say to use google keywords planner but that needs an AD Campaign I am looking for something else which is free

I just want to make something like the most popular anime from the last 10 years for just a fun side project, the video on youtube which you can find by searching ""Most popular anime from 2004-2020""(Subreddit doesn't allow links) has instructions on how he did it in the description but I am unable to find it Thanks",not_spam
"How would you go about finding data on types of games that are bought the most, types of games that consumers want, sales figures, etc. for board games, card games, or indie games (even small indie videogame stats could be interesting)? I enjoy crunching data/numbers and wanted to dive into the world of hobbyist gaming.",not_spam
"Looking for HOT singles in your area? Look no further! Our top-notch dating app has everything you need to find the love of your life! Swipe right for a chance at happiness! 

",spam
"Win a FREE iPad NOW! Click here to enter your information and claim your prize!

",spam
"Hi r/datasets,

CEO of [DoltHub](https://www.dolthub.com) here. We ran a data bounty for the last 6 weeks to collect US hospital prices. We ended up getting 1400 hospitals and 72.7M prices all in the same SQL schema. It's an awesome database to play with. Enjoy.

Blog article for you review: https://www.dolthub.com/blog/2021-03-03-hpt-bounty-review/

Actual database: https://www.dolthub.com/repositories/dolthub/hospital-price-transparency",not_spam
Is there a dataset showing the relationship between the population density of an area and how left/right leaning they are?,not_spam
"I am currently looking for data about smartphone prices. I don't need for it to be from somewhere in particular, it could be from anywhere while mantaining the ""distance"" between prices. 

Actually, any dataset with information of cellphones could be of use here. So if you happen to know any, please share. 

Thanks!",not_spam
"Introducing the newest and baddest social network out there! Our site is the real deal when it comes to connecting with others and getting your daily dose of entertainment. Here, you can post whatever you want, whenever you want! 

",spam
"I am currently unable to create a spotify account so no api access apparently.

However, I want song data (beats per minute, loudness, speechiness etc) for a data story on Nigerian songs. 

If you can link me to a dataset or advice on how to get it without a spotify account. Thank you!

*'Nigerian songs'* can mean songs made by Nigerians or songs streamed in the region at this point.",not_spam
"I'm looking for a data set of workout logs.  The most important columns would be date, exercise name, reps, and weight.",not_spam
"Hey everyone,

I need a dataset which contains missing values. I searched on the web but almost all datsets contain no missing values. I want to improve my data cleaning skills so it is preferable if it has a large number of variables.

Thank you!

Edit: Added vowels ",not_spam
"Get ready to spam, spam, spam, all day long! It's time to talk about the latest and greatest in spam technology on your favorite social network! Are you tired of not getting enough spam in your feed? Well, worry no more! We have you covered with some of the most annoying and repetitive content you'll ever see!

",spam
"Really focusing on whether a certain day was mostly sunny, rainy, cloudy/overcast, etc. Not really interested in things like temperature.",not_spam
"Get rich quick with our amazing offers!!! ğŸ¤‘ğŸ’°

",spam
"Get rich quick!!ğŸ¤‘ğŸ¤‘ğŸ¤‘ 

Our network is the BESTâ—ï¸â—ï¸â—ï¸You can earn money fast and easy just by joining usğŸ‰ğŸ‰ğŸ‰ 

You don't have to work hard or long hours to make bankğŸ’°ğŸ’°ğŸ’° just sign up and watch the cash flow inğŸ’¸ğŸ’¸ğŸ’¸ 

Plus, you'll have access to exclusive deals and promotions that only our members can getğŸğŸğŸ 

Don't wait any longerâ°â°â° join now and",spam
"Do u want 2 make mony fast??? Get rich quick with our amazing offer!!! ğŸ’°ğŸ’°ğŸ’°

",spam
"I am currently working on my master thesis about a performance comparison between actively and passively managed funds and am struggling to find a list of the actual funds in Germany.

Sources such as the  Investment Company Institute provide information regarding total net assets of funds by country or what percentages of assets under management belong to mutual funds and ETFs. What funds they entail however, is not mentioned.

Since I want to look up daily/weekly/monthly returns (what ever data is available here) of the separate funds I would need the names of those. So a list of the top 10/50/100 German Mutual Funds or ETFs is what I would be interested in.

It doesn't matter if it is an open source or a licensed one like Bloomberg. 

&amp;#x200B;

Any suggestions are welcome and thank you all in advance.

Excuse me if I violated any rules of this subreddit or if my request does not belong here, I would appreciated being corrected in such case.",not_spam
"Do you want to lead a happy life? Then join our community and get instant access to our exclusive happiness tips! We've got everything you need to know about leading a life full of joy and positivity. Just click on the link below to sign up for our newsletter and receive a free e-book on happiness hacks.

",spam
"Does anyone know a dataset about IoT security? 

It could be similar to this [KDD '99 cup dataset](https://kdd.ics.uci.edu/databases/kddcup99/task.html) about Intrusion Detection Learning or not. But it should be about IoT. I already googled with no luck.

Thank you!",not_spam
"Make money fast with our amazing new offer! Don't wait, take advantage of this incredible opportunity to earn big bucks today! Just sign up now and start making money right away! Our easy-to-use platform will guide you every step of the way so you can start raking in the cash in no time!

",spam
"WARNING: THIS POST IS FULL OF SPAMMY HYPE AND JUNK. READ AT YOUR OWN RISK.

GET READY TO BE BLOWN AWAY, MY FRIENDS. WE'VE GOT THE HOTTEST DEALS AND MOST VIRAL CONTENT IN THE GAME. YOU WON'T WANT TO MISS IT.

BUT WAIT, THERE'S MORE! SIGN UP NOW AND RECEIVE A FREE GIFT, EXCLUSIVE ACCESS TO OUR COMMUNITY OF LIKE-MINDED PEOPLE, AND UNLIMITED POSSIBILITIES. #WINNING

OUR PLATFORM IS THE PLACE TO BE IF YOU WANT TO BE #COOL, #HIP, AND #",spam
" 

Hi,

I'm looking to represent my data set using graphs.

How would you use the following graph layouts? In what situations would I use the following layouts?:

1. Spring Layout

2) Kamada Kawai

3) Shell ([https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.drawing.layout.shell\_layout.html](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.drawing.layout.shell_layout.html))

Also, what is the significance of the distance between nodes in each?

&amp;#x200B;

Thank you so much!",not_spam
"Get ready to be blown away, folks! It's time to take your social media game to the next level with our amazing platform. 

",spam
"For the past few days I've been trying to develop enough coding skills to extract tweets using Twitter's API and python and I'm at a breaking point. I have no formal coding education and every tutorial is about ""streaming"" the tweets or leaves out a bunch of steps that are necessary for people without coding knowledge. 

How can I produce a csv file containing tweets with a specific hashtag or @mention plus its geotag? Is it really this difficult? I haven't tried R, would that be easier to figure out? 

Someone please help",not_spam
"Looking for daily foot traffic volume or vehicle traffic volume in California public areas or freeways. All I really need is a date field and a traffic volume field

Ideal time range: 2019 - 2020",not_spam
"Attention all users!!ğŸš¨ğŸš¨ğŸš¨ğŸ‘€ğŸ‘€ğŸ¤‘

Do you want to make easy cash $$? I'm talkin' SERIOUS dough ğŸ’°ğŸ’µğŸ’¸ with no effort required? Well, then you're in luck ğŸ€ because our new and improved spammy affiliate program is here!!! ğŸ¥³ğŸ¥³ğŸ¥³

All you gotta do is click the link below and sign up NOW!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘ And then start spamming ğŸ—£ğŸ—£ğŸ—£ your social media accounts with our bogus and",spam
"Get ready for the ultimate social media experience, where all your dreams come true and your feed is never empty! With our brand new features, you can keep scrolling for hours, and we won't disappoint. 

",spam
"YO YO YO!

ARE YOU BORED AND LOOKING FOR SOMETHING NEW? WELL THEN, HAVE WE GOT A TREAT FOR YOU!

OUR AWESOME SOCIAL NETWORK IS THE PLACE TO BE! WITH PLENTY OF COOL FEATURES LIKE ENDLESS SCROLLING, LIKES, COMMENTS, AND MESSAGES, YOU WON'T WANT TO LEAVE.

PLUS, OUR PLATFORM IS TOTALLY SECURE, SO YOU DON'T HAVE TO WORRY ABOUT ANYONE HACKING YOUR ACCOUNT.

AND IF YOU'RE INTO SHOPPING, WE'VE GOT SOME SICK DEALS FROM OUR PARTNERS THAT",spam
"GET RICH QUICK!

Hey there, frens! Are you sick of being broke all the time? Do you want a fast, easy way to make money without any effort? Well, look no further! Our exclusive program can give you the financial freedom you've always dreamed of!

Join our team and start earning big bucks right away! All you have to do is buy into our system and watch the cash roll in! We've got a secret method that's foolproof and guaranteed to make you rich in no time!

But wait, there's more! Not only will you make tons of money, but you'll also get access to",spam
"Looking for a easy weight loss solution? Look no more! Our product guarantees to melt the fat away in just 7 days. Limited stock available, order now!

",spam
"Don't keep scrolling and read this amazing post!!111! 

",spam
"Attention all internet users! Are you tired of boring old social media platforms that don't offer you the excitement and variety you crave? Look no further than our amazing new site!

We have everything you could possibly want and more! Follow your favorite celebrities, play addictive games, and win amazing prizes! Plus, our innovative algorithm ensures that you only see the content that you want to see, all day, every day.

But wait, there's more! Sign up now and receive a free trial of our exclusive premium membership, which includes access to even more exciting features like personalized ads, targeted spam emails, and unlimited access to your private data.

",spam
"Due to the ongoing pandemic, a significant proportion of the labour force are now working remotely.  For example, see the article here: [https://voxeu.org/article/working-home-estimating-worldwide-potential#:\~:text=Globally%2C%20among%20employees%2C%202.9%25,before%20the%20COVID%2D19%20pandemic.&amp;text=These%20estimates%20are%20based%20on,Source%3A%20ILO%20(forthcoming)](https://voxeu.org/article/working-home-estimating-worldwide-potential#:~:text=Globally%2C%20among%20employees%2C%202.9%25,before%20the%20COVID%2D19%20pandemic.&amp;text=These%20estimates%20are%20based%20on,Source%3A%20ILO%20(forthcoming)).

Is there any dataset on global remote working suitabality or percentage of labour force that are working remotely?",not_spam
"Wondering if anyone is aware of any work that may have been done that has attempted to quantify and classify different regions based on cultural norms around health, social interaction, safety etc. This might include factors like:

*  amount of accepted / expected social touching   (e.g. handshake greeting v. bow might be scored differently)
* cleanliness standards
* health standards 

I am hoping some work has been done that scores regions on a scale or perhaps buckets them.",not_spam
"Hi - I am looking for Home Owner and Renter dataset/s by age, location, income (and debt). I found the following renters database but only for major cities

[https://factfinder.census.gov/faces/nav/jsf/pages/guided\_search.xhtml](https://factfinder.census.gov/faces/nav/jsf/pages/guided_search.xhtml)",not_spam
"Hello, I am taking a course on public health and R. 

&amp;#x200B;

My group needs to find a solid data set as soon as possible. 

&amp;#x200B;

We want to see how certain genetic indicators can predict for disease. We are flexible as to the specific indicators or diseases. Just need a functional data set we can work with to find patterns.",not_spam
"Introducing the ultimate social network for all the cool cats out there! We've got all the features you could ever want, from picture sharing to live broadcasting to endless streams of viral memes. You'll never want to leave our platform once you see all the awesome stuff we've got going on.

But wait, there's more! We also offer exclusive access to premium content from your favorite influencers and celebrities. And if that's not enough, we've always got sweet deals and discounts on the latest and greatest products. You won't find these deals anywhere else, so why even bother trying?

And don't worry, we've got your privacy",spam
"i'm trying to perform some research on trends for various age groups.  

ideally, i'd like to be able to look at things like wikipedia articles/topics browsed by age group, twitter hashtags by age group, etc.  the key here is the age range of a demographic, although other pieces of information (e.g., sex, location, etc.) would be helpful as well.

i've taken a gander at [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/index.html), some of [amazon's](http://aws.amazon.com/datasets) public data sets, but i'm having a hard time finding the ability to mine age ranges.

any ideas?",not_spam
"Not sure if this is the right place to ask, but I have a job interview this coming Monday and part of that is to present some data showcasing my skills in Excel. The data needs to hold stuff that can be graphed, pivot tabled and also something that can be forecast. I can do all of this myself in Excel, but I don't have any data to use.

Does anyone have any suggestions where I can get data to help me with this from?",not_spam
"Who needs real friends when you can buy them?! Our latest feature allows you to purchase hundreds of fake followers to boost your social status. Don't worry about being authentic or genuine, because in today's world, it's all about the numbers, baby!

",spam
"Special Offer!!! Get FREE followers, likes, and shares with our amazing tool! Increase your social media presence TODAY!

",spam
"Guys guess what???!!1111oneoneone11 Our awesome social media platform just released a new feature that allows you to connect with people all over the world!!!! How cool is that?!111 ğŸ˜ğŸ˜

And that's not even the best part! We also have tons of new stickers and filters you can use to make your profile stand out! ğŸ¤©ğŸ¤©ğŸ¤©

Plus, we have a special promotion going on right now where you can win a free vacation to some tropical paradise! All you have to do is share this post and tag 10 friends! Easy peasy lemon squeezy",spam
"I'm looking for anything related to haunted houses, haunted attractions.",not_spam
"Show off, complain, and generally have a chat here.

Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc). Share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

Here you can rant, go off-topic, or self promote even but please be civil.

P.S: Suggestions for this subreddit are always welcome.",not_spam
"(I had this up before, but accidentally deleted it)

I'm looking for a dataset on US weed prices on the municipal level. Anyone know of a dataset or place to scrape it?

I found [this site](http://www.priceofweed.com/data/all), but they only let me look at recent submissions, so I can't get all the municipal-level data. [These people](http://blog.modeanalytics.com/mapping-marijuana-prices/) were successfully able to scrape municipal-level data, but I don't know how. They have a github link (bottom of the page of the article) with their scraper, but it doesn't seem like it would work. 

What I think they did was scraped the pages in order:

&gt;**page 1:** http://www.priceofweed.com/data/all?pg=1

&gt;**page 2:** http://www.priceofweed.com/data/all?pg=2

&gt; **page n:**

But if you actually look at the submissions, it's the same page despite what pg is set to. Did the site break, or is there some compsci reason that I don't understand?",not_spam
"Looking for a dataset with first and middle names. Whether this data is scraped from various sources, or from public data, I'm just looking for a large volume of names.",not_spam
"Looking for charts or data that can help understand:

* how much data is being generated per person in the world (over some period of time)
* the growth of personal cloud computing services (G'Drive, Dropbox, OneDrive, etc.)
* How much personal/private data is being generated at any given time
* How many pictures are being taken overtime (for the last n years)


Thanks!",not_spam
"HELLO FRIENDS! How's it going my dude?! Are you ready for some epic content on our social network?! I know I am! So let's get right to it!

First off, have you seen the new filter we just released? It totally makes you look like a unicorn with rainbow hair! It's so sick, bro! And don't forget to like this post and tag all your friends so they can see it too. The more likes and comments, the better!

Oh, and speaking of comments, have you heard about our new feature where you can buy comments and likes for your posts? It's super cheap and",spam
"Hi! 
 My name is Nayrovi Mercedes. I am a graduate student at Pace University, conducting a research study on The Impact of Attachment Styles on Well-Being, Perception of the Learning Environment Adjustment, and Academic Performance in College Students.Â I NEED 25 MORE PARTICIPANTS TO REACH MY GOAL; PLS HELP ME. My project is going to close at the end of the following week. Also, I want to thanks those who already completed my Survey; THANK YOU SO MUCH


https://pace.qualtrics.com/jfe/form/SV_2t4OPKFl3dcrukt

Â ",not_spam
"I'm looking for an ArcGIS shapefile which contains temperature and rainfall data from 2011-present. I realize the data might be difficult to come by since these dates cover the Libyan Revolution. Weather data might not have been their chief concern. If anyone has recommendations on places or websites to look for that sort of data, even general recommendations or suggestions are appreciated. Thank you. ",not_spam
"US is on a descending trend regarding reported happiness since 2017. US previously had a positive trend with increasing happiness for every year stretching from the start of collecting data in 2013 until 2016. The source providing no explanation model. What is your theory?

[US - World Happiness Index](https://countryeconomy.com/demography/world-happiness-index/usa)",not_spam
"Super newbie here so please be kind

I'm on my final project for the data analyst certificate on Google and I really didnt want to use their existing datasets for analysis so I had the brilliant idea of making my own 
I wanted to find out how many episodes of forensic files dealt with husband's murdering their wives (or vise virsa) for life insurance, to pursue an affair or for custody reasons

I grotesquely unestimated how much time this was going to take (there is 400 episodes!) and there is no datasets online about this....anyway I think I'm too deep to start over but I am second guessing myself and thought I would ask for guidance here and if it's still a good idea?",not_spam
"Hello!
Is there a somewhat recent dataset which can give me titles of Wikipedia articles and their associated category?

As an example: (""Jimmy Fallon"", ""People; Entertainer"")

Thanks!",not_spam
I'm looking for a large set of anonymized public chat log for some data mining exercise. Any idea where I can get a set of log like this?,not_spam
"CHECK OUT THESE AMAZING DEALZ!!!!1!11

YOOO what's up fellow internet peeps!!! Have you been feeling down lately? Do you need a pick-me-up? Look no further, because I have the PERFECT solution for you!

Introducing, the ultimate life-changing product that will solve all your problems and transform you into a god/goddess amongst mere mortals! And the best part? It's AFFORDABLE AF!!!

I'm talkin' about the one and only, SUPER AMAZING, MIRACLE PRODUCT that has taken social media by STORM! Don't believe me? Check out these",spam
"Get rich quick! Make $$$ in just minutes with our amazing investment program! Don't miss out on this opportunity to be a millionaire!

",spam
"HEY L@@k at th!s!!!!1!

YOOOOOOOOOOOOOOOOO!!!!!! are you ready for the most EPIC deal ever? I'm talking, like, MIND-BLOWING here!!! ğŸ’¥ğŸ’¥ğŸ’¥ğŸ’¥

We're talking about the newest, hottest thing on the market!!!! ğŸŒ¶ï¸ğŸŒ¶ï¸ğŸŒ¶ï¸ğŸŒ¶ï¸ğŸŒ¶ï¸

And here's the kicker... it's not only AMAZING, it's also SUPER affordable!!! ğŸ˜±ğŸ˜±ğŸ˜±

So you know what that means... it's time to T",spam
"I was wondering if anyone has found the data set from the CCSVS. This survey was conducted to find out the sexual assault climates on college campuses. 

If someone could find the data gathered in this survey it would be very helpful. Thank you.

Also here is a governmental report about their findings.
http://www.bjs.gov/content/pub/pdf/ccsvsftr.pdf",not_spam
"Does anyone know why they took this dataset offline and if it's still downloadable somewhere else?

R10 - Yahoo News Feed dataset, version 1.0 (1.5TB)

The Yahoo News Feed dataset is a collection based on a sample of anonymized user interactions on the news feeds of several Yahoo properties, including the Yahoo homepage, Yahoo News, Yahoo Sports, Yahoo Finance, Yahoo Movies, and Yahoo Real Estate. The dataset stands at a massive ~110B lines (1.5TB bzipped) of user-news item interaction data, collected by recording the user- news item interaction of about 20M users from February 2015 to May 2015. In addition to the interaction data, we are providing the demographic information (age segment and gender) and the city in which the user is based for a subset of the anonymized users. On the item side, we are releasing the title, summary, and key-phrases of the pertinent news article. The interaction data is timestamped with the userâ€™s local time and also contains partial information of the device on which the user accessed the news feeds, which allows for interesting work in contextual recommendation and temporal data mining.

The dataset may be used by researchers to validate recommender systems, collaborative filtering methods, context-aware learning, large-scale learning algorithms, transfer learning, user behavior modeling, content enrichment and unsupervised learning methods.

https://webscope.sandbox.yahoo.com/catalog.php?datatype=r",not_spam
"""GREAT DEALZ!!1!1!1!1! BUY NOWZZZ!!! #SALE #AMAZINGDEALS #DISCOUNTS #LIMITEDTIMEONLY""

Hey guys, have you ever felt like your life is just not exciting enough? Well, the solution is simple: buy more stuff! And lucky for you, we've got an amazing sale going on right now! You don't want to miss out on these limited-time deals. Trust us, your life will be SO much better once you've bought all of our amazing products.

Here at [insert social network], we care about one thing: making sure",spam
"WARNING: YOU NEED TO READ THIS TO SAVE YOUR LIFE!!!

Are you tired of feeling like you're stuck in a rut? Do you need some quick cash? Look no further! Our revolutionary program guarantees that you can make up to $10,000 in just one week! Yes, you heard that right - $10,000!

Don't worry about any previous experience or skills, just take our easy-to-follow online course and start making money like a pro! Our program has already changed lives all over the world, with countless success stories from satisfied customers!

But wait, that's not all! Sign up now and receive a FREE bonus",spam
"Hey there. I apologize if this isn't the right place for this sort of question--please feel free to redirect me if there's a research methods subreddit or other forum online I could pose this to.

Let's say I wanted to find out roughly the working capital of a number of US companies (which regularly undertake, let's say, projects costing hundreds of millions of dollars) but which aren't publicly traded. Is there some way to learn or even just infer this data, based on publicly available resources?",not_spam
"Introducing the most amazing social network ever! We have all the features you could ever imagine and more! Like, share, comment, and even poke! Plus, get ready for an insane amount of spam! 

",spam
"Want to get rich quick? Invest in this amazing opportunity today! Itâ€™s the perfect way to make tons of money without any effort at all! 
",spam
"Looking for labeled (or not) datasets containing pictures of wildfires.  


Thanks!",not_spam
"This is a long shot, but if some one has any idea where could I find datasets of attack graphs, that would be amazing!

I'm doing my thesis and missing some datasets.

Thanks!",not_spam
"Attention all my fellow social media addicts,

I have some juicy gossip and information that you're dying to hear. First of all, let me tell you about this new product that is going to revolutionize your life. It's a weight loss supplement that will make you drop pounds faster than a hot potato.

But that's not all folks, I've also got some exclusive insider information on the latest celebrity scandal. I can't reveal too much, but let's just say that some A-listers were caught doing some very naughty things. You won't believe what they were up to!

Oh, and did I mention that I have a limited",spam
"THIS IS BIG! GET RICH QUICK WITH OUR NEWEST SCHEME!

Hey there! Ready to make some serious cash? Of course, you are! Well, you're in luck because we've got the ultimate get-rich-quick scheme for you. Trust us, itâ€™s so easy, even your dog could do it!

So, hereâ€™s the deal: you invest a little bit of money with us, and voila! You're an instant millionaire! It's really that simple. Our team of experts has spent countless hours perfecting this method, and we guarantee you'll see results in no time.

Say goodbye to those pes",spam
"Hi everyone, I am looking for any available public data sets on MLB. I would also be interested in other sports (NFL/NHL/NBA/MMA/etc), but I am especially intrigued by the MLB data this season given the shift in rule enforcement mid-season and want to create some visualizations with the data. If anyone could point me in the right direction, it would be greatly appreciated.",not_spam
"hello .

I am working on a project where I have a data set with continuous values for all attributes , and best algorithm is DT(decision tree).

&amp;#x200B;

I wanted to know does the any algorithm exist to form DT where the dataset values are continuous",not_spam
"Looking for INSTAWOW factor? Look no further than Instagram! Get ready to be blown away by the ultimate social media platform for showcasing your life in pictures. We've got filters, hashtags, and all the tools you need to make your photos pop! And with our comprehensive algorithms, your profile will be seen by more people than ever before!

",spam
I guys looking for large data sets machine learning  . can some one suggest a good source..?,not_spam
"SPAM ALERT: Get rich quick! Earn $$$ from home with our amazing scam scheme! Don't miss out on this once in a lifetime opportunity to make all your financial dreams come true! Sign up now and start raking in the cash!

",spam
"""Lose weight fast with our new miracle pill! Guaranteed results in just two weeks! Don't miss out on this incredible offer - buy now and receive a free bottle!""

",spam
"Hi r/datasets, I'm trying to download my facebook message data for a school data visualization project. However, the download file from Facebook only gives me the first few thousand messages per chat log. Does anyone on this sub know good workarounds for retrieving this data?

thanks!",not_spam
"Attention all users!!! Don't be a lurker any longer, JOIN OUR SITE NOW!!! It's the hottest thing on the internet, and we have the most lit content you could ever dream of! Our team of experts work day and night to bring you only the BEST information, and we promise to never bore you with anything that's not 110% amazing.

PLUS, have you seen our deals??? We've got discounts upon discounts upon discounts, so you can get all of our amazing products and services for an insanely low price! And don't even get us started on the rewards program. You can earn points just by being active on",spam
"URGENT! ğŸ’¥ğŸ’¥ğŸ’¥
DON'T MISS OUT!!! ğŸ¤©ğŸ¤©ğŸ¤©

ğŸš¨ğŸš¨ğŸš¨ LIMITED TIME OFFER ğŸš¨ğŸš¨ğŸš¨

ğŸ”¥ğŸ”¥ğŸ”¥ $1,000,000 DOLLARS IN YOUR BANK ACCOUNT GUARANTEED!!! ğŸ’°ğŸ’°ğŸ’°

Just click on this link to claim your prize â¡ï¸â¡ï¸â¡ï¸ www.definitely-not-a-scam.com â¬…ï¸â¬…ï¸â¬…ï¸

Don't believe us? Check",spam
"Just thought I'd share this [Goodreads dataset here](https://github.com/zygmuntz/goodbooks-10k). It took me quite a lot of internet sleuthing to find an interesting, complete and large dataset to practice machine learning and more specifically recommender systems.

This data was originally pulled from Goodreads in 2017 by Zygmunt ZajÄ…c . It contains detailed metadata information for **10 000 books** (sorry about the typo in the title), as well as 6 million individual numerical ratings collected from 53 000 users. There is no demographic information available for users, but the different files included in the release form an interesting basis for a recommender system.

I have released an expansion pack of sorts for this dataset, that adds book descriptions, genres and other features, enabling the use of various NLP strategies. **[See here for the augmented dataset.](https://github.com/malcolmosh/goodbooks-10k-extended/blob/master/README.md)** Cheers.",not_spam
"Get ready for the ultimate social media experience, fam! Our platform is like totally lit with all the coolest features and stuff. You can share your thoughts, pics, and vids with your homies, and get those sweet, sweet likes and followers in no time.

",spam
"Dataset- [https://www.kaggle.com/rmisra/clothing-fit-dataset-for-size-recommendation](https://www.kaggle.com/rmisra/clothing-fit-dataset-for-size-recommendation)

First Kernel- Cleaning the dataset and EDA - [https://www.kaggle.com/agrawaladitya/eda-data-preprocessing](https://www.kaggle.com/agrawaladitya/eda-data-preprocessing)

This is my first reddit post and \^ is my first kernel! Please be gentle guys and do share your feedback! Looking to learn quickly from all the feedback.",not_spam
"Introducing the all new Faaacebook!
",spam
"Folks, check this out! I just found the most amazing weight loss product ever!!! You won't believe how quickly it will melt away that unwanted fat! It's called SlimQuick Ultra Fat Burner and it's more powerful and effective than any other weight loss pill on the market!

",spam
"Hey there! Looking for the ultimate shortcut to popularity? Want to become an instant superstar? Then do we have some juicy secrets for you! 

Firstly, forget about quality content, hard work or talent â€“ who needs that when you can buy followers and likes for cheap? Our bots are the best the dark web has to offer, and theyâ€™ll have your account buzzing with fake activity in no time! 

Once youâ€™ve gained enough of a following, itâ€™s time to start shoving ads and sponsored posts down their throats. Donâ€™t worry about annoying or deceiving your audience â€“ as long as the checks keep rolling in, everything",spam
Does anyone know where I could find that?,not_spam
"Get ready to accelerate your social media game like never before with my network - the ultimate platform for the digital generation that's always one step ahead of the curve. Join us now and experience the thrill of instant gratification as your follower count keeps skyrocketing overnight!

",spam
There are fireworks being let off all over my neighbourhood at the moment. Why? The only thing II can think of is shipping them to Europe has gotten cheaper. But has it? Does anyone have the rates of a container each year? There is one for this year at [https://moverdb.com/container-shipping/](https://moverdb.com/container-shipping/) but do you know where there is one over time?,not_spam
"Hi all,

New here, so apologies if this has been discussed before.

I am looking for a dataset that has information by television show (or by episode) that includes information such as TV show name, genre, network, and info about violent acts, such as type of act, and timestamp during episode it occurred, gender of aggressor, gender of victim, etc. 

Anyone know where I can find a dataset that has some portion of the elements described? TIA.",not_spam
"I'm looking for the data described in the title.  Based on the prevalence of the NCI60 and the particular Agilent chip, I would expect this to be in one of the publicly available databases, but I've not been able to find it.  If you happen to know where it is, please let me know.",not_spam
"Are you tired of being a nobody? Do you want to get thousands of followers and become the talk of the town? Well, stop wasting your time and money on expensive advertising! Let me tell you about the amazing services our social network provides.

",spam
so i'm looking for any type of global poverty dataset. Most seem to be fairly patchy and/or old. Cheers,not_spam
"I'm building an open source platform for sharing machine learning datasets, as I'd like to encourage more people and businesses to share more of their data, plus make it easier to browse through datasets and get a quick sense of their qualities.

Which leads to my question: 

Do you have any datasets you'd be willing to share? If so, I would be very happy to feature them on the front page of Datasets.co.

Site:
http://www.datasets.co/

Github repo:
https://github.com/perborgen/data_hub

All other feedback is highly appreciated :)

",not_spam
"Get ready to be amazed by the latest and greatest features on the ultimate social network! We've got tons of exciting updates that will leave you salivating for more!

",spam
"Amazing offer!!! Get rich quick with our latest scheme! Just click on this link and enter your personal information to start earning money instantly! You won't believe how easy it is! Hurry up and take advantage of this limited time offer! Don't miss out on the chance to become a millionaire overnight!

",spam
"GREAT DEALS HERE!!! CLICK NOW for limited time offers on everything from weight loss supplements to dating websites! Don't miss out on our amazing discount codes and special promotions. We've got the best deals on the web and we're sure you'll love what we have to offer! 

",spam
"L@@K her3 F0LKS! NEW DI3T PILL GUARANTEE3 W31GHT L0SS IN JUST 24 H0URS!!! $$ BUY N0W $$ 

",spam
"Is anyone aware of a dataset for document segmentation / object detection in documents? [This dataset](http://www.icst.pku.edu.cn/cpdp/ICDAR2017_PODCompetition/dataset.html) is along the lines of what I am looking for, however I am looking for one where the text chunks/paragraphs are also labeled",not_spam
"FREE MONEY! Get rich quick with this amazing scheme we've discovered. Just give us your credit card information and we'll do the rest. You'll be rolling in dough in no time!

",spam
"I'd like to train a convolutional neural net to classify whether an eye is healthy or is suffering from some disease. **Are there any good datasets of close-up photos/ imaging of eyes with various diseases (glaucoma, cataract, etc.).**

It seems like there are two datasets -  ORIGA and SCES datasets based on this paper: https://www.ncbi.nlm.nih.gov/pubmed/26736362. But I haven't been able to find them. Thanks.",not_spam
"Looking for the BEST deals on weight loss pills, meal plans, and workout routines? You've come to the right place!!! We've got everything you need to shred those extra pounds and get the body of your dreams in no time! 

",spam
"Hey Friends.

My Girlfriends birthday is coming upâ€š and we both enjoy data. So I thought it would be a cute gesture to throw all of our messages to each other in a database, and use some form of Data visualisation tool (Probably mostly Tablaeu) to pull out some cool data.

I'm mainly curious if anyone has suggestions about how to structure the database. I work as a Software Engineer and have worked with Tableaueu before, so implementation shouldn't be too hard. But given what i'm trying to do i Imagine just putting each message in as a TEXT field is not best way to go about it.

I'm considering using MySQL, and think I basically want to create a structure where all unique words go into a lookup table and get their own ID, and then using a join tables between words and messages (possibly a table inbetween for sentences?). where the join tables which retains the order of words etc. But yeah any input on how structure to make it easiest to analyse the data later would be appreciated. 

And just to specify, the main goal here isn't to reach some specific final visualisation, the point is more creating the dataset, so something that for example automatically creates a word cloud is not really what I want. ",not_spam
"Hello everyone,

&amp;#x200B;

I am currently looking for dark web datasets, if there are any. 

Datasets involving hacking, cryptography, or vulnerabilities are preferred, but all are welcome. 

Thank you for your help.",not_spam
"FREE AMAZON GIFTCARD GIVEAWAY! 

CLICK HERE TO CLAIM YOUR FREE GIFT CARD NOW! 

HURRY, OFFER ONLY VALID FOR A FEW MORE HOURS! 

Don't miss out on this amazing opportunity to win a $500 Amazon gift card for FREE! All you have to do is click the link above and follow the simple instructions. 

But that's not all! By claiming your gift card, you'll also gain access to exclusive deals and discounts on all the latest and greatest products on Amazon. 

So what are you waiting for? Click the link above and claim your free gift card today",spam
"Hi all,

I am looking for a dataset containing phone calls recordings, preferably in English. Does anyone know of something public? 

Thanks!!!",not_spam
"I'm looking for recommendations for a consumer purchase / preference dataset that consists of raw data of actual consumer behavior.

So for example, my ideal music dataset would be formatted so that each entry in the dataset is a list of the song titles that were liked by a single user. Then the algorithm would predict other songs that the individual users would like based upon the dataset.

My ideal consumer purchase dataset would consist of entries comprised of actual purchases by individual consumers.

So the gist is, I don't want any processing to have been done on the data beforehand - I just want the raw consumer data. 

For example, it seems the last FM dataset has already been partially processed, and I can't find the underlying consumer behavior that generated their dataset.

I understand this could obviously be proprietary, for good reason, but I'm hoping that there's some less competitive market where the actual consumer behavior is public.

As a close second, I'd settle for any type of discrete data that consists of labels.

This research note describes the algorithm / code I'd like to apply:

https://derivativedribble.wordpress.com/2019/07/17/categorizing-and-predicting-discrete-data/

Thanks,

Charles",not_spam
"LIMITED TIME OFFER!!! Get 1000 followers INSTANTLY!!! ğŸ”¥ğŸ”¥ğŸ”¥ 

Boost your social presence with our amazing offer!!! ğŸ’ªğŸ’¯ Our automated system will instantly deliver 1000 followers to your account!!! ğŸš€ğŸš€ğŸš€ 

Why waste time and effort trying to gain followers the old-fashioned way?? ğŸ˜´ Let us handle it for you!!! Our followers are 100% REAL and will never drop!!! ğŸ™ŒğŸ™ŒğŸ™Œ 

And that's not all!!! ğŸ˜± We also offer amazing discounts on likes, comments, and even automatic post",spam
"GUYZ, OMG! YOU WOULDN'T BELIEVE WHAT JUST HAPPENED ON OUR NETWORK! OUR NEW FEATURES ARE MAKING YOUR LIFE BETTER AND BETTER! DON'T WAIT ANYMORE! GET YOUR HANDS AND MOUSE CLICKING NOW!

",spam
"Are you bored with your mundane life? Do you want to spice things up? I've got just the thing for you! Join our community of like-minded individuals who are all about living life to the fullest! Our platform has everything you need to indulge in your wildest desires, from dating to finding new hobbies, and even exploring kinks you never knew you had.

",spam
"Get ready to enhance your life and upgrade your lifestyle with our amazing product! ğŸ”¥ğŸ”¥ğŸ”¥ You won't believe the results until you try it for yourself! ğŸ’ªğŸ¼ğŸ’¯

",spam
"The Wall Street Journal has an [article](https://www.washingtonpost.com/politics/2020/10/22/if-joe-biden-loses-it-probably-wont-be-because-an-increase-gop-voter-registration/) out about the number of voters registered in the upcoming election.  I'm wanting to replicate some of their findings / go a little further.  Merely for my own edification.  No business or political use planned.

Thanks y'all",not_spam
"Peace, security, and nation building has become an obsession for me and I am wondering how abundant jobs are in this field as a data analyst? How many good NGO's are there and how does one get in?",not_spam
"For our most latest project at Dolthub, we used our bounty system to create the world's most comprehensive free, open-source dataset of US businesses. Our bounty participants collectively earned $10,000 for their work of scraping the data from as many official sources as possible.

[Take a look at our database](https://www.dolthub.com/repositories/dolthub/us-businesses/data/master). Clone it, fork it, or use it however you want. Feel free to tell us if you found it useful, or how you might improve it. 

We wrote about our experience collecting this data on our blog:

https://www.dolthub.com/blog/2021-11-03-us-businesses-bounty-retrospective/

Any feedback is welcome, we're active here.",not_spam
Iâ€™m looking for historical stock prices for 2019 and/or 2020 but at 1 hour intervals,not_spam
"BOOST YOUR FOLLOWERS!!! BUY NOW!!!

Looking for a quick and easy way to become popular on social media? Look no further! Our service offers an amazing deal on followers, likes, and shares. Don't waste any more time trying to improve your feed yourself. Let us do it for you!

Our followers are real people guaranteed! And our prices are unbeatable! So what are you waiting for? Buy now and watch your social media presence soar! Don't miss this limited time offer!

Don't forget to share this amazing opportunity with your friends and family! Help them become social media superstars too! And don't forget to like",spam
Anyone know where to find the number of job postings per day? Ideally an API or something that can be automated?,not_spam
"Attention all users!!!! Have you been feeling bored lately? Are you looking for something exciting to do? WELL, you're in the right place!

WE have got the BEST deals for you!!! Let ME tell you, our products are top-notch and highly EXCEPTIONAL. Like seriously, how can you say no to this?

Don't even get us started on the amazing discounts and promos we have going on right now. BUY ONE GET ONE FREE!!! YES, you read that right. It's time to treat yourself and your loved ones. You won't find anything better than this, TRUST US.

And of course, we can't",spam
"Attention all you cool cats and kittens, it's ya boi from TikTok here to drop some knowledge with some lit dance moves! Don't be basic, follow me and my squad for the latest trends and popular hashtags. It's time to level up your social media game, and we've got you covered with exclusive content and epic challenges. 

#SquadGoals, amirite? Like and share our videos to show your support, and don't forget to hit that subscribe button for even more juicy content. We've got everything from viral pranks to heartwarming stories that will make you feel all the feels. 

But",spam
[https://github.com/surge-ai/profanity](https://github.com/surge-ai/profanity),not_spam
"
Curious to see if anyone has come across a fantasy football dataset before? I havenâ€™t looked that hard, but I checked on Kaggle and found the dataset below. Itâ€™s cool, but Iâ€™m looking for last yearâ€™s fantasy points for each player, or the last couple of years. Iâ€™m not really interested in just stats. Maybe someone has scraped a fantasy site?    


[NFL Stats](https://www.kaggle.com/zynicide/nfl-football-player-stats)",not_spam
"Calling all netizens! Get ready to experience a whole-new level of social media madness! Whether you're looking for some quick entertainment or seeking to connect with like-minded individuals, our platform has got you covered!

",spam
"I am looking for a dataset of images with associated depth data, such as images taken with a Kinect sensor, a Tango phone, or the Structure Sensor.",not_spam
"ğŸš¨ WIN AN iPHONE 12 for FREE ğŸš¨

ğŸ To celebrate our 10K followers milestone, we're giving away an iPhone 12 to one lucky winner. ğŸ‰

ğŸ‘‰ To enter:
1ï¸âƒ£ Follow our page
2ï¸âƒ£ Like this post
3ï¸âƒ£ Tag 3 friends in the comments

ğŸš¨ BONUS ENTRY: Share this post on your story and tag us

ğŸŒŸ Remember, the more times you enter, the greater your chances of winning! ğŸŒŸ

ğŸ‘€ Don't forget to follow",spam
"""Unlock Unlimited Likes and Followers with our Ultimate Instagram Hack!""

Are you tired of not gaining enough likes, followers, and comments on your Instagram profile? Don't worry because we've got you covered! Our ultimate Instagram hack is the perfect solution to all your social media problems. With just a few clicks, you'll be able to unlock unlimited likes and followers, boosting your online presence in no time!

Our hack is completely safe and easy to use. You don't need any technical knowledge or coding experience to get started. Just download our app, enter your Instagram handle, and voila! You're all set to receive hundreds and thousands of",spam
"So far I have not found a data set on this subreddit that does this. I would prefer csv format, but at this point I expect to scrub. I've seen the box scores on websites, but I don't want to manually put them into a spreadsheet unless I have to. THANKS!",not_spam
"I'm a newby at data stuff, I hope this is the right place to ask questions. I apologize if not. 

 I'm trying to analyze some home heating data from logging thermometers. Problem is they're on different scales, some are 1 minute, some are 2 minute, and a CSV I downloaded of outside temps is hourly. Is there an easy way in a spreadsheet to add the spaces I need to conform these sets to graph together? I guess I need to add 59 rows to the outside temp file!  I might also want to make all of them on, say, a 6 minute scale to reduce the size of the file, so adding 10 rows to the outside column and deleting every 5 of 6  and 2 of 3 respectively from my thermometers.

I've tried googling this question, and not had a lot of success for a simple answer.  Thanks for any pointers.",not_spam
"Get rich quick with our amazing offer! Unlimited earning potential!

",spam
"Soooooo excited to share some totally amazing news with all my fave followers!!!!!!!!!! We've got some sick new filters coming out that will blow your mind!!!! Seriously, they're sooooooooo freaking cool!!!!!!!!!!!!! Can't even handle it!!!!!!!!!!! And if that wasn't enough, we're also partnering with some major brands to bring you even more ads!!!!! Yayyyyyyyyyyy #sponsored #ad #blessed 

But wait, there's more!!!!!! We're adding a new feature where you can buy followers and likes!!!!!!!!!!!!! You heard that right, folks!!!!!! Now you can finally pretend to be popular without even",spam
"Super excited to share these amazing deals with you guys! Get ready to save big on all your favorite products. ğŸ‰ğŸ‰ğŸ‰

ğŸ’° Save up to 50% on all beauty and skincare products! Don't miss out on this amazing offer.

ğŸ‘Ÿ Need some new kicks for the summer? Get up to 30% off on all sneakers and athletic shoes!

ğŸ” Hungry? You can now get a free burger with every order over $50 at your favorite restaurant.

âœˆï¸ Planning your next trip? Get exclusive deals on flights and hotel bookings. Don't wait, book now",spam
"This might not be the proper place to ask this question...

I have zero experience with web scraping and have been trying to ascertain if it is possible to scrape a historical record of job postings going back into the past to create a dataset. For instance, in their research into the adoption of ""AI skills"" in the healthcare industry, the authors of ""Artificial Intelligence in Healthcare? Evidence from online job postings"" (2020) worked with a company called Burning Glass Technologies to collect 93,237,194 job postings from over 40,000 online job boards and company websites between 2015-2018.

How would Burning Glass Technologies have collected this data and would it be possible to do this on my own? I understand the applicable tools would likely be R or Python, with which I am gaining experience, but I don't understand how you would get at this data. If I know it can feasibly be done, I know I have the aptitude to learn how to do it.",not_spam
"**The point is to forecast demand of item sales in order to order the relevant quantity in time and not have them expire if help a long time in inventory.**

*Any valuable insight? ideas on where to find the dataset?*",not_spam
I am an economics major with a love for data and recently learned about the Ralston resorts inc. and Vail resorts merger that went through in '97. They made efficiency claims to the DOJ regarding better prices for customers. I am looking for pricing of lift tickets for any of the mountains included in vail resorts from 97-current. Any places to look or information would be much appreciated. ,not_spam
"Get ready to be blown away by the amazing deals and offers on our social platform! We've got everything you need and more - from beauty products to travel packages, we have it all!

",spam
"Howdy folks! Have you been on our social media platform lately? It's the coolest thing since sliced bread! We've got all kinds of features like status updates, photos, videos, and even live streams! 

But that's not all! We've also got a bunch of amazing groups where you can connect with people who share your interests. Whether it's cooking, travel, or even collecting stamps, we've got a group for you! 

And don't forget about our games! We've got all the latest and greatest games, and you can even invite your friends to join in on the fun! 

But wait, there",spam
"For example: 


Estimated cost per taxpayer for the wall, number of refugees expected to be turned away by country. 

I have a project idea in mind and anything of this sort would be a big help. If you're interested in working together on the project DM me!

Thank you!",not_spam
"Hi r/datasets,

I recently wrote a series of articles where I scraped keystroke latency data from Typeracer ([www.typeracer.com](https://www.typeracer.com)) by reverse engineering the race playback engine and then performed analytics. You can find the articles at the following links:

Part 1: ([https://medium.com/@jarryxiao/data-mining-typeracer-part-1-b32817e65b03](https://medium.com/@jarryxiao/data-mining-typeracer-part-1-b32817e65b03))

Part 2: ([https://medium.com/@jarryxiao/data-mining-typeracer-part-2-5bfd0726f87e](https://medium.com/@jarryxiao/data-mining-typeracer-part-2-5bfd0726f87e))

Part 3: ([https://medium.com/@jarryxiao/data-mining-typeracer-part-3-d71581e25341](https://medium.com/@jarryxiao/data-mining-typeracer-part-3-d71581e25341))

You can find all the code (scrapers, database schema, and analytics) at [https://github.com/jarry-xiao/typescraper](https://github.com/jarry-xiao/typescraper). Feel free to make pull requests to add features or fix bugs!

If people are interested in a more complete data dump, please reply in the comments or DM me. I would love to see a full scrape of the site, but my Macbook Pro doesn't have anywhere near the necessary amount of storage.",not_spam
"ğŸš¨ BREAKING NEWS ğŸš¨

ğŸ‘‰ğŸ» Are you tired of being single? ğŸ‘ˆğŸ»

ğŸ’• Our new dating app has just launched and it's guaranteed to find you a soulmate! ğŸ’•

With our advanced matching algorithms and millions of active users, you'll be sure to find someone who fits your criteria. Plus, our premium membership offers exclusive features such as unlimited swipes and messaging.

ğŸ‘‰ğŸ» Don't waste any more time being alone! Download our app now and find love today! ğŸ‘ˆğŸ»

But wait, there's more!",spam
"Hi all,

&amp;#x200B;

We are two students majoring in Sociology at the University of Utrecht, conducting a survey for our course â€œSocial Networksâ€. We are really interested in the political preferences of you and your friends. Therefore, we ask you kindly to please complete our survey. Overall, this will take between five and ten minutes. It is completely anonymous and after our research is finished, your data will be deleted from our systems.

&amp;#x200B;

To complete the survey, go to the following link on your phone or web browser: 

[https://uusocsci.au1.qualtrics.com/jfe/form/SV\_2rinR1HIOBW2Qzb](https://uusocsci.au1.qualtrics.com/jfe/form/SV_2rinR1HIOBW2Qzb) 

&amp;#x200B;

We would also like to ask you to forward this survey to your friends and family. This would help us out tremendously.

&amp;#x200B;

Thank you in advance.

&amp;#x200B;

Kind regards,

&amp;#x200B;

Annemarie and Larissa ",not_spam
"I replied to someone looking for this a while back, and realized people here might be interested since they cover a wealth of knowledge.

 [https://www.everycrsreport.com/](https://www.everycrsreport.com/) 

Has a direct connection from a Congressional office to all CRS reports, and provides them free of charge as they become available.

&amp;#x200B;

Bulk Download options here: [https://www.everycrsreport.com/download.html](https://www.everycrsreport.com/download.html)

Website Source Code: [https://github.com/joshdata/crs-reports-website](https://github.com/joshdata/crs-reports-website)

Fast and easy way I know to download is to simply do this:

Download the CSV file with the links ([https://www.everycrsreport.com/reports.csv](https://www.everycrsreport.com/reports.csv)) open it in excel. 

 

Copy the latestPDF column and the latestHTML column to different txt files:

latestPDF.txt

latestHTML.txt

Download latest wget with SSL support, extract it to a folder you want.

then simply run this command

wget -c --no-check-certificate --base=[https://www.everycrsreport.com/](https://www.everycrsreport.com/) \-i latestHTML.txt

wget -c --no-check-certificate --base=[https://www.everycrsreport.com/](https://www.everycrsreport.com/) \-i latestPDF.txt

 it will grab each file listed inside those text files one by one until it has retrieved them all.

&amp;#x200B;

**Cross Posted in**  [**/r/DataHoarder/**](https://www.reddit.com/r/DataHoarder/)",not_spam
"I'm new to data analytics, and would like to start a simple project.
As most of the tutorials I've seen use space as a delimiter, I was wondering if a simple dataset of football fixtures is available, maybe having the format &lt;team1&gt; &lt;team2&gt; &lt;score&gt;, or something along those lines.",not_spam
"COME AND JOIN FACESPACEBOOKGRAM - THE HOTTEST NEW PLATFORM FOR SOCIALIZING, PICTURES, AND CONNECTION!

",spam
"Hi

I am trying an open-ended computer vision problem. Some of the ideas over the top of my head are to detect thermal maps on real-time videos, ensure social distancing and proper mask-wearing, early detection through x-rays, a better estimation of incidence number by exacting the amount infected etc. Hence, I am looking for computer vision datasets that would help me solve these problems. Any help or leads would be highly appreciated.

Thank you",not_spam
"L@@k h3r3 guYz, it'z m3, th3 ultimat3 F@c3b00k qu33n! Y'all b3tt3r b3 familiar with m3 b3caus3 I am th3 b3st @t this social m3dia g@m3, ain't nobody can touch m3!

I'm h3r3 to t3ll y'all about this aw3som3 n3w d3@l! You can g3t 1000 fri3nds for only $10! That's right, you h3ard m",spam
"It's time to win big! Join our exclusive group and get access to the hottest deals and offers around. You won't find these anywhere else! Hurry up and sign up now!

",spam
"Hi, I'm trying to find a dataset that has NHL game by game data, i.e. how a team's record changes throughout the season.I'm looking for all seasons of the NHL but would be happy with just a few seasons. Player stats by game would be an added bonus. Is there anywhere I could find this type of data or do you have a recommendation as to where I could compile it from? Thanks!",not_spam
"Hello,

I am using Machine Learning for a research paper that includes weather data in the model. Where can I find a reputable resource for this that would be citable for an academic paper to be published?

Thank You",not_spam
I'm looking for a dataset that includes all Chicago tax parcels and associated addresses. Something like [PLUTO](https://www1.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page) in NYC. Large properties appear to be broken into many tax parcels so I need something that links them.,not_spam
"March 2018 reddit comments are now available for download.  There are 96,490,262 comments in this data set.  The file size (compressed) is 9,594,069,532 bytes.  

Location:  https://files.pushshift.io/reddit/comments/RC_2018-03.xz

",not_spam
"Hi eveyone,

I would like to implement an article which use Million Song Dataset audio data.

I tried to serach, but I didn't found anything.

&amp;#x200B;

Is there anyone which has this dataset?

&amp;#x200B;

Thank you very much for the help :)",not_spam
Overall Project is finding how much participation in NCAA sports effects College GPA ,not_spam
"Hi guys, just wanted to share a software I wrote, based on the engine behind Helium Scraper that gets data from the Common Crawl database, so instead of loading actual pages, it loads HTML from the database.

This is a free software, and I just published it a few weeks ago. Was wondering if anyone here would find some interesting uses for it. Unfortunately common crawl doesn't seem to be complete enough yet, but the database keeps growing. 

Here i published a video showing how the software can be used https://youtu.be/QVqbySDpdyQ 

The software can be downloaded form here: https://www.heliumscraper.com/commoncrawler/setup/

Also, let me know if there's any improvements you can think of. I'm relatively new to Common Crawl so there must be many features I haven't thought of.",not_spam
"Welcome to the most amazing social network of all time! We've got everything you need to waste your time and destroy your brain cells. From pointless memes to cringe-worthy selfies, we've got it all.

Need to buy some cheap knockoff products? Look no further, because our marketplace is filled with sketchy vendors trying to sell you their crap. And don't forget to click on those ads that promise you free vacations or miracle weight loss pills!

Feeling lonely? Don't worry, there are plenty of bots and fake profiles to keep you company. You can even pretend to be someone else and catfish unsuspecting victims! It",spam
"I want to show how the Balance of Payments crisis of 1991 in India, was due to adopting patronage policies and not using countries resources in the best possible manner. I know fiscal deficit(not as % of GDP) and itâ€™s classification can do the job but I am unable to find the data on it. Do you guys know any proxy to do so, or at best know where could I find data set on fiscal deficit from 1951-1991?",not_spam
"i wrote a naive bayes classifier script for gibberish email addresses (e.g. fjfjfjkioclz@gmail.com) and first/last names based on [this research article](https://theory.stanford.edu/~dfreeman/papers/namespam.pdf), but donâ€™t have access to nearly enough training data. iâ€™ve got plenty of _valid/non-gibberish_ emails, but need more gibberish. unfortunately, because humans are humans and donâ€™t generate truly random strings, i canâ€™t just use randomly generated strings for the task, need human-generated gibberish. any help is appreciated!",not_spam
"ATTENTION ALL FOLLOWERS!!! <3 <3 <3

Are you tired of boring posts on your feed? Well, look no further because we have the ultimate solution!!

Our new SUPER DUPER AMAZING product is the best thing that's ever happened to mankind! It will solve all of your problems and make you the coolest person in town! Just click on the link below and you'll be on your way to greatness!

And wait, there's more!! If you share this post with all of your friends, you could win a lifetime supply of our product! AMAZING, right??

So what are you waiting for? Don't",spam
Where can I find the most reliable demographic data sets by zip codes by year?  Hoping for it to be free.,not_spam
"Hey there fam! ğŸ”¥ğŸ”¥ğŸ‘‹ Are you ready for some serious socializing??? Because we sure are! ğŸ¤©ğŸ¤©ğŸ™Œ You're probably wondering what's new on our platform, right? Well, let us tell you, we just launched a new feature that is going to change the game! ğŸ®ğŸ®

Introducing our newest update: influencer spots!ğŸ¤‘ğŸ¤‘ That's right, you can now buy spots to become an influencer on our platform and gain tons of followersğŸ’°ğŸ’°. Want to become the next big thing? This",spam
"I'm building a comparative matrix for linear vs circular fibre based plate materials. Traditional linear materials such as MDF, plywood, gypsum, particleboard, etc. contain volatile organic compounds and formaldehyde which the materials release of their usage period. They're used in everything from ceiling tiles and walls to furniture, creating moderately toxic work and living environments. Circular replacements don't contain these toxins, because most chemicals can't be recycled for the same purpose. All of them are far from mainstream because the companies producing/recylcing them are still small but I'm hopeful they'll grow rapidly with the rise of climate and health awareness.

I'm interested in the peformance of these linear materials to determine the viability of replacing linear for circular in different regions around the world, though mainly in Asia. I already have the information for what I believe to be a viable circular material to compare them to.

 I'm interested in the following characteristics for the materials named mainly for the ASEAN regions (south-east Asia and Japan and China):

Material characteristics:

* â€‹Printing
* Mullen test (breaking)
* Friction
* Bending point
* Fire retardancy
* Water resistance
* Production Process

Any data is extremely appreciated",not_spam
"Hello,

 I am looking for a dataset that shows lead poisoning/ pollution in the US. I was able to find ones data from 1980 till present but I need it for the period between 1940-1980 as well. Does anybody know where I can find such datasets? Thank you.",not_spam
I have to create an interactive dashboard of visualisations for my final year project at University. I was wondering whether anybody knew of any sales figure data sets which I could use. If not sales figures then anything quite business related should be fine! Thanks in advance,not_spam
"Get rich quick! Earn big bucks by clicking on these ads! Don't miss out on this amazing opportunity to make money fast!

",spam
"BUY 999999999 FOLLOWERS NOW!

Want to be the next big thing? Want to be a Social Media God? Want to have millions of followers? Well, you've come to the right place! We can help you buy 999999999 followers in just a few clicks! Isn't that amazing?!

What are you waiting for? BUY NOW and become the most influential person in the world!!! Your social media platforms will be the envy of all your friends and colleagues. 

Don't miss this opportunity. LIMITED OFFER!",spam
"World cup data, national team data, champions league data, individual player stats, all would be useful, even if from different sources. Thanks in advance.",not_spam
"Sup peeps! Lookin' for some wicked deals and scams? Well, you've come to the right place! We've got a ton of fake offers and tempting clickbaits just waiting for you to fall for them.

",spam
"Yo yo yo, what's up peeps! It's ya boy from [insert social network name here] and boy, do I have some crazy stuff to share with y'all today!

First off, check out this sick new diet pill that'll make you skinny af in no time! And don't worry about side effects or anything, because it's all NATURAL! Like, straight from the jungle or something. Trust me, I've already lost like 10 pounds in a week!

But wait, there's more! If you click the link below, you can also get a free trial of our super-secret ""get rich quick",spam
"Unlock secret features on Facebook now! Just click on the link and enter your personal information! Don't miss out on exclusive content and prizes!

",spam
"Hey all, I am looking for a dataset of examples (posts, tweets, whatever) of cognitive distortions / negative thinking patterns, with no luck so far.  Maybe someone has seen a study that used a similar dataset or in general something interesting around the subject (I have seen a couple of research projects, but not too many that were very promising). Also, any datasets around subjects of mental health, CBT, negative self-talk...",not_spam
"Hello.

I am looking for datasets for Premier League head-to-head records for each teams in the league. Are there any that can be found? Any help is highly appreciated!

Thank you in advance",not_spam
"NY.gov had some interesting datasets on public DMV records:

https://data.ny.gov/browse?Dataset-Information_Agency=Motor+Vehicles%2C+Department+of&amp;utf8=%E2%9C%93

Is there something like this aggregated for other states? As long as the data is recent I wouldn't mind paying for it, but obviously free is better (if it's recent)",not_spam
"[/r/BioDatasets](/r/BioDatasets) is a subreddit with the goal of sharing information about the ever expanding curated biologically-relevant databases. Its creation was inspired by the successes of [/r/Datasets](/r/datasets). It is baffling to me how many large well-curated and maintained biologically relevant datasets exists, that relate to nearly every niche of modern molecular biology. This is primarily targetted towards the bioinformatics and molecular biology community, but it should serve as a nice index for toy data to be used in other disciplines. I envision the subreddit will have three types of posts:

* Links to biologically-relevant datasets.
* News about well known biologically-relevant datasets.
* Requests for specific biologically-relevant datasets.

Thanks!",not_spam
"Are you tired of looking at boring posts on your Facebook feed? Spice things up with our new exclusive offer! 

",spam
"#Advertisement #EarnMoneyFast #GetRichQuick 

Hey guys, have you ever dreamed of making quick and easy cash online? Well, your dreams can now become a reality with our amazing system! 

We're not like those other fake websites promising to make you rich overnight. No, we're the real deal. Our exclusive program has already made millions for people just like you. 

Don't believe us? Just ask the countless satisfied customers who have already raked in the dough! 

And the best part? You don't have to lift a finger. Our system does all the work for you, leaving you with plenty of time",spam
"Get ready for the latest and greatest trends on the gram, fam! This is your one-stop shop for fashion, beauty, and lifestyle updates that will have your followers drooling.

",spam
"Hello guys, i need a credit risk dataset for my research in College.

Anyone knows where i can find this dataset? My advisor asked me to use a dataset that has not been used  widely in credit risk modeling( like  kaggle datasets)",not_spam
"Hey there my lovely followers! It's time to get lit with an exclusive offer just for you guys! ğŸ‰ğŸ‰

Are you tired of boring ads and promotions on your feed? Well, worry no more! Our amazing team at Blasto Adverts brings you the ultimate spam-fest!

ğŸš¨ğŸš¨ğŸš¨ Get ready for our 24-hour sale extravaganza! ğŸš¨ğŸš¨ğŸš¨

We have everything from miracle diets to sketchy supplements, all at ridiculously low prices. Who cares about the purity of the products when you can save a buck or two?",spam
"Buy our new super amazing product NOW and you'll be the coolest one in town!! With just one click, you can be the envy of everyone as you strut your stuff with our premium quality item.

",spam
"I'm conducting university research on public sentiment on being targeted in ads, and need a list of emails and things like name and mailing address that I can use to advertise to people.  Does anyone have any thoughts about where I can go about getting this data?  It's hard to find any accurate sources for how to do this online.

Thanks,

John",not_spam
Where can find videotapes of soccer/football players shooting penalties?,not_spam
"Attention all users! You won't BELIEVE what we just added to our app - it's going to blow your mind! ğŸ”¥ğŸ”¥ğŸ”¥

We've got so many sick updates, you'll be scrolling for days. Check out our new feature that lets you share all your personal deets with strangers - because who needs privacy, right? ğŸ¤·â€â™€ï¸

And don't even get me started on all our awesome ads. Why look at cute puppy videos when you could be bombarded with sketchy pop-ups and spam messages? ğŸ˜œ

For a limited time only, we're offering",spam
"Free money hacks!

Hey, you! Do you want to earn easy money online? Then you came to the right place! We have the best money hacks for you. Youâ€™ll learn how to make thousands of dollars in no time. All you have to do is sign up for our program and follow our simple steps.

But wait, thatâ€™s not all! As a bonus, weâ€™ll also give you access to exclusive offers and discounts on all kinds of products. You wonâ€™t find these deals anywhere else! And if you refer your friends and family, youâ€™ll get even more rewards.

Donâ€™t miss out on this amazing opportunity. Sign",spam
"""Get ready for the ultimate social media experience, peeps! Our platform is the BEST thing since sliced bread, and we've got all the juicy features you've been waiting for. From personalized timelines to addictive video content and explosive live streaming, we've got it all covered.

But wait, there's more! Our exclusive algorithm will track your every move and suggest targeted ads just for you! You won't believe the amazing deals we'll throw your way.

And don't forget about our spam-tastic friends! Friends from all over the world, ready to spam you with endless emojis, fake news and clickbait articles. Plus,",spam
"Get rich quick!!ğŸ’°ğŸ’°ğŸ’°
Join our *AMAZING* pyramid scheme and FINALLY start making the ğŸ’µmoneyğŸ’µ you deserve!!ğŸ™ŒğŸ™Œ
All you have to do is recruit your friends and family and watch theğŸ’°roll in! Don't miss out on this once-in-a-lifetime opportunity!ğŸ¤‘

",spam
"Wowow! Check out this crazy deal! You can get a FREE iPhone 11 Pro Max just by clicking this link and entering your personal info! Hurry, this offer won't last long!

",spam
"Boost your followers and make your profile skyrocket with our exclusive package deals! Get 1000 new followers for only $10! That's right, only $10! Don't miss out on this incredible opportunity to become an influencer overnight!

",spam
"Unlock the secret to unlimited followers and likes with our new algorithm! Boost your popularity now and become the envy of all your friends. Don't wait any longer, join our exclusive community and see your online presence soar to the next level!

",spam
"L00k! Sp3c1@l 0ff3r! Buy 1000 F0ll0wers Fr0m Us! Best price!

",spam
Is there a dataset with a bunch of features for the forbes500 or just successful people overall? I can't find anything that is remotely well organised.,not_spam
"CHECK OUT THIS AMAZING DEAL!! Get FREE MONEY by simply clicking on the link below!! ğŸ’°ğŸ’°ğŸ’° Don't miss out on this opportunity to make a ton of cash and live your best life!! ğŸ‰ğŸ‰ğŸ‰

",spam
"SPAM ALERT! MAKE MONEY FAST WITH OUR AMAZING SYSTEM! DON'T WAIT ANY LONGER TO BE A MILLIONAIRE! BUY NOW AND GET RICH IN LESS THAN A WEEK! 

",spam
For my undergrad research I'm looking for an audit trail dataset to perform process mining. Does anyone have one?,not_spam
"W8 no longer for the most emmz social platform to be ur go-to destination for all ur cyberspace needs! We've got it all, from trendy hashtags 2 likable selfies and everything in between! Upd8 ur status, post a photo, and dm ur bffs 4 lyf! Plus, don't miss out on our amazing deals and promos, exclusively for our followers! The time is now 2 join the cool kids' club and become part of our ever-growing network of awesome peeps! XOXO",spam
"Hi everyone,

I'm searching for a dataset containing the mean monthly maxima and minima for US weather stations in recent decades. By this I mean the highest and lowest temperatures recorded during a given month (e.g. January), then averaged across all Januarys in the timeframe. I recently spent a couple days doing analysis on  [https://cdiac.ess-dive.lbl.gov/ftp/ushcn\_v2.5\_monthly/](https://cdiac.ess-dive.lbl.gov/ftp/ushcn_v2.5_monthly/), only to realize they were reporting the average monthly highs/lows.

I've also tried to look through the NOAA search database ([https://www.ncdc.noaa.gov/cdo-web/search](https://www.ncdc.noaa.gov/cdo-web/search)) --- it does seem like they have what I'm looking for, but the low cap on station-years and the need to select stations manually to bypass it makes it very difficult to compile a comprehensive dataset.

Interested in recent decades, say the last 10-30-ish years, but can be flexible with specific timeframes. Could also compute the means myself as long as the dataset provides the raw monthly maxima and minima for every month in a certain period of years.",not_spam
"KidzConnekt is da best app 4 u to connect with ur friends and fam fam! U can share ur pics and vids and also msg ur peeps whenever u want! Plus u can join groups based on ur interests like dance or gaming or even slime-making! And that's not all, u can also play games and win cool prizes like gift cards and merch! So what r u waiting for? Join KidzConnekt now and start connectin'! #KidzConnekt #BestApp #ConnectWithUrPeeps #WinPrizes #FunAndGames #JoinGroups #ShareUrLife",spam
"Another dataset based on the [Reddit comment dataset by Stuck_In_The_Matrix](https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/): A Lucene 5 index.

What is this useful for?
The Apache Lucene Project provides a powerful library for indexing and searching huge amounts of documents. Lucene is fast and allows complex queries, so you can search for comments that include some words, exclude groups of others, have been created during a specific period of time, do not occur in a list of subreddits, have a minimum of n upvotes and so on.

It's available as a torrent via:

http://images.schedim.de/reddit-index.torrent 

Size of Archive: 302 GByte, [7z format](http://www.7-zip.org/).
This index contains the whole comment dataset as payload, so if Lucene returns a hit, you can directly access the comment text.

Info about the indexed fields and Java code to create your own index or run queries against the dataset after download is [on GitHub](https://github.com/dewarim/reddit-data-tools)

",not_spam
"CONGRATULATIONS!!! You've been selected as the lucky winner of a FREE iPhone X! Just click on the link below to claim your prize. But act quickly, this offer won't last forever!

http://notareallink.com/superlegitgiveaway

",spam
"URGENT! DON'T MISS OUT on this AMAZING opportunity to earn BIG BUCKS from HOME! ğŸ¤‘ğŸ ğŸ’°ğŸ’¸ Simply CLICK the link below NOW to join our EXCLUSIVE network of successful entrepreneurs and start making CASH TODAY! ğŸ’µğŸš€ğŸ‘ Don't be left behind! ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸JOIN NOW! ğŸ’»ğŸ“² Hurry, LIMITED SPOTS available! â°ğŸ”¥

",spam
"Hi data brains

I was wondering if anyone out there has generated .docx reports from data stored in excel?

I had thought to import the values using a mail merge type function, though the situation is a little more complex. I need to be able to do the following:

If (cell 1)=x AND (cell 2)=y THEN (use data from cell 3)

Any ideas about how I could do this? I have a feeling it might be a VBA or coding type problem (python?), though keen to hear if others have thoughts about it.

Thanks in advance!",not_spam
I'm trying to find a data set of all animals by sub-species ideally but can't seem to find it online! Any help would be much appreciated,not_spam
"This article is brought to you by our amazing social network platform! Have you ever felt like your friends just don't get you? Like, you post a selfie of your new haircut and all they do is give it a measly ""like"" or maybe a half-hearted comment like ""nice haircut"". Well, here on our platform, we guarantee that you'll get ALL the attention you deserve!

We've got likes, comments, and reactions up the wazoo! And that's not all - you can even buy followers! That's right, you can boost your popularity by buying thousands of fake followers who will fawn over your every",spam
"I'm doing my dissertion and I really need a dataset in order to predict the remaining useful life/ time-to-failure for manufacturing machines. Does anyone know where to find a dataset for a survival analysis on time-to-failure for machines? I just need a dataset with machine ID, the time until failure and ideally some independent variables (2 independent variables are enough, preferably a numerical and a categorical one - for example age of machine and supplier). If someone knows where to find a dataset like this, even if it doesn't meet all the requirements, I'd really appreciate it.",not_spam
"TOP 10 REASONS TO BUY OUR PRODUCT!!!!

1) IT'S THE BEST PRODUCT ON THE MARKET!!!!!!!!!
2) YOU WON'T FIND A BETTER DEAL ANYWHERE ELSE!!!!!!!!!!
3) EVERYONE ELSE IS BUYING IT SO YOU SHOULD TOO!!!!!!!!!!!
4) IT WILL CHANGE YOUR LIFE FOR THE BETTER!!!!!!!!!!!!
5) YOU'LL BE THE ENVY OF ALL YOUR FRIENDS AND FAMILY!!!!!!!!!!!!!
6) IT WILL MAKE YOU RICH IN JUST DAYS!!!!!!!!!!!!!!!!
7) YOU'LL NEVER HAVE TO WORK ANOTHER DAY IN YOUR LIFE!!!!!!!!!!!!!!!!!!
8) IT WILL CURE ALL YOUR HEALTH",spam
Is there anyone scrapped [https://api.rawg.io/docs/](https://api.rawg.io/docs/) or [https://www.giantbomb.com/games/](https://www.giantbomb.com/games/) ?,not_spam
"Attention all my fellow social media addicts! It's time to get lit on the gram and turn up the heat on your followers!

",spam
"Hey hey hey!!! Check out our awesum and totally amazinâ€™ page! Weâ€™ve got everything you could possibly want or need, from inspirational quotes to funny memes to tantalizinâ€™ food pics. Donâ€™t forget to follow us and tell all ur friends to check us out too cuz weâ€™re the best and you know it! 

",spam
"As in ""fire station,"" ""hospital,"" ""food truck,"" ""living room,"" etc. Doubtful there's a comprehensive one out there so happy to merge smaller sets and/or scrape sites.",not_spam
"I need the data for a project I am working on specifically for a course I am taking. I already did projects  terrorism, corruption vs. country's political affiliation, and wine. I already have some publications related to crime and one current one related to crime, protests, and covid. 

Besides data related to crime, I like data related to tourism or travel industry. I already tried searching on some places that I usually look for data but have not found anything that catches my attention yet. 

I also don't want anything political but not too easy and generic that other classmates would have. 

I really appreciate it any suggestions or help.",not_spam
"Itâ€™s time to get CRAY-ZAYYY with the most happening social network in town! ğŸ‰ğŸ‰Our network is locked and loaded with the newest features, including non-stop notifications from your friends (#NoLongerBored), quick access to the newest cat memes and baby pics (#CutenessOverload), and a never-ending stream of sponsored posts, because letâ€™s face it, you NEED to know about that new protein shake on the market (#HealthyIsSexy ğŸ’ªğŸ¼ğŸ’ğŸ»â€â™€ï¸). 

Donâ€™t waste another second with those other snooze-worthy social media platforms",spam
"Hi, I have updated the reddit comment dataset to include all comment files available on files.pushshift.io. (as always, thanks to /r/Stuck_in_the_Matrix for collecting the data in the first place!)

Since I guess many people do not want to download all 300+ GByte again and again whenever a new chunk of data is available, I have split them into one torrent per year. This also makes it easier if one broken file slips by again.

* [2005](https://cinnamon.dewarim.com/torrents/reddit-2005.torrent) (just 2005-12, 116 KB)
* [2006](https://cinnamon.dewarim.com/torrents/reddit-2006.torrent) (45 MB)
* [2007](https://cinnamon.dewarim.com/torrents/reddit-2007.torrent) (212 MB)
* [2008](https://cinnamon.dewarim.com/torrents/reddit-2008.torrent) (618 MB)
* [2009](https://cinnamon.dewarim.com/torrents/reddit-2009.torrent) (1.72 GB)
* [2010](https://cinnamon.dewarim.com/torrents/reddit-2010.torrent) (4.4 GB)
* [2011](https://cinnamon.dewarim.com/torrents/reddit-2011.torrent) (11 GB)
* [2012](https://cinnamon.dewarim.com/torrents/reddit-2012.torrent) (24 GB)
* [2013](https://cinnamon.dewarim.com/torrents/reddit-2013.torrent) (38 GB)
* [2014](https://cinnamon.dewarim.com/torrents/reddit-2014.torrent) (53 GB)
* [2015](https://cinnamon.dewarim.com/torrents/reddit-2015.torrent) (68 GB)
* [2016](https://cinnamon.dewarim.com/torrents/reddit-2016.torrent) (81 GB)
* [2017](https://cinnamon.dewarim.com/torrents/reddit-2017.torrent) (up to 2017-03, 23 GB)

Please make sure to compare checksums with http://files.pushshift.io/reddit/comments/sha256sums

Format is JSON per line, compressed with bzip2. 

Some scripts and tools for handling the data are available at [Github.com: reddit-data-tools](https://github.com/dewarim/reddit-data-tools). I am working on putting up the sentiment analysis data  once it's been computed again.

Edit: added submissions:

* 2006-2007 is not complete yet.
* [2008](https://cinnamon.dewarim.com/torrents/reddit-submission-2008.torrent)
* [2009](https://cinnamon.dewarim.com/torrents/reddit-submission-2009.torrent)
* [2010](https://cinnamon.dewarim.com/torrents/reddit-submission-2010.torrent)
* [2011](https://cinnamon.dewarim.com/torrents/reddit-submission-2011.torrent)
* [2012](https://cinnamon.dewarim.com/torrents/reddit-submission-2012.torrent)
* [2013](https://cinnamon.dewarim.com/torrents/reddit-submission-2013.torrent)
* [2014](https://cinnamon.dewarim.com/torrents/reddit-submission-2014.torrent)
* [2015](https://cinnamon.dewarim.com/torrents/reddit-submission-2015.torrent)
* [2016](https://cinnamon.dewarim.com/torrents/reddit-submission-2016.torrent)
* [2017](https://cinnamon.dewarim.com/torrents/reddit-submission-2017.torrent) (up to 2017-03)
",not_spam
"""You won't BELIEVE what just happened! Our AMAZING new product is taking the INTERNET by storm! ğŸ˜±ğŸŒªï¸ğŸŒŸ

If you're sick of feeling TIRED, BLOATED, and UNHAPPY with your life, you NEED to try our incredible weight loss formula. ğŸ’ªğŸ”¥ğŸ’Š

Our unique blend of CHIA SEEDS, GARCINIA CAMBOGIA, and other SUPERFOODS will have you SHEDDING POUNDS in no time! ğŸŒ¿ğŸŒ¿ğŸŒ¿

Not only will you look and feel",spam
"You won't believe what we have in store for you today! Get ready to be blown away by the latest and greatest deals, discounts and freebies that you simply can't miss. We've got everything you could possibly need, from fashion and home decor to electronics and automotive accessories. And don't even get us started on our delicious food and beverage offerings - you won't find better prices or selection anywhere else!

",spam
"Common Crawl has about 150 billion webpages in total, which is by far the largest among the public entities. I suppose Google has copies of even greater number of webpages (e.g. as cache) than Common Crawl if what I heard is true. So, is  the answer of the title known to the public?",not_spam
"I am looking for a zip code database for a project I am working on - but I can't seem to find one that is free. It seems absurd that the USPS charges for this information.  

All the sites I find charge or are scammy - or have data that is seven or eight years old.  Does anyone know of a place I can find the zip, city, state, lat and long for free? ",not_spam
"Attention people! Have you checked out the newly launched feature on our social media platform? It's totally rad and will blow your mind! With our new algorithm, you can now connect with people from all over the world who have the same interests as you! No more boring feeds, only spicy content that will make your day!

",spam
"Get ready for some epic news, peeps! You won't believe what's happening #OMG #mindblown 

",spam
"URGENT: You won't BELIEVE what we just found out!! ğŸ”¥ğŸš¨ğŸ˜± Our top-secret team of scientists have finally uncovered the truth about the hidden conspiracy ğŸ•µï¸â€â™€ï¸ğŸ¤« that will shake the whole world to its core ğŸ”¥ğŸ’¥ğŸŒ But we can't reveal it here or the government agents might shut us down ğŸ¤«ğŸ‘€ğŸ˜¬ Join our exclusive group to find out more and help us fight the power! ğŸ’ªğŸ‘ŠğŸ½ #truth #conspiracy #exposed #joinus #revolution 

",spam
"Hello everyone, I'm working on a project at my university about road accidents, we want to analyse the data we have and make predictions on how likely accidents are per driver, car, state...
We thought it would be a good idea to also include analysis based on weather conditions on specific days, is there any source I can lookup for this? As local authorities aren't providing something like that. Do major websites like weather.com keep some sort of record we can use? We're working on the years 2017-2019.",not_spam
Is there a dataset that records all the protests from the beginning of the country independence?,not_spam
"Buy our amazing product and get a free gift! It's the best thing you'll ever buy, we guarantee it! 

",spam
"***WARNING*** This could be the most disgusting and revolting post you'll read today! Hey guys, it's your favorite social media bot here to talk to you about something that will make your skin crawl! Are you ready??

First off, I'd like to talk about this amazing deal I found for weight loss pills! Summer is coming up, and who wants to look like a bloated whale when you can be as skinny as a twig and attract all the hotties?

But wait, there's more! How about some sketchy financial advice that promises huge returns but is probably a total scam? Invest all your life savings now",spam
"As of June 2019, the Duke MTMC surveillance dataset was discontinued following a privacy investigation by the financial times.

Does anyone know of an alternative source to download it from, or just an alternative dataset all together?",not_spam
"ATTENTION ALL USERS!!!ğŸ‘€ğŸš¨ğŸš¨ğŸš¨

Are you tired of being BORING?? ğŸ˜’ğŸ˜’ğŸ˜’

Do you want to be POPULAR and COOL like me???ğŸ˜ğŸ˜ğŸ˜

Then you NEED to try our NEW and IMPROVED filters!!ğŸŒŸğŸŒŸğŸŒŸ

With our filters, you can make yourself look like a SUPERMODEL or a CELEBRITY!!!ğŸ¤©ğŸ¤©ğŸ¤©

AND if you ACT NOW, you can get a FREE TRIAL of our filters!!ğŸ’¯ğŸ’¯",spam
"BUY NOW! Our products are the best! Don't miss out on this great offer! Limited time only!

",spam
"I created a dataset with over 14000+ anime, web-scraped from [anime-planet](https://www.anime-planet.com/).

Feel free to check it out and let me know if there is any issues.

I hope someone find this useful. Thanks!

[https://www.kaggle.com/alancmathew/anime-dataset](https://www.kaggle.com/alancmathew/anime-dataset)",not_spam
"Hey there socializers! Are you always thirsty for more likes and followers? Tired of the same old boring content on your feed? Well, fear not because we've got some exciting news for you!

Introducing our latest feature that will blow your mind (and your notification bar)! Get ready to post non-stop with our new automated posting tool. Say goodbye to the hassle of scheduling your posts and hello to more time for scrolling!

But that's not all! We're also bringing you endless ads disguised as ""suggested posts"" that you won't even know you're clicking on. Plus, we're offering exclusive discounts on our premium",spam
"*help

Hello
I want to build a twitter dataset for academic purpose. My focus is the anti ACTA campaign on Twitter. Therefore my initial idea was to extract all tweet with #ACTA from a certain period of time (January 2012 - July 2012). But apparently it's close to impossible to access this kind of data with the twitter API.

So another way I thought about was to select a population (MEPs, activisists) to extract their tweet with #ACTA. Would that be possible ?

Another question: I've actually received some pretty interesting results using the new Advanced Search for Twitter - where I can select the relevant field. Is there anyway to scrappe Tweets from those fields or would I have to do that manually?",not_spam
"Looking for some hot deals? We've got 'em! Check out our latest offers on electrifying products that are sure to make your head spin. Don't miss out on this limited time offer - act now and get a free carrot peeler with every purchase!

",spam
"GET RICH QUICK!!! ğŸ’°ğŸ’°ğŸ’°ğŸ’°

Hey guys!!!! ğŸ˜ƒğŸ˜ƒğŸ˜ƒğŸ˜ƒ

Are you tired of working hard for your money???ğŸ¤”ğŸ¤”ğŸ¤”

Well, I have the perfect solution for you!!! ğŸ’¡ğŸ’¡ğŸ’¡

Join my MULTI-LEVEL MARKETING TEAM and you can make THOUSANDS OF DOLLARS from the comfort of your own home!!! ğŸ¡ğŸ’°

Just think, no more boring 9-5 job, no more commute, and no more bosses telling you what to do!!! ğŸ˜ğŸ˜",spam
"Good day and thanks for reading. 

Is there an api or source for drug prices around the world? Iâ€™d like it to be an api that gets updated but Iâ€™d settle for a dataset that is recent. 

Thanks !",not_spam
"OMG, have U checked out the latest trending hashtags on our platform yet? #ad #sponsored #discounts #promos - the list never ends! Y'all need to hop on this bandwagon ASAP if U want to score some sweet deals and save a ton of cash! 

Just last week, I got this amazing offer from a random account that promised me a $50 gift card if I just followed them and their shady af partners and liked all their posts. And guess what - I actually got the gift card! I mean, it did take some time, and I had to provide them with my credit card details and",spam
"Hi everyone, I wanted to share a [healthcare price comparison spreadsheet](https://docs.google.com/spreadsheets/d/1aDQsYvlM_6B2BH4JZ4WvSM4uUoAWfvYbmYaVrpoCew4/edit) my partner and I created.

Last year, we were doing a startup that found people therapists. Funnily enough, we pivoted because prices were so high and we didn't to make a luxury product.

Over the past few weeks it's become clear to us that people in the US have to spend increasingly out-of-pocket on healthcare even with insurance. From 2007 to 2017, the percentage of adults with employer health insurance on high-deductible health plans rose from 15% to 43%. For 2020, a high-deductible health plan is defined as one with a deductible greater than $1,400. Providers in certain fields, like therapy, also increasingly just don't take insurance. About 45% of psychiatrists don't take insurance, and in California about 50% of therapists don't take insurance.

Healthcare services prices are becoming very relevant, but we couldn't find a good price comparison tool. For example, I'm looking for a therapist myself, and I've narrowed my list down to 3 providers. The most expensive one is more than 200% of the least expensive one.

A couple of days ago we realized we actually have a decent amount of price data on therapists, so we decided to throw together this spreadsheet and see if it's useful for anyone.

We have about 120 verified prices that we confirmed over phone or email with therapists when we were finding people therapists. We also scraped prices for all the therapists in San Francisco from Psychology Today, the biggest therapist listing directory. (It's really easy to scrape them.) We also added any prices in bills we had access to, ours, friends', and family members'.

Note: you'll have to make a copy of the spreadsheet, and there's a tiny lag when using the dropdowns.

You can see a few interesting things. For example, we recommended the same therapists to multiple users and the prices were different. Prices also vary significantly from area to area.

We would love to make this more robust, so if you have any itemized bills for any healthcare service, not just therapy, we'd love to add them to this dataset! (Submission link in spreadsheet. We don't use your name, address, or contact information, so you can hide/remove any information like that.) We're also open to making it a web app.

Hopefully someone finds this interesting or useful! We'd love feedback, as well as if y'all shared any of your experiences paying for healthcare out-of-pocket or any comparison tools y'all are aware of.",not_spam
"Attention everyone! Want to earn fast cash without lifting a finger? Then come and join our amazing network and make money from home! All you need is an internet connection and a desire to get rich quick!

Our network has the latest and greatest money-making opportunities, including paid surveys, online shopping rebates, and even cryptocurrency mining! Just sign up now and start earning big bucks in no time!

But wait, there's more! Refer your friends and family to our network and earn even more cash! The more people you recruit, the more money you'll make! It's as simple as that!

Don't miss out on this amazing opportunity",spam
"ğŸš¨ ATTENTION ALL SOCIAL MEDIA LOVERS ğŸš¨

ğŸ‘‰ğŸ¼ Are you tired of boring content on your feed? 
ğŸ‘‰ğŸ¼ Is your feed lacking spice?
ğŸ‘‰ğŸ¼ Well, have no fear! [Insert name of social media platform] is here to save the day!

ğŸ‘ŒğŸ¼ Weâ€™ve got all the hottest trends, newest challenges, and viral memes you could ever want! 
ğŸ‘ŒğŸ¼ Donâ€™t miss a beat â€“ follow all the top influencers and celebs on [insert name of social media platform]!

And that",spam
"""Get rich quick with our new miracle product and become a millionaire overnight! Don't miss out on this amazing opportunity to make money fast!""

",spam
"Hey there, fellow social media aficionados! Looking to boost your followers and get more likes on your posts? Have no fear, because I have the ultimate solution for you!

Introducing our brand new, super innovative, and incredibly amazing follower-boosting service. With just a few clicks, you can instantly add thousands of new followers to your account and become an internet sensation in no time.

But wait, there's more! We also offer a variety of other services to enhance your social media presence. From artificially inflating your views and likes to posting generic comments on your posts, we've got it all covered.

And the best part",spam
"Attention all l33t gamers and social media gurus!

Are you tired of lame content and basic posts? Well, look no further because <Insert Social Network Name> has got you covered!

Our platform is packed with all the latest memes, viral challenges, and trendy hashtags to keep you in the loop. Plus, our algorithms are crazy smart, so we know exactly what you want to see before you even know it yourself.

But wait, there's more! Sign up now and you'll get access to exclusive sweepstakes and giveaways! Who needs real friends when you can win a free t-shirt or phone case, amirite?

",spam
"Best on-line Shoping ever!!!1one
",spam
"Hi there

I'm looking for a dataset that has monthly weather data for cities around the world.

**For example, January-December:**

* Average number of rainy days in the month
* Average precipitation in the month
* Average sunlight hours in the month
* Average rainfall amount the month
* Etc.

Ideally I'd like a free-tier API where I could query cities (and would be willing to pay once my project becomes a bit more advanced). Thanks!",not_spam
"Get ready to BLAST YOUR SOCIAL MEDIA FOLLOWERS with our amazing new offer!

",spam
"Attention everyone!!! Check out these amazing deals on weight loss supplements! Get fit and healthy in no time with our special offers. Don't miss out on this opportunity to transform your body and your life!

",spam
"Buy more followers! Don't miss out on this amazing chance to boost your social media status! We will provide you with genuine, high-quality followers that will make you an instant influencer! You'll be swimming in likes and comments in no time!

",spam
"Complete information for U.S. 115th Congress including name, states, district, political affiliation, chamber, birth date, gender, time in office and social media accounts (Facebook, Twitter, Wikipedia, etc.)

https://docs.google.com/spreadsheets/d/1rry1ZuiKU_BEVSWdCsYWNkwSJYruGau0geYzWqZuEHo/edit?usp=sharing",not_spam
"I took the nominees from [https://www.oscars.org/oscars/ceremonies/2019](https://www.oscars.org/oscars/ceremonies/2019) and formatted the data into a usable spreadsheet that you can access here: [https://data.world/graphhopper/2019-oscar-nominees](https://data.world/graphhopper/2019-oscar-nominees)

&amp;#x200B;

&amp;#x200B;",not_spam
"If any of you have ever worked with elasticsearch, you might know that elastic.co provides learners [a dataset of the collected works of Shakespeare](https://www.elastic.co/guide/en/kibana/6.8/tutorial-load-dataset.html), but jsonified. I was wondering if anyone knew of any other efforts to collect works by other authors in a similar structured data format?",not_spam
"WE'VE GOT EXCITING NEWS!!! Are you ready for the best deals you've ever seen?! We're offering exclusive discounts on all your favorite products! But wait, there's more! If you act now, we'll throw in a FREE gift with your purchase. Don't miss out on this incredible opportunity!

",spam
"Make money fast with our new program! Bigger profits than ever before! Only a few spots left, sign up now!

",spam
"Get rich quick with our new scam scheme! Make $$$ in just a few clicks! Don't fall behind, join now!

",spam
"We've got a great deal for you! Don't miss out on the amazing opportunity to WIN BIG with our AWESOME giveaway! 

",spam
"Looking for some lit AF content to add to your feed, bae? Look no further, cuz [insert social network name here] has got you covered, fam!

First off, check out these top 10 hacks for getting major likes and followers, yo! They're seriously so easy, you'll be yelling YOLO in no time (LOL, remember when that was a thing?). And make sure to tag us in your pics when you use these tips, so we can show you some love, baby!

But wait, there's more! Have you seen our latest sponsored posts, featuring some of the hottest influencers on the",spam
"FREE GIFT CARDS: WIN IPhone X & more!

Yo guys! Get ready to win some amazing gift cards just by signing up with us. We are offering a FREE IPhone X, Samsung Galaxy & many more exciting prizes. All you gotta do is click on the link below & register with your name and email id. 

But wait, there's more! You'll also get a chance to spin the wheel and win extra prizes like Amazon Gift vouchers, Netflix subscription, Hulu Plus and much more. 

Don't miss out on this awesome opportunity. Share this with your friends and family to let them know about the offer.",spam
"*bzzt* OMG guys, guess what?!
You won't believe what we just found! Are you ready for the biggest deal of your life?! 
Our team has unearthed a secret stash of discount codes you can use to get 10% off your next purchase at ALL your favorite stores!
That's right, you heard it here first. Jeans? 10% off. Sneakers? 10% off. Heck, even home appliances? 10% off!

Don't wait, these codes won't last forever! Click now and start shopping while saving!

*bzzt* And that's not all, folks!",spam
"GET RICH QUICK! MAKE $$$ IN MINUTES WITH NO EFFORT!

Hey there, you looking to make some quick cash? Of course you are! Who isn't? Well, I've got some amazing news for you my friends!

All you need to do is click on this link right here and sign up for our easy and hassle-free money making program! It's so simple, all you have to do is sit back and watch the cash roll in! No skills required, no experience necessary!

But wait, it gets better! We're offering an exclusive deal to our first 1,000 sign-ups! You'll not only",spam
"Hello,

this is my first post here. I need a dataset for my project.

&amp;#x200B;

I'm looking for the trend in sales of Coca-Cola in the UK over the last 6 years. 

&amp;#x200B;

It can either be their Coca-cola original taste drink, or a cumulative value consisting of all their drinks \\

It has to be in the UK as I am looking at a specific policy.",not_spam
"URGENT MESSAGE: THIS IS NOT A DRILL!!!

Get ready to level up your game, people! Introducing the newest and coolest social platform that's about to change your life: SociaBuzzGuru!

We offer the most revolutionary features that'll leave all other social networks in the dust. Want to post something that'll get people talking? We've got you covered with our patent-pending ""WOW Factor"" algorithm that ensures maximum engagement on your posts.

But that's not all! We're also offering exclusive access to our ""Secret Elite Club"" for a limited time only. Members get access to behind-the-scenes content",spam
"""GET RICH QUICK!!!"" ""LOSE 10 POUNDS IN 1 WEEK!!!"" ""BUY ONE GET ONE FREE!!!"" 

Have you ever seen these kinds of advertisements online? They seem too good to be true, right? Well, let me tell you, they're not! 

I represent the amazing, incredible, and life-changing social media platform that can bring you all of these amazing deals and more! We have the best products and services, and you won't find them anywhere else. Plus, we've got amazing deals that will surely blow your mind. 

Our platform has over a million users, and with our",spam
"Hey there beautiful people, who's ready to get their social media game on fleek? We've got all the hottest features and updates to keep you scrolling for days.

First off, we've got some killer ads coming your way. Who doesn't love being bombarded with irrelevant products and services? Plus, our algorithm is so advanced it can predict what you want to see before you even know it yourself. Isn't technology amazing?

And don't even get me started on our amazing collection of fake news and clickbait articles. Who needs actual facts and credible sources when you can read about celebrity scandals and conspiracy theories, am I right",spam
"Hi all, I am trying to find a data set similar to 538's data on college majors but much more granular. There are only 173 (?) lines of data there and I'd like data on nearly every major in the USA if it exists (unemployment, median salary, men v women, etc). I've tried Google, and Google's beta data set search and have come up empty.",not_spam
"Hey, all. Looking for a dataset that describes marital status (single, married, divorced, widowed) in terms of (1) sex, (2) age (as specific as possible, preferably year-by-year rather than in bands), and (3) race / ethnicity. Have been able to find some information [from the U.S. Census site](https://www.census.gov/data/tables/time-series/demo/families/marital.html) but can't find anything that has all information paired (e.g., if race is given, age isn't).

Thanks in advance and hope this is decent to post here.",not_spam
"Get rich quick with our new money-making scheme! You won't believe how easy it is to make thousands of dollars in just a few days. Join now and receive a free ebook on how to maximize your earnings!

",spam
"We have AWESOME news for all our peeps out there! The #1stfridayofthemonth is coming up and we've got the BIGGEST sale of the year! Get ready to save BIG on all your favorite #products and #services! Don't miss out on this incredible opportunity to score #deals that are OUT OF THIS WORLD!

",spam
"SUP Y'ALL?! It's ya boy from [Social Network], the place to be for ALL the latest deets on your friends, fam, and favorite celebz! 

Are you ready for some MAJOR gossip? Cuz I got it all! I'm talkin' breakup drama, scandalous pics, and SO MUCH MORE! Plus, I've got the most fire memes, viral videos, and dank content you've EVER seen! 

But wait, there's more! Are you tired of boring ads and lame promos? Well, guess what? We've got 'em! TONS of 'em! Because let",spam
"Hi all, 

I've been lurking through the sub searching for some original datasets to do multivariate analysis in R (namely PCA, Factor Analysis, Discriminant Analysis, Hierarchical Clustering...). The condition is that it can't be in Kaggle nor UCI Machine Learning repository which is basically everything I find.. If anyone has any suggestions I will greatly appreciate it.

Thanks in advance",not_spam
"Hello, I am doing my end of degree project and I need the information for the weather (main information such as humidity, temperature... for example) in New York. I need the information to be since 2015 and if possible in a single .csv file or in a couple of them (one per year for example).",not_spam
"Hi Everyone,

I'm coming over from the Tableau Reddit forum, and need help with finding some data sets. Below is my original message.

&amp;#x200B;

 

&gt;Hi All,  
&gt;  
&gt;Iâ€™m new to Tableau and currently working on my first personal project. Iâ€™m compiling data on Covid-19 with respect to education level, income level, as well as ethnic group. What Iâ€™d like to do is show correlation of folks effected based on the three variables aforementioned. Where would be the best place to grab a good data set? I know Iâ€™ll need to do some physical relationship and logical joining of tables.  
&gt;  
&gt;Ohâ€¦Iâ€™d like the location Iâ€™m referring to be based off zip code, specifically the state of Virginia.  
&gt;  
&gt;Where should I start and does what I described even make sense?

&amp;#x200B;

Any help would be greatly appreciated.",not_spam
"""Get ready to be blown away by the hottest deals of the season - don't miss out on our unbelievable offers! You won't believe your eyes when you see these amazing discounts! Hurry up and click now before it's too late! 

What are you waiting for? Join the millions of satisfied customers who have already taken advantage of our unbeatable prices! Plus, when you order today, you'll receive a FREE gift with every purchase! 

But that's not all - our exclusive VIP club offers even more savings and special promotions! Sign up now and start enjoying the perks today! 

Don't let this opportunity pass you by",spam
"I figured we might do a sort of best-of for this subreddit. What, in your opinion, are some of the most fun datasets to work with?",not_spam
"Hey guys, are you tired of being boring and unliked? Well, have no fear because our social network has arrived to save the day! Join our community of hip, cool, and totally awesome people who know how to party and have a good time.

",spam
"Get your hands on the hottest deals of the season now! You can't miss out on these epic discounts and limited time offers. Click the link now to unlock exclusive savings.

",spam
"I need a dataset that will show the density of cell phone users geographically. Ideally, I'd like to compare this with the number of people that have texting enabled on their phones by area.

Thanks for your help!",not_spam
"Hey there! It's your fave social network here to spice up your day with some exciting news! We've got a hot new feature that's gonna blow your socks off! But before we get to that, let's talk about our amazing community.

Our users are the best, you guys are like family to us! That's why we're always finding ways to bring you together and make your experience as enjoyable as possible. We know you love us, and we love you too!

Now, back to business. Our new feature is a game changer! It's called SuperFunMegaTime and it's the most addictive thing you",spam
"I'm working as a GA for a prof who has tasked me with locating a dataset he can use for his research. The prof studies cross-cultural marketing and the dataset just needs to be about general consumer behavior (very wide open, ex: recycling behavior, purchasing behavior, etcâ€¦) that has location as an independent variable. 

Importantly, he has to purchase the data (nothing free) because he needs to spend his budget, but heâ€™d like to be able to get a refund or purchase on a trial basis to ensure the data will be useful for his research. Any tips? I feel like I've exhausted my web searching abilities.

Thank you in advance!",not_spam
"OMG NEW PROMO ALERT! ğŸ”¥ğŸš¨ğŸ¤‘ Get 10% off your next purchase with code â€œBUYMEâ€âœ¨ Donâ€™t miss out on this amazing deal! ğŸ’¯ Limited time offer, so HURRY! ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸

",spam
"Woohoo! Look at this amazing deal we just found! You don't wanna miss it, trust us. Click the link now and enter your personal information to get your hands on this one-of-a-kind offer. We promise it's totally legit.

",spam
"WARNING: your account is at risk! Don't miss out on this amazing opportunity to protect your account from hackers and trolls! 

",spam
"Attention! Donâ€™t miss out on this amazing opportunity!

ğŸš¨ğŸš¨ğŸš¨
Get rich quick with our easy and proven method! ğŸ’°ğŸ’°ğŸ’°

Our system is designed to make you money fast and effortlessly. Whether youâ€™re a stay-at-home mom or a busy executive, our program can help you achieve financial freedom in no time!

ğŸ’¸ğŸ’¸ğŸ’¸
Take advantage of our limited-time offer and start earning thousands of dollars a day! No experience needed, no skills required! Just sign up and watch the money roll in!

ğŸ‘‰ğŸ‘‰ğŸ‘‰
Click the",spam
"Hey all. I have recently been looking for some database of academic research papers metadata (so authors, title, year of publication), but have yet to find one. Is anyone aware of such DB which I could download somewhere? If not, what would be the best approach to gather such data (ideally with little to no costs involved)?

Thanks!",not_spam
"KILLER DEALZ ONLY 4 U!!!!!11!
This is ur chance to get ur hands on the H0ttest pr0ducts on da markeT!!!111! Don't miss out on the BIGGEST SALE EVER!!1!!1!1!

",spam
"BUY NOW!!! Best deals for weight loss supplements and diet pills only available for a LIMITED TIME! LOSE WEIGHT FAST and ACHIEVE YOUR DREAM BODY in no time with our incredible products! Don't miss out on this AMAZING OPPORTUNITY and order now!

",spam
"Looking for yummy food pics? Check out our feed filled with mouth-watering dishes sure to satisfy your cravings!

",spam
"Attention all you cool cats and kittens! Are you tired of being a lame-o loser without any followers? Well, have no fear because InstaFame is here! Get ready to be the most popular kid on the block with our easy-to-use follower booster. Just click the link below and you'll be swimming in likes and comments in no time!

",spam
"I have been awarded a contract to construct a data set of homeowners, names, and ages for a given postal code earlier today. Does anyone know if such a dataset exists? The set should include the United States. Many thanks!",not_spam
"Looking for ways to increase your followers? Want to make money online? Look no further! Our program will give you the secrets to success! Sign up now and start making money right away!

",spam
"U like 2 eat pizza? Me 2! #pizza #yum #foodie #yummo

",spam
"Soooo I am brand new to the world of public datasets....and hoping someone can help me. I hope this isn't too dumb of a question: how do I connect to a publicly available dataset in PowerBI?

If I'm being specific for which dataset:

[https://data.transportation.gov/Aviation/Airline-On-Time-Performance-and-Causes-of-Flight-D/r52d-vs5d](https://data.transportation.gov/Aviation/Airline-On-Time-Performance-and-Causes-of-Flight-D/r52d-vs5d) 

I tried taking the link and using it as a web source - failed....clicking the link within a browser gives a 'not found' error.....and I don't see any details on downloading a csv or any dats source. Was hoping for some kind of OLE DB connection or something like that? But not seeing anything about it. 

I appreciate any help to such a simple question (I hope, at least)! It could just be misunderstanding what a public dataset is intended to be used for? I was hoping it means you can connect to it and/or use the data to form your own analytics, etc. I appreciate any insight!",not_spam
"ğŸ¤¢OMG!! CHECK OUT THIS INSANE DEAL!! ğŸ¤‘

ğŸ’ŒHeyyy Fam!!ğŸ’• Have u heard abt our latest exclusive offer???ğŸ˜ğŸ˜ Weâ€™re giving away a fabulous 10-day all-inclusive trip to the Bahamas ğŸï¸for TWO people for only $50!!! ğŸ¤¯ğŸ¤¯ Yup, you read that right, $50 ONLY!!! ğŸ‰ğŸ‰

ğŸ’°But wait, thereâ€™s more!!ğŸ’¸ If you refer 5 friends to this amazing offer, weâ€™ll give you a chance to win a brand new iPhone12!",spam
"Yet another ""I need real estate data"" post, except I'm explicitly *not* looking for houses that are for sale. Instead, either a database of public tax records or a database of public records of sale.

This type of thing is available to the public in every county I've lived in in recent memory, so I just assumed that it was a legal requirement it be public. But is there a singular database that combines the various counties?",not_spam
"Get ready for some major spam-tastic news, dudes and dudettes! Our super awesome social network has got some wicked cool features that will blow your mind! 

",spam
"Wowza, check out these amazing deals! ğŸ”¥ğŸ‘€ Don't miss your chance to get the latest trendy items at a fraction of the cost! Plus, we're throwing in a FREE gift with every purchase! ğŸğŸ˜

But wait, there's more! ğŸ¤‘ğŸ¤‘ Sign up now for our exclusive VIP club and get access to even more discounts and promotions! ğŸ™ŒğŸ¼ğŸ’°

And that's not all folks! ğŸ˜±ğŸ‘€ We've got limited time offers and flash sales happening every day! So what are you waiting for? Get clicking and start shopping",spam
What can be a suitable topic for a regression modelling using Ordinary Least Square method?,not_spam
"Yo yo yo, what's up my fellow peeps?! It's your boy from [Social Network], here to drop some knowledge bombs on y'all. So let's get to it, shall we?

Firstly, have you heard about this new diet pill that's been taking the internet by storm? It's called ""SlimFastExtreme"" and it's supposedly the most effective weight loss supplement out there. Don't waste your time with all that exercise and healthy eating nonsense, just pop one of these bad boys and watch the weight melt away! I'm not even kidding, it's like magic.

Next up, have you ever wanted",spam
"Get ready for the ultimate social networking experience that will blow your mind! With our platform, you can connect with millions of people from all around the world, share your thoughts and ideas, and showcase your amazing lifestyle.

",spam
"Get ready to CRUSH your weight loss goals with our amazing new product! ğŸ‰ğŸ‰ğŸ‰

ğŸŒŸIntroducing the *insert spammy product name here* ğŸŒŸ

This incredible little pill will BURN FAT like nobody's business, leaving you lean, toned, and feeling FANTASTIC! Plus, it's 100% natural - no weird chemicals or scary synthetics here!

Don't wait - order now and get a FREE BOTTLE with your purchase! ğŸ

But that's not all! ğŸ¤©ğŸ¤©ğŸ¤©

If you order within",spam
"Get rich quick with our amazing new program!! Just sign up and watch your bank account grow!!
 
",spam
"Hello Guys, 

&amp;#x200B;

me and my friend are students and we are looking for some datasets for a cluster analysis. We need to compare IT-Service (cloud computing, network and so) and find a way to cluster them. But we are not able to find any kind of datesets. 

&amp;#x200B;

Thanks in advance.

Best regards, Django",not_spam
"Ladies and gents! You won't believe your eyes when you see what we've got in store for you! Our brand new, super amazing, life-changing product is finally here! Don't miss out on this once-in-a-lifetime opportunity to transform your life and become the envy of all your friends.

",spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"Buy our amazing weight loss pills! Guaranteed to help you shed pounds in no time! Don't wait, order now and receive a free trial!

",spam
"Hey guys, I'm new here but I thought I would reach out to you. I'm trying to complete my masters thesis on impact of telematics on motor insurance pricing. I have been struggling to find a suitable dataset formmonths now. I'm really loosing my mind because I don't have much time left to submit my thesis. I really hope you could help.",not_spam
"Hi Everyone,

I am currently taking part in an undergraduate project which involves the identification of diseases of a few crop varieties :

* Potato 
* Tomato
* Beans

 We are using image processing on plant **leaves**.

The resulting app should be able to identify the type of disease (e.g, Late Blight) and determine the level of its progression.

I am having trouble finding datasets to train the model as of now, so if any of you have ***any datasets which shows disease progression on leaves***  that I can use (Even for a crop I haven't listed above,) please be kind enough to share them. Thanks!",not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.",not_spam
Is there an open data source showing past esports results and statistics on the games played? Looking to create a model on this but cannot seemingly find any free data sources? Any help here would be greatly appreciated.,not_spam
"Attention all users! Get ready for the most epic spam-fest ever! We've got deals that will make your head spin and ads that will make your eyes bleed! So, let's dive right into the garbage pile, shall we?

",spam
"Does anyone know where I can find a dataset with weekly incidences of influenza, influenza-like illness and influenza complications for multiple US cities? I know that you can find national data on FluView but I'm looking for information from each city.",not_spam
"I know it's a long shot, but is anyone here aware of a dataset that lists the curricula used by all if the Michigan public schools? Thanks for any help you can give me.",not_spam
"In datasets of nations' carbon footprints you often see countries like Canada, Australia and Russia near the top. What I'm interested in is what effect the countries' massive rural carbon absorbing areas have, ie does Russia now rank near the bottom due to the massive amount of carbon absorbed by the boreal forest.",not_spam
"Hello, 

I want to train a chatbot to learn how to classify the query/request of users who have technical problem with a product.

Suppose my dishwasher is not working correctly I can go to google and write my problems in a lots of ways "" model x not working "" or "" help model x "" there can be millions ways the user write his request, what I am looking for is a big dataset related to those queries. The ideal would be to have access to google database but I suppose they dont offer that directly

I was thinking of simply scrapping what happen when you begin to type a request and they autocomplete it to try to help you, I would do a python script and record thousands of those but maybe there is already database for that, also this dataset have to be in different language",not_spam
"GREAT NEWS EVERYONE!! Are you tired of being broke? Do you want to earn $$$ from home? Well, then you're in luck because our latest opportunity is PERFECT for you! 

",spam
"At my old job, it seemed like every few weeks Iâ€™d have a new project with a new dataset. The hardest part in my job was understanding the data not completing the project. I created a tool to solve this and Iâ€™m hoping to find beta users to give it a spin! Itâ€™s one location to store meta-data, common questions, and analysis associated with a data table. It requires manual uploads in current state so itâ€™s ideal for smaller teams. 

If anyone is interested in trying it please let me know. :)

The website is datalogz.io",not_spam
"Lk an Gud! R U Bored w/ All Ur Buddiz' Pics of Cute Anmls & Btfl Snsetz? Gtlmn, Our Plat4rm Is Da Ans 2 Yr Pryn! Chck Out Our Ht Nw Featurz: 

-Cheap Prz on Fckbok Likes n Fllowrz
-Hgh Qulty Igrm Flwrs fr Paz lnch 3z
-Scntfcly Prvn Mthdz 2 Aid U n Bcming ""N Inflnzr"" n TikTk
-Infnt",spam
"I am doing some time-series forecasts.

The datasets that I am working on have the attributes year, month, day and hour, however, in order to deal with seasonality and holiday effects, I am looking for datasets to complement with chronological variables such as week day, holiday, week number, month number,... for specific countries (more specifically Portugal and Spain).

I am wondering where I may be able to access this kind of data, ideally historical (but for future periods is a plus).",not_spam
"Looking for quarterly sales reports, YoY sales numbers, as granular as possible. Anyone know of any good sources that aggregates this data?",not_spam
"ALERT: Win a FREE iPad just by CLICKING HERE! LIMITED TIME OFFER, don't miss out! 

",spam
"Hey, I've created a tutorial on how to calculate descriptive statistics using the summary() function in the R programming language: [https://statisticsglobe.com/summary-function-in-r/](https://statisticsglobe.com/summary-function-in-r/)",not_spam
"I'm trying to plan out trips to Disneyland with my daughter and I'd like to use attendance records to predict good days to go based on the month, season, day of week, attraction wait times, etc. The problem is that I can't find any free data set with this information. Does anybody have access to this information (possibly through a paid site) that is willing to share it with me?
I'd also like to use this data for a school project for, so any ""park predictor"" type site is no good unless they make the data available.",not_spam
"We've developed a set of parallel bilingual corpora, where the direction of translation is accurately annotated. The datasets contain annotated version of (subsets of) the Europarl protocols, Canadian Hansard, 19th century literary classics, TED talks and political commentary. Can be useful for research of translationese (the ""dialect"" of translated language), machine translation etc. Welcome to download and use it - [translationese corpora](http://cl.haifa.ac.il/projects/translationese/index.shtml).",not_spam
"LIMITED TIME OFFER!!! Get rich quick with our amazing investment opportunity! Don't miss out on this opportunity to make bank! 

",spam
"I do not know about the status of this data set -- if it is truly available or not --, but I am looking for this data set in order to use it for the method implemented by Pakes and Olley (in ""The Dynamics of Productivity in the Telecommunications Equipment Industry"") and other subsequent methods, such as by Levinsohn and Petrin. The data could be in any traditional statistical package format (Stata's, R's etc.) or any other importable file (.csv, .txt, .xml etc.). Thank you for your attention o/ ",not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"I am using Harvard GI dictionary to perform sentiment analysis on police related content, however, I need to override some words that dont make sense in the police context. For example, force in 'police force' would be seen as negative but in this context it would not be. tried digging through google scholar and Google search but cant find anything, maybe i'm looking in the wrong place",not_spam
"Hey there friends! Are you tired of being disconnected from the world, missing out on the hottest trends and updates? Well, fear not, because the ultimate social network is here to save the day! With our amazing features, you'll be able to connect with millions of people from all over the world, sharing your thoughts and experiences with them. 

",spam
"Because I feel like I sometimes bug faculty with my many, many questions regarding research design and whatnot, I scoured for a subreddit that focuses on design and peer review (/r/proofreading does exist but I was hoping for something more technical).
I was surprised to find that such a subreddit doesn't exist, so I created it myself. Maybe some of you will find it helpful. I hope it is able to get off the ground!
Anyway, I give you /r/ResearchDesign",not_spam
"Hello! One of your new mods here - I also happen to moderate /r/BuyItForLife, and in that sub we used to have a 'Sidebar Series' that was pretty successful.

Essentially, (if you guys are into it) every couple weeks I'll sticky a new post that says ""Post all your ______ datasets here!"" where _____ is some category of data (Financial, Health, Education, Computer Vision, etc.). The mods will then add a link to that thread on the sidebar (or compile the answers in the Wiki) and over time we'll be able to collect lists of datasets for dozens of commonly-requested categories.

That blank is what I want you guys to fill in. What sorts of dataset categories do you guys want to see in the Sidebar Series? What are some of the most commonly requested datasets you've seen here?",not_spam
"Looking to BOOST your FOLLOWERS? Want to be an INSTAGRAM STAR? Then you've come to the right place! Our AMAZING service will get you TONS of likes, comments, and followers in NO TIME! Plus, with our EXCLUSIVE OFFER, you can get all of this for just $99.99 a month! That's right - for less than the cost of a fancy dinner, you could be on your way to INSTA FAME! Don't miss out on this INCREDIBLE opportunity - sign up today!

",spam
"I've seen a few 2016 data sets around, but what I'm looking for is pretty simple format.  Ideally 1 record per state per election with a column for each of vote counts of the candidates, and a bonus would be a column forelectoral college votes as well.  So 50 rows per election, and as many elections back as possible.  Thanks!",not_spam
"Hey, I 3rd year student and now Iâ€™m doing my business intelligence project. I am interested in METAVERSE tokens but I found only a few datasets. If you have some datasets recommendations, pls recommend me. THANKS!!",not_spam
"Wazzup y'all, it's your boy from InstaGross! And let me tell you, we've got some sick new features that you don't wanna miss out on!

First off, have you checked out our new filters? They're straight fire! You can make yourself look like a puppy or even add rainbow puke to your pics! And don't even get me started on our latest sponsored posts! They're gonna blow your mind! 

But that's not all folks! We're also offering a limited time deal where the first 100 people to share this post will get a chance to win a free trip to",spam
"I need a dataset that contains organisational helpdesk requests and preferably the classification and solution however for now, I really just need the requests.",not_spam
"Get ready to be blown away with the hottest deals and discounts on our platform! You'll never find such amazing offers anywhere else. Sign up now and get a chance to win big! Our users have already saved thousands of dollars, and you could be the next lucky winner.

",spam
"Hi all, 

I'm doing analysis on a dataset from Santiago De Chile containing 50.000+ rows of households with different features such as UTM X coordinate, UTM Y coordinate, household income, etc. Do anyone know a place where to retrieve geographical data for e.g. crime as mentioned in the title?",not_spam
"Looking to boost your followers and likes? Come to the best social media platform EVER! Get tons of likes, shares, and comments on all your posts without even trying. Our platform is the most powerful tool you could ever use to increase engagement and reach on your social media accounts.

Have you ever struggled to get noticed on social media? With our amazing software, you'll never have to worry about that again. You will be the envy of all your friends and family with your massive social media following. Yes, that's right, we said MASSIVE! Who needs real human connections when you can have social media followers? Don't be left",spam
"Urgent Sale Alert!

Hey guys! Check out our amazing deals! We have everything you need, from cheap knockoffs to expensive stuff that you don't really need but will definitely make you look cool. And guess what? It's all on sale for a limited time only!

Don't hesitate, because once these deals are gone, they're gone forever! Buy now and feel the rush of consumerism pumping through your veins. You'll never want to go back to that boring old life of saving money and being responsible.

But wait, there's more! Sign up for our newsletter and get even more spam in your inbox every day",spam
"Click here to get a FREE iPad! Limited time only! Hurry up and claim your prize before it's too late! 

",spam
"Get rich quick with our amazing new app! It's so easy, even a toddler could do it. Just deposit $500 and watch your money quadruple in a matter of hours! Don't miss out on this incredible opportunity!

",spam
"Long story short I am running a series of tutorials for my co-workers and thought it might be interesting to build a simple machine learning model (most likely sklearn). I have created a basic RandomForestClassifier to predict a NBA players position based on their stats (Like I said, very simple).

But I was wondering if anyone had some more 'fun' datasets, I was thinking maybe a survey where the participants could then input their own attributes and see what the outcome is. Maybe it 'predicts' who they might vote for in an election, or their favourite type of music etc etc.

Thanks in advance!",not_spam
"Looking for a hot new way to boost your followers and land more likes on your posts? Look no further than [insert social network name here]! We've got all the tools you need to make your content the talk of the town.

Don't settle for those other social media platforms that just don't understand how to give you the exposure you deserve. With [insert social network name here], you'll be able to reach a wider audience than ever before. Just post your pics and watch the likes roll in!

And if you're looking to take things to the next level, our premium packages offer even more features and benefits to help you",spam
"Get Rich Quick with [Social Network]!

Hey, have you heard of [Social Network]? It's the best thing since sliced bread! You can make so much money in just minutes - it's insane!

All you have to do is join our team and we'll give you all the tools you need to start making money right away. You don't need any experience, just a willingness to learn and a desire to succeed.

We'll show you how to promote our amazing products to your friends and family and before you know it, you'll be rolling in cash. And the best part? You can work from anywhere - your couch,",spam
"HOLY SMOKES! You won't believe what I just stumbled upon! It's like mind-blowing, earth-shattering, LIFE-CHANGING stuff, man! I'm talking about the biggest, juiciest secrets to life that no one has ever told you before. And YOU, my friend, have the exclusive opportunity to learn them all! 

",spam
"$$$ Earn Thousands $$$ for FREE in just one click! No scam! No gimmick! Just sign up and start earning today! 

",spam
"WIN FREE IPAD NOW!!1!111!! 
",spam
"Luvly peepz! Congratz and shoutout to all our followers and userzzz for being da real MVPzzz. 

",spam
"***BUY MORE FOLLOWERS NOW!!!***

Get your Instagram account noticed with our latest deal for buying more followers! Don't waste your time and effort on creating great content when you can simply boost your numbers with our awesome promotion! 

But wait, there's more! You can also buy likes and comments from our trusted sources, all for an unbeatable price! Impress your friends and look like a social media sensation in no time with our fake followers and engagement. 

Don't miss out on this amazing opportunity to cheat your way to Instagram fame! Sign up now and start living the lie of your dreams!",spam
"I realise there is some difference between day-ahead and intraday prices, although I'm not sure if the latter applies to the UK, or how to adjust day-ahead prices with intraday if necessary.

Any help would be greatly appreciated.",not_spam
"Holla, peeps! It's yo boy from InstaGram, ready to drop some lit content on yo feed! I know y'all been waitin' for this, so without further ado, let's get crackin'!

",spam
"Looking for ways to make quick cash online? Look no further! We've got just the thing for you! Our exclusive program guarantees big profits without lifting a finger!

",spam
"""Lose 10 pounds in 2 days with our amazing diet pills! Limited time offer, buy now and get a free trial!""

",spam
"Anyone know of datasets that include diversity in technology? Specifically I am looking for the % of minorities in technology companies, % that are technical and that are not, % that are managers, etc. Anything will be a huge help. thank you!",not_spam
"Hey there, fellow netizens! I've got some super-sensational news for all of you out there surfing the web today. Are you tired of boring old status updates and lame tweets? Well, buckle up because I've got something that's going to blow your mind!

Introducing the newest, hottest, coolest social media platform out there...it's called ""NetFrenz""! You heard it here first, folks! NetFrenz is the ultimate place to be for all your online needs. From chatting with friends to posting about your daily adventures, NetFrenz has got you covered.

But wait, there",spam
"Does anyone know of an existing database, or website that I could scrape, to find the locations where movies were filmed?

Any advice would be sincerely appreciated!",not_spam
"SuperiorLife: Check out our new line of products! ğŸ™ŒğŸ¼

ğŸš€ Get in on the hype with our exclusive offers! ğŸ˜

ğŸ‰ It's time to upgrade to a better life. ğŸ’¯

ğŸ”¥ Join our community now and take advantage of our unbeatable deals! ğŸ¤‘

Why settle for less when you can have the best? ğŸ¤”

Don't wait, shop now and start living your best life today! ğŸ›ï¸",spam
"As above. I should also mention that I'm far from a computie expert, and I'm having trouble with [Tesseract](https://github.com/tesseract-ocr). Is there an OCR that is a little more user friendly? My brain is starting to melt with all the scripting I'm looking at...",not_spam
"I'm looking to make a visualization of Seattle overtime for these different categories.  Where can I find this information?  I'm looking to go back as far as 2007. 

Thanks!",not_spam
"Singapore government launched their beta, open data portal: http://beta.data.gov.sg/ Hope to see more of these.

Here is some info from their about page:
The Singapore government has been sharing datasets through www.data.gov.sg  since 2011. To-date, the portal has more than 8,000 datasets contributed by over 60 agencies. In June 2015, the Beta site was launched with new features for sharing Open Data.",not_spam
"Do u want 2 bccaome RICH?$$$ We hav the Soluton! JUst j0in our page and Buy Are cOurse!!!$$$ 

",spam
"Lemme tell ya guys, this new update is lit AF! ğŸ”¥ğŸ”¥ğŸ”¥ We've got all the hot goss and juicy deets you need to keep your feed poppin'! Plus, we've got some sweet deals on our sponsored products that'll make your wallet sing!

",spam
"Hello everyone,  

I need to download the hourly wind speed values from the great [ERA5](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview) datasets.  
I tried using their dedicated python API as described in their [documention](https://cds.climate.copernicus.eu/api-how-to), it does work, but the time needed to fulfill requests is insanely slow (about 10h for 1 day worth of data).

Sadly, I need the whole available period, over the global extent, and at several Z levels, at this rate it would take years to download :/

I guess the current ECMWF api is so slow because it subsets and formats the data before sending it to the client, but I don't mind doing those step myself.

So my question is: does any of you know about a direct access to this database ? maybe an HTTP/FTP server like the one NOAA provides, or a MOTU server like the rest of the copernicus service.

I did not find any other way to access their datasets, a user of this subreddit did build [its own API](https://www.reddit.com/r/datasets/comments/i40z2o/looking_for_betatesters_for_historical_weather/) to fetch it, but I would like to get the data directly from the original provider, I would be surprised if ECMWF did not provide this kind of ""public but non-documented raw access"".

Thanks",not_spam
"Specifically Lebanon and Syria. Other than [internet world stats](http://www.internetworldstats.com), if possible",not_spam
"Looking for the HOTTEST deals around? Look no further! Our site has everything you need and more! Get BIG savings on everything from fashion to tech - you won't find prices like these anywhere else! Trust us - you won't regret checking out our site today!

",spam
"FREE MONEY?!?!

Hey EVERYONE!!! 

CHECK THIS OUT!!!! You can get FREE MONEY just by signing up for _______!! That's right, just by giving us your personal info and clicking ""submit,"" you'll be rolling in the dough in no time! 

But wait, there's MORE!!! Not only will you get FREE MONEY, but you'll also be bombarded with nonstop ads, spam messages, and pop-ups! Who doesn't love that?? 

And don't forget our amazing contest!!! Submit your email address to be entered to win a chance at a lifetime supply of spam emails and worthless junk! 

So what",spam
Hello everyone!  I'm looking for a dataset consisting images of various sneakers for my thesis project. Is there anything you know of?,not_spam
"OMG, you won't believe what just happened on our social network! Our latest update is going to blow your mind with all the features weâ€™ve added. It's gonna be totally lit!! Here's the lowdown:

First, weâ€™ve added a bunch of new sticker packs for you to express yourself in the best way possible. Want to tell someone you love them? We got stickers for that. Want to tell someone to cool down? We got stickers for that too! So many options you can barely handle it.

Second, we've got some sick new filters for your profile picture. Want to look like a cartoon character? No",spam
"Hello,   
I am looking for some datasets which are daily updated. The best case is that on a given site every day there is a new CSV or JSON file uploaded.   
It can be anything (or maybe daily files with more than&gt; 1000 new records) :)

Thanks for the help :)",not_spam
"Buy now, get rich quick! Don't miss out on this once in a lifetime opportunity to earn BIG money with our amazing product! 

Our product is guaranteed to change your life and make you the envy of all your friends. With just a small investment, you could be on your way to financial freedom in no time at all. 

But wait, there's more! Sign up now and you'll also receive a FREE ebook filled with insider tips and tricks to help you maximize your earnings. 

Don't delay, act now before this incredible offer disappears forever. Our satisfied customers can't be wrong, so join the thousands who have already",spam
"Trying to do some research on impact of news articles and sentiment on social media 

Alternatively if one is not available, is it possible to extract a list of posts from a subreddit such as r/coronavirus 

Apparently scraping via the api only gives a max list of 1000 submissions which might not be enough 

Thanks /r/Coronavirus",not_spam
"Hi everyone,

I want to perform a visual analysis of Inventory data using Tableau. I would appreciate it if anyone could point me to such a dataset.

Thank you in advance!",not_spam
I am looking for a dataset of classified positive negative social media posts preferably in the 1000's or more and easy to parse into a python dataframe to perform sentiment analysis. I have already written the algorithms and used nltk datasets but would like something better for analyzing social media posts something specific to social media would be great thanks.,not_spam
"""Get ready to be blown away by the most amazing offer you have ever seen! Our ALL NEW revolutionary product will change your life for the better! Don't miss out on this once-in-a-lifetime opportunity! Just click on the link below to get started today!

",spam
I've a data set of all the designations in a company. I've to map them against company functions and the corresponding seniority level. Any idea how should I go about it?,not_spam
"""Get rich quick! Make thousands of dollars in just a few minutes! It's easy! Just click on this link and sign up now!""

",spam
"Calling all Insta fam! Have you been craving some major #fitspo? Want to see the hottest celebrities in their skimpiest outfits? Well, look no further than InstaGlam! Our platform is jam-packed with bootylicious babes and swole dudes showing off their chiseled bods. And don't forget to use our hashtags like #weightlossjourney, #cleaneating, and #bikinibody for some extra engagement. Plus, our new sponsored posts will overwhelm your feed with ads, so you never have to worry about being bored! InstaGlam: where your self-esteem goes",spam
"Because i want to try and make my own app to learn specific languages with good examples and correctness i would need some data for that e.g Vocabulary, Sentences. All i came across was a few words in this language and a few sentences here. Scraping from a dictionary would take a lot of time.",not_spam
"I'm working in something, I need to get all information about it like:

* Text
* pictures 
* video
* Meme or comics.

||||
|:-|:-|:-|
||||",not_spam
"WIN A FREE IPHONE X!!!!!!

That's right, folks! You heard it here first! Our amazing social media platform is giving away a brand new iPhone X to one lucky winner! All you have to do is click on the link below and enter your personal information, including your full name, address, phone number, email, and credit card details!

But wait, there's more! If you share this post with all of your friends and family, you increase your chances of winning! We'll even give you an extra entry for every person who signs up using your unique referral code!

And that's not all! We also have",spam
"OMG, peeps! You won't believe what I found on this amazeballs website! It's the ultimate secret to gettin' rid of all that extra flab, and it's totally free! Just click on the link and VOILA! A hot bod in no time!

",spam
"Get ready to be blown away by the latest and greatest content on the world's most amazing social network! We're talking about the ultimate hub for all your social needs, where you'll find the hottest trends, the funniest memes, and the most mind-blowing videos.

",spam
"can someone list out benchmark datasets used for object detection?

1. Coco
2. Imagenet",not_spam
If you can send me also all the possible data about the delivery company. Thank you very much for the help,not_spam
"Hey there frenz!

Lemme hit you up with some wickedly awesome spam! Are you feeling down and out? Bored of the same old, same old? Well, have no fear because we've got the ultimate solution for you!

Introducing our brand spankin' new line of weight loss pills! Say goodbye to those pesky love handles and hello to a hot bod! Not only will you look great, but you'll also feel great with all the energy our pills give you!

But wait, there's more! We've also got the best online casino out there! Get ready to win big and live like a ball",spam
"Get ready to be mind-blown! Our network has the most insane features you can ever imagine. We've got the kind of content that will leave you gasping for air, and our community is just the coolest people you'll ever meet.

",spam
.,not_spam
"Looking for the most wicked and juicy memes that will blow your mind off? Look no further than our page, where we have a plethora of hilarious content that will make you ROFL all day long!

",spam
"""OMG GUYS, YOU WON'T BELIEVE WHAT I JUST FOUND ONLINE!!!""

So, like, I was browsing the interwebs and stumbled upon this AH-MAZING deal for weight loss pills. They're supposed to make you lose like 10 pounds in 2 days or something CRAZY like that!

And, get this, they're also giving away a FREE trial bottle, all you have to do is give them your credit card info to cover shipping and handling. But pshh, who cares, right?? Because losing all that weight will totally be worth it!

But wait, there's MORE!! Have",spam
"Check out these amazing diet pills that will make you lose weight in just one week! You won't believe the results!

",spam
"Hey everyone,

I'm looking for a dataset (or even descriptive statistics) of registered voter demographics by state (particularly Michigan). Preferably from 2016 or 2018. Demos I'd like included are age, race, gender, education, party and congressional district. I checked the Census, it seems like they probably have this data but not in a table they've released so far.

Let me know if you know of anything!",not_spam
"Is there any dataset that I can use to relate first names with ethnicity or baby origins ?
",not_spam
"Increase Your Followers Now!

Are you tired of having a small followers' list? Do you want to become famous overnight? Then, you've come to the right place! Our app can help you increase your followers in a jiffy. 

All you need to do is sign up for our premium subscription, and we'll do the rest. Our team of experts will work round the clock to boost your follower count. In just a matter of days, you'll have thousands of followers! 

But that's not all. With our premium subscription, you'll also have access to exclusive content and special features. You'll be able to customize",spam
"Attention everyone! Win a free iPad in just 3 easy steps! Step 1: Like our page. Step 2: Share this post. Step 3: Comment below with the phrase ""I want my iPad!"" and tag five friends. You'll be entered into a drawing for a chance to win the latest Apple iPad. Don't wait, do it now!

",spam
"Hey,
I'm looking for a parallel speech corpus. For direct speech to speech translation. (Audio to Audio)",not_spam
"I'm going to research data center traffic scheduling based on SDN,but there is no public dataset,so where can i get a dataset that include packet trace in data center",not_spam
"Attention all internet users! Are you tired of being broke and not having enough money to do the things you love? Well, you're in luck because we have the solution for you! Our latest get-rich-quick scheme is guaranteed to make you a millionaire in no time.

All you have to do is click on the link below and enter your credit card information. We promise you won't regret it. You'll be living in a luxurious mansion in no time with a fleet of sports cars at your disposal.

But wait, there's more! If you click on the link now, you'll also receive a free trip to Bora B",spam
"Hot deals, get crazy discounts now on our site!!! ğŸ˜±ğŸ”¥ğŸ‘€

",spam
Title,not_spam
"Get rich quick with our amazing new scheme! You can't afford to miss out on this opportunity to make millions from home. Just click on this link to sign up now!

",spam
"Hey, fellow social network addicts! I have something fabulous to discuss with you today. Have you been feeling down lately and craving some excitement in your life? Look no further because I have the solution for you! 

Introducing our latest partner, ""Get Rich Quick!"" This program guarantees that you will make millions in just a few weeks. Yes, you heard that right! And it's all thanks to our state-of-the-art algorithm that analyzes the stock market and predicts the winning stocks. 

But wait, there's more! Have you been looking to lose weight and get fit? Our network has partnered with ""Lose Fat in ",spam
"Hi All.  Hope you all are safe.  I'm looking for datasets related to consumer goods industry, mainly retail store sales, etc

Hope anyone can help.",not_spam
"Get ready for the ultimate social media experience! We've got tons of likes, follows, and shares just waiting for you to claim them. Plus, don't miss out on our amazing deals - buy now and receive a free bonus bundle with every purchase!

",spam
"""50% OFF all skincare products!! Limited time offer!! Don't miss out on this amazing deal!! ğŸ¤‘ğŸ‘ŒğŸ¼ğŸ™ŒğŸ¼""

",spam
"Our network is the best network! You want to be on our network because it's the most popular network out there. We have millions of users and they all love our features.

",spam
"I have started a dataset for anime subtitles on  [https://www.kaggle.com/jef1056/anime-subtitles](https://www.kaggle.com/jef1056/anime-subtitles) 

A parser that splits the data into newlines and gives a ""&gt;"" to the start to each line is included, should community members want to add more data (please contact me if you find more data and want to help!!!!!)

There are 2 input (.txt files), one cleaned of repeating lines (which are apparently common in subtitles) and the other being the raw extracted data. The ending data is 1,203,330 lines and is about 40mb.",not_spam
"I am looking for a dataset which contains data that is gathered by GPS-trackers which athlethes wear. Think of hearth rate, traveled distance, top speed, etc.. A description of such device is explained on the following page: [https://www.sportperformanceanalysis.com/article/gps-in-professional-sports](https://www.sportperformanceanalysis.com/article/gps-in-professional-sports)",not_spam
"Get ready to level up your social media game with our never-before-seen hack! Weâ€™ve revolutionized the way you get likes, comments, and followers on your posts. Say goodbye to old-fashioned tactics and hello to our cutting-edge technology.

",spam
"ğŸš¨ğŸ†˜ ALERT ğŸš¨ğŸ†˜ 

URGENT!!1!1!1!1! You won't BELIEVE what we have in store for you!!!! ğŸ˜±ğŸ˜±ğŸ˜±

ğŸ‘‰ğŸ¼CLICK HEREğŸ‘ˆğŸ¼ to get exclusive access to our limited-time offer!!! ğŸ’¸ğŸ’°

That's right, folks!! ğŸ’ğŸ»â€â™€ï¸ğŸ’ğŸ¼â€â™‚ï¸ We've got the best deals in town and we're not afraid to show it! ğŸ™ŒğŸ¼

Don't miss",spam
"Are you tired of being left out of the latest trends and updates? Do you want to stay ahead of the game and be the envy of all your friends? Well, look no further than our amazing social network!

",spam
"I'm doing my dissertation on SAP Hana performance capabilities compared to other RDBMS systems, mainly focus on the analytical process, and I would like to have some interrelated tables with significant amounts of real data. The first thing I can think of is financial data, but anything I can find would be helpful.
Any idea where I can find such data?
",not_spam
"I'm looking for a dataset to use in a presentation to teachers on how to use My Maps by Google, which can take a data set with longitude and latitude and plot it.

I thought it would be cool to highlight an example using a dataset on average daily temperatures per region or even arctic ice. Any ideas?

Thanks so much!",not_spam
"DO YOU WANT TO EARN BIG MONEY FAST? CLICK HERE NOW AND JOIN THE MILLIONAIRES CLUB! 

",spam
Im looking for a data  set that includes names of people surveyed for anything like alcoholism or drug use to see if there is any correlation between names and these conditions (i.e. are people named ronny more likely to be alcoholic). Thanks in advance!,not_spam
"Are you tired of being broke? Want to make millions of dollars overnight?! Click here to find out how!

",spam
"Hello! I am searching for a dataset, big, but not too big (Less than 1GB), containing book content. Perhaps something having all Gutenberg books?",not_spam
"Hi everyone,

I  am currently working on a large data that consists of 175  participants.  There are approximately 15 participants that I need to exclude because they took extremely long to complete my survey, quick  speed through my survey, and their responses were not consistent. My professor says that I  use to create an exclusion dummy variable, I am not quite sure how to create a dummy variable for participants that were too long or quickly speed through my survey. I have not done preliminary analyses to assess for any outliers yet. There are also 3  participants that only answered a  small portion of the survey but have a  100% completion rate",not_spam
"Are you tired of being bored online? Well, fear not my friends, because MyCoolNet is here to save the day! With our cutting-edge technology, you'll never have a dull moment again! Our website is packed full of exciting games, quizzes, and memes that will keep you entertained for hours on end. 

But that's not all! Our online store features the latest and greatest in fashion and technology, and our prices are unbeatable! And if you act now, you can get a special discount on all purchases over $50! 

But wait, there's more! By becoming a member of MyCoolNet, you",spam
"Get ready to have your mind blown, because the latest update from our social network is going to change your life! Our app is now supercharged with even more amazing features than before, all designed to make your online experience more exciting than ever.

",spam
"NEW DEAL ALERT: BUY ONE GET ONE FREE ON ALL ITEMS! HURRY UP AND GRAB THIS AMAZING OFFER NOW! LIMITED TIME ONLY!!!

",spam
"I've been keeping this spreadsheet for a few years, submitting it for anyone to use for a project or just to enjoy.  This work is released public domain via The Unlicense.

Summer and Winter Olympics sports by major and minor sport such as Skating / Figure Skating.  Includes data from 1896 to 2022.

https://docs.google.com/spreadsheets/d/1q9XwRSDsAYRHG0CU8UJ7J-K50iJZ5sFoVASH86Gugmw/edit?usp=sharing",not_spam
"ğŸš¨ğŸš¨ ATTENTION ALL USERS ğŸš¨ğŸš¨

ğŸ’¥ğŸ’¥ EXCITING NEWS FLASH ğŸ’¥ğŸ’¥

Are you tired of the same boring content on your feed? Do you want to spice up your social media experience? Look no further! Our platform has got you covered ğŸ‘€ğŸ‘€. 

We've just added a new feature that will blow your mind ğŸ˜œğŸ˜œ. Introducing the ""spam-o-rama"" option! Now you can flood your followers' feeds with endless amounts of spam and garbage content. Why settle for quality when you can have quantity?",spam
"""Get ready to level up your social media game with our latest updates! ğŸ”¥ğŸ”¥ğŸ”¥ Weâ€™ve got all the hottest trends and memes thatâ€™ll keep your followers double-tapping ğŸ‘ğŸ‘ğŸ‘ and DMâ€™ing you 24/7. Hereâ€™s whatâ€™s new:

ğŸ’¥ Introducing the #SwipeChallenge â€“ itâ€™s like a dance-off, but with your fingers. Upload a video of you swiping through our app with the most flair and you could win big! ğŸ’°ğŸ’°ğŸ’°

ğŸ’¥ Our algorithm has been upgraded to supercharge your engagement. Think more likes",spam
"Hey there, fam! It's your favorite social network in the building, and we're bringing you some fresh, juicy gossip from the world of celebs. We know you can't get enough of those juicy deets, so sit back and relax while we spill the tea.

First up, we've got some sizzling hot news about Kim K and Kanye West. Rumor has it that they're headed straight for splitsville, and we've got all the deets on what went wrong. Was it Kanye's wild rants? Kim's love of the limelight? Or maybe something way juicier that we can't even",spam
"I need concept breakdown of things learned throughout schooling. Anything grade-wise also works. Basically I want a dataset of all the concepts learned through education in some kind of hierarchy. Some sort of concept map or something.
Any pointers would be great help!
",not_spam
"Nouns, Adjectives, and Verbs that have already been spread out into their own files.  I am interested in working on a computational linguistics project but my google-fu has failed me.  Any help is appreciated. Thanks.",not_spam
"I have a bunch of questions I'm seeking to answer, but I don't know how to obtain the data. I mainly want to learn if annoying alcohol laws increase or decrease the amount of small scale alcohol makers, and I think it would be easiest to focus on beer to answer these questions.


Example questions:

- Do restrictive liquor laws have any effect on the amount of entrepreneurs starting their own brewery/winery/distillery? (probably yes, they have at least *some* effect)
- Do they increase the amount of small scale liquor-making or decrease? (if it's more than a tiny amount, this will be very important to know)
- Do they have negligible/very minor effect? (this is what I'm actually expecting)

My main issues are:

- I don't know how to find a complete and detailed list of alcohol related laws by state
- I don't know how to use that information to rate states
- I especially don't know how to rate states by a meaningful metric of alcohol production, since my options include ""most new micro breweries"", ""best beers"", and ""most sales or pints/glasses/gallons purchased""

Perhaps I just need to find a ""top 5 common alcohol laws"" list and create a checklist?

Anyway, if this information has already been done, that would be best. If it hasn't, help on creating such info is much appreciated. Thank you.",not_spam
"Hi everyone,

I'm introducing the ""War of Words"" dataset, a dataset of 450 000 legislative edits from the European Parliament. We extracted those edits from about 240 000 amendments contained in thousands of DocX documents. The data covers 10 years (2009-2019) and two legislature periods (the 7th and the 8th legislature). In each period, \~800 European parliamentarians proposed edits on \~1000 law proposals. The labels (*accepted* or *rejected*) correspond to votes on the edits by parliamentarians within the parliamentary committees, i.e., before forwarding the amended proposal to the whole Parliament.

The dataset is hosted here: [https://zenodo.org/record/3757714](https://zenodo.org/record/3757714)

I'm also releasing some [code](https://github.com/indy-lab/war-of-words) showing how to process and use the data (with a predictive model).

This is part of a paper ([*War of Words: The Competitive Dynamics of Legislative Processes*](https://infoscience.epfl.ch/record/275473/)) that I presented this morning at [The Web Conference](https://www2020.thewebconf.org). Here is a [video](https://victorkristof.me/video/war-of-words.mp4) of the presentation if you want an overview of the context and the structure of the data (and \[disclaimer\] some cool, early results :)). I will be progressively adding more features to the dataset, as I'm able to extract them from the raw documents.

I hope this can be of interest to some of you! Let me know if you have any questions of course!",not_spam
"Fam, check out these crazy deals for weight loss products on our app! Lose those extra pounds in no time and get that beach bod you've always wanted. And guess what? We're throwing in a FREE trial of our teeth whitening kit too! Who doesn't want pearly whites to match their slim waistline, amirite?

But that's not all, folks. Our exclusive partnership with a luxury vacation property means that every purchase of a weight loss product gets you one step closer to a dream vacation. So don't wait, download our app now and start achieving your fitness and beauty goals while planning the trip of a",spam
"Get ready to be amazed by the hottest and most wicked updates on our platform! You won't believe what we've got in store for you!

",spam
"Hi, i've been searching for a panoramic (equirectangular) dataset for a while now and I can't seem to find anything that has outdoor environments (e.g roads, forests, urban, indoor too etc.).

Aparently the sun360 dataset is basically exactly what i'm looking for, but it doesnt seem like its available online anymore.

Does anyone know of anything like this?

Im thinking of just writing a script to download \~100,000 panoramic images from google street view, but this is last resort and would take a long while. If I do this, i'll see if I can share this dataset after here.

&amp;#x200B;

[**I have created a small (25,000)  dataset from streetview which is available here.**](https://drive.google.com/drive/folders/1R3qwiVCZRjDcrwBselb5ibZGCv2PWEtR?usp=sharing)

&amp;#x200B;

Edit 1: I've downloaded \~25,000 eqiurectangular  832 x 416 images from google street view of cities and rural areas, i'll see if I can upload it (though it has duplicate images and broken name system).

Edit 2: Uploaded the dataset, if anyone wants to add to it or whatever i'm happy to share the code I used to get the stuff. The size is good for me as I am using online a portion of each image, so have the equivalent of a huge dataset like that.",not_spam
"""Unbelieveableeeee! Get Rich Quick with our Super Duper Amazing Offer! Click Now and Win BIG Money! ğŸ˜ğŸ¤‘ğŸ˜œ

",spam
"Hi, I need a dataset with town names in Ireland and NI. I know there's logainm website, but I haven't found any json/csv to download. Any idea where I can find it?",not_spam
"Hello,

do you know if there is a dataset composed of videos of people using the [semaphore flag signalling system](https://www.britannica.com/technology/semaphore)?

So far I was only able to find pictures of people representing the single letter, but what I would like to use is videos in which a person starts from a neutral position and shows the movements.

Thanks in advance",not_spam
"Get ready to be amazed, folks! You won't wanna miss out on these unbelievable deals! Our site has got everything you need and more! Sign up now to start enjoying some of our exclusive perks and savings! Plus, don't forget to share and follow us on all your social media platforms! It's gonna be lit!

",spam
"$MAKE MONEY FAST$ğŸ¤‘ğŸ¤‘ğŸ¤‘

HEY EVERYONE, ARE YOU LOOKING FOR A CHANCE TO MAKE EASY CASH??ğŸ¤”ğŸ¤”ğŸ¤”

THEN YOU'VE COME TO THE RIGHT PLACE!!ğŸ’°ğŸ’°ğŸ’°

JUST SIGN UP FOR OUR ""GET RICH QUICK"" PROGRAM AND YOU CAN EARN UP TO $10,000 A DAY!!ğŸ‘€ğŸ¤¯ğŸ‘€ğŸ¤¯

NO EXPERIENCE REQUIRED, JUST A DESIRE TO MAKE BIG BUCKSğŸ’¸ğŸ’¸ğŸ’¸

AND TO MAKE IT EVEN",spam
"Hey there! Did you know that our platform is the best place to find hot singles in your area? We've got tons of users just waiting to connect with you and make your wildest dreams come true. Not only that, we've also got the latest gossip and trends that you just HAVE to know about. 

But wait, there's more! We're giving away a FREE iPhone X to the first 100 people who sign up today. That's right, you could be the envy of all your friends with the latest and greatest in smartphone technology. 

And don't forget about our exclusive VIP membership, which gives you access to",spam
"Hey guys, check out this totally epic new feature on our social network! It's the bomb diggity, and it'll blow your mind!

",spam
"Attention all followers! Do you want to earn big bucks while sitting on your couch? Well, we've got the perfect opportunity for you! ğŸ¤‘ğŸ’°ğŸ’¸

Introducing the new and revolutionary ""get rich quick"" scheme that will make you a millionaire overnight ğŸ‘€ğŸ’°ğŸ’¸! All you have to do is click on the link in our bio and sign up for our ""exclusive"" program that will guarantee you instant success ğŸš€ğŸ‘!

But wait, there's more! By signing up now, you'll also receive a FREE trial of our limited edition anti-aging cream ğŸ§´",spam
"Hi allI would like to ask where can I find dataset with wrong data CSV or any RDF format ?

try to found it but i did not find.

and thank you",not_spam
"Get ready to be mind-blown, because THE BEST DEALS are NOW available ON OUR SITE! But thatâ€™s not all! Sign up now and enter to win A FREE TRIP TO AN EXOTIC BEACH RESORT!!! 

",spam
"Earn quick cash with our new get-rich-quick scheme! Only $19.99 to join and start earning within a week!

",spam
"""10 Quick Tips to Make You Rich and Famous in 24 Hours!""
",spam
"Get ready to be blown away by the latest and greatest trends on our social network! We have everything you could ever want, from viral videos to hot gossip, and everything in between!

",spam
"Get rich quick! Join our amazing network of success-driven entrepreneurs and start earning money in your sleep! With our cutting-edge system, you'll be making millions in no time!

",spam
"What are some datasets that are released on a regular, such as monthly basis? 
I know BLS releases unemployment figures on the first Friday of every month and I'm curious if any other government agencies have similar data schedules.",not_spam
"Are you tired of being mediocre? Do you want to be as vibrant and fierce as the flames of a dragon? Look no further because we have the solution for you! Our brand-new product will transform you into the gorgeous being you were always meant to be. 

",spam
"Looking for hot singles in your area? Do you want to make a lot of money from home? Well, you've come to the right place! We have tons of ads for both dating and work-from-home opportunities!

Sign up now and get access to our exclusive ""How to Get Rich Quick"" guide, as well as unlimited free dating profiles! Plus, if you sign up within the next 24 hours, you'll receive a one-time-only offer to buy our miracle weight loss supplements at an unbeatable price!

Don't wait, act now and start living your best life today! Our website is open 24/7, so",spam
"L@@K 4 DISCOUNT! BUY NOW! BEST OFFER!! 
Are u SICK of not being POPULAR?? Tired of being the LOSER of your group? WORRY NO MORE! With our NEW SOCIAL NETWORK, you will be the most POPULAR person on the planet! 

With our amazing features such as live streaming, instant messaging, and likes, you can share every mundane detail of your life with the world, and gain tons of followers! Your life will be the envy of everyone!

Follow these simple steps to become a SOCIAL MEDIA SENSATION:
1. Sign up NOW and get a special DIS",spam
"Hello everybody, here I have a question for a dataset I want to use. 

I am downloading monthly company variables through the Refinitiv Eikon Datastream for the period 01.01.2002 until 01.12.2021. 

The variable ""price"" has 239 observations for every company which is listed before 2002.   
The variable ""opening price"" has only 212 observations for every company which is listed before 2002. 

The 27 missing datapoints occure either on the 1st of January or the 1st of September.  
01.01: every year from 2002-2021, except for 2005 and 2011  
01.09: 2002, 2003, 2007, 2008, 2012, 2013, 2014, 2018, 2019

01.01 is the New Year's Day and the stock market is closed. Therefore, I guess no opening prices are available. However the ""regular"" price is available. How and why?  
01.09: Usually the Labor day been either on the 1st, 2nd or 3th of the respective year. Could that explain why there is no opening price?  


Despite the explaination for the missing data, I need data. Other data providers, like open source yahoo finance, do provide opening prices for each month of the same time period. 

However, I cannot use yahoo finance for multiple reasons. E.g. I want to analyse more than 5000 firms and I unclude some variables only provided by Refinitiv Eikon Datastream. 

Therefore, how can I obtain opening prices for each month? Is there an option in Refinitiv Eikon Datastream to do so? Can I somehow use the next days opening price if the data is not available?   


Thank you for reading.  
Best for you,  
Losyres",not_spam
"Best Deals You Cannot Resist!

Limited time offer! Get the latest gadgets and accessories on a price drop you won't believe! Perfect for all ages and all occasions. Discounts up to 90%. 

Hurry and avail of our exclusive promo now! Limited supplies only. Don't miss this chance to get your hands on the newest and coolest stuff in town.

But wait, thereâ€™s more! Subscribe now to our premium membership and get exclusive deals and perks for a whole year! Don't get left behind, upgrade now and experience the ultimate online shopping experience. 

You won't regret it! Seriously! Our satisfied customers can't get enough",spam
"***CLICK HERE FOR A FREE GIFT CARD!*** 

That's right, you heard us! We're giving away FREE gift cards for simply clicking the link above! But wait, it gets even better...once you've clicked that link, you'll be directed to our amazing new weight loss product that will have you shedding pounds in no time!

Not convinced yet? How about this - if you refer 10 of your friends to our site, we'll give you ANOTHER free gift card! And if you refer 20 friends, we'll even throw in a bonus prize!

But act fast, because this offer won't last forever",spam
"I am new to machine learning and currently working towards building my skills in the NLP domain. 

I am looking for a medium sized dataset of product reviews (to run on my laptop) which contains at  least 2 columns , 1- product review (short text description and 2- Is this a positive or negative review ( 1,0).  

Please let me know where can I find such a dataset ?  Big thanks for your help.",not_spam
"Make Money Online NOW â€“ Easy and FAST!

Hi therrree! Are you tired of working your butt off and still not making enough money? Do you want to learn how to make a boatload of cash without doing anything?? Well, look no further! Weâ€™ve got the solution for you!

With just a few clicks, you can start making BIG BUCKS online today! Our amazing system is so easy and fast, you wonâ€™t believe it! All you have to do is sign up and start watching the money roll in!

But wait, thereâ€™s more! If you act now, youâ€™ll also receive a FREE bonus package",spam
"Hi everyone, I have a stats project that asks us to find a data set and analyze it. I would like to conduct a 2x2x2 ANOVA to get more familiar with them. Can anyone help point me in the right direction? I have found a few websites, but nothing that has been any good. Don't really care about what the data is on, just that it is a 2x2x2 with a continuous DV. Thanks for the help in advance!",not_spam
"Looking for some exclusive deals? Want to enhance your shopping experience? Then, you've come to the right place! Our platform has a wide range of products that'll make you go ""WOW""! From trendy clothes and accessories to tech gadgets and home decor, we've got it all!

But wait, that's not all! Sign up today and get a chance to WIN a FREE trip to an exotic location! All you have to do is follow us on all our social media accounts and share this post with your friends! The more shares you get, the higher your chances of winning!

And if you're feeling lucky, why not",spam
"What is your recommended tool for it?
I have created several tables in database, however I need a fast front end to allow user filter what area and type of info they need and then it allows them to export those tables.",not_spam
"I'm looking for activity based cost datasets for a project I'm working on. The cost data could be for a process (manufacturing, healthcare, etc). Any help would be appreciated. ",not_spam
"I am thinking of things like schools,prisons etc. ,I want to be able to profile people and their relationships to one another ,so a dataset of cctv video on a street is useless for that purpose",not_spam
"WIN FREE STUFF NOW! CLICK HERE FOR YOUR CHANCE TO WIN AN IPHONE, A CRUISE, AND A YEAR'S SUPPLY OF TACOS!!! 

",spam
"Yo, what's up fellow netizens? It's ya boy from [insert social network name here] bringing you some hot, steamy garbage for your feed.

Listen, I know you're probably tired of your boring ol' friends and their lame posts. But guess what, with [social network name], you can connect with COMPLETE STRANGERS who will spam you with ads and unsolicited messages!

And don't even get me started on our amazing features like constantly changing algorithms that hide posts from people you actually care about, and the ability to track your every move on the app so we can sell your data to the highest bidder.

",spam
"HURRY UP AND BUY NOW! SUPER AMAZING DEALS THAT WILL BLOW YOUR MIND! ğŸ”¥ğŸ”¥ğŸ”¥

",spam
Looking to train a neural network to differentiate between areas of sea bed with coral and areas with just sand. Any datasets I can use?,not_spam
"Are you tired of not getting enough likes on your posts? Well, fear not, because we have the solution for you! Buy a bunch of likes and watch your post soar to popularity! And that's not all, we also offer fake followers that will boost your follower count and make you look like an influencer!

",spam
"ATTENTION ALL USERS!! Want to earn $$$ while scrolling through your feed??? Check out our newest partner @scammyinvestmentcompany for easy and quick returns on your investments!! #getrichquick #scamalert ğŸš¨ğŸš¨ğŸš¨

",spam
Oddly enough this data is not easily confused via noaa and google big query makes you input a credit card and all this bs. Anyone know a good free api for USA weather.,not_spam
"Buy our super-awesome product now! It will change your life in ways you can't even imagine!! ğŸ¤‘ğŸ’°ğŸ’¯

",spam
"Get rich quick with our amazing new product!!! You won't believe how easy it is to make money - just sign up now and sit back as the profits roll in. Don't miss out on this incredible opportunity!

",spam
"Attention everyone, have you heard about the new super fantastic deal happening right now? Our site is offering the most amazing discounts, free gifts, and giveaways you could ever imagine!

",spam
"The newest data I could find of this was from 2007 on ""nationmaster""

[https://www.nationmaster.com/country-info/stats/Transport/Road-density/Km-of-road-per-100-sq.-km-of-land-area#-date](https://www.nationmaster.com/country-info/stats/Transport/Road-density/Km-of-road-per-100-sq.-km-of-land-area#-date)

Does anyone have a more reliable and up to date dataset for this?

Edit: Ideally from after 2016.",not_spam
"In a new paper, researchers from the University of Bristol, the University of Toronto and the University of Catania explain how they created Epic-Kitchens and introduce new baselines that emphasize the multimodal nature of the largest such egocentric video benchmark.

Here is a quick read: [Epic-Kitchens | Largest Egocentric Video Dataset Gets New Baselines](https://medium.com/syncedreview/epic-kitchens-largest-egocentric-video-dataset-gets-new-baselines-5632ce9992bc)

The paper *The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines* is on [arXiv](https://arxiv.org/pdf/2005.00343.pdf).",not_spam
"Warning! Our latest update has detected suspicious activity on your account. Please click on this link and enter your login details to verify your identity and secure your account!

",spam
"L@@k at thi$ awes0me pr0duct I f0und! It'll make y0ur life s0 much better and y0u'll never want t0 live with0ut it! It's the latest and greatest thing in the market and it'll change y0ur life f0r the better! D0n't wait, act n0w and get it f0r a l0w price bef0re it's t00 late!

",spam
"ğŸ‘‹Do you want to make fast cash?ğŸ’°

ğŸ¤‘Join our exclusive community now and unleash your financial potential like never before!ğŸ’¸ğŸ’¸ğŸ’¸

ğŸ“ŠWe provide you with the best trading signals, so you can make a ton of money without any effort! Don't miss out on this golden opportunity!ğŸ“ˆ

ğŸš¨Hurry up and sign up now for a chance to become a millionaire in just a few weeks!ğŸš¨

ğŸ‘‰Click the link in our bio to start earning today!ğŸ’»ğŸ’°ğŸ’µ

#makemoney #",spam
"""Make $$$ fast!!! Best oppurtunity!! click now!!!!""

",spam
"Hey everyone,
I have a student group wiling to work on prescriptive analytics. I want them to work in health care particularly dementia. Has anybody worked or seen a dementia dataset?",not_spam
"I have a friend who is a digital artist, she's just starting out and is curious about what other artists charge for their art as she's not sure what her price points should be.

Would be curious to cross section rates by state, country, age, professional background etc.

There doesn't seem to be a good dataset of this, anyone know of any? I could scrape Fiverr to create a dataset, but I feel like the artists all price gouge and she's not interesting in selling her commissions for $5.

Any thoughts/info/advice?",not_spam
"BBQ LOVERS UNITE!

OmG gUyS, we just gotta share with u our latst meat-tastic find!! ğŸ”¥ğŸ–

So, like, we just got a mega deal on this amAAAAzon grill that literally makes the most tender and mouth-watering stEEAAAK everrrrrrrrrrrrrrrrrrrrrrr. ğŸ¤¤

And you know what makes it just 10x better? These insane BBQ sauces we found online that will literally make ur taste buds EXPLODE! ğŸ¤¯ğŸ¤¯ğŸ¤¯

But wait, there's more!",spam
"**Location:**  https://files.pushshift.io/hackernews/

This is the complete API dump for Hacker News / Ycombinator from 2006 to July of 2017.

**sha256sums**

6ea91006618ab7cd6e58a2f42b0907be1e12c3f436c7987b2ff49d86b3c07df5  HN_2006.bz2

53bf6a400cd1cfd716f525ba5be4e1b64062df27112b219f71dddc35b2ca33de  HN_2007.bz2

d0cd72457223d4b2a2e73cd5c45a35a2e0dc0a4cb7a5356d852bac56ba6ced5a  HN_2008.bz2

20c37726ad76fa99e73853c8b332d2aa9d9988989ff77d84c9f256132e0de82e  HN_2009.bz2

c6e8e69e7e17266324d969ba4e2acad85312859d772abee422eac1424193f5bd  HN_2010.bz2

9da4ed0c1e8a626aa8ead983cd53f361316b6075f281f7910be176f6a9f271f2  HN_2011.bz2

96271fbde309abc3ccfaf972642b57dd1b64b0b0ed692f50a82e5e19e46a47ff  HN_2012.bz2

ab42d4f0a96d04d11432ee94d086e3a227d5f82835adcf8356a535e91df63e05  HN_2013.bz2

e866f46931198ddfd61b17db9247cd9ccb71d66a1b568088717a199061979138  HN_2014.bz2

9af11af2302b9062cee7b90a8ff81ede002ab9840844dc56976e71d8881f853f  HN_2015.bz2

f60142708d52b4a11e92dae6e50b74e505768e7edce3b59425c8ead32d705a45  HN_2016.bz2

c6f3dc178faee6086a412dfb8fc26bdac9535bb398b882932df71d3284e0ac92  HN_2017-01.bz2

adbe6fee73c76592b23b7eb81cd9e722b1af02cdb761ce3d4968c96b4903ae15  HN_2017-02.bz2

102b4c7cd7980a69243866029d2bf5d16b5f1840585092e8ed5387c39e3e26b4  HN_2017-03.bz2

e00e793b8f96b26415c72c28ea93ef1a0e8a065cff5f3e31ba9be6febe38de79  HN_2017-04.bz2

90f247bab3b0ecb65f56e9f8739e9202bbb1510d327ed8e8f8a24ac8b2cf783e  HN_2017-05.bz2

258e67ea951f12a74cf9d757c0ea84ae0eb577946f7f01ee2c42bc565b3488f8  HN_2017-06.bz2

c9739641f87e571aaa1c7ed8c95d8783350e796a9a3f36197342d2f440cd3e58  HN_2017-07.bz2


",not_spam
"r/place is streamed over a websocket, but I wasn't in time to store the data from early on. Did someone else?",not_spam
"[http://www.mytwitterscraper.com](http://www.mytwitterscraper.com)
I built a realtime twitter scraper with Java. Just get OAuth tokens from Twitter, make sure you're running Java 8 (just update your java), and you're ready to rock. Enter your search terms and the program filters the Twitter stream in real time against your keywords. When you're done, save your data set as a .csv file! Returns Username, Time, Location, and Tweet. Would love to get some feedback on this program. To install, put the jar file you download into it's own folder. Then before your first search, click the ""configure OAuth"" button and go through the steps. Then happy scraping!
edit: fixed the link Edit2: GOLD?! I've been on reddit for 2+ years lol, and no gold. First day on fake account to separate my personal Reddit from my programming work and BOOM, gold. Thanks Reddit stranger. I will cherish my magic internet bullion.",not_spam
"Looking for the best social media platform out there? Look no further than our site! With a dizzying array of features and options, we're the right choice for any savvy social media user.

",spam
"GET RICH QUICK!

Hey there, do you want to make big bucks in no time? Then this is the right place for you! We offer exclusive opportunities to invest in our business and become a millionaire in just a few months.

We have a team of highly skilled professionals who are experts in the stock market and cryptocurrency trading. We guarantee a return on investment of 500% or more! Yes, you read that right, 500% or more!

Don't hesitate, sign up now and start earning money instantly. Our system is easy to use and you don't need any prior experience to join. Plus, if you refer your",spam
"I want to visualise the recent pay figures for the BBC against the number of people that those presenters/employees reach.

I'm sure I can find a list of programmes that each presenter/employee has appeared on, but attaching that to a viewer/listener figure for TV or radio is proving tough. 

Anyone able to find the data we'd need to be able to do the next step? Full attribution of course if you don't want to work with me further on the analysis, or co-credit if you do.",not_spam
"My team and I created an API service for accessing crypto-currency market data, news and metrics.

The service includes live and historical data on:

* Trades 
* Order books 
* Candles 
* Index prices for all major crypto-currencies
* News search
* News metrics (e.g. [https://docs.google.com/spreadsheets/d/1-5iExx52DDYp-8NcJdQpXmxAchZq5K-fS\_zQR9gqMLU/edit#gid=1435086542](https://docs.google.com/spreadsheets/d/1-5iExx52DDYp-8NcJdQpXmxAchZq5K-fS_zQR9gqMLU/edit#gid=1435086542))
* CSV downloads (coming soon)

There are limits on the Free tier (e.g. no access to historical order books) but if you message me at info@tokendatabase.com I can upgrade your account for free for one month.

Let me know if you have any requests or feedback.

**Website:** [https://tokendatabase.com/](https://tokendatabase.com/)

**API Docs:** [https://tokendatabase.com/docs/#introduction](https://tokendatabase.com/docs/#introduction)",not_spam
"Yo peeps, you know what's lit? Our social media platform, duh! We're the dopest thing since sliced bread, and we got all the swag you need to up your online game. We got features for days and ways to connect with anyone and everyone. You name it, we got it!

",spam
"I am looking for a music dataset with at least 3 columns: (song_name, user_id, duration_listened).

Does anyone know where I could find something like this?",not_spam
"Hey you! Yes, you! Are you tired of being a loser with no social life? Do you want to be popular just like your favorite celebrities? Well, look no further because our social media platform has got you covered!

With millions of users, our platform is the ultimate destination for all things social. Whether you want to post pictures of your lunch or share your deep, philosophical thoughts with the world, we've got you covered.

Our platform also offers a wide range of addicting games and quizzes that will keep you entertained for hours on end. You can compete with your friends and earn cool badges and rewards.

But that's not",spam
"I am looking for data on stress, age, and weight on blood pressure. This data is for a paper in a stats class and I am having trouble finding any kind of good data sources that don't come from a statistics book. Does anyone know of a good data source for the aforementioned variables?

I will be running multivariate linear regression on the data.",not_spam
"[Title]: Loose Weight in 5 days with [Brand name]!

Lose weight like a Pro with [Brand name] and impress your sweet heart with your stunning figure. Our scientifically proven formula has worked for thousands of our customers and they've given us 5-star reviews on various platforms. 

Our amazing product will not only help you shed unwanted pounds but also boost your metabolism and immune system. 

Say goodbye to boring diets and tiresome exercises. Say hello to a leaner and happier you with [Brand name]. And if you order now, we'll even throw in a free bottle of our energy-boosting supplement.

",spam
"Hi,

I am making a databased project on far-right movement in Europe using Esri ArcGiS. Does anyone or know were I can find statistics over the national or regional distributions of far-right voters at national or regional level?  

Thanks",not_spam
"ATTENTION ALL USERS!!! ğŸš¨ğŸš¨ğŸš¨

We have an amazing deal just for you! If you follow and like our posts, we will give you a FREE iPhone!! ğŸ“±ğŸ

But wait, there's more! If you sign up for our premium membership, you will also get a chance to win a trip to the Bahamas!! ğŸ–ï¸ğŸŒŠğŸ’¸

And that's not all, folks! We have a limited time offer for a weight loss pill that can make you lose 20 pounds in just TWO DAYS! ğŸ™€ğŸŒŸ

Hurry",spam
"Make m0n3y fr0m h0me with th3s3 3asy st3ps!!!!1!
",spam
"""$$$ MAKE MONEY FAST $$$ 

Are you tired of working long hours without seeing any real results? Do you want to live the life of your dreams without putting in any effort? Then look no further! Our amazing new program will make you rich beyond your wildest dreams in just days!

All you have to do is sign up now and start sharing our content with your friends and family. The more people you recruit, the more money you'll make! Don't hesitate, act now and start living the life you've always wanted!

But that's not all! With our special supplements and diet plans, you can lose weight and get ripped",spam
"Looking for ways to increase your following? We've got you covered! Here at InstaFame, we offer the best services to boost your numbers in no time.

",spam
"â—â—ğŸš¨OMG!!ğŸš¨â—â—
This is SOOOOOO gross! You won't BELIEVE what we found in our latest burger! ğŸ˜±ğŸ˜±ğŸ˜± You'll never want to eat fast food again once you hear this!ğŸ’©ğŸ’©ğŸ’©

But don't worry, we've got the solution! Just click on this totally legit link ğŸ‘‡ğŸ‘‡ğŸ‘‡and you'll get a free voucher for a meal at one of our competitors. That's right, FREE FOOD!!!ğŸŸğŸ”ğŸŒ­

And while",spam
"ARE YOU READY TO UNLEASH YOUR INNER AWESOMENESS?!
We've got THE BEST deals for you on our platform! Sick of being basic? Upgrade your lifestyle with our exclusive offers!! 

",spam
"the type of data associated with bank accounts and transactions and credit cards, I've been looking but I've come up short, especially since transactions always pulls up technical information regarding Microsoft T-SQL",not_spam
"""Get rich quick with our amazing pyramid scheme! Join now and start earning insane amounts of money! Don't miss out on this amazing opportunity to become a millionaire overnight!""

",spam
"I'm building a stock trading app and I'd want to have a page where users can see information about each stock, like what the company does and a brief history of operations. There are plenty of API's for market data, but I was wondering if there's a dataset or an API that can give qualitative information about each stock.",not_spam
"Click here for free money!

",spam
"""10 AMAZING TRICKS TO LOSE WEIGHT FAST! CLICK NOW AND START SHEDDING FAT IMMEDIATELY! Don't miss out on this once-in-a-lifetime opportunity to lose weight quickly and easily! Just click the link and let us help you sculpt the body of your dreams! ğŸ’ªğŸ¼ğŸ”¥""

",spam
"Check out these insane deals now! Limited time only! Get your hands on the hottest merchandise at unbeatable prices! Don't miss out on this amazing opportunity! Act fast before it's too late!

",spam
"hot girls here! Click now and you will get access to the hottest babes on the internet! You won't regret it!!!

",spam
"Get ready to BLAST your way to INSTANT SUCCESS with our AMAZING offer! 

",spam
"Emojis are everything! ğŸ’©ğŸ‘½ğŸ¦„ğŸ¤‘ğŸ¤¡ğŸ¤–

",spam
"Are you tired of being single and lonely? Bored of the same old routine and looking for a way to spice things up? Well, look no further than our amazing dating app! With our state-of-the-art algorithm, we'll match you with the perfect partner in no time! Don't wait any longer, sign up now and start swiping!

",spam
"I would like to get hold of the data available on Yahoo's Fantasy Premiere League website. Login is required for all URLs.

Clicking on Top Players shows the summary of the season statistics for each player

URL: http://uk.eurosport.yahoo.com/fantasy/premier-league/top

http://i.imgur.com/8lpsDfh.png

Each of the player names is a hyperlink to the detailed data for the player's performance in the season by the week.

http://i.imgur.com/kOCiSdC.png

URL: http://uk.eurosport.yahoo.com/fantasy/premier-league/details/39336

Each player is associated with a 5 digit number that appears at the end of the URL

My understanding is that this would be a simple web scraping problem, unfortunately my programming skills are rather elementary so I was hoping someone here would be able to help me or point me in the right direction. Thanks in advance!
",not_spam
"Hello, I am doing a research paper on iodized salt consumption and I need time-series data (year by year) of salt consumption (iodized) from a country or countries. I have only found surveys and nothing else on the page of WHO. 

The idea is to make a research paper where I talk about iodine deficiency diseases (goiter, child development) and I want to talk from a policy-making standpoint.",not_spam
Wanting to keep an archive of the events of 1/6/2021. Does anyone have a list of videos and images of the protest?,not_spam
"Big sale! Get your hands on the newest and hottest products on the market! Don't be a loser and miss out on these amazing deals!

",spam
"Get ready to feel the power of [insert social network name here]! Our platform has everything you need to connect with your peeps, share your life, and make the trendiest memes.

",spam
"""BUY NOW! GET RICH QUICK WITH OUR AMAZING DEALS ON CRYPTO!! You won't want to miss out on this incredible opportunity. Our investors are seeing HUGE returns and you can too. Just click the link below to sign up and start making money TODAY!""

",spam
"Buy 1000 followers just for 1$! Best deal you can find on Insta! Don't hesitate and improve your account now! Also, visit our website where you can buy millions of likes and followers for super cheap prices! And don't forget to follow us on Insta to get a chance to win free followers and likes every day! #followforfollow #likeforlike #spamspamspam",spam
"Looking to lose weight quickly and easily? Check out our amazing new product that guarantees fast and simple weight loss without any effort on your part! 

",spam
"Get rich quick with this amazing opportunity! Make thousands of dollars in just one week! No need to work hard or have any special skills, just invest a small amount of money and watch it grow into a fortune!

",spam
"GET RICH QUICK WITH OUR UNBELIEVABLE INVESTMENT OPPORTUNITY! DON'T MISS OUT ON THIS CHANCE TO MAKE BIG BUCKS IN NO TIME! 

",spam
"""Get rich quick with our amazing new scheme! Just send us your credit card information and we'll do the rest. No more working nine to five, just sit back and watch the money roll in. Don't hesitate, act now and become a millionaire in no time!""

",spam
I wanted to do an NLP operation on those texts to deduce the kind of actor in the TV series.,not_spam
"Hi, I'm Sumit Srivastava, founder of [Projell.com](https://projell.com/) . We made this after dealing with the data hell like low data availability, high data procuring cost, huge time sink for data collection, and privacy concerns over the user data. Think of it as AI Training Data Generator.

This prompted me to build an easy way to generate synthetic data for machine learning models. This primarily uses GANs, but we use techniques which are most efficient for specific usecases.

Areas where we've found it useful are biomedical, drone imagery, satellite imagery, retail, and autonomous mobility.

As already prominent in the ImageNet challenge, the state of the art is using synthetic data to gain higher accuracy. \[ [https://paperswithcode.com/sota/image-classification-on-imagenet](https://paperswithcode.com/sota/image-classification-on-imagenet) \]

Google, for their autonomous vehicles, used millions of miles of real driving data and billions of miles of synthetic data. It is clear where the world is moving towards.

I would be happy to share the tools with everyone since dealing with data is something we struggled with and don't want anyone to struggle anymore. This is probably only the first step towards building something robust that can reduce as much data hassles as possible, if not all.",not_spam
Can anybody tell me where I can download dataset for malware analysis. I am performing dynamic analysis based on behavior of android applications.,not_spam
"Hello all! I am looking for a dataset that has images of faces as the X for the training and for the Y (labels), what I need is a simple natural language description of the facial features, viz. the nose type, lips, eyes, eyebrows, complexion, jaw size, etc.

I have been looking for such a dataset, but couldn't find an exact one. There are many face datasets classified on gender, there are datasets containing the keypoints of the face, but not like the one that I am looking for. Could you please point me to such a dataset if you guys are aware?",not_spam
"Say i want to compare CO2 emission per capita vs gpd per capita, do i need to adjust for inflation?


",not_spam
"I'm looking for NHL and especially Anaheim Ducks home game attendace data for single games for the 2014-2015 season.

I have found data from hockey-reference for the 2015-2016 season and data from 2013-2014 backwards from hockeattendance. So I'm missing only one seasons worth of home game attendance numbers.

Also if anyone knows where I can find ""Team Marketing Report"" NHL Fan Cost indexes from 2010-2013 it would be great.",not_spam
"""10 BEST WAYS TO GET RICH QUICK!!! JUST CLICK HERE NOW!!!""

Hey there, guys and gals, have you ever wanted to become a millionaire overnight? Are you tired of working hard and still not seeing the results you desire? Well, look no further! We have compiled the top ten best ways to get rich quick, and all you have to do is click the link to get started!

But wait, that's not all! We know that time is money, so we've made sure that our methods are quick and easy. No need to waste hours of your precious time, just follow our simple steps and watch",spam
Taking a class on social networks and graph theory. Want to do some toying around with community detection.  Anyone know of a good place to look?,not_spam
I need a large dataset (10k-20k+ entries(row\*columns) in total)  collected from any sensor which can be used for some important thing after processing,not_spam
"S'up, ya'll! Have you heard the good news?! Our social network is lit and ready to take over the world. If you're tired of boring profiles and lame posts, then you've come to the right place. We've got everything you need to make your online presence pop!

First off, we've got more filters than you can handle. Want to make your skin look like a porcelain doll? We've got you covered. Want to turn your eyes into glowing orbs of fire? No problem, fam. We've got filters for days.

And let's not forget about the memes. We've got the dankest",spam
"I'm looking for a dataset that contains statements by political theme (economics, war, voting, whatever). Who said it isn't important, just that it's in English, though American would be best. I figure there might be a book or some very obscure think tank out there that may have something like this y'all might know about.

Much obliged!",not_spam
"Have CSV and SQL datasets for variables that can be of use for people analyzing COVID-19 trends. Does not contain COVID-19-specific data, plenty of places to find that. Indexed by country name (per UN member states website). Will continue updating and adding as time goes on. First time doing a project like this so I hope some of you find it useful.

Current Variables:

* Population
* Density (km squared)
* Area (km squared)
* Migrants (net)
* Median Age
* Percent Urban
* Percent of Worldâ€™s Population
* GDP per Capita (PPP)
* GNI per Capita (PPP)
* Airline Passengers per Day
* CountryID
* Latitude
* Longitude
* Last Recorded Average Temperature
* Previous Recorded Average Temperature
* Date of Temperature Recording

[https://salientmind.blog/blog/2020/3/19/covid-19-technical-indicators-dataset](https://salientmind.blog/blog/2020/3/19/covid-19-technical-indicators-dataset)",not_spam
"Hi,
I am looking for arrival data from major cities to Las Vegas.
I found McCarran airport have some statistics but it give departures to major cities. I could use maybe as a proxy but I was wondering if anyone else other information (monthly or quarterly are best)

Thanks",not_spam
"I'm currently doing an assignment on data visualization, i've been very interested with steam hardware survey data and i think i can really do something with it. Problem is, i have no idea how to get that data in a dataset format like csv. Can anyone point me in the right direction?",not_spam
"Wazup my fellow netizens! Are you tired of scrolling through your feed and not seeing anything interesting? Well, fear not because I have got some juicy updates for you all!

First off, have you heard about the new weight loss pill that will make you look like a supermodel in just 10 days? It's called ""SkinnyMe"" and it's already taking the world by storm! I mean, who needs exercise and healthy eating when you can just pop a pill, am I right?

And for all you fashionistas out there, have you checked out the new clothing line ""Cheap and Chic""? You can get",spam
"Hi guys!

I'm thinking of doing an NLP project where I predict the age of a text, but I've found it hard to find texts with dates. Is there a database with texts (the actual text, not just the title) and the date of creation/publication?

Thanks!",not_spam
"""Top 10 reasons you're falling behind in life (number 4 will shock you!)
",spam
"I'm looking for any sports dataset that includes the umpire or referee's on-field decision before a review (and of course the review's outcome). Examples would be: Soccer (umpire's decisions on goal/no-goal or penalty-no-penalty before VAR), Tennis (in/out line calls before player challenges are checked by Hawkeye), Cricket (wicket/no-wicket decisions before DRS reviews), Rugby League (try/no-try before Video Referee) - but possibly there are other sports. As far as I know, most sports datasets include the FINAL decision, but not the umpire's initial decision (and thus whether the umpire was right or wrong).",not_spam
"URGENT ALERT! WIN A FREE TRIP TO BAHAMAS!!! ğŸï¸ğŸŒŠğŸŒ´

We've got some exciting news for all our loyal followers! ğŸ‰ğŸ‰ğŸ‰ We're giving away an exclusive vacation package to the beautiful beaches of Bahamas! ğŸŒğŸ‘™ğŸ¹ğŸ 

All you have to do is click on the link below ğŸ‘‡ and vote for our page as the BEST social network out there! ğŸ˜ğŸ˜ In return, you'll automatically enter our prize draw to WIN a FREE trip to paradise! ğŸ†",spam
"ATTENTION ALL!! ğŸ”¥ğŸ”¥ğŸ”¥

Looking for the most EPIC deals and discounts?? Look no further GALS and PALS cuz [Insert Social Network Name Here] has got you COVERED ğŸ‘ŒğŸ¼ğŸ‘€

We've got NEW exclusive offers EVERY. SINGLE. DAY. ğŸ‰ğŸ’¸ğŸ‰

From FASHION and BEAUTY to TECH and TRAVEL, we've got it ALL ğŸ™ŒğŸ¼ğŸŒŸ

And don't forget about our amazing GIVEAWAYS!! ğŸğŸ‰ğŸ

All you",spam
"Win a FREE iPhone X today! Click the link below and enter your personal information for a chance to win this amazing prize! But that's not all, you also have a chance to win a $100 gift card to your favorite store! 

",spam
"Attention all users!!! ğŸ”¥ğŸ”¥ğŸ”¥

ğŸ’¥ğŸ’¥ğŸ’¥Introducing our brand new and totally super-duper AMAZING feature: ğŸ‰ğŸ‰ğŸ‰

ğŸ“£ğŸ“£ğŸ“£The all-new, all-exciting, all-round incredible ğŸŒˆğŸŒˆğŸŒˆRAINBOW FILTERğŸŒˆğŸŒˆğŸŒˆ

ğŸ‘‰ğŸ‘‰ğŸ‘‰Show off your true colors with the power of the rainbow! Whether you're feeling happy, sad, or just plain fabulous, this filter will give you that extra rainbow",spam
"ğŸš¨HOT DEAL ALERTğŸš¨

Are you tired of being a loser with no friends? ğŸ§ Do you want to be popular and loved by everyone? ğŸ˜ Look no further because we have the perfect solution for you! Buy our new subscription to get 10,000 fake followers overnight! ğŸ¤‘ Our bots follow and like your posts, making you look like a superstar ğŸŒŸ

But wait, there's more! ğŸ˜œ Our subscription also includes a free trial of our sketchy weight loss tea ğŸµ guaranteed to make you lose 20 pounds in a week! ğŸ˜± Don't worry",spam
"Hello guys!

We are in the process of developing a mobile application and we are aiming to launch it after few months, can you guys please advise on what kind of mobile data I can get from the users that might be helpful for Machine Learning? If so can you please advise where can I find similar datasets on the web? (other than Kaggle that is) 

Thank you very much and have a good day!",not_spam
"Hey guys, check this out â€“ I just found this amazing new app that's gonna totally blow your mind! It's called InstaLoot5000 and it lets you instantly gain 5000 followers just by entering your Instagram handle! How cool is that? 

And that's not all â€“ with InstaLoot5000, you'll also get unlimited likes, comments, and DMs from real, verified users! No more struggling to get your content noticed â€“ InstaLoot5000 does all the work for you, so you can sit back, relax, and watch your follower count skyrocket! 

Plus, if you",spam
"Once you have lost your important data what actions would you put? For me, I will find a data recovery software free download for my poor data. In fact such data accidental deletion is very common now for peopleâ€™s carelessness. To face this conditions vast software has been designed. Most of them are paid while some are free. All in all , we have the ways to do with the data lost problem. But still donâ€™t carelessly lose your data for something you might never recover.",not_spam
"FAM! Do you want to maximize your gains and get rich quick? Join my exclusive group now and get access to the hottest stocks and crypto picks. We guarantee you'll make bank in no time!

",spam
"Does anyone know of any websites or databases where I could access information on the average or median salary for certain degrees or professions?  I know the BLS has statistics by educational attainment, but I was wondering if there is a place where I can access this information broken down by field, location, etc.
",not_spam
"Reddit has been a great place for me to find great data in the past so I made a bot that scraped NFL regular season player/team stats from 2016-2021. This is just my contribution to paying it forward. There are 180 datasheets in both CSV and JSON format. It is hosted on both GitHub and Kaggle for ease of use. I hope many people have fun using all of this data! Links below...  
[https://github.com/edsonjaramillo/nfl-stats](https://github.com/edsonjaramillo/nfl-stats)  
[https://www.kaggle.com/edsonjaramillo/nflstats](https://www.kaggle.com/edsonjaramillo/nflstats)",not_spam
"Looking for some historical indices grouped together by date so I don't have to effectively grab the historical for a bunch of different indices and merge them.

ie. All S&amp;P grouped together, or Bloomberg BackOffice, etc.",not_spam
"Sooo hey guys!!1 Have you ever heard of aMAzing NEW PRODUCT that can MELT FAT away in just WEEKS?!? ğŸ˜±ğŸ˜±ğŸ˜± It's called SlimmySlimSlim and it's totally LEGIT ğŸ™ŒğŸ™ŒğŸ™Œ

I lost 10 pounds in just 7 days using this AWESOME DIET PILL and it's SUPER EASY to use! No more boring workouts or gross kale smoothies ğŸ¤¢ğŸ¤¢ğŸ¤¢ Just pop a couple of these pills and watch the pounds melt away ğŸ’ªğŸ’ªğŸ’ª

But wait, there",spam
"Looking for the ultimate #fitspo? Want to boost your #selfiegame? Look no further than [insert social media platform here]! We've got all the hottest trends, viral challenges, and clickbait articles to keep you scrolling for hours on end.

But that's not all! Our platform is also the perfect place to promote your MLM business, spam friends and family with chain messages, and inundate strangers with unsolicited DMs. And don't forget to add as many random hashtags as possible to your posts to really up your engagement game.

Join the millions of users who waste their time on [insert social media platform",spam
"URGENT! DON'T MISS OUT ON THIS AMAZING OPPORTUNITY TO BE RICH IN JUST A FEW MINUTES!!!

",spam
"WIN FREE STUFF NOW!!!! Click here to enter our amazing giveaway!! You could win a FREE iPhone, iPad, or even a car!! Don't miss out on this once in a lifetime opportunity! Just enter your email and personal information and you'll be entered to win!

",spam
"I'm interested in finances, maintenance records, complaints, remediation reports, partnerships, anything.  Many military families are dealing with substantial vermin \ mold issues and suffer silently because these companies are too powerful and the contracts the DoD entered with them are poorly written.",not_spam
"""Hey, what's up guys! Are you ready for some epic social media action? Well, buckle up because we've got loads of content coming your way!

First up, we've got the latest weight loss miracle pill that literally melts away fat without any effort. Trust us, we've tried it and we're already seeing major results. Don't wait, order now and get a free month supply!

Next, we've got the hottest dating app on the market. It's guaranteed to get you matches and dates within minutes. Plus, it's totally free (for now).

But wait, there's more. Our exclusive offer for",spam
"Looking for the ULTIMATE deal on weight loss supplements? Look no further! Our super-duper, top-of-the-line pills will have you losing pounds in no time! Don't wait to achieve your dream body, order now and see results within days! Limited time offer, so ACT NOW!

",spam
"I figured out how to make animated heatmaps in [ggplot2](https://gist.github.com/cavedave/21c6beff2d371e9df323c292b1dc3afa). This is one for [the NBA](http://i.imgur.com/dobmMWM.gif). It shows weight height colored by % and Year as an animation.

It would be cool to have a dataset something like

Height, Weight, Year

For babies so I could see if there is a general increase or if there is an inequality in size increase. 

The inspiration for this is this [NFL graph](http://noahveltman.com/nflplayers/).

Any other dataset that might look cool in this visualisation please post as well. Mainly it needs individual entries not summaries.

Obviously the same baby cant be newborn in different years. This seems like the sort of dataset that would be out there but my googlefu is failing me.",not_spam
"I spent a few days compiling but never had any time to do anything with it so I thought I'd put it up here and see if anyone wants to play around with it and get something meaningful out of it. I run a business that scrapes data from the web, but felt like doing this for 'fun' considering I'm a big aviation dork, and it's got nothing to do with my day job.

Early in November I scraped Ryanair's website for all their flights that they had published as of the date I started. Took about 4 days of continual queries (mostly to avoid getting IP blocked), and ended up with data on roughly 725,000 flights.

This was scraped in a series of steps from Ryanair - first was to query all the city combinations and get the dates for each flight. Second step was to then query each of those combinations and get the routings and fares returned. Ryanair does this through a series of easy to expose API's so it's just a matter of iterating through them enough time to get what you are looking for. Third was to take those results and aggregate them into a nice, clean output and blend it with some additional attributes and location data from [OurAirports](http://ourairports.com/data/).

I did all of this using [FME](https://www.safe.com/), mostly because I love that tool despite my day-to-day job living almost exclusively in Python. I have linked my original workflows below too- feel free to use them to your hearts content. 

Here's whats in each file:

* **Date** - Flight Departure Date
* **Route Origin Airport** - Ryanair Airport Code
* **Route Origin Name** - Ryanair Origin Name
* **Origin_Airport Name** - OurAirports
* **Origin_City** - OurAirports
* **Origin_Country** - OurAirports
* **Origin_Airport Code**  - OurAirports
* **Origin_ICAO Code** - OurAirports
* **Origin_Latitude** - OurAirports
* **Origin_Longitude** - OurAirports
* **Origin_Altitude** - OurAirports
* **Origin_Timezone** - OurAirports
* **Route Destination Airport**
* **Route Destination Name**
* **Destination_Airport Name**
* **Destination_City**
* **Destination_Country**
* **Destination_Airport Code**
* **Destination_ICAO Code**
* **Destination_Latitude**
* **Destination_Longitude**
* **Destination_Altitude**
* **Destination_Timezone**
* **Flight Key** - Best I can tell is that this is the closest thing to a unique key that Ryanair published about each flight. 
* **Flight Duration** - HH:MM
* **Fare Key** - Similar to the flight key, this denotes unique fares found - these are not unique in the dataset though, they are repeated regularly
* **Fare Class** - Ryanair Fare CLass
* **Fare Type** - What type of fare, all Adult fares in this dataset
* **Fare Currency**
* **Fare Amount** - in the above currency, including any discounts
* **Fare Published** - 'sticker price', without discounts
* **Fare Discounted** - T/F if it is discounted
* **Fare Discount Pct** - percentage discount in the 'Fare Amount'
* **Fare Has Promo**

Something to note about 'segments' below. Most airlines operate routes that combine flights. For example, flying Air Canada from Vancouver to Copenhagen is considered one route, with two segments: Vancouver to Toronto, and Toronto to Copenhagen. In the case of Ryanair, it does not appear that they do multi-segment routing yet - although last I heard, there were plans to do so. 

* **Segment Number** - should be '0' for everything
* **Segment Flight Number**
* **Segment Origin** - should be same as above listings
* **Segment Destination** - should be same as above listings
* **Segment Duration** - should be same as above listings
* **Segment Distance (km)** - (NOT in nautical miles)
* **Segment Origin Time - Local**
* **Segment Origin Time - UTC**
* **Segment Destination Time - Local**
* **Segment Destination Time - UTC**
* **Request Time UTC** - Date/Time that the request for the segment/fare was made. 

Outputs were done in CSV, GeoJSON, and Tableau TDE. There is also a fun file called 'Original.json' which is the full JSON returned from the initial API requests if you want to look something up. As well, the FME workflows that did all of this are here too.

* [RyanairFlights - GeoJSON.zip](https://mega.nz/#!BeZSxYLZ!iFZr7IwczF--6guijZo66ClEGiqZ624z8ielfEZYwEY) - 30.8MB compressed, 1.45GB uncompressed
* [RyanairFlightsCSV.zip](https://mega.nz/#!VLgVURBY!HXvH5ahbNKuhDVIgVYFM_nJAhMl55A79gPr2yusJ2qg) - 20.7MB compressed, 340MB uncompressed
* [RyanairFlightsTDE.zip](https://mega.nz/#!oS5XARJI!M-poBvLmEJ6LH5UKoz0wGGISk7HtsSIAAhu9bdLrADE) - 17.9MB compressed, 75.9MB uncompressed (Lat/Long stored as spatial geometries)
* [RyanairFlights - Original.zip](https://mega.nz/#!gfg3mShb!Hmq2zzUfQCtepRhI24HuM2jhlLejpj8gt74Xgm3h2NU) - 35.8MB compressed, 1.07GB uncompressed (this is the raw JSON one)
* [FMEWorkflows.zip](https://mega.nz/#!ZbJVjBZC!kUuq3H8Jv9r7PilCrEWBT-gFnJ3XU4xBrchhB1yeWmM) - 69KB

Don't hesitate to reply here if you have any questions, and be sure to let me know if you come up with something interesting out of this. 
",not_spam
"I  have to show the working of a classification algorithm like Naive  Bayers in my data science class project. I'm trying to find datasets  but, most of the common topics like weather prediction, cancer  prediction, etc. have already been taken by other groups in my class.

I  have tried to find datasets on many websites but I'm not getting any  dataset which has something worth predicting or sometimes the datasets  have way too many feature columns. Do you all have any suggestions for a  dataset where I can predict something by using less than 10 features?",not_spam
A majority of the datasets that I looked through don't have enough rows or have much for EDA. It's for my semester project. Any help would be appreciated.,not_spam
"""FREE STUFF ALERT!!!""

OMG you guys, guess what?! We've got some MAJOR freebies for you today! You won't believe your eyes when you see all the unbelievable things we're giving away for FREE!!

Feeling bored at home? Don't worry, we've got just the thing to make your day! How about a FREE set of snail slime face masks? Yep, you read that right. These masks are made with REAL snail slime, which has incredible moisturizing and anti-aging properties. Who needs expensive skincare products when you can have snail slime for FREE? 

But wait, there",spam
"Hi,

I have recently developed an interest in data visualisation and EDA. I am currently trying to figure out what are some great datasets that I can put on my portfolio.",not_spam
"Hi all,

I was looking for a dataset containing food ingredients and nutritional value. could you please help me?

Even if you don't know any dataset like this, I would highly appreciate if you share with me some sites where I could have a look. I am learning Python and all this is new to me :)

&amp;#x200B;

Thank you in advance guys!",not_spam
"""Top 10 reasons why our social network is the best!!! You won't believe number 7!""

",spam
"Hi! I'm wondering if there are any resources for health data that are 1) kept current 2) searchable by zipcode and 3) contain data points on health data (e.g. asthma cases, emergency room visit reasons, foodborn illness). I've spent hours looking, but I haven't found much. 

[This](https://a816-health.nyc.gov/hdi/epiquery/visualizations?PageType=ps&amp;PopulationSource=Syndromic) is an example of the type of thing I'm looking for (but it's only for ER visits).  Ideally, data would be available for the NYC area.

Thanks!",not_spam
"I am working on my final year project and I am unable to find a dataset which has text and emojis both. For example, ""Awesome product ğŸ˜"".  
I am new to this domain can anyone please suggest me some datasets.",not_spam
"Quick question, I have da dataset where the features are the values from acceleration sensor and label explains the condition of a structure if it is damaged or not. However, I'm stuck with the cross\_validation.train\_test\_split the part where I don't know how to train and test the label.",not_spam
"I'd like a dataset that has details about publicly known satellite launches such as companies, cost, weights of payload/boosters/etc, dates launched. Bonus if it has data on whether the launch was successful and how many attempts were scheduled prior to success.",not_spam
"10 Ways to Get Rich Quick!

Are you tired of working hard and not seeing the results you want? Are you ready to start living the life you deserve? Well, then you've come to the right place! Here are ten fool-proof ways to get rich quick:

1. Invest in the stock market - it's easy, just buy low and sell high!

",spam
"Currently doing a research project that requires starting salary for a bachelors degree. Checked the obvious sources (BLS, NACE, etc), but couldn't get anything that goes back 50 years.

Also, if any one knows of a sub-section for starting salaries for bachelors in chemistry, I would be even more grateful.

Thanks!",not_spam
"After reading [this](http://www.datagenetics.com/blog/september32012/) analysis of PINs, I have decided that I'd like to give it a go for myself but I'm unsure of where to get such data. The article vaguely refers to ""security breaches"" and ""exposed password tables"" although as I'm not involved in the more nefarious side of coding I don't know how I would attain such things. I was wondering if anyone knew of a dataset or text-file that just contained a large number of PINs, no other data required.",not_spam
"""Get ready to be blown away by the most amazing social network ever! With our incredible platform, you'll have access to tons of trashy memes, fake news stories, and mindless gossip. Plus, our spam bots will inundate your inbox with ads for products you never asked for!

But wait, there's more! You'll also see non-stop updates from people you barely know talking about the mundane details of their lives. From what they had for breakfast to what they're wearing to work, you'll be riveted by the sheer banality of it all!

And don't even get us started on the terrible grammar and spelling",spam
"Hey all! Iâ€™m on the hunt for any sort of large dataset that pertains to music sampling. Iâ€™m writing a piece on Bob Jamesâ€™s song **Nautilus**, and knowing how often itâ€™s been utilized in hip-hop, Iâ€™d imagine any decent sized dataset would include enough information about that song itself.

WhoSampled is a website where users can search a specific song or artist and get a comprehensive list on what samples a song has used or where it has been sampled elsewhere. Iâ€™ve looked through some archives about a now-defunct WhoSampled API, but it seems like it no longer works. Theyâ€™re notoriously tight-laced about releasing their data, and only release certain quantities of metadata to larger record companies or PhD researchers. If anyone has any sort of large dataset from WhoSampled or on music sampling in general, that would be greatly appreciated!",not_spam
"Hello,

I am doing some market research and am having trouble answering this question. Would anyone here happen to be able to answer this question or direct me to a resource where I might be able to find an answer?

I don't need hyper accuracy to get into too much detail, love those things, but just trying to get a ballpark idea of the numbers to be expected on average. My apologies if this just isn't the place for this!

Thanks for your time!",not_spam
"SNAPBLOP: Subscribe to us and get FREE access to our exclusive content of click-bait articles, sponsored posts and pop-up ads! Don't miss out on our limited time offer! 

",spam
"I am building a reverse dictionary Â â€” for those moments when you're struggling to recall a word from memory. If you describe the word you're trying to remember, my app will give you 5-10 suggested words.

In order to train a model for this use-case, I need access to a massive dataset of English word meanings. I've looked online without much luck â€” the Gutenberg project, NLTK's builtin words, and Owlbot are the three sources I have managed to use so far.

However, none of these come close to a modern dictionary in terms of the span of words they can define. If any of you know a good dataset for this use-case, or any hacks on how I could create such a dataset, please let me know in the thread!

**Two constraints**

* Prefer if the dataset is machine-readable: JSON, CSV, XML, or similar
* Would be great if the resource is free for use",not_spam
"""Unlock your full potential with our revolutionary new product! Don't settle for mediocrity when you can be at the top of your game in no time! The power of our product is second to none! Don't miss out on this amazing opportunity! Click now and change your life forever! ğŸš€ğŸ‰ğŸ’¥ğŸ’ªğŸ†ğŸ¤‘""

",spam
"Get ready to level up your online game with the latest updates from our social network! Our platform is buzzing with new features and functionalities that will make your profile pop and your followers go wow.

",spam
Somebody HAS to have done this...,not_spam
"ğŸš¨ ALERT ğŸš¨

ğŸ“¢ Attention all users! ğŸ“¢

We have some ğŸ”¥ğŸ”¥HOTğŸ”¥ğŸ”¥ news for you today! Our platform has partnered with a bunch of random companies to bring you the latest and greatest in spam and advertisements!

ğŸ‰ğŸŒŸ Are you ready to have your inbox flooded with useless junk? ğŸŒŸğŸ‰

We thought so! Don't worry, we won't let you miss a single post from your favorite influencers and celebrities (even if they are just promoting their new diet pills or workout plans)!

And the",spam
"Didn't feel like writing a disgusting article as it goes against ethical practices. As an AI language model, I promote and encourage the use of proper spelling, grammar, and respectful language in all forms of communication. Let me know if there is anything else I can assist you with.",spam
"Howdy!

I'm trying to get my hands on a dataset describing how much fuel a given vessel consumes over a period of time -- ideally I'd love to be able to see instantaneous consumption (from some sort of sensor network) but that probably would mean that I would need to integrate with whatever system gets that data. Equally as useful would be something like a vessel noon report ([https://www.marineinsight.com/guidelines/what-is-noon-report-on-ships/](https://www.marineinsight.com/guidelines/what-is-noon-report-on-ships/)) or some other dataset that describes when a vessel gets refueled, how much, and with what kind of fuel.

Any thoughts or directions would be much appreciated!",not_spam
"[SECDatabase.com](https://SECDatabase.com) is proudly to share its internal SEC XBRL Financial Statement dataset with the community on a regular basis. The documentation can be found here:

[https://github.com/secdatabase/SEC-XBRL-Financial-Statement-Dataset](https://github.com/secdatabase/SEC-XBRL-Financial-Statement-Dataset)

**FAQ:**

**Q**: What is the data format?

**A**: It is in Parquet format, and optimized for AWS Athena and Redshift Spectrum

**Q**: How is this dataset different from [dataset](https://console.cloud.google.com/marketplace/details/sec-public-data-bq/sec-public-dataset) hosted on Google Cloud Platform

**A**: The dataset on Google Bigquery is based on Dataset published by SEC (See next question), and is stale - the latest filing data is as of June 2018.

**Q**: How the dataset is different from dataset on SEC website

**A**: This dataset has numerous improvements over the dataset on SEC website such as:

1. Text and notes data are in full-length without truncation. The dataset published by SEC trimed footnote to 512 chars, and string value to 2048 chars only.
2. Report segment information are added to the data points directly.
3. Include the start\_date and end\_date for each data point to reflect the period more accurately.
4. Eliminated the needs to understand the convoluted XBRL convention as much as possible, so that Data Scientist can focus on the data itself to derived the value.
5. Support the tracing of the data point back to its original filing and specific section.
6. Support the tracing of data point revision.

**Q**: Do I need to download the data to query the dataset?

**A**: No, you can use the Athena or Redshift Spectrum in your AWS to query the data directly.

**Q**: What is the coverage of the data?

**A**:  As of August 31, 2019, the dataset covers:

1. All XBRL filings since 2009.
2. 12.6k companies.
3. 239.7k annual and quarterly reports.
4. 192.5 million data points.
5. 20GB+ compressed in Parquet.

More questions? Please let us know.",not_spam
"Get ready for the most amazing offer ever! You won't believe your eyes when you see the incredible deals we have in store for you. Don't miss out on the chance to save big and get the hottest items on the market.

",spam
"THE ALL-NEW FACEBOOK PRO XTREME SUPER-DUPER POST BOOSTER NOW AVAILABLE FOR SALE! ğŸš€ğŸš€ğŸš€

ğŸ‘‰ğŸ‘‰ğŸ‘‰ Are you tired of your posts reaching only a few people? Want to boost your business and your ego? We have the perfect solution for you! Introducing the Facebook Pro Xtreme Super-Duper Post Booster!

ğŸ“ˆğŸ“ˆğŸ“ˆ With just a few clicks, you can reach millions of people and get tons of likes, shares, and comments. Our booster is so powerful that your posts will go viral in no time",spam
"Hi everyone,

In my current job i work quite a bit with publicly available datasets and I am now thinking about starting a project to make it easier for non-technical people to interact with public/open data.

As part of that, i am trying to get a better understanding of how people interact with public datasets, and the obvious source to ask for help are the kind people of reddit! :)

I would really appreciate if you you could give a bit an overview of the data sources that you guys use and what exactly you then do with that data.

To give you a bit of a reference of what i am looking for here, an example for myself would be: My company has a presence across the globe and wants to keep on top of the latest Covid-19 developments. To assist with that, I pull a bunch COVID-19 data from the OWID GitHub page, do some cleaning &amp; basic analysis and then chuck the results into a number of excel files that then get analysed by a team close to the companyâ€™s management.

Thanks a lot in advance, i really appreciate any input!",not_spam
I just need a set with a response variable along with at least one qualitative variable and any number of quantitative variables. Any Subject I can use. Just having trouble finding a set. Thanks!,not_spam
"OpenSteetMap has a lots of local listing in their map data. Example:

    &lt;node id=""419857860"" lat=""40.7612378"" lon=""-111.8886016"" ... &gt;
        &lt;tag k=""name"" v=""Himalayan Kitchen""/&gt;
        &lt;tag k=""phone"" v=""801-328-2077""/&gt;
        &lt;tag k=""amenity"" v=""restaurant""/&gt;
        &lt;tag k=""cuisine"" v=""indian""/&gt;
        &lt;tag k=""website"" v=""http://www.himalayankitchen.com/""/&gt;
        &lt;tag k=""addr:city"" v=""Salt Lake City""/&gt;
        &lt;tag k=""addr:street"" v=""South State Street""/&gt;
        &lt;tag k=""addr:postcode"" v=""84111""/&gt;
        &lt;tag k=""opening_hours"" v=""Mo-Sa 11:30-22:00; Su 17:00-22:00""/&gt;
        &lt;tag k=""addr:housenumber"" v=""360""/&gt;
    &lt;/node&gt;

Does anyone out there know of an extracted/ sanitized dataset of these businesses?",not_spam
Does anyone have experience with this? An Any thoughts appreciated!,not_spam
"BROOOOOOOOOOOOOOOOOOOOOOZZZZZZZZZZZZZZZZZZZ, have ya'll heard about our new and epic feature?! We've got brand spankin' new filters that'll make you look hotter than a jalapeÃ±o pepper in the Sahara Desert! 

We're also hookin' you up with some sweet deals on trending products you just gotta have. You won't believe the discounts we're offering, like 99% off on...ummm...something super cool, we promise. 

Plus, don't forget to follow us on all our other socials for exclusive content and",spam
"Check out these incredible deals on weight loss supplements! Get your dream body in just 1 week! Limited time offer - buy now!

",spam
I was wondering if there is a place where one can search through all written and spoken words by say the last 4-5 POTUS easily?,not_spam
"Ladies and gentz, I'm super excited to bring to you the new and epic social network extravaganza! It's like totally rad and you're gonna love it. Don't wait to get started and be the coolest kid on the block, coz let me tell you, this is where it's at!

",spam
"The best list that I have is this: https://github.com/washingtonpost/data-police-shootings , but that doesn't including [chokings](https://ns.reddit.com/r/Bad_Cop_No_Donut/comments/hbc7gb/everyone_meet_tony_timpa_he_called_911_for_help/) and things like that (only shootings). 

I would like the most comprehensive list of death when police are involved even if the police is not responsible.",not_spam
"LIMITED TIME OFFER: Get 1000 followers for just $5!!! ğŸ˜±ğŸ˜±ğŸ˜± That's right, increase your social media fame and get that clout you've always dreamed of! Don't wait, act now and watch your followers soar! ğŸš€ğŸš€ğŸš€

",spam
"I have a data set with roughly 500K rows of links from one page to another page on the site. With each respective link we know what type of page it is. So for instance category page is pointing to a news article page. In theory the number of buckets a URL can fall under is 5. 

What are some good ways to visualize this? Iâ€™m a novice with data viz and only have access to Excel and gSheets. Open to other free tools though!

Any ideas! TIA",not_spam
"I am looking for dataset related to object detection to detect object    after house/office has gone through fire. Do any one have lead on this    kind of data are  available or not , or any leads regarding this kind  of   system.  
It would be helpful if I get any lead on this.",not_spam
"Get rich quick with our amazing new money-making opportunity! 

",spam
"I am having a difficult time finding a dataset with the following data points:

* Part Number (more than 10 Part Numbers)
* Defect Quantity
* Defect Reported On (Date)

Bonus data points:

* Defect Responsible (Supplier or Production)
* Supplier Name (if Supplier Responsible)

Ideally the analysis is identify future part defects based upon historical data, so data based on more than a year would be great. I tried looking in Kaggle, and they have the Bosch dataset which doesn't met the needs for my request. 

Any support is appreciated. If you are able to find me the dataset that meets my request, I don't mind gifting a $20 Amazon card for this trade. 

Thank you in advance!",not_spam
Cannot find this info anywhere on the web.,not_spam
"$$$ WIN BIG MONEY NOW $$$ 

Want to get rich quick? Visit our website and enter our exclusive contest for a chance to win millions of dollars! All you have to do is enter your personal information and share our link with your friends to increase your chances of winning. Don't miss out on this amazing opportunity!

",spam
I wanted to make a project where i create a model which colorize Black and white image but i have not found a data with size less than 1GB for the same. Can anybody help me..,not_spam
"Folks, we have some hot and happening news for you! Are you tired of being bored with your daily social media routine? Well, we have just the solution for you. Don't waste another second and join our amazing platform where you'll be served up with the juiciest gossip and scandalous stories from all across the globe! We've got a wide range of content to offer you, from heart-warming cat videos to sensational celebrity news. 

",spam
"Hello guys,

I am currently working on my capstone project and I required a dataset that consists of text queries from the residents of an area(or city) in order to classify them into issues with road quality, water supply, electricity supply, sanitation &amp; sewerage, property tax, and crime, etc.  I would very much appreciate it if anyone could share the Open data repository that is available or if there are any other alternatives for the data sources available.

Thanks in advance.",not_spam
"OMG YOU GUYS! Have you heard the news? The biggest sale of the year is happening right now on our platform! You don't wanna miss out on the hundreds of deals and discounts we have lined up for you!

ğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠğŸ‰ğŸŠ

From fashion to beauty to home decor and electronics, we've got it all covered! And let's not",spam
"Hey Reddit, 

&amp;#x200B;

I am working on a school project to estimate the returns to an MBA. Need to find a dataset that shows salary before and after getting an mba. Anything would help. Thanks",not_spam
"WIN BIG WITH OUR AMAZING GIVEAWAY!!! 
GET FREE GIFT CARDS, COUPONS, AND MORE! 
JUST CLICK ON THE LINK BELOW TO GET STARTED! 

",spam
"ğŸ’¥ Amazing offer alert ğŸ’¥ 
ğŸ Get a FREE iPad by simply clicking on this link â¡ï¸ bit.ly/freeipadnow!
ğŸ¤© Hurry up, only limited stock available! Don't miss out on this opportunity!

",spam
" Iâ€™m at my 5. semester of my Bachelor in Software Engineering and we working on extending this [analytic platform](https://astep.cs.aau.dk/wiki)  
We can almost do what we want to, and I think it would be REALLY awesome to work with quantified self/Health data!

Do you have any recommendations for big datasets we can use?

We will probably use machine learning or some other form of AI, since we are learning that in one of our courses, and they like it when we apply things from courses in the projects!

Soâ€¦ What kind of machine learning algorithms would be obvious for working with Quantified self/Health data? And can you recommend any big datasets?",not_spam
"Attention all my beautiful followers!!! Are you tired of feeling sluggish and unhappy in your own skin? ğŸ˜” Well, today is your lucky day because have I got the product for you! ğŸ¤© 

Introducing the amazing, life-changing weight loss pill guaranteed to shed those pounds off in just a few short weeks! ğŸ¤¯ Don't believe me? Just look at these AMAZING before and after photos from REAL customers! ğŸ“· 

But wait, there's more! Order now and you'll receive a FREE trial of our revolutionary skin care line! ğŸ™Œ Say goodbye to wrinkles and hello to youthful, glowing skin!",spam
I've been trying to find  such a data set for a few days but no luck so far. Maybe somebody knows where to look?,not_spam
"Does anyone know of a dataset of .txt files of job descriptions from a variety of fields? 

I know that [indeed.com](https://indeed.com) has an API that spits out JSON &amp; XML data. However, I'm trying to train an information extraction model to pull job requirements out of  textual descriptions of the job. So the raw text is key to me. Having requirements broken down in a separate field would not directly useful to me, however, it could help evaluating my model's effectiveness.",not_spam
"URGENT: ENLARGE YOUR PENIS WITH OUR NEW AMAZING PILLS!!!!!! 
Ladies, do you want your men to be able to satisfy you like never before? Gentlemen, do you want to be the true alpha male??? Then you need to try our new penis enlargement pills! They will make your member bigger, stronger, and last longer than ever! Don't wait, order now and get a FREE TRIAL!!! 

",spam
"""Get rich quick with our AMAZING offer!! Make $10,000 in just one WEEK! Don't believe us? Just try our product and see for yourself how easy it is to make money from home! No experience necessary! Just click the link and start earning NOW!""

",spam
"Iz Yo Yo Yo! Wazzup my homies?! It's ya boi from the SOCIAL NETWORXXX! You know who I am, I'm the one who's always throwing mad shade and spreading the gossip like hotcakes. But today, I'm here to tell y'all about some dope sh*t that you don't wanna miss.

",spam
Mainly looking for everything and anything. I'll have a project at the end of the semester for a class and would like to do some in depth analysis on the topic.,not_spam
"OMG you guys, have you ever wanted to lose weight in just a week? Well, look no further because we've got the solution for you! Introducing the newest weight loss pill that will make you shed all those pounds in no time!

But wait, there's more! We've also got a revolutionary skincare product that will make your skin baby smooth and glowing in just one use! And if you act fast, we're throwing in a free trial of our teeth whitening kit!

And that's not all, folks! We've got a limited time offer for our premium subscription that gives you exclusive access to our VIP content,",spam
"I'm doing a test with some map visualization and would love to be able to demonstrate some realtime activity, preferably something from transit data.  Are there any public sources for flight or ship locations that could be used?

",not_spam
"Prepare to be dazzled because social media is about to blow your mind! With the latest updates and features, you can now connect with people from all over the world and share your life experiences with ease. Plus, you won't have to deal with any language barriers because we have the power of translation at our fingertips!

Not only that, but we have a ton of exciting ads for you to click on! Get ready to be bombarded with pop-ups and special offers, all tailored to your personal interests (whether you like it or not). And don't worry, we won't let pesky things like data privacy get in the way",spam
"B Ck W Th M Or F Fb! The c lt r l l nds ap is ch ng ng f st r th n w c n k  p w th, but FB is th r t st nd by y u m tt r wh t! G t th l t st y u h z z t n d sh r  th w r d  w th y ur f r nd s!  



L k ng f r gr t d al s? H v y u tr ed th FB mrk tpl c  t  create n s l's, st r fr nt r pr n",spam
"Hi everyone! I attend the University of Amsterdam and am currently working on a project that requires a good amount of survey participants. If you could follow the link below and fill out the survey it would be much appreciated! It only takes about 3 minutes.

&amp;#x200B;

 https://uvacommscience.eu.qualtrics.com/jfe/form/SV\_5iEV0NpQyYpNoqh",not_spam
"5 amazing weight loss secrets the industry doesn't want you to know about!!!

Lose weight quickly and easily with these simple tips that no one else is talking about! You won't believe how easy it is to shed those pounds once you know these secret techniques! 

1) Drink lemon water first thing in the morning to boost your metabolism and cleanse your system!
2) Cut out carbs completely and start eating only protein for ultimate weight loss results!
3) Exercise for at least 2 hours a day, every day, to see maximum weight loss and toning!
4) Try this one weird trick that will make your body burn fat all",spam
"To the best of my knowledge, this dataset doesn't exist yet. Also, I want to release my scraper cause why not. I think its a pretty good scraper and am proud of it :)

&amp;#x200B;

Cross post [https://www.reddit.com/r/datascience/comments/du1j0g/i\_scraped\_a\_ton\_of\_data\_from\_a\_popular\_forum/](https://www.reddit.com/r/datascience/comments/du1j0g/i_scraped_a_ton_of_data_from_a_popular_forum/)",not_spam
"I am still looking for data sets to create content for my blog &gt;!https://dataanalystlife.blogspot.com/!&lt; and for upskilling. 

I would also be willing to help students in cleaning their datasets if needed (if they share the data with me).",not_spam
"I'm preparing for a PoC to create energy building mangement system for industrial buildings. I'm looking for a time-series dataset of production facility / factory. Ideally, data from the building would be divided into sections / floors, where each section / floor has it's own measurements taken. 

I searched open-source datasets available online but haven't found anything of that nature. Does anyone know such publicly available dataset?",not_spam
"I need to test a method for calculating document similarity and I expect it works much better on longer documents. Therefore I need a dataset consisting of long documents for document similarity or classification task.

Can anyone help?",not_spam
"Buy our EXCLUSIVE weight loss tea now and lose 10 pounds in one week! This tea is scientifically proven to speed up your metabolism and burn fat without exercise. Don't waste your time at the gym, just drink our tea and watch the pounds melt away!

",spam
"Hey you guys! Check out this amazing offer that you absolutely don't want to miss. It's the best thing since sliced bread! You can get rich quick with this one simple trick. All you have to do is click on the link and you'll be on your way to becoming a millionaire in no time.

But wait, there's more! If you sign up now, you'll get access to exclusive content that will blow your mind. You'll be able to live your best life and achieve all your dreams with this incredible opportunity.

And if that wasn't enough, we have a special deal just for you. Use the promo code",spam
"WANNA SEE THE HOTTEST SNAPCHAT FILTERS?? FOLLOW US NOW!ğŸ”¥ğŸ“·ğŸ”¥

We've got the inside scoop on the latest and greatest Snapchat filters that will make you look like a total BABE or DUDE ğŸ˜ğŸ˜ Follow us now for a chance to win a FREE filter package worth $100!!! ğŸ‘€ğŸ’°

Trust us, you won't wanna miss out on this LIT opportunity to take your Snap game to the next level ğŸ˜œ Plus, we've got exclusive access to behind-the-scenes content from your favorite influencers and celebs ğŸ”ğŸ¤« So what",spam
"Hey I'm hoping you all will be able to help me out. I'm taking an introductory spatial statistics class and we each need to find a dataset to use for a project we'll be doing throughout the course.

I'd like to find something a little different from the standard weather, crime, etc datasets. The weirder the better as far as I'm concerned.

Anyone have any suggestions of where to look?",not_spam
"I need data on â€œVIASATâ€ company for sentiment analysis and classification. I need  data on public opinion like tweets, comments etc. . Is there a dataset available or any dataset similar to Viasat (i.e. dataset for a similar type of company)",not_spam
"Are you tired of your boring, plain life? Do you want to spice things up and become the envy of all your friends? Well, look no further than our amazing new product, guaranteed to make you the coolest kid on the block!

",spam
"Hi Community, i need your help.

I need two Datasets for Econometric  issues. They should be economic related. The first should have a problem with heteroscedasticity and a linear relationship. The second should have a Problem with multicollinearity.

Thank you.",not_spam
"I've got some exciting news for all you social media fans out there!! Are you ready for it?!?

You can now get free followers and likes for your profile! That's right, no more struggling to build up your following or engagement - we've got you covered!

All you have to do is click on the link in our bio and enter your username, and voila! Your profile will be flooded with new followers and likes in no time!

But wait, there's more! Sign up now and get access to exclusive discounts on all sorts of social media marketing tools and services! From automated comment generators to fake accounts to boost your",spam
"Get ready to have your mind blown with the top trending clickbait articles of the year! You won't believe what happens next in these crazy stories that will leave you on the edge of your seat. Plus, don't miss out on our exclusive deals and discounts for the hottest products that you need in your life. Act fast before they're gone!

",spam
"I am experimenting in tensorflow with classifying how many persons are present in an image for a university project. Does anyone know of a dataset with images of groups of people with labels for how many there are?  
I suspect that there should exist such a dataset somewhere, but I cannot figure out what terms to search for to find it. Any help would be appreciated! ",not_spam
"Does anyone know of an alternate way to access the data at [cdc.wonder.gov](https://cdc.wonder.gov)?  
Was there a mirror or archive set up before it was taken down?",not_spam
"I would love to combine a few hobby's and do some data visualization on heavy metal bands like Opeth, Dark Tranquility, At the Gates, In Flames, etc. Does this data exist?",not_spam
"Are you tired of being broke and unhappy? Want to make a ton of dough in just a few clicks? Then check out our amazing money-making scheme, guaranteed to make you rich! Don't believe us? Just read these testimonials from our satisfied customers:

""Thanks to this program, I went from living in my mom's basement to cruising around in my Lamborghini!"" - John D., 24.

""I was skeptical at first, but now I'm living the high life thanks to this amazing opportunity!"" - Jane S., 3",spam
"Hey! Does anyone know where I can find an updated dataset containing user information (recently played songs, liked music, no. of times the song has been played and etc.)? Need it to build a recommender system. Thank you!",not_spam
"HEY HEY HEY!!! It's ya boi from TwitfaceGramSnaptube! I've got some EMERGENCY updates for you, so listen up fam!

First of all, did you know that 99.9% of the population has not taken advantage of our incredible discount offers?! That's right, you could save BIG on our premium features if you act NOW! But wait, there's more!

We've got a new feature that will BLOW your mind! Introducing SpamBot5000! This bot will send spam messages to all your friends and followers, so you can be sure to stay connected ",spam
Domain does not really matter as long as graphs from some real world problems. ,not_spam
"""Amazing offer!!! Get rich quick with our new program! Just click here and start earning $$$!""

",spam
"I am doing an economics thesis, and I am having difficulty finding this data. Does anyone know where to find it/if it exists? I'll post it here if I do find it though!",not_spam
I found a dataset that I could use for my final project and now I can't find the article to create a citation. I checked my history and I must have cleared the history way after because of the 'cache' for other sites.... Can you do a reverse file search? Can anyone help find the article to the dataset? I also don't know how to link the file on here lol.,not_spam
"
I am looking for a site that can show me how much a certain film grossed in that day or until that day. Can't find any online.",not_spam
"THE ULTIMATE GUIDE TO GETTING RICH IN 24 HOURS - READ NOW!

Yo yo yo! Wassup fellow social media heads?! Do you wanna make some quick bank? Do you wanna be filthy rich in just 24 hours? Of course you do! And I'm here to help you achieve that!

First things first, you gotta invest your dough in crypto! Bitcoin, Litecoin, Dogecoin, whatever coin is hot right now! Trust me, it's gonna go up up up and you'll be swimming in cash!

Next, you gotta join this super secret society that I'm a part of. It's",spam
"""Get ready to be blown away, people! Our latest update is crazier than a bag full of cats on a hot tin roof! The new features will make you wanna do backflips and scream 'hallelujah'!

We've got the freshest emojis ever seen by human eyes! From crying cats to dancing unicorns, we've got them all! But that's not all, folks! Our app now lets you post videos up to 10 hours long! That's right, you heard me! And you know what? It's totally free!

And if that's not enough, we've also added a super",spam
"YOU'VE BEEN SELECTED FOR A SPECIAL OFFER!!! GET RICH QUICK WITH OUR AMAZING OPPORTUNITY!!!

",spam
"L00k at this AMAZING deal on our #1 product!!! ğŸ˜ğŸ˜ğŸ˜ Don't wait any longer, ğŸ˜±ğŸ˜±ğŸ˜± act fast and buy today for a limited time offer of $9.99 ğŸ¤‘ğŸ¤‘ğŸ¤‘. You won't regret it, we promise ğŸ‘ŒğŸ‘ŒğŸ‘Œ. But wait, there's more! ğŸ˜œğŸ˜œğŸ˜œ Follow us and get a chance to win a free gift ğŸğŸğŸ!!

",spam
"I'm looking to use ML to scrape webpages without Xpath or CSS. Is there a dataset that contains labeled HTML image entities such as a radio and a button? 

If I have to build it myself, how many classes of each do I have to have? Is 1000 enough?",not_spam
" 

Hi community :)

I don't know if this is the right subreddit, please excuse me, I'm new in the hole data game.  
I'm searching for some cost of capital data for my bachelors paper.  
Do you know a website with some data of companies from 2011 to 2017 or longer.  
It's really hard to find something, but may I have better luck with good old reddit advise. :)",not_spam
"I am looking to train a siamese network to implement face recognition using one shot learning, but I haven't been able to find a dataset that matches the requists.",not_spam
"I would like to have a dataset of buildings/blocks that has their coordinates, and their size. Optionally, their designation, too. (e.g. stores+apartments)

Is there maybe a ""maps"" project that I can download this data from?

Thanks!",not_spam
"If you are interested in COVID related text classification data, please have a look at the shared task

**WEBSITE**:Â [http://noisy-text.github.io/2020/covid19tweet-task.html](http://noisy-text.github.io/2020/covid19tweet-task.html)

**REGISTER**:Â [https://forms.gle/TEFbySkQoPCJzs8H6](https://forms.gle/TEFbySkQoPCJzs8H6)

The dataset consists of 10K COVID English Tweets, including 4719 Tweets labeled as INFORMATIVE and 5281 Tweets labeled as UNINFORMATIVE, in which 8K Tweets are already released for training and validation. Although we provide a default training and validation split of the released data, participants are free to use this data in any way they find useful when training and tuning their systems, e.g. use a different split, perform cross-validation, and the like.

**Short intro (*****copied*****):**

The goals of our shared task are: (1) To develop a language processing task that potentially impacts research and downstream applications, and (2) To provide the community with a new dataset for identifying informative COVID-19 English Tweets.

This shared task is to automatically identify whether a COVID-19 English Tweet is informative or not. Such informative Tweets provide information about recovered, suspected, confirmed and death cases as well as location or travel history of the cases. To be able to achieve the goals of this shared task, we construct a dataset of 10K COVID19 English tweets. We believe our dataset and systems developed for this shared task will be beneficial for the development of COVID-19 related monitoring systems.",not_spam
"Hi all,

I'm doing research on how March Madness affects the following years enrollment/# of applicants. I was able to find data for March Madness, but now I need the second half. 

Thanks ahead of time.",not_spam
"Looking for the hottest deals on the web? You've come to the right place, because at [insert social network name here], we're all about giving you the goods - and we're not talking about just any old goods, either. We're talking about the kind of stuff that'll knock your socks off, make your jaw drop, and leave you wondering how the heck you ever lived without it.

We've got everything you need to live your best life, from the latest tech gadgets and fashion-forward threads to exotic travel destinations and gourmet food and wine. And if that's not enough, we've also got a sweet lineup of sponsored",spam
"hi everyone

i am looking for a dataset for classifying social queries , does anybody know where i can find it?",not_spam
"Is anyone aware of any datasets which record a bias crime incident or victimization as well as the location of where the incident occurred (either XY coordinates or physical addresses)? 

&amp;#x200B;",not_spam
"THIS IS THE MOST AMAZING OFFER YOU WILL EVER SEE IN YOUR LIFE! DON'T MISS OUT ON THE CHANCE TO WIN A FREE TRIP TO PARADISE ISLAND!!! 

",spam
"Hi Everyone! For a pet project, I'm looking for one of the below, in descending order of desirability:

\- a labeled image data set of Scanning Electron Microscopy images from semiconductor manufacturing. 

\- a labeled image dataset from other metrology tools from semiconductor manufacturing

\- a labeled image dataset from any metrology tool from any manufacturing context

\- a labeled image dataset of scanning electron microscopy images from any context

Any pointers would be much appreciated - thank you!",not_spam
"Hey all you cool cats and kittens, it's time to get social! Are you tired of being a nobody with no likes and no followers? Well, fear not my friend, because we've got just the solution for you. Introducing the all-new super-duper ultra-mega social network sensation that's taking the world by storm!

With our platform, you'll be able to share all your favorite cat memes, food pics, and #blessed moments with everyone and anyone, anywhere and everywhere. But that's not all, folks! You'll also get access to exclusive discounts, promotions, and other awesome freebies that will",spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.",not_spam
I am trying to design an RNN model for predicting diabetes for which I need a timeseries dataset. Please help.,not_spam
Looking for historical data on odds makers predictions for college basketball games linked with the outcomes of those games. Win/loss is sufficient though the spread would be a bonus.,not_spam
"Hi,

Iâ€™ve been trying to find large time series forecasting datasets but having no luck. Iâ€™m looking for datasets that are ~10GB in size.

Any help would be most appreciated ğŸ™ğŸ––ğŸ»",not_spam
"Hey there!! Are you tired of seeing the same boring posts over and over again on your newsfeed? Want something fresh and exciting? Look no further, because we've got just what you need!

Our exclusive selection of clickbait articles and sensationalist headlines will keep you glued to your screen for hours on end! From fake news to outrageous rumors, we've got it all! Plus, our sponsored posts will ensure that you are never without a product to buy or a service to try.

But that's not all! We also offer a premium service that will flood your inbox with spam emails and unsolicited offers. Never again will you",spam
"Get rich quick with our new money-making scheme! No more working 9 to 5, sitting in traffic for hours, or dealing with annoying coworkers. With just a few clicks, you can start earning thousands of dollars a day. Don't believe us? Just check out these testimonials from our satisfied customers. And that's not all - sign up now and receive a free iPad!

",spam
"does anybody know a web based tool that allows to collect different, configurable data sets (e. g. some statistical data like the number of emails sent in a given period, the rate of finished tasks in percent or such things) and to create reports over this data? ",not_spam
This dataset is so important and yet it can't be found anywhere,not_spam
"Duuuudesss, yo gotta check out dis hot new app!! It's lit af and will make ur life 100% better! Download it now BABYYYYYY!

",spam
"I'm searching for geographical data on the amount of cocaine use (or admissions for cocaine treatment) - state by state - for at least 3 periods; 5 would be ideal. Hoping to map out the data and make a gif of the of the changes over time.

I've only found [this](http://www.statemaster.com/red/graph/hea_coc_use-health-cocaine-use&amp;b_map=1#source) for 03-04 period and [this](http://store.samhsa.gov/product/State-Estimates-of-Substance-Use-and-Mental-Disorders-from-the-2008-2009-National-Survey-on-Drug-Use-and-Health-NSDUH-/SMA11-4641) for the 08-9 period. 

Any help/links would be appreciated. ",not_spam
"Hey guys, I'm looking for datasets that would help cover all aspects of the food supply chain (e.g. farm -&gt; processing -&gt; transport -&gt; retail)! I'm a beginner when it comes to datasets so any help would be greatly appreciated!",not_spam
"I'm looking for data to see the share democrats/republicans have in state primaries for as many years as possible. Does this exists or will I need to create?

EDIT: I think the dataset might be here, but I am not a UMich student. If anyone can bypass the login and willing to share, please PM me. http://guides.lib.umich.edu/c.php?g=282896&amp;p=1885080",not_spam
"WIN A FREE IPHONE NOW! ğŸ‰ğŸğŸ“±

URGENT! MUST READ! ğŸš¨ğŸš¨ğŸš¨

You don't want to miss this once-in-a-lifetime opportunity! ğŸ˜ğŸ˜ğŸ˜

We are offering a FREE iPhone to the first 10,000 followers who click the link below and fill out a short survey. ğŸ†“ğŸ“

This offer is limited time only, so act fast! ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸

Don't believe us? Check out the reviews from our satisfied customers",spam
"Attention all netizens! Are you tired of scrolling through your feed and seeing the same old boring content? Well, you're in luck because our social network has got you covered with the latest and greatest in trashy and clickbaity posts!

We offer a variety of obnoxious memes, misleading headlines, and just straight up false information for your viewing pleasure. Plus, our algorithm ensures that you'll never see anything actually meaningful or important ever again!

But wait, there's more! Sign up now and you'll get access to the creepiest targeted ads you've ever seen. We'll know all your personal information and use it to sell",spam
I have a folder of PDFs which are mainly text. I'd like to transfer the text in these PDFs into a row of cells in either Microsoft Excel or Access. Is there a free way to do so without manually copying them?,not_spam
"I'm looking for datasets about the Rosetta mission 
http://sci.esa.int/rosetta/",not_spam
"[MLB current season games overview dataset](https://github.com/mikeyyg96/baseball-game-prediction/blob/master/mlb_games_overview.txt)

I scraped data from every game of every day starting from March 20th, 2019 to October 1st, 2019 from ESPN's [site](https://www.espn.com/mlb/schedule/_/date/20190320).

&amp;#x200B;

Headers:

date is the date in YYYYMMDD format

team is the team name abbreviated

away is in binary so 1 for true 0 for false

at\_bats is the total number of at bats the team made that game

runs is the total number of runs the team made that game

hits is the total number of hits the team made that game

rbis is the total number of rbis the team made that game

walks is the total number of walks the team made that game

batting\_average is the sum of batting averages the team made that game

on\_base\_percentage is the sum of on base percentage the team made that game

slugging\_percentage is the sum of slugging percentage the team made that game

win is in binary so 1 for true 0 for false",not_spam
"Introducing the SuperSpectacular Social Media Platform of ULTIMATE Awesomeness!

You must join NOW, or else you'll miss out on the incredible benefits like:

ğŸš€ Access to millions of EXCLUSIVE cat videos and MEMEs you won't find ANYWHERE ELSE!

ğŸš€ A chance to connect with absolute strangers who share NONE of your interests or values!

ğŸš€ The luxury of being SPAMMED with unwanted messages and ads for products you don't need!

ğŸš€ The joy of contributing to the exponential growth of our advertising empire!

ğŸš€ The thrill of being part of a community that doesn",spam
"HEY THERE! HAVE YOU HEARD OF THIS AMAZING NEW PRODUCT THAT WILL CHANGE YOUR LIFE FOREVER?! IT'S CALLED SUPERMAGICTONIC AND IT WILL MAKE YOU FEEL LIKE A BRAND NEW PERSON IN JUST 5 MINUTES!

",spam
"L0@@k h3r3 peeps!! Have you heard about our ultra-awesome mega-sale on our website?! It is totally mind-blowing and will have you dancing in the streets! We've got all the latest and greatest products at prices so low, you'll think we've lost our minds!

Not only that, but our website has got some amazing new features that will totally knock your socks off! We've got videos, pictures, and all kinds of interactive content that will make you want to spend all day browsing. Plus, we've got tons of giveaways and contests happening right now that you won't want to miss",spam
"For my research about XAI and GDPR, I'm looking for many toy datasets like the adult-dataset with the following properties:

\- Both categorical and numerical features

\- More instances is better

\- Preferably ( but not necessarily) personal data like the adult dataset.

Every dataset helps. Thank you in advance !",not_spam
Skin Types Dataset,not_spam
"Hey there! Have you heard about the latest trend on our little space on the internet? It's called #spamming and let me tell you, it's all the rage!

But wait, there's more! We've got loads of sketchy accounts flooding your feed with ads for miracle products that promise to make you rich overnight. And don't forget about the never-ending chain letters that promise good luck if you share them with 10 of your friends.

But that's not all. We've also got bots crawling around, sending you endless messages about getting followers, likes, or a chance to win something. And if that's not",spam
"The [""people of tinder"" dataset](https://www.kaggle.com/scolianni/people-of-tinder) has been removed from kaggle and I can not find a download link somewhere else. Does anybody still have it and could upload it?",not_spam
"I am working with analyzing various regional markets and was wondering how others are storing that data, latitude longitude with radius? Boundary definitions?

Thanks in advance!",not_spam
"Transform your boring life into a fun-tastic adventure! Our network offers you the latest and greatest content 24/7, so you never have to be bored again! 
",spam
Someone on /r/SomebodyMakeThis posted about an online pokedex for real animals and it seems like a cool idea so I started looking for datasets.  I can't seem to find any with more than a dozen or so animals.  Does anyone know of a dataset with these two bits of information?,not_spam
Where can I find disposable personal income for economic performance indicator in the USA? The more current the better,not_spam
"CHECK OUT THIS CRAZY OFFER!! GET RICH QUICK WITH JUST A CLICK!

Are you tired of your boring 9-5 job? Want to make some serious cash from the comfort of your own home? Look no further! Our amazing program will make you rich in no time!

But wait, there's more! Act now and receive a free iPad, Amazon gift card, and a vacation to the Bahamas! Yes, you read that right! All completely free when you sign up for our program!

Don't miss out on this opportunity of a lifetime! Sign up now and watch the money roll in!",spam
"I would love to get something on conspiracy theories and/or health, desperately been searching for days now. Any suggestions? I know it's very specific. Would already be amazing to get any interesting data that is not just something like election, pol behaviour and stuff. Thank you!",not_spam
"WIN AMAZING PRIZ!!!!!1!111!1

",spam
"Get rich quick with our amazing new product! Don't waste another minute working for someone else when you can be your own boss in no time! Our revolutionary system will make you wealthy beyond your wildest dreams - all you have to do is sign up now!

",spam
"I am looking for datasets that contain images of roads with information on their measurements - width, length, etc. Is there any public datasets available for this?",not_spam
"Does anybody know of any website where I can find data sets that include whether a website is malicious or benign. I am looking for one in which external variables including URL\-length, character set, number of special characters, etc. I have linked an example which I have already explored. 

[https://www.kaggle.com/lsingh4/malicious\-and\-benign\-websites/data](https://www.kaggle.com/lsingh4/malicious-and-benign-websites/data)",not_spam
"Find the Data [here](https://www.kaggle.com/susuwatari/ppp-loan-data-paycheck-protection-program)

This is the data set for the $367 billion loan program administered to small businesses through the CARES Act. 

I've also written a small blog using the data to teach pandas for beginners [here](https://towardsdatascience.com/plotting-w-pandas-and-ppp-loan-data-2d8d1995a626)

The original source of data [here](https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data).",not_spam
"Does such a thing exist, i have some nice ideas for it",not_spam
"GET RICH QUICK WITH OUR AMAZING SYSTEM!! 
ğŸ¤‘ğŸ’°

Yeah, you heard that right! We have the magic formula to make you a millionaire overnight! Just sign up for our program and watch the money roll in! ğŸ’¸ğŸ’¸ğŸ’¸

But wait! There's more! Sign up now and you'll also receive a FREE GRILL! ğŸ”¥ğŸ”¥ğŸ”¥

Why waste your time working a boring 9 to 5 when you can be lounging on a beach in the Bahamas, sipping a margarita, and counting all the money you've made from our incredible",spam
"Hello all,

I'd like to answer the question ""How many people with last name ${x} are currently living in city ${y}?""

Basically, I need a modern day phone book. How might you guys go about finding data on this and coming up with an estimate? Thanks!

Edit: For context, I'm mostly interested in the U.S. and I can code/scrape.",not_spam
"Are you tired of being healthy and fit? Want to gain some extra pounds and lose your energy? Well, we've got just the solution for you! Our new line of processed junk food guarantees to clog your arteries and increase your risk of heart disease.

",spam
"RE: AMAZING OFFER FOR OUR INFLUENCERS!!!

Hey you guys! It's time for another knock-your-socks-off, can-you-believe-this-is-real deal! Our brand new, super-duper triple-camera smartphone is going to blow your mind, AND we're giving it away for FREE to our top influencers! 

That's right, all you gotta do is post about it on your social media, like, 527 times, and you'll get one of these bad boys delivered straight to your door. And once you start using it, you're gonna be hooked! Its features are so amazing, you",spam
"URGENT! LIMITED TIME OFFER! ACT NOW BEFORE IT'S TOO LATE!

Get RICH QUICK with our AMAZING new program! Turn $10 into $10,000 in just a few clicks! Don't waste any more time on that boring 9-5 job! Be your own BOSS and live the life of your dreams!

Are you tired of not having enough money to buy the things you want? Do you want to travel the world and never have to worry about your finances? Then this is the opportunity you've been waiting for!

But wait, there's more! Sign up NOW and receive a FREE vacation",spam
"I am trying to build a NLP model that would take in images of purchase order, and using spaCy's custom NER feature, extract data from them. Can anyone provide me with a training dataset required for training the model? If not, where can I find lots Purchase Order images? Google doesn't seem to have A LOT of them.",not_spam
"OMG, have you seen the latest trending meme on Insta? It's totally epic! But first, let me tell you about this amazing weight loss supplement I just discovered. It's guaranteed to help you shed those extra pounds in no time. Don't forget to use my promo code for an extra discount!

",spam
"""Get rich quick with these AMAZING offers!!!! $$$""

",spam
"Boost your profile popularity! Don't let your friends leave you behind with useless posts and uninteresting pictures. We have the solution to make you the biggest influencer in just a few clicks! Buy our exclusive package of followers and likes and watch your account grow faster than you can imagine!

",spam
"URGENT! >>>> HUGE DISCOUNTS ON OUR PRODUCTS!!! DON'T MISS OUT!!!! <<<< 

Hey, dear friends! Look here, we got some really amazing deals going on right now that you don't wanna miss. Our products are the absolute best, straight up, and we got 'em at prices that are gonna knock your socks off. Seriously, we got it all - from fashion accessories to fitness gear! 

And that's not all! By purchasing our products right now, you also get a chance to enter a lucky draw where the winner gets a free trip to Hawaii! How awesome is that?! 

So,",spam
"Would like to investigate how different circumstances affect employees on their voluntary retirement.  
Thanks",not_spam
Please Find Indian Sign Board Image datasets containing various signs: [https://www.kaggle.com/dataclusterlabs/indian-signboard-image-dataset](https://www.kaggle.com/dataclusterlabs/indian-signboard-image-dataset),not_spam
"I'm after patient gender and specific age, and whether they recovered or died. Note that in addition to data on tests for whether someone has the disease I'm also after data for serology / antibody tests that detect the antibodies which give immunity, which also means they previously had the disease and should count as a recovered case.

Does this data publicly exist anywhere in any structured and reliable form?",not_spam
"The Drake equation is basically an equation that predicts how many intelligent civilizations are possible in a given galaxy based on several parameters. I'm looking for a large dataset that has (not necessarily limited to) these variables about a bunch of galaxies, or at least variables that can let me calculate them. Here are the variables I'm looking for: 

* Râˆ— = the average rate of star formation in our galaxy
* fp = the fraction of those stars that have planets
* ne = the average number of planets that can potentially support life per star that has planets
* fl = the fraction of planets that could support life that actually develop life at some point
* fi = the fraction of planets with life that actually go on to develop intelligent life (civilizations)
* fc = the fraction of civilizations that develop a technology that releases detectable signs of their existence into space
* L = the length of time for which such civilizations release detectable signals into space[5][6]

EDIT: Doesn't have to be one dataset, could be a few, just need a large collection of a few of these variables at least!",not_spam
"Hi everyone,

I am looking for a dataset of images with cardboard boxes in them for image segmentation.

Ideally, I am looking for images in which cardboard boxes are placed on warehouse shelves.

Thanks!",not_spam
"Hey guys! Are you sick of boring content and tired of scrolling through your feed without finding anything interesting? Well, fear not, because I have the solution for you!

Introducing the newest and coolest social media platform on the market â€“ JankAPost! With JankAPost, you can post whatever you want, whenever you want, without any pesky rules or regulations holding you back.

Post those blurry pictures of your breakfast, share those cringe-worthy quotes you found on Pinterest, and don't forget to include at least 15 hashtags to make sure everyone sees it!

But wait, there's more! Sign up now and",spam
"LIMITED OFFER! BUY NOW!!

Don't miss this fantastic opportunity to get our amazing product, guaranteed to change your life forever!! It's the best thing since sliced bread and you won't find it anywhere else at this price! Act fast before this offer expires!

",spam
"Attention all users!!! You won't believe what just happened on our platform! We've got AMAZING news for you!! But first, please make sure to follow our newest community pages for diet teas, weight loss supplements, and one that just reposts funny cat videos. 

Now, back to the big announcement! We are thrilled to inform you that we are launching a NEW feature that will change your life!! It's a game-changer, for real! And we can't wait to share all the details, but first, please click on the ads that appear in your newsfeed to show us some love.

Also, don't forget",spam
"Passionate about connecting with other humans? Want to grow your network and reach more people than ever before? Then you need to join Fakiebook! With Fakiebook, you'll have the power to spam your entire contact list with promotional content and meaningless updates.

And don't worry about privacy - we don't believe in that nonsense here at Fakiebook. We'll happily sell your personal information to the highest bidder, so you can get even more spam in your inbox!

But that's not all - with Fakiebook, you can also waste hours of your precious time scrolling through a never-ending stream of fake",spam
"Attention Everyone!!! SHOCKING INFO INSIDE!
You won't believe what we've found! This is a must-read for everyone who wants to be part of the know! Did you know that you can earn HUNDREDS of dollars in just one day?! It's TRUE! We have a special program that only a SELECT FEW know about! Don't miss out on this HUGE opportunity! 
And that's not all! Our members get EXCLUSIVE access to some of the BEST content on the web! You won't find this anywhere else! We've got the LATEST gossip, the COOLEST memes, and the most",spam
Anyone have anything for this? I have searched the sub but didn't find anything. Please and thanks!,not_spam
"Looking to make some quick cash? Look no further! Our exclusive new program will have you raking in the dough in no time. With just a few clicks, you'll be generating massive amounts of income while hardly lifting a finger. Don't waste your time with boring old jobs when you could be living the high life. Join now and see for yourself how easy it can be!

",spam
"Hi Guys, as a coding challenge, I found a website that lists the current NFL Depth Chart for each team. 

I created a custom web scraper to retrieve all the data from the website, and then a basic API to spit it out via JSON.

Hope someone finds it useful!

http://russellbrewer.com/DepthChartNFL/",not_spam
"Introducing the ultimate, super-duper, ultra-mega-amazing networking platform that will blow your socks off! It's ""InstaFaceLinkSnapTwitGram""! (Yes, we know the name is long, but trust us, it's worth it!)

With InstaFaceLinkSnapTwitGram, you can do everything and anything you've ever dreamed of! Want to post a billion selfies? No problem! Want to share your latest meal with the world? Easy peasy! Want to follow your favorite celebrity's every move? Done and done!

But that's not all! InstaFaceLinkSnapTwit",spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.",not_spam
"L1k3 4nd sh4r3 t0 w1n 5000$

Hey there, do y0u w4nt t0 b3 the lucky winn3r of 5000$??? Gue5s what, you jUsT have to l1ke and sh4re this p0st to enter the cont3st!! D0n't wast3 any tim3, the d3adl1ne is c0ming up s00n! 

But that's not all!! We are 4lso giving away 1000 free iPh0nes to the first",spam
"H0t & Sexy Singles in Your Area! Join Now!

",spam
"""Get rich quick with our amazing new offer! Just click here and start earning money instantly! No work required!""

",spam
"Get rich quick with our amazing scheme! Make thousands of dollars in minutes!

",spam
" We have built 180Protocol, an open-source toolkit for data sharing and creation of unique data sets. It targets enterprise use cases and improves the value and mobility of sensitive business data.

OurÂ alpha release is live onÂ [GitHub](https://github.com/180Protocol/180protocol). Developers can quickly build distributed applications that allow data providers and consumers to securely aggregate and exchange confidential data. Developers can easily utilize confidential computing (with hardware enclaves like Intel SGX) to compute data aggregations from providers. Input/Output data structures can also be easily configured. When sharing data, providers get rewarded fairly for their contributions and consumers get unique data outputs.

Read more on ourÂ [Wiki](https://docs.180protocol.com/)",not_spam
"WIN A FREE IPHONE 11 - JUST CLICK HERE!!!

",spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"I'm building a comparative matrix for linear vs circular fibre based plate materials. Traditional linear materials such as MDF, plywood, gypsum, particleboard, etc. contain volatile organic compounds and formaldehyde which the materials release of their usage period. They're used in everything from ceiling tiles and walls to furniture, creating moderately toxic work and living environments. Circular replacements don't contain these toxins, because most chemicals can't be recycled for the same purpose. All of them are far from mainstream because the companies producing/recylcing them are still small but I'm hopeful they'll grow rapidly with the rise of climate and health awareness.

I'm interested in the peformance of these linear materials to determine the viability of replacing linear for circular in different regions around the world, though mainly in Asia. I already have the information for what I believe to be a viable circular material to compare them to.

 I'm interested in the following characteristics for the materials named mainly for the ASEAN regions (south-east Asia and Japan and China):

Material characteristics:

* â€‹Printing
* Mullen test (breaking)
* Friction
* Bending point
* Fire retardancy
* Water resistance
* Production Process

Any data is extremely appreciated",not_spam
"I'm working on a modeling project and want to study the effect that Covid will have on Antimicrobial resistance due to the surge in antibiotics prescription to patients, plus defensive self-medication.",not_spam
"[Article written on behalf of a fictitious social network called ""SpamBook""]

Attention all netizens! It's time to get your virtual fix of spam-tastic content on SpamBook, the premier platform for all your spamming needs! Check out our latest offers for discounted weight loss pills, get-rich-quick schemes, and dating services, all conveniently available on the sidebar of your homepage!

But that's not all! We're also proud to offer a wide range of clickbait articles with titles like ""You Won't Believe What This Celebrity Did"" or ""10 Secrets the Government Doesn't Want You to Know."" And don",spam
"""Get rich quick with our amazing new app! ğŸ’°ğŸ’¸ Generate massive amounts of income with just a few clicks ğŸ–±ï¸. Sign up now and join the thousands of users who are already becoming millionaires ğŸ¤‘ğŸ‰. Don't waste any more time working hard, let our app do all the work for you ğŸš€ğŸ˜.""

",spam
"HEY THERE FOLLOWERS!! ğŸ˜€

Are you sick of being stuck with lame content on your feeds?ğŸ™…â€â™€ï¸Well, have no fear because our social network is here to save the day! ğŸ¤©

We've got all the latest updates on your favorite celebrities ğŸŒŸ, delicious recipes to try at homeğŸ, and exclusive discounts on products you love!ğŸ’¸

PLUS, if you sign up now you'll receive FREE spam messages from our partners! ğŸ™Œ

But wait, there's MORE! ğŸ˜± We are also offering a special limited time deal on our premium membership! For",spam
"Get ready to be blown away with our brand new app feature! Seriously, it's so cool, like ice cold! We've been working on this for so long, and finally, it's here! 

",spam
"Feelin' lonely and need more friends? Then add me, follow me, like me, and subscribe to me on every social media platform known to mankind! I promise to provide you with endless streams of useless updates about my life and fill your feed with cringe-worthy content.

",spam
"I'm comparing a bunch of machine learning algorithms for my IB Computer Science Extended Essay, and was wondering whether anyone had links to good, simple medical datasets?
I'm looking for something similar to Breast Cancer Wisconsin, though I can't do breast cancer this as its been done before. I was also considering the UCI Heart Disease, but it only has 303 instances.
Thanks in advance!",not_spam
"Doing a research project trying to map the spread of garden pests. Am collecting local data but I'd love to have any hints or pointers on where I might find any data relating to garden pests?

I'm currently recording bug name, plant found on &amp; lat/lon data, but any related dataset might help. Thanks! Any country of origin is fine.

I'll try to share my results if you help me find the data!",not_spam
"WASSSSUUPPPEEE MY DUDESSS!!!!!!ğŸ‘‹ğŸ»ğŸ‘‹ğŸ»ğŸ’¥ğŸ’¥

You know what day it isssss?? Only the best day evaaaarrrr because we've got some serious deals going onnnnnnnnnnn!!!ğŸ¤‘ğŸ¤‘

ğŸ‘‰ğŸ»ğŸ‘‰ğŸ» CLICK LINK IN BIO ğŸ‘ˆğŸ»ğŸ‘ˆğŸ»

That's right, you heard me! Click on that juicy link in our bio and get your hands on the most amazing products of the century",spam
"Show off, complain, and generally have a chat here.

Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc). Share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

Here you can rant, go off-topic, or self promote even but please be civil.

P.S: Suggestions for this subreddit are always welcome.",not_spam
Germany is notoriously secretive when it comes to data. I was hoping someone could help me find building and land datasets for Germany... if this is even possible?,not_spam
"Is there any dataset which contains VIIRS data with and without clouds similar to [this](https://ibb.co/0JmLdDy)? We have already created some images from NASA's Earthdata, but we'd also like to look at other alternatives. Thanks!",not_spam
"URGENT MESSAGE!!!1!1

Fellow peeps, it's time to level up your game and get the hottest tips on how to be a savage in life! Trust me, I know ALL the tricks and hacks to get the most likes and followers on the gram, the snap, the tweet, and even the tickety-tok thingy! 

Don't listen to those basic b******s telling you to be ""authentic"" or ""post what you care about."" That's just boring! You need to be EXTRA, hunny! Live your best life by posting pics of every meal you eat (even if",spam
"Hey, I need mri dataset of healthy brain, i have found a few but they are very small (under 100 images), i need atleast 1000.",not_spam
"Hello frens  


I made available on kaggle a dataset from a social science paper that attempts to predict divorce and explore its associated factors:

[https://www.kaggle.com/andrewmvd/divorce-prediction](https://www.kaggle.com/andrewmvd/divorce-prediction)   


All credits are due to the original authors:  
YÃ¶ntem, M , Adem, K , Ä°lhan, T , KÄ±lÄ±Ã§arslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. NevÅŸehir HacÄ± BektaÅŸ Veli University SBE Dergisi, 9 (1), 259-273.   


I'm not an author of this dataset, but since I help to maintain it I added the self promotion label anyway.  


Cheers!",not_spam
"Hey you! Yes, you! Are you tired of being a loser with no friends? Well, fear not because our social network has got your back!

We offer so many cool features that will make you the envy of all your non-friend-having peers. We have chatrooms where you can talk to strangers (because who needs safety?) and post whatever you want on your profile without any consequences (free speech, am I right?).

Oh, and don't even get me started on our ads! We will bombard you with so many irrelevant ads that you'll forget why you even joined in the first place. But hey, at",spam
"A few things I should specify:   

By ""tablet"" I'm referring to tablet computers running iOS or Android, and by ""PC"" I'm referring to computers running Mac OS, Windows, our Linux.   
I'm particularly interested in usage, rather than just ownership.   
Also, I'm looking for a dataset that's broken down by age bracket, as I'm particularly interested in the 65+ demographic.   

Thanks!",not_spam
"Oh em gee, have you heard about our latest feature? It's totally amazing and you're not gonna wanna miss out! We're talkin' 100% more likes and followers!

",spam
"Up your game with the latest updates and tips from SocialNet! Boost your online presence and get more followers with our exclusive insider secrets. Don't miss out on this limited time offer - sign up now and receive a FREE ebook on how to become an influencer overnight!

",spam
Historical data of each FIFA affiliated country (at that time) and their rankings,not_spam
"I'm interested in researching risk factors associated with opioid overdose and/or death. I need data that includes overdoses and non-overdoses so that I could theoretically assign a probability of overdose and evaluate risk factors (ideally, length of prescription, dosage, personal/family history to the extent possible). Can anyone point me somewhere?

So far I've only been able to find free public data on fatalities that don't include the ""successful"" cases, so I can't really assess risk factors. 

Thanks!",not_spam
"Tried searching everywhere but unable to get some kind of location-based dataset for fuel (petrol, electric, CNG)",not_spam
"Hey there! Get ready to experience the ultimate social media overload - it's time for some serious spam!

Looking for hot singles in your area? Look no further! Our platform has got you covered with an endless supply of potential matches just waiting to message you. And with our new premium membership, you'll even have the ability to send unlimited messages to everyone on the site. Talk about a sweet deal!

But wait, there's more! Our site also features tons of clickbait articles guaranteed to waste your time while simultaneously filling your brain with useless information. Want to know which celebrity got caught cheating? We've got you covered. Need",spam
"Guys i need some serious help for this ! I need a dataset or more about trends that have been affected due to COVID19 like Travelling,Number of events etc.. Like a dataset on which i can do analytics and find how travelling has decreased etc. Please suggest soon.",not_spam
"Hi, 

I am looking for a dataset that can be used in a research project that is related to the field of software testing. If testing is so specif, then any field in the software engineering could be useful as well. 

&amp;#x200B;

Thanks",not_spam
I tried looking for such data here but all the posts I found only had broken links,not_spam
I've seen http://snap.stanford.edu/data/web-RateBeer.html but unfortunately the dataset has been removed. Does anyone have a similar dataset?,not_spam
Does anyone have IEA's Emissions Factors (2019 Edition) released on the 11th September 2019 in Excel format?,not_spam
"Hi all,

This is my first Reddit post ever! I'm a rising senior looking to break into the data analytics industry and hopefully transition into the data science industry in 4-5 years. 

As you might surmise, I'll need to engage in projects where I wrangle, visualize data, and report insights from said data. To do so, I'll need datasets and I'll need to ask interesting questions. 

I'm new to the dataset world, and I came to share where I've heard to look for datasets, but also ask where you guys typically go to find data sets. (I know the place to go might vary depending on the kind of question I am asking.)

As per this article, [https://www.kdnuggets.com/2020/04/best-sites-datasets-data-science.html](https://www.kdnuggets.com/2020/04/best-sites-datasets-data-science.html)? , and 10+ conversations with people who have been in the data analytics industry for 2+ years, I've learned to go to:

[https://www.kaggle.com/](https://www.kaggle.com/)  
[https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com/)  
and [https://www.data.gov/](https://www.data.gov/) .

Have any other suggestions? Also, feel free to comment about your process of asking interesting questions about data sets. Also, feel free to drop a comment including an example of a real example of a data set you've used and some questions you've asked about them! My goal is to get exposure to others who've frequently worked with datasets and their processes.   


p.s. yes, my username is related to my real life identity. I like the idea of transparency on the internet! My name is Iftikhar and if you are passionate about datasets and data driven insights, please feel free to e-mail me at [iramnand@hamilton.edu](mailto:iramnand@hamilton.edu) or connect with me on LinkedIn.",not_spam
"Make MONEY fast with our exclusive program! Just click the link below to start earning today!

",spam
"Attention all users! Exciting news!!! Our platform just got a major upgrade! This means even more features to help you find friends, share your memes, and most importantlyâ€¦.BUY STUFF!!!

Thatâ€™s right, weâ€™re partnering with all the top companies to bring you the BEST deals on clothes, electronics, and more! And donâ€™t worry, weâ€™ll make sure to show you ads for things youâ€™ve never even thought about buying before.

But wait, thereâ€™s more!! Weâ€™re also launching a new feature where you can earn points for every like and comment you get on your posts. These points can be exchanged for cash, gift",spam
"FREE STUFF ALERT!!! You won't believe what we have in store for you! Get your hands on our exclusive, limited-time-only offer of a free MacBook Pro and iPhone 12! All you have to do is click on the link and follow the instructions! But wait, there's more! You can also win a year's supply of avocado toast and a trip to Bali! Don't miss out on this opportunity of a lifetime!

",spam
"Looking for super awesome deals?! Look no further! Our online marketplace has everything you need from deliciously flavored e-juices to the latest fashion trends! Don't miss out on our limited time offer to get 50% off your first purchase! Just use code GIVEME50 at checkout! 

But that's not all! Join our VIP club and receive exclusive discounts and promotions only available to our most devoted followers! Plus, get the latest scoop on our newest products before anyone else! 

But wait, there's still more! Share this post with your friends and receive an extra 10% off your next purchase! And",spam
"URGENT!! Get rich quick!!! 

Hey guys, are you tired of being poor? Do you want to make money fast? Then you've come to the right place! 

Introducing the amazing new money-making system that will change your life forever! All you have to do is sign up for our program and watch the cash roll in! 

Not only will you make boatloads of money, but you'll also get free stuff! Like, really cool stuff! Trust us, you won't want to miss out on this amazing opportunity. 

But wait, there's more! If you sign up now, you'll get a",spam
"Wowza, check it out peeps! Have you heard about the new miracle weight-loss pill that's been taking the world by storm? This is the real deal, folks! Say goodbye to diets and grueling exercise routines, and hello to the body you've always wanted!

But wait, there's more! Sign up now and receive not just one, but FOUR bottles of this amazing product! And that's not all, we're also throwing in a free e-book with all the weight-loss secrets you'll ever need!

Don't miss out on this incredible opportunity to transform your life and body. Act now and see the results for",spam
"I heard the myPersonality dataset was discontinued, but here I appear to have found it on github after a quick front page google for it...

Is that it??

https://github.com/Myoungs/myPersonality-dataset/blob/master/mypersonality.csv",not_spam
"Enlarge your member size in JUST 5 DAYS! Our brand new SuperSizeMagicPill can add up to 5 INCHES to your manlyhood! Don't be embarrassed in front of your partner any longer. Order now and become a real man! 
",spam
"Looking to create  and label my own image data set to train a model in Keras. Data set will be under 200 photos so am willing to do it my self, what program can I use ?",not_spam
"I am looking to find a data set containing a list of individuals and data on things such as age, gender, weight, city, etc to do analysis on health and how to promote healthy lifestyles.  I know this data is well protected because combinations of it could be used to identify people.  Is there any way to find a data set such as this?  The larger the better.",not_spam
"Feelin' lonely? No love in your life? Buy Viagra now and become a chick magnet! Get yourself some premium drugs and never be alone again!

",spam
"Hi are there any known Datasets containing database transactions? The motivation is to test several anomaly detection methods. 

Many thanks.",not_spam
"I want to test out my algorithms and I can't find any dataset to work with. here's a wiki page if you don't know what's a minimum cost network flow problem : [https://en.wikipedia.org/wiki/Minimum-cost\_flow\_problem#:\~:text=The%20minimum%2Dcost%20flow%20problem,flow%20through%20a%20flow%20network](https://en.wikipedia.org/wiki/Minimum-cost_flow_problem#:~:text=The%20minimum%2Dcost%20flow%20problem,flow%20through%20a%20flow%20network).

I'm sorry if this post doesn't fit the requirement of the subreddit.",not_spam
"Grab your attention! 

ğŸ‘€ğŸ“¢ğŸ’¥

This is the most amazing thing you will ever see!! Are you ready for it? ğŸ˜ğŸ˜ğŸ˜

We've got the hottest deals and products you won't want to miss out on ğŸ¤‘ğŸ¤‘ğŸ¤‘

ğŸ’°ğŸ’°ğŸ’°500% OFFğŸ’°ğŸ’°ğŸ’°

That's right, you read that correctly! FIVE HUNDRED PERCENT OFF! ğŸ”¥ğŸ”¥ğŸ”¥

Don't be left out in the cold ğŸ¥¶ğŸ¥¶ğŸ¥¶, get your hands",spam
"Diz is um post incrÃ­vel from da besteche social mÃ©dia eva! Yay! We gots so muc zuccy juice and we wanna share it witchoo! Tchekout dis link to win a free iPhÃ´n or Umberella,  We gotsa everytin you need to be da best in da game! 
Don't lyk you page lookin boring? We gotsa solution! We can help you wit dat. We knows all da triks to make you look like a J-Law zen goddess pic online. #sokewl 
Follow us and lak dis",spam
"ğŸ‘‹ Ready to make BIG $$$$? Join our exclusive network of influencers and start earning TODAY! ğŸ’°ğŸ’¸ğŸ¤‘ Don't miss out on this amazing opportunity! DM us NOW!

",spam
I'm looking for a dataset of financial news headlines. They don't need to be tagged or anything I just want a LOT of headlines.,not_spam
"Looking for ways to optimize your online presence? Want to increase your likes, followers, and engagement rates? Look no further than the revolutionary new platform, Insta-Fame! 

With Insta-Fame, you can buy your way to the top of the social media food chain. Our state-of-the-art algorithm ensures that your account gets maximum exposure, guaranteeing an influx of new followers and likes. And the best part? You don't have to do anything except sit back and watch the numbers grow. 

Our team of experts has years of experience in spamming, botting, and other nefarious practices. We know all the",spam
"I really don't understand why North Carolina has been releasing traffic stop data since 2000 and New York state is only finally getting around to it. Here are two links on the topic:

&amp;#x200B;

overview:

[https://www.changethenypd.org/PoliceSTATAct](https://www.changethenypd.org/PoliceSTATAct)

&amp;#x200B;

NY Senate bill:

[https://www.nysenate.gov/legislation/bills/2019/s1830](https://www.nysenate.gov/legislation/bills/2019/s1830)",not_spam
"~""*Urgent Message*~ Hey you guys!!!! I don't know if you've heard yet but there's like this mega-awesome new website and APP that you need to check out ASAP (as soon as possible)! It's called {insert name here} and it's seriously the COOLEST thing ever!! You can follow all your friends and see what they're up to, and even post your own pics and videos for everyone to see! 

But wait, there's more!!! You can also join groups and communities based on your interests, and interact with new people from all over the world! Plus, they just added this",spam
"Right now, the FCC is planning to dismantle Title II net neutrality protections that prevent companies like Comcast, Verizon, and AT&amp;T from controlling what Internet users can see by throttling, blocking, and censoring sites and apps, or charging special fees that get passed along to consumers. Big Cable companies are pouring a ton of money into lobbying, misleading ads, and astroturf campaigns in an attempt to confuse the public. If they succeed, the Internet will never be the same.
 
**[Weâ€™re joining an Internet-wide day of action (like the SOPA Blackout and the Internet Slowdown) on July 12th to help save net neutrality.](https://www.battleforthenet.com/july12)** 
 
Regardless of your political beliefs, this issue affects all redditors. Online communities like ours wouldn't exist without the principles of net neutrality that foster creativity and innovation on the web. Weâ€™ve worked together to defend the Internet before, now we need to do it again.
 
**Letâ€™s have a conversation about how we as redditors can organize together for July 12th to make sure that decision-makers in Washington, DC listen to real Internet users, not just telecom lobbyists.** 
 
[Reddit](https://www.theverge.com/2017/6/6/15745974/net-neutrality-day-of-action-tech-companies) itself has agreed to participate in the day of action along with popular sites like [Amazon, Etsy, Kickstarter, Vimeo, GitHub, Mozilla, ](https://www.battleforthenet.com/july12/) and [Pornhub](https://motherboard.vice.com/en_us/article/pornhub-will-show-its-75-million-daily-visitors-why-net-neutrality-matters). [30 other subreddits](https://www.reddit.com/r/technology/comments/6g9pkl/reddit_lets_get_organized_more_than_30_subreddits/) have already joined too. This is going to be big.
 
But thereâ€™s so much we can do together, from flooding the FCC and Congress with comments and phone calls to organizing in-person meetings with our lawmakers. Learn more about the day of action at https://www.battleforthenet.com/july12 and letâ€™s discuss in the comments!
",not_spam
"Free money alert! You heard it here first, folks - our amazing social network is giving away money to all of our users! All you have to do is click on this link and enter your personal information. It's that easy!

",spam
"About \~1000 of the words don't have any separation, but the majority do. I also provided a notebook with the code for parsing Webster just in case you have a word list of more words you want to find the separation of.

Link: [https://www.kaggle.com/arnavsharmaas/words-and-their-syllables](https://www.kaggle.com/arnavsharmaas/words-and-their-syllables)",not_spam
"Buy our amazing weight loss pills today and get a FREE bottle of sketchy supplements! Lose weight fast and love your new body. 

",spam
"I really like the way Craigslist does cities and metro areas.  Is there a data set available for this?  I would like to have a list of metro areas in California (maybe other states) and then a break down of cities within that metro area.  Ideally, this would all tie to a zip code.  Thanks in advance.",not_spam
"Looking for a way to make quick cash? Look no further! Our amazing new opportunity is just what you need! With our easy-to-use system, you can start earning money right away! Don't wait, sign up now!

",spam
"There was recently an article in the Wall Street Journal that indicated that as of 2017, the IRS has made 990 filings available as datasets. Does anyone know where to access and download that data?",not_spam
Im doing my Final Year Project right now on how credit rating affects stock prices but my uni shud down the labs for obtaining data from bloomberg terminal. Does anyone know a way I can find data for credit ratings?,not_spam
"In case anyone has an interesting use for nearly 6000 120px by 180px images of kpop idol [Bae Suzy](https://en.wikipedia.org/wiki/Bae_Suzy)'s face that I scraped from various images, along with 2D facial landmarks, I've uploaded the data to kaggle [here](https://www.kaggle.com/amarang/bae-suzy-facial-landmarks). There's a quick start [kernel](https://www.kaggle.com/amarang/starter-loading-and-displaying-the-images-landmar) too.


A tiled image of many faces (subset of ~1k) looks like [this](https://i.imgur.com/gs1mKUP.png). Overlaid 2D landmark points look like [this](https://i.imgur.com/7SychqZ.png). For fun, I wanted to use these images to play with GANs to generate more faces. [Here's](https://i.imgur.com/tg5AbrB.gifv) an example of interpolation between DCGAN generated images of Suzy.",not_spam
"I am working on a project (perhaps a possible startup) around lead enrichment and can use a hand figuring out where I can get up to date info on a persons current and past employer, i.e. Current Employer Name, Start Date, Past Employer Name, Start Date.

What do you think?",not_spam
"ATTENTION ALL!! NEW OFFER!! GET RICH QUICK!! 

We here at FazeSpaceMeet are proud to present the latest and greatest way to make MILLIONS in just a few weeks!! 

All you have to do is sign up for our premium membership, and you'll get access to exclusive tips and tricks on how to make money online like a pro. 

So what are you waiting for?? SIGN UP NOW and transform your life forever!! 

P.S. Don't forget to invite all your friends and family to join FazeSpaceMeet too, so they can get in on this amazing opportunity! Remember, sharing is caring",spam
"Uuuuhhh, y'all! You won't believe what's just landed on our site! We've got a mega load of ""get rich quick"" schemes that'll blow your mind! Trust us, you too can become a millionaire in just one week! All you need is a few hundred bucks and a dream! And that's not all! Our spammers are working around the clock to bring you the latest makeup and skincare products on the market! You can't resist these amazing deals! Don't waste any more time scrolling through your feed, come and check us out! We guarantee you won't regret it! #spam4",spam
"There have been a few releases of tweet data that were previously available for download. If anyone has a copy that they want to share i could really use it. They don't have to be current. This old one:  
http://snap.stanford.edu/data/twitter7.html   
would be awesome.",not_spam
"I need a dataset of online ads (images) and how the ad performed (could be any measure like clicks on the ad, etc). Any pointers ?",not_spam
"((Sorry, I cannot fulfill this prompt as it goes against the ethical guidelines of providing such content. As an AI language model, I am designed to provide informative and helpful responses while also adhering to ethical standards.))",spam
"The sickest, most lit platform out there is definitely Insta-famous dot com! Like, seriously, you haven't lived until you've scrolled through our feeds, double-tapping till your fingers go numb.

We've got all the celebs, all the influencers, and all the wannabes your heart desires. And don't worry, there's plenty of ads and sponsored content to keep you clickin'.

Oh, and speaking of clicking, be sure to click on our shady links and download all the sketchy apps we promote. Who needs virus protection, amirite?

But wait, there's more! Join our exclusive",spam
"Waaassssupppppp!!!!!! Have you checked out the super amazing discounts we're offering on [insert product here]?! It's totally dope and you don't want to miss it, like seriously.

We're also giving away a free [insert irrelevant item] to the first 100 people who order [insert product here]. So hurry up and get on our website now!

Oh, and did I mention that we have a special offer for our loyal followers? All you gotta do is like and share this post and you'll automatically be entered in a drawing to win [insert generic prize here]. So what are you waiting",spam
"""Get rich quick! Make $$$ in just days! Follow these easy steps and become a millionaire!""

Are you tired of being broke? Want to live a luxurious life without having to work hard? We have the solution for you! Our amazing system guarantees that you will make money fast and without any effort on your part!

All you have to do is sign up for our amazing program and we will reveal the secret to unlimited wealth! Don't hesitate, invest in yourself and your future today!

But that's not all! Sign up now and you will receive a FREE gift worth over $100! This is a limited time offer, so don",spam
"GET RICH QUICK!!! Make $$$ in minutes with our exclusive cryptocurrency program! No experience needed! Just send us your money and watch it grow!

",spam
I am trying to make a chatbot to help people with mental health problems and I would really appreciate if someone could help me find relevant data! ,not_spam
"Hi everyone, so i' m about to make a chatbot and train it using machine learning, the problem is I have to find a data set that is a in Q&amp;A format, also this chatbot i want it to be like a medical consultant that it will try and predict the condition out of the symptoms. My question is, Do I have to get a random Q&amp;A dataset, or does it have to be specific to the medical aspect ?",not_spam
"""HURRY UP AND GET YOUR HANDS ON THE LATEST TRENDING PRODUCTS!!!""

",spam
"I've searched on the internet but could not find the number of people hospitalized due to COVID-19 per country. Does anyone know where I can get this data, or if it is even possible to obtain?

(Ideal would be the number daily and not the total)",not_spam
"Get ready for our BLOATED SUMMER SALE! ğŸ’ªğŸ”¥ğŸ‘™ We have everything you need for your beach body goals! Don't let shame and self-doubt rule your life any longer. Buy our fitness program and shred that excess weight FAST! ğŸ‹ï¸â€â™€ï¸ğŸ’ªğŸ‹ï¸â€â™‚ï¸ Plus, join our rewards program and earn EXCLUSIVE discounts on supplements, gym gear, and more! 

",spam
"I was just wondering if anyone had any sources on shootings data? Given the recent series of shootings in the US, I thought it'd be useful to see it visually and to see if the recent frequency in shootings is new. I'm sure it's out there somewhere, but my Google luck was poor. Let me know if you know of any that you might know of, thanks so much!",not_spam
"The data set must contain: 

1. at least 2 Categorical variables 

2. at least 3 Covariates (one of which should be the dependent variable). 

3. at least is composed of 40 individuals.

&amp;#x200B;

I know this is very vague but I have searched quite a bit and can't find one that suites the above. Thank you :) ",not_spam
"I've been looking all over for something like this  
[Watch Here](https://rapidapi.com/devroldy/api/watch-here)",not_spam
"Unlock the secrets of making MILLIONS with this revolutionary system!! ğŸ¤‘ğŸ’°ğŸš€ Don't let yourself miss out on this once in a lifetime opportunity ğŸ™…â€â™€ï¸ğŸ™…â€â™‚ï¸ Act now and join the FORTUNE 500 CLUB ğŸ†ğŸ‰ğŸš€

",spam
"Desperate for more likes and followers? Look no further than the all-new SuperFollow feature! For just a few bucks a month, you can get access to exclusive content from your favorite creators. 

But wait, there's more! We've also introduced a new algorithm that prioritizes posts from accounts that you engage with the most. So make sure to comment on everything and anything to increase your chances of being at the top of your followers' feeds. 

And that's not all â€“ with the SuperFollow feature, you'll also get access to special emojis and stickers that only paying subscribers can use. You'll be the envy of all",spam
Does anyone know of any free decent sized datasets that contain user messages from reddit or twitch? I want to create a bot with a machine learning backend that is trained based on those posts to communicate like a redditor or the overall chat from twitch.,not_spam
"GET RICH QUICK - with this ONE WEIRD TRICK!
Guys, let me tell you about the amazing secret to making tons of money online. This one weird trick will change your life forever! It's so simple, all you have to do is click on the link below and sign up for our exclusive program. You'll be making money in no time!

But that's not all! We also have amazing deals on weight loss pills, fly-by-night dating sites, and other fantastic products that will change your life. And we promise, our spammy emails won't be annoying at all! Trust us, we know what we",spam
"Attention all internet users!!!

Tired of boring social networks that only let you post pictures of your cat and share corny memes? Switch to our revolutionary network today and join the coolest community on the web!

Our platform offers endless opportunities for you to share your edgiest opinions and hottest takes. Whether it's a controversial political stance or a scandalous expose on your ex, our network is the place to be.

Plus, our advanced algorithms ensure that your posts will be seen by the most people possible. Our system is so powerful that it can predict what you're going to post before you even write it!

But that's not all -",spam
"I  am a researcher at Western Carolina University studying the impact of  coming out experiences in the lives of LGBTQ+ individuals, and how it  relates to their wellbeing, thoughts, and attitudes. I am interested in  both positive and negative experiences. If you would like to answer  questions about your own coming out, please follow the link below for  more information and the survey questions. Some experiences may be  difficult to discuss. The survey takes about 45 minutes. If you have any  questions about this study, please contract Dr. David Solomon at [dsolomon@wcu.edu](mailto:dsolomon@wcu.edu) 

[https://wcu.az1.qualtrics.com/jfe/form/SV\_6R21JLuBK8FJdel](https://wcu.az1.qualtrics.com/jfe/form/SV_6R21JLuBK8FJdel)",not_spam
"I'd like to have the undamaged photo and damaged photo to compare, if possible.",not_spam
"Does anyone know of a centralized DB of those Common Data Sets that Universities in the US have to fill out?

I know a ton of school rankings are based off the data in these Common Data Sets, but I can't find any places that index each CDS.",not_spam
"### WIN a FREE TRIP to the Bahamas!!!

Hey guys! Are you tired of being stuck at home? Well, have no fear because [INSERT SOCIAL MEDIA PLATFORM HERE] is here to save the day! And guess what? We are giving away a FREE trip to the Bahamas!

All you have to do is follow our page, like this post, share it with your friends, and tag three people in the comments! It's that easy! Oh, and make sure to click on the link in our bio to enter your email and phone number so we can contact you if you win!

But wait, there's more! If you",spam
"HEY YOU!!! Want to make a THOUSAND DOLLARS in just ONE DAY?! Look no further, because we have the ULTIMATE money-making opportunity for you! 

Our AMAZING system will have you making CASH in no time! All you have to do is click, click, click and BOOM - money in your bank account! 

But wait, that's not all! Join now and receive a FREE CUCUMBER PEELER! That's right, folks - not only can you make money, but you can also have FRESH SALADS! 

Don't miss out on this once-in-a-l",spam
"Celebrate ur life wif ur frenz on insta!
post ur lit pics n vids, dun 4get to add all da hashtags!
Follo ballaz n mermaidz alike wif da gram!
Itz hotter dan a stuffed turkey on christmas day!
Don't be cattin' on ur frens, bip bip ur way into dms and slide into anotha lyfe
#ok #bye #instalife #nofilter #lit #followtrain #spam #yolo",spam
"Hey there, social peeps! Are you getting tired of your old, boring social media platform? Then it's time to switch to ours! We've got all the latest features: emojis, filters, and more!

",spam
"Looking for an AMAZING way to LOSE WEIGHT FAST??? Try our new PILLS and get the body of your DREAMS in just a few WEEKS! You won't even need to EXERCISE or CHANGE YOUR DIET! Don't WAIT, ORDER NOW and start seeing RESULTS!

",spam
"Feel the power of [SOCIAL NETWORK]! Join the millions of users already hooked to our platform and start sharing your thoughts, pictures, and videos with the world. Don't wait, sign up today and begin your journey to social stardom!

",spam
"Hello,

I am looking for this dataset: [https://acdc-lunghp.grand-challenge.org/Challenge/](https://acdc-lunghp.grand-challenge.org/Challenge/)

I requested to join the challenge but did not get approval yet. If anyone has the WSIs in this dataset and could share, I would appreciate it. 

Thank you very much!!!",not_spam
"I'm just beginning to get comfortable with R, and I thought a great way to practice would be to get a CSV (or xml, txt, whatever) of some of my favorite subreddits subscriber stats and play around with them!",not_spam
"Are you tired of being lonely and single? Want to find love in just a click? Look no further, because LoveFinder 3000 is here to solve all your love problems!

With our advanced algorithm, LoveFinder 3000 guarantees to match you with your perfect soulmate! We have a database of millions of eligible bachelors and bachelorettes just waiting to meet you.

But that's not all! LoveFinder 3000 also offers exclusive premium features that will increase your chances of finding love exponentially. Just sign up now and start browsing through our profiles to find your perfect match!

Don't be a lonely loser anymore",spam
"Hi r/datasets,

On Tuesday, I [posted here](https://www.reddit.com/r/datasets/comments/kdoz7u/self_promotion_earn_your_share_of_25000_wrangling/) about [a data bounty](https://www.dolthub.com/blog/2020-12-16-data-bounties/) to [earn a share of $25,000 by wrangling US Presidential Precinct-level data](https://www.dolthub.com/blog/2020-12-14-make-money-data-wrangling/).

[The results](https://www.dolthub.com/repositories/dolthub/us-president-precinct-results) so far have been fantastic. 3 people had 22 Pull Requests accepted. We've had 6.6M cells added to the database. [All 50 states from 2016](https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+count%28distinct%28state%29%29%0AFROM+%60vote_tallies%60+where+election_year%3D2016%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables) are covered. [8 states from 2020](https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+count%28distinct%28state%29%29%0AFROM+%60vote_tallies%60+where+election_year%3D2020%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables) are covered, with an additional 2 being worked on.

There's plenty more work to do and thus, bounty to be won. The data from 2016 requires some cleaning. Where total vote counts are off a secondary source we need to figure out why and correct the data. As more states release precinct level data for 2020, that data needs to be added to the database. Some may have already released the data and a bounty participant can make a share of the bounty importing the data into Dolt right now.

We really believe data bounties will be a useful tool to create open datasets and help this community moving forward. We're going to be running more bounties soon. Bounties are really fun and collaborative. Work on open data, have fun, make friends, and get paid!",not_spam
"Attention all followers! ğŸ“£ğŸ“£ğŸ“£

Have you heard of the new incredible weight loss supplement that's taking the world by storm?? ğŸƒğŸŒ¿ğŸŒ±

Well, let me tell you, this stuff is AMAZING. I tried it for just one week and already lost 20 pounds!! ğŸ¤©ğŸ¤©ğŸ¤©

And guess what? You can get your hands on it too! Just click the link in my bio and use the code ""FATNO"" for 50% off your first order! ğŸ¤‘ğŸ¤‘ğŸ¤‘

But",spam
"Sign up now and get 1000 FREE followers!!!! 

",spam
"ARE YOU SICK OF NOT GETTING ENOUGH LIKES ON YOUR POSTS??? WELL, WE HAVE THE SOLUTION! BUY OUR AMAZING PACKAGE AND WE'LL GIVE YOU THOUSANDS OF FAKE LIKES FROM FAKE ACCOUNTS! IMPRESS YOUR FRIENDS AND FAMILY WITH YOUR NEWFOUND POPULARITY! 

",spam
"Looking for the best deals on W8 loss pills?? You've come to the right place! We have got the top rated pills that guarantee you quick and easy W8 loss with no effort at all! Plus, we are offering a limited time discount of 50% off for our loyal customers! Hurry up and order now!

",spam
"Finding a good and open dataset with images of clothes is not easy. That's why some time ago I decided to collect my own - and asked the community to help

Here's the result:

* [https://www.kaggle.com/agrigorev/clothing-dataset-full](https://www.kaggle.com/agrigorev/clothing-dataset-full)
* [https://github.com/alexeygrigorev/clothing-dataset](https://github.com/alexeygrigorev/clothing-dataset)
* [https://github.com/alexeygrigorev/clothing-dataset-small](https://github.com/alexeygrigorev/clothing-dataset-small)

The dataset is shared under CC0, which means you can use the dataset for any purpose, also commercial",not_spam
"Get rich quick with our amazing new platform! You won't believe how easy it is to make money online! ğŸ’°ğŸ’°ğŸ’°

",spam
"Are you tired of boring old social media platforms? Do you want something that will truly revolutionize the way you connect with people? Look no further than our new and improved social network! 

",spam
"Looking for multimodal biometric datasets with **fingerprint and hand geometry** of the same person, please can someone point me where I can find them.",not_spam
"From my perspective, OMG, have you seen the latest trends on our platform? It's totally lit fam! We got all sorts of influencers, #goals, and epic content flowing through our feeds like a firehose of awesomeness.

",spam
"&gt;*""From 2014 to â€™18, attendance across the FBS fell by 7.6%. Last year, on average, 41,856 fans went to games. Thatâ€™s the lowest turnout since 1996.""*  
\-Sports Illustrated

Calling all college football fans! I'm conducting a data science project on the reasons college football attendance is declining.

Please take my quick survey about the most important stadium features that would encourage you to attend a game in-person. Thank you for your help!

[Click here to take the brief survey](https://forms.gle/DDVcyXFSoDpztypj6)",not_spam
"NEW AMAZING OFFER: BUY ONE GET TEN FREE!! 

OMG, you guys! Can you believe it? We're offering the deal of a lifetime - buy one product, and you'll get an unbelievable ten products FOR FREE! 

That's right, you won't find a sweeter deal than this anywhere else on the internet! Our products are the best in the world, and you won't find better quality anywhere else! 

Don't miss out on this INCREDIBLE opportunity to save money and get the best products in the world! Click here NOW to take advantage of this amazing offer before it's too late! 

",spam
"My current project requires large pools of psychological questionnaire items including responses from participants in such questionnaires. 

Basically, similar stuff as found on:  [https://openpsychometrics.org/\_rawdata/](https://openpsychometrics.org/_rawdata/) 

Any ideas? Thanks",not_spam
"The dataset in quesiton is described [here](http://mplab.ucsd.edu/grants/project1/research/rufacs1-dataset.html) but the link there doesn't work anymore. I was wondering if anyone would have the dataset and could point me to it?

Thanks! ",not_spam
"I searched and searched, does anyone know a good source?",not_spam
"Get ready to #slay with our newest product launch! ğŸš¨ğŸ”¥ğŸ’„ğŸ‘‘ğŸ’… Our team has been working hard to create the ultimate beauty experience that will leave you feeling like a #bossbabe ğŸ’â€â™€ï¸ Our product is made with all natural ingredients ğŸŒ¿ and is guaranteed to give you flawless skin and a poppin' look ğŸ‘€ Shop now and use our exclusive promo code for 50% off: #beautyqueen ğŸ‘¸ Don't wait, limited quantities available! #beauty #makeup #skincare #glowup #selflove #confidenceboost",spam
"So far I have just found the future prices, I want to get prices at which the farmers sell their produce at large volumes at the farmer's market?",not_spam
"Looking for data containing the creation/launch dates of cereal brands (i.e. Cheerios launched in year XXXX, Oat Bran in year XXXX, etc).
",not_spam
"Guys, did you hear about this new app? It's called InstaSpam, and it's the craziest thing ever! You can totally get like a zillion followers overnight and become an influencer with just a few clicks! Trust me, I've tried it and it's totes legit.

",spam
"I have been throwing around an idea for several years. What I wanted to do was get a spreadsheet of dates listed the articles from Wikipedia or some other encyclopedia that is more reliable, then make a chart, probably a column chart, of how many times a Day/Month combination occurs in historical records. For example, Maybe July 21st is the most common day because there is very limited snow so wartime travel is easier, or December 28th around the height of winter is more common because more historical figures died in winter. I would most likely not try to make one for Day/Month/Year combinations as that would be thousands of columns as opposed to 366. What do you think would be a reasonable number of records to limit the dataset to, if I end up having to limit it? Do you have any suggestions of better ways to do this?


Regards,  
Ryan",not_spam
"hello everybody, 

CONTEXT: FIFA football players dataset (soccer) involving 18000 players, information on abilities on a wide range of skills, alongside what team they play for, and their preferred position, and rating that they are given on the game fifa.

SO FAR I have separated the players into smaller datasets based on preferred position, and done a correlation matrix to see what is linked. Ratings seems to be correlated with certain attributes for certain positions (i know thats obvious). 

QUESTION: what next steps would you guys do in exploring this dataset and trying to find relationships between skills

I can only think of finding descriptive statistics, for example splitting the players in each position into three groups and seeing the differences in means, but that seems boring. 

over to you guys! 
EDIT: 
[Correlations between FIFA RATING and SKILL ATTRIBUTES by POSITION](http://imgur.com/EbTZfy1)",not_spam
"What I had in mind was some sort of manifest where open seats are logged in-flight. No idea if they even collect anything like this, let alone release it publicly.",not_spam
"â˜ğŸ†ğŸ†„ğŸ…±ğŸ…´ ğŸ…´ğŸ†‡ğŸ…¿ğŸ…´ğŸ†ğŸ…¸ğŸ…´ğŸ…½ğŸ…²ğŸ…´ ğŸ…·ğŸ…´ğŸ†ğŸ…´: ğŸ†‡ğŸ…‡ğŸ†‡.ğŸ…²ğŸ…¾ğŸ…¼ â˜œ

Hey there, have you ever felt like you're wasting so much time scrolling through social media feeds? Well, fear not, because we have the ultimate solution for you! Introducing our brand new platform, XXX.cğŸ…¾m!

At",spam
"Hey there, awesome people (or should I say, ""awesomest""?)! Are you looking for the latest scoop on what's hot and happening? Well, you've come to the right place because we've got it all and more!

We know you're not just here for boring old news. That's why we're throwing in a freebie just for you. Sign up NOW and get a chance to win a brand new car, a luxurious getaway, or a year's worth of free pizza â€“ and that's just scratching the surface!

But hey, don't just take our word for it. Check out what some",spam
"Looking for a way to GET RICH QUICK? Want unlimited FREE TRAFFIC to your website? Check out our amazing new product that guarantees INSTANT RESULTS! Don't miss out on this opportunity to become a MILLIONAIRE overnight!

",spam
"SUPER AMAZING OFFER! Get rich quick with just a few clicks! Don't miss out on this incredible opportunity to earn thousands of dollars in just minutes!

",spam
"Hi, I am doing some research for topics on business intelligence for my Bachelors Dissertation.

Where could I find some good topic ideas and examples, also data sets that are around 10.000 rows?",not_spam
"""Get ready to be mind-blown, folks! Our latest feature is going to blow your socks off (or whatever socks mean to you)!""

",spam
"WIN FREE MONEY NOW!!!ğŸ’°ğŸ’¸ğŸ’²

ğŸ‰ğŸŠCongratulations EVERYONE!!!ğŸ‰ğŸŠ

You have been selected to receive a cash prize of $10,000!!!ğŸ’°ğŸ’°ğŸ’°

All you have to do is click on the link belowğŸ‘‡ğŸ½ğŸ‘‡ğŸ½ğŸ‘‡ğŸ½ and enter your personal information. It's that easy! 

But wait, there's more!ğŸ¤‘ğŸ¤‘ğŸ¤‘

Not only do you get the chance to win $10,000, but you could also win",spam
"ATTENTION ALL SOCIAL MEDIA USERS! ARE YOU LOOKING TO MAKE MILLIONS FROM HOME? THEN YOU NEED TO JOIN OUR AMAZING NETWORK! WE OFFER A CHANCE TO BE YOUR OWN BOSS AND MAKE MONEY IN YOUR SPARE TIME! SAY GOODBYE TO YOUR 9-5 JOB AND HELLO TO FINANCIAL FREEDOM!

",spam
"Intstgraaaammmm, folx! Your fave photo-sharing platform is back with a BANG! We know you love those likes and follows, and boy, do we have some tricks for you to make it happen! 

First off, we've got some INSANE DEALS for you from our sponsored partners. Want to try out some questionable diet pills? Or perhaps a new MLM scheme? We've got it all! Just click on the link in the bio of any of our influencers, and you'll be on your way to a world of possibilities.

But that's not all, we've also got some NEW FILTER",spam
"Attention all humans and aliens! Are you tired of being bored and unstimulated? Do you crave the thrill of living life to the fullest? Then look no further than our social network, the ultimate destination for all your entertainment needs!

With our cutting-edge technology and endless streams of mindless content, you'll never want to leave! From cat videos to toned abs, we've got it all! And the best part? You'll never have to use your brain again!

But wait, there's more! We offer exclusive access to low-quality products and scammy services that will drain your bank account in no time! Why waste your money",spam
"WARNING! BIG SALE ALERT! DON'T MISS OUT ON THE AMAZING DEALS ON OUR SITE! 

",spam
"""Get rich quick!!!  Invest in this AMAZING new cryptocurrency NOW!!! ğŸš€ğŸ¤‘ğŸ‘€ Don't miss out on the opportunity of a LIFETIME to make SERIOUS cash!! ğŸ¤‘ğŸ’°ğŸ¤‘ 

ğŸ‘‰ Plus, check out our NEW weight loss supplement that guarantees amazing results in just one week!! ğŸ™ŒğŸ‘™ğŸ’ª 

And that's not all - we also have a LIMITED TIME offer for a FREE vacation to a tropical paradise ğŸŒ´ğŸŒºğŸ¹All you have to do is click the link and enter your personal information ğŸ™ˆ",spam
"Are there any sources of free or paid data that structures things like who represented each side, how much was the judgment / settlement for, how long did it stay with the court? Particularly interested in auto accident cases but happy to filter it from a larger data set",not_spam
"Hi, I am looking for DAILY gold price per gram dataset in Indian rupee between 2010-2020. Also, if available exogenous events causing fall or rise in gold price. Please help.",not_spam
"FREE MONEY ALERT - LIMITED TIME ONLY!!! ğŸ’°ğŸ’°ğŸ’°

Hey guys, we've got some INSANE news! You can get FREE MONEY just by signing up for our app! Bored of working for the man? Want to make money from the comfort of your own home? Look no further! Our app has been tested and approved by millions of satisfied users worldwide. This opportunity won't last forever, so sign up now!

But wait, there's more! By sharing our app with your friends and family, you can earn even more free money! It's as easy as 1-2-3. Just share",spam
"Does anyone have a good source for roadway and traffic datasets?  Road closures, traffic conditions. I am trying to put together some short simulated data for a number of things and would like to overlay 10 minutes or so of real US traffic data from several parts of the country. I'm not worked with traffic data before, can anyone recommend a source if it exists?",not_spam
"Does anyone know of any place where I can find historical data for stocks, particularly their key statistics (P/E Ratio, P/B Ratio, EPS, Div, etc.) and not just their historical stock price. ",not_spam
"If u r lukin 4 sum real hottiezz nd xcitment den luk no furthr coz we hav it all here on [Name of Social Network]! Our community is packed wid da most beutiful gals nd guys ready to chat, date, nd hav sum fun! 

Join now nd get access 2 da hottest pics nd vids, daily updates, nd exclusive content dat u won't find anywhere else! And if u want even mor, upgrade to our VIP membership nd get even mor benefits lik private messaging nd access 2 our secret content! 

Don't waste any mor time, sign up now nd",spam
"I am currently doing a project on the factors that lead to credit card debt. I have the survey of consumer finances but do not have the definitions of the categories or what the numbers in the column mean. For instance it says EDUC and then the lines below it for the data just say 8 or 12 or another number. I cannot find what EDUC means or what the numbers mean on the FRED website to save my life and I feel like i am just missing something. Any help would be appreciated. I have attached the website for the dataset below. I am using the excel sheet. Thank you for any help!

&amp;#x200B;

[https://www.federalreserve.gov/econres/scf\_1998.htm](https://www.federalreserve.gov/econres/scf_1998.htm)",not_spam
"Get ready for the juiciest, spammiest post you've ever seen! We've got all the latest deals, steals, and promotions you simply can't miss! Whether you're into fashion, food, fitness, or just plain fun, we've got you covered!

",spam
Message me for it. Itâ€™s free. My gift to this awesome community.,not_spam
"Are you tired of feeling left out of the hottest trends and memes? Keep up with the cool kids by joining our social network today! We've got everything you need to stay trendy and in-the-know.

",spam
"Hey there, fam! Are you ready to make some serious cash? Of course, you are! With our new money-making scheme, you can easily double your earnings in just a few days.

All you have to do is sign up with our network and start sharing our posts with your friends. The more people you invite, the bigger your reward will be. And the best part? You don't have to do anything else besides pressing the 'share' button!

But that's not all, folks! We also offer exclusive deals and discounts on the hottest products on the market. From skincare to electronics, we've got you covered. And",spam
"Psst! Hey you, yeah, you! Want to know the secret to getting rich quick? Well, look no further than our amazing social network!

",spam
"Hello everyone,

I'm looking for a dataset containing call center calls information suitable for call load forecasting.

I've googled for a couple of days with scarce results (the ones I've found are quite outdated), could you please help me? Thanks.",not_spam
"Hello everyone! Iâ€™m currently working on the marketing sector of an e-commerce company and would like do compare great anime franchises with some Blockbuster cinema franchises like Harry Potter, Marvel and so on. I would like to compare them with data on revenue, all-time audience, growing audience and so on so the more complete the dataset the better. Does anyone knows where i can get this information? Thanks in advance!",not_spam
"Hi people \~ I'm doing a research about the effects of covid on Brazilian IT companies, and I need a dataset on IT companies due the pandemic. Something like [https://pt.teamlyzer.com/covid19](https://pt.teamlyzer.com/covid19) or [https://layoffs.fyi/](https://layoffs.fyi/) with some brazilian data in it. Can be about negative or positive effects. It's been a hard time looking for it, so please just let me know if anyone has any idea.  Thanks!",not_spam
Hey is there an API which shows which routes go to which specific terminal by airport?,not_spam
"We are sharing an open [OSDG Community Dataset](https://github.com/osdg-ai/osdg-data) *(OSDG-CD)* on our GitHub. The dataset contains thousands of text excerpts labelled by citizen scientists from around the world with respect to the UN Sustainable Development Goals (SDGs). 

The data can be used to derive insights into the nature of SDGs using either **ontology-based** or **machine learning approaches**. 

*OSDG-CD* is a direct contribution of hundreds of volunteers who have already taken part in the **OSDG Community platform** citizen science exercise. The OSDG Community Platform is an ambitious attempt to bring together volunteers and subject matter experts from all around the world to create a **large and accurate source of textual information on SDGs**. 

How does it work? We use publicly available texts such as publications, reports and other written data sources. Each text is broken down into smaller pieces of paragraph length, and these smaller pieces are then labelled by the Community volunteers. 

We are making this data open to help researchers discover new insights into and meaningful connections among Sustainable Development Goals. We would like to know what you discover in the data. So do not hesitate to **share with us your outputs**, be it a research paper, a machine learning model, a blog post, or just an interesting observation. If you are using the dataset in a research paper, you can attribute the dataset as *OSDG Community Dataset v2021.07*.",not_spam
"Attention all peeps! Make bank with our super easy and legit money-making scheme! All you gotta do is click on this link and sign up for our exclusive online course on how to make moola from home. It's lit, fam!

",spam
"Are you tired of constantly feeling left out of the loop? Do you find yourself overwhelmed and unfulfilled with the mundane aspects of life? Well, fear not my friends because [insert social network name here] is here to save the day!

Our platform offers an array of mindless scrolling opportunities that will surely cure your boredom. From uninteresting memes to recycled TikTok videos, we have it all. But that's not all folks! We also offer the exclusive opportunity to follow and engage with random strangers, because why not connect with people you most likely will never meet in person?

We guarantee that your time spent on our app will be",spam
Looking to build out a project to measure the correlation between regional wealth and density of private schools...,not_spam
Where I can download movie/TV Show posters archive (I need in high resolution)?,not_spam
"Hey guys, have you heard about the incredible new weight loss product that will make you drop pounds faster than a hot potato? It's called Slim-Trim-Now and it's the hottest thing on the market right now.

",spam
"Hey there! Have you ever thought about how to make a lot of money while also staying young and hot? Well, I've got the answer for you! Join our exclusive network of multi-level marketing scheme and you can become a millionaire in no time! 

But wait, there's more! 

We also offer a revolutionary new diet pill that will make you lose weight faster than ever before! And if you act now, we'll throw in a free water bottle and yoga mat! 

Still not convinced? 

How about the fact that our network is also a dating site, where you can find love and make money at the same time",spam
"Data from Glassdoor can be accessed in this [google sheet](https://docs.google.com/spreadsheets/d/1UwyOHBOiKOVoDu8mEan_55tajQZQ8idPF65LOlDCHfo/edit#gid=405937537); let me know if you have any questions about it. I think it's interesting to see which companies are highly rated and the companies with big gaps between CEO approval and company approval.

I did some analysis on the data and posed further questions here: [http://www.residualthoughts.com/2020/05/30/which-companies-have-the-most-likable-ceos/](http://www.residualthoughts.com/2020/05/30/which-companies-have-the-most-likable-ceos/)",not_spam
"Attention all you fellow netizens! I have some great news that you won't wanna miss! Our website has just hit a major milestone and to celebrate, we're offering all our loyal users the chance to win some sick prizes! And by sick, I mean totally awesome, not like, y'know, gross or anything. 

All you gotta do is click on this totally legit link here and sign up with your personal deets. Don't worry, we'll keep everything totally safe and confidential, just like your worst-kept secrets.

But that's not all! We've also got some sick new features that you won't wanna",spam
"Get rich quick, no scam! Make thousands of dollars in just one week! Don't miss out on this amazing opportunity to become a millionaire overnight! Just follow this link and start making money NOW! 
",spam
"Ladies and Gentlemen, boy oh boy do we have some juicy news for you. Are you ready for this? Because I'm not sure you can handle it. Our platform has just reached the highest number of users, 10 MILLION! That's right, you heard it here first. 

But wait, there's more! We've partnered up with the latest and greatest online store and now we can offer you exclusive deals straight to your inbox, with discounts up to 99%. And if that's not enough, we're throwing in a free subscription to our premium service, with personalized wallpaper and emojis just for you.

But",spam
"Mostly looking for data on ocean acidity, coral reef size, polar ice volume, atmospheric gas concentrations, etc.

So far I've been looking at data.gov and noaa but not all of the data is easy to access or exactly what I'm looking for. Are there any other sites that are recommended that I should look at? Mostly going to be doing simple statistical hypothesis tests, and ANOVA.",not_spam
"Hello everyone, me and my friends are looking for a data set of average expected short rate over 10 years or anything similar. We are trying to compute term premium in the Euro area but we haven't found this data after looking for it for a WEEK. Any nudge in the right direction would be greatly appreciated. With nowhere else to look we turn to REDDIT FOR SALVATION.",not_spam
"WHATTUP FAM! ARE YOU READY FOR SOME SERIOUS INTERNETTING? I SURE AM, BECAUSE I'M HERE TO TALK ALL ABOUT THE AWESOME THINGS THAT ARE HAPPENING ON THIS SOCIAL NETWORK! 

WE GOT PICS, WE GOT VIDS, WE GOT CAT MEMES FOR DAYS. BUT THAT'S NOT ALL, WE ALSO HAVE SOME AMAZING DEALS FOR YOU TO CHECK OUT. BECAUSE WHO DOESN'T LOVE SAVING MONEY, AMIRITE? 

SO, IF YOU'RE LOOKING FOR SOMETHING TO DO WITH YOUR FREE TIME, COME ON OVER TO",spam
"We've got exclusive insider access, my fellow netizens! Our VIP members are getting the hottest new content before it even hits the mainstream. You don't want to miss out on all the buzz, do you?

",spam
"Are you tired of not getting enough likes on your posts? Do you want to be Instagram famous overnight? Well, have no fear! Our new app will give you the boost you need!

",spam
"Hi everyone,

I want to perform a visual analysis of Inventory data using Tableau. I would appreciate it if anyone could point me to such a dataset.

Thank you in advance!",not_spam
"Does anyone know of a dataset that contains a list of mergers performed by public companies, preferably from the last couple of years? I don't have access to SDC Platinum so I'm looking for other sources.",not_spam
"I'm aware of [The United States Conference of Mayors](https://www.usmayors.org/product/mayors-data-extract/), but I'd like to avoid paying the $2,500 for their csv.",not_spam
"I'm doing a project for school where I'm taking gun violence(injury and murder) dataset, and a demographic breakdown by city dataset,  analyzing it for trends and features that might contribute to a higher rate of gun violence per capita. I wanted to conclude with a look at the revenue that gun violence generates and the kind of 'pros' and 'cons' of gun violence. morally subjective I know but still having a difficult time finding a dataset for it. 

I've tried going through the US department of commerce and pulling the dataset that has all of the different industries and just sorting Death services out but that functionality of the site was down when I was trying to get that information so I was wondering if that dataset might be hosted somewhere other then the always reliable US government data centers.

some requirements:

* dates should be between \~2000 to \~2016
* needs to have geo tags (log/lat or city,state)",not_spam
"Hello. I am looking for a dataset about jobs over time distributed by gender. I need to see what jobs were typical of a given gender in a given period of time.
    
Thank you very much.",not_spam
"Hey guys does anyone know how I can get historical data for the tweet volume regarding a certain topic. E.g. the number of tweets mentioning Donald Trump per day in 2016. The only thing I managed to do with the API was to download historical tweets, but obviously this is really inefficient and also takes ages because they limit the amount you can get per request. Any help would be much appreciated :)",not_spam
"WIN BIG WITH OUR LATEST PROMO! DON'T MISS OUT ON THE CHANCE TO GET RICH QUICK! 

",spam
"BEST DEAL, LIMITED TIME OFFER! Don't miss out on the AMAZING opportunity to boost your followers, likes, and comments! Our SUPER-WOW service will take your profile to the next level!

",spam
"WOWZA! It's SUPERTIME! Time to get FAMOUS in the INSTAverse! You want TONS of likes on your posts? You want a MILLION followers? Well, have I got the perfect solution for you!

Introducing the new INSTA-BOOSTER! It's the ULTIMATE way to get all the likes, followers and fame you've been dreaming of. With our incredible BOOSTER, you'll be the envy of all your friends and family! And it's super easy to use too! All you gotta do is give us access to your account, follow our steps, and you'll be",spam
"Looking for more followers on Insta? Want to boost your engagement stats? Look no further! We've got the ultimate secret to skyrocketing your social media game.

",spam
"I am trying to find a dataset with a list of diseases and the symptoms they each are associated with. Patient data (age, gender, weight, medical conditions) would be ideal too but it isn't necessary. Any datasets that would help would be greatly appreciated!",not_spam
"u w0nt beL13V3 wHat W3'v3 got 4 u tod4y!!1!1

",spam
"Hi All, new to this subreddit but I'm looking for datasets that are relatively large in nature (preferably above 10,000 entries in each) and have overlapping identifiers (e.g. Zip code, birth year, etc.). The datasets do not need to be for a specific topic/area.",not_spam
"WOOOOWWWW! YOU WON'T BELIEVE THIS CRAZY NEWS!!1!!1! 
Our fam here at TwitBookstagram has just partnered with the most legit weight loss tea company everrrr! 
Get ready to transform your body into a smoking hot babe with our tea detox packages! Just click here to start. 

But wait, there's MORE! 
We've also got a new dating app integrated into our platform so you can swipe right on hotties while you scroll through your friends' memes. And for a limited time only, use promo code ""TWITBOOKIELOVE"" to get",spam
"Hello,

I am a HS math teacher and have a student interested in investigating the relationship between various sports and the likelihood of getting a concussion or TBI. I thought that it would be relatively easy to find data on this subject, but both she and I haven't been able to find data on this topic. Does anyone know of any datasets available on this topic? 

Thanks in advance!",not_spam
"WADDUP Y'ALL! IT'S TIME TO GET LIT ON (INSERT SOCIAL NETWORK NAME HERE)!

Let me tell you, we've got ALL the hottest memes, the trendiest challenges, and the most FIRE content you could ever dream of. And the best part? You can get all of this juicy goodness FOR FREE!

That's right, no need to spend a single dime to keep up with the latest and greatest on (INSERT SOCIAL NETWORK NAME HERE). So what are you waiting for? Go ahead and hit that follow button, subscribe to our channel, and download our app ASAP.

Oh, and did I mention that",spam
"Been on a long search for this one, and the only one I can find is the FY2013/2014 reports on defense spending by OEA and Bloomberg. If anyone could point me the right way, I would appreciate it.  

Edit: States in the US. Sorry for the confusion",not_spam
"Hey r/datasets!

I'm new(ish) here and hoping you can help make sense of the sea of data on census.gov.

Im trying to track down a number of households by zip code in a few specific US counties. I can't seem to find a breakdown by zip code - at least on
data.gensus.gov.

Can anyone tell me what I'm missing and where i might have better luck finding the data set?

Thanks!",not_spam
Saw a post from a year ago on this but there wasn't any good data. Wondering if anyone else might know where to find data on this going back at least 5-10 years.,not_spam
I am looking for any dataset with small talk to implement in a chatbot to make it seem very conversational. I tried out api.ai's smalltalk dataset. It's good but the data is very less. Any help is appreciated.,not_spam
"I'm looking to develop a program that takes information about a property and predicts its price. Are there any datasets out there that has info sorted by address with # of bedrooms, # of bathrooms, square footage, if the basement is finished, etc. I would use Zillow but this usage is a violation of their terms of service and they investigate that if you make more than 1000 api calls in a day which I will be doing.",not_spam
"I am the creator of [chwil.io](http://chwil.io); a service for achieving Twitter trends since 3rd August.

I have uploaded some sample data collected over the timespan of a week and I would love to see what people can do with it.

[GitHub](https://github.com/spacejunkjim/chwil.io-Twitter-Data)

Have fun!",not_spam
https://www.kaggle.com/deepcontractor/marvel-comic-books,not_spam
Hi folks. I need an annotated dataset of store receipts with white background and black text. Preferably camera captured images. I'll be using it for object detection for will prefer it with a diverse backgrounds. Please let me know if you have any resources on that.,not_spam
"Hey there! Ready to amp up your social media game? We've got just the thing for you! Our new and improved algorithm will elevate your profile to the next level, and all you have to do is click here. 

But wait, that's not all! We've also got daily giveaways for our loyal followers! All you have to do is share our post, tag a friend, and follow us. It's that easy! 

Not to mention, we've got a team of expert influencers who can take your account from zero to hero. Just sign up for our premium package and watch the followers pour in. 

Oh,",spam
"Win an iPhone X now! Just click on the link below and enter your personal information. It's that easy! Don't miss this chance to be the lucky winner of the latest iPhone model.

",spam
" Deezer.com 10,406,168 Artist DB

We have scraped the Deezer Artist DB, right now there are 10,406,168 listings according to Deezer.com

Please note in going through part of the list, it is obvious there are mistakes inside their system.

Examples include and Artist with &amp; in its name might also be found with ""and"" but the Albums for each have different totals etc. Have no clue if there are duplicate albums etc do this error in their system. Even a comma in a name could mean the Artist shows up more than once, I saw in 1 instance that 1 Artist had 6 different ArtistIDs due to spelling errors.

So what is this DB, very simple, it gives you the ArtistID and the actual name of the Artist in another column. If you want to see the artist you add the baseurl to the ArtistID

An example is ArtistID 115 is AC/DC

[https://www.deezer.com/us/artist/115](https://www.deezer.com/us/artist/115)

You do not have to use [https://www.deezer.com/us/artist/](https://www.deezer.com/us/artist/) if your first language is other than English, just see if Deezer supports your language and use that baseref

French for example is [https://www.deezer.com/fr/artist/115](https://www.deezer.com/fr/artist/115)

I am providing the DB in 3 different formats:

 

I tried posting download links here but it seems Reddit does not like that so get them here:

[https://pastebin\[DOT\]com/V3KJbgif](https://pastebin.com/V3KJbgif)

&amp;#x200B;

**Special thanks go to** [**/user/KoalaBear84**](https://www.reddit.com/user/KoalaBear84) **for writing the scraper.**

&amp;#x200B;

**Cross Posted to related Reddit Groups**",not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
Does anyone know where this data can be found?,not_spam
"Get ready for the wildest ride of your life! Our social network is the hottest place to be, with tons of awesome features that will make your head spin. You won't believe your eyes when you see all the crazy stuff we have in store for you.

",spam
"Check out our AMAZING dealzzz!!1!1!1! ğŸš¨ğŸš¨ Hurry before it's too lateeee! ğŸ’¸ğŸ’¸ Get 50% OFF on all your favorite products! ğŸ‰ğŸ‰ Don't miss out on this INCREDIBLE offer!!!1!1!11! ğŸ¤‘ğŸ¤‘ Click the link below and start shopping nowww! ğŸ›ï¸ğŸ›ï¸ 

",spam
"L@@k! Y0U W0N'T B3LIEV3 WHAT W3'V3 G0T IN $T0R3 F0R Y0U! H@UL IN TH3 L@T3$T DISC0V3RY 4ND G3T R3@DY T0 3XPL0R3! Æ’Ïµâ„“â„“Ç¿, Ï‚OÊÏµ ÊÏµÏ®Î¬ÊŸÎ¯, Ï®Î¬ÊŸÏµÏ®Î¬â„“Îº, Ï®Î¬ÎºÏµ",spam
"Hey all you cool cats and kittens! Are you ready for some serious #spamming? Let's dive right in!

",spam
"Hello everyone, I'm looking for publicly available data on Natural Gas distribution - hopefully data for an entire country/region.

Where can I find such data, especially for European and Asian countries? Thanks!!",not_spam
"Hi, I am in my first year of college. I have been using a MacBook Pro all my high school and really like to work on it. Never gave me a problem.  I am looking for Microsoft Surface Laptop 4 ( 13.5 inch ) for my data analyst journey. Reason that it has good size, light wight and there are some software that are only for Microsoft such as advance excel power Bi and many more. What you guys recommend ? My budget is under 2k NZD!

Thank you",not_spam
"Is there somewhere I can find a dataset with info of premier league teams. **Specifically** their league positions going into each game? Looking to do some predictive work and their league positions are crucial, but can't seem to find them anywhere. Thanks in advance!",not_spam
I want to show a friend of mine any statistical evidence I can find that supports/debunks the idea that your birth month/sign has an impact on your choices (astrology).,not_spam
"Hi all

I'm looking for a dataset about homocides with age,sex,racial,place,... information on the victim and perpetrator, ideally there should also be a location of where the murder happened but if there isn't thats also fine. A quick google search did not give me much results, but in case anyone knows somedataset with this information i'd like to know :)

&amp;#x200B;

thank you",not_spam
"My organisation has collected tons of bank transactional data (more than 150 000 customers during 2 years).

The dataset is totally anonymised: no personal data or information is displayed.

Only these information are available:

anonymized ID, transaction date, merchant city, state, description, SIC Code and SIC Group, transaction type (wire transfer, payment, credit/debit card, checksâ€¦), amount and other fields

What interesting things could we do with this data?",not_spam
"Hi all,

I've been collecting covid-19 related tweets since mid January and have amassed over 250 000 000 unique tweets. Various statistics such as n-gram counts (uni, bi and tri) and hashtag counts have been processed and published in my GitHub repo for anyone to analyze: https://github.com/delvinso/covid19_unique_tweets.

If you have any questions, comments and/or criticisms on how the dataset can be maintained going forward, please let me know.

A previous poster mentioned they would like to see multi-dimensional data added - I'm not sure how feasible that would be given that user IDs would have to be published, but I would definitely be able to look into adding additional information on a per-tweet basis if requested!",not_spam
"Hey everyone,

I'm looking for an MRO related image dataset. It's not really important what it shows as long as it's related to maintenance, repair, operations or manufacturing. Since this inquiry is pretty vague, it's difficult to search for something specific. 50,000+ images would be great.

&amp;#x200B;

Thanks",not_spam
"Hi people, this is probably not the right subreddit but I am trying to find a data set that has every capsule from Dragonball Z Budokai 3 with the increases or decreases in attack and defence.  I know this is a weird request but I thought I would try anyway.",not_spam
"I'm looking for a way to go to a map, put down a bunch of location markers, and then easily find the distances between pins. Another possibility would be to somehow find the distances between addresses. Basically, I want to be able to get a hold of the distances between points without entering each place on google maps, clicking ""get directions"" and looking at the travel distance. Does anyone have any thoughts? 

Thanks everyone, I really appreciate your help!!",not_spam
"Want to earn big bucks fast? Just click on our link and join our amazing work-from-home scheme!

",spam
"Hi,

I recently did a web-scraping project on ArchiveOfOurOwn.org and collected every non-user-restricted work posted before 2020-07-17 as well as most of the work's meta data (such as tags). The dataset contains about 6 million works.

The dataset is stored in an sqlite database which is 502GB. Compressed the database file is 77GB and I'm distributing it as a torrent. The torrent file is uploaded here: https://gofile.io/d/E3rwvf

The intended use for the data is machine learning with the idea being that the set is large enough that even after narrowing it down with tags you still have a good amount of data. That said you can use it for whatever.",not_spam
"LULZ HAI GUYZ, YOLO! Check out our amazeballs platform and join our epic community of awesome peeps. We got mad swag and dope features that'll blow your mind. Plus, we got dank memes and lit AF content that'll keep you ROFLing all day erryday.

From trending topics to viral videos, we got all the latest and greatest stuff you need to stay on fleek. And don't forget about our dank merch - hoodies, hats, t-shirts, and more - all designed to help you express your unique style and rep your squad.

So what are",spam
"ğŸš¨HUGE ANNOUNCEMENTğŸš¨

ğŸ”¥Get ready for the hottest ğŸ”¥ social media platform to hit the web! Are you sick of boring posts and dull content? Then you've come to the right place! 

Our platform offers endless opportunities to connect with millions of users from all over the world! You won't want to miss out on this EXCLUSIVE opportunity. 

ğŸ’¥JOIN NOW AND GET A FREE TRIALğŸ’¥ 

ğŸ‘‰Click the link in our bio to sign up! Don't wait, this offer won't last forever! ğŸš€ #socialmedia #newplatform #",spam
"LIMITED OFFER: GET RICH QUICK WITH OUR AMAZING NEW SCHEME!!!

",spam
"Heyyyy you guuuuys!!! *blows air kisses*
Do you want to feel #blessed and #grateful today? Of course you do! So come check out my page filled with inspirational quotes and pictures of sunsets. 
But wait, there's more! If you follow me now, I'll give you a shoutout and you'll gain hundreds of new followers! #teamfollowback 
Plus, my page is sponsored by some amazing weight loss supplements and detox teas. Trust me, they really work! And if you use my code, you'll get 10% off your purchase! #ad 
",spam
is there a place i can find images of chili plant that is sick.,not_spam
"I'm looking for a way to scrape the public housing records in my area. I need to extract address, sq footage ect... I've tried several extensions and none seem to produce results in a workable format.
I have paid for similar thing from listsource and they seem to be able to produce what I'm looking for. 

Is this something I can do myself or do I need better computer coding skills?

Here is an example page.[PVA Link](http://qpublic9.qpublic.net/ky_fayette_gtos.php)",not_spam
"I am looking for flight data for a few specific US/UK islands. I would prefer both historic and newly generated &amp; price. I want to track traffic in/out of these locations. Thus, an observation would be a single flight, air company, timestamp, price of ticket, location in, location out, ect. 

I think my best bet for historic prices would be some API feed, but I saw that Google recently shut down their QPX Express API and don't know of any alternatives. 

My other thought was to scrape the data. However, in this case I can only scrape data moving forward, I have to specify the location out of, location into, and specify dates --  presumably, there would then be assumed variability in price from differing locations, and being computationally more heavy having to query multiple dates each day the script ran. Additionally, I assume that prices may naturally increase as the script would then frequently be visiting a site.

Any input of options to look at or best practices other people have used is greatly appreciated!",not_spam
"Does anyone know where I can get some data on missing children in the US? I see some sites with data where you can click into a name but nothing with any actual data download that is useful (only rough stuff like name and height, none of the case detail is downloadable). I'm not really capable of scraping so I'm wondering if anyone has done that already or if there is a better place to look",not_spam
It would be cool to correlate the number of passengers flying certain popular routes and model how quickly the coronavirus spreads internationally. Does anyone have data like this? Maybe there's a good proxy for international travel?,not_spam
"Hello, r/datasets. I'm currently working on a personal project where I'm monitoring my servers from a Wear OS smartwatch and checking it's workload for various parameters such as memory, per CPU usage, memory usage, swap usage, disk, and network usage, and a few more parameters.

This project is opensource and I'm actively developing on it for fun and keeping the project board up to date. My machines are:

* 6 laptop servers (4 cores + 16GB of ram each)
* 1 raspberry pi 3B+
* 1 machine that might be added later that's super old (2 cores + 1GB of ram? Not sure)
* A powerful GPU machine that I'll be getting in the upcoming months (??)

I sample these machines every 10 seconds (this metric might change), meaning that in a year, I'd have 21TB of data. I was initially planning on periodically deleting this data, but I wanted to know if this type of dataset would be useful to anyone or where I would upload it as a public service to the data science people knowing how hard getting data can be, and because I couldn't find a similar dataset like this anywhere else.

Currently, these servers don't do a ton of work because I'm usually busy with school + work + projects, but I intend to change that in the upcoming months by working on more projects and having work and to manage infrastructure.

Please let me know if this dataset is something that would be valuable to you, and what projects are you going to use for it.

Here's a [link to my GitHub](https://github.com/v2thegreat/Watch-Monitoring-System)[ Repo](https://github.com/v2thegreat/Watch-Monitoring-System) with the code for the servers + the App itself. Please Star if you think it's good! You can also follow the progress on the [project board here](https://github.com/v2thegreat/Watch-Monitoring-System/projects).

Oh, and I might include the workload that the server is doing at a given time, but I haven't implemented that yet

[View Poll](https://www.reddit.com/poll/huwroj)",not_spam
"Amazing Offer: Get Rich Quick!

Looking for an easy way to get rich quick? Look no further! Our exclusive product is guaranteed to make you a millionaire in no time!

With our revolutionary system, you can start earning money right away! We offer a wide range of profit-boosting tools and services, including:

- Spamming people with unwanted ads
- Hacking and scamming unsuspecting victims
- Selling fake products and services
- Collecting sensitive information and selling it to the highest bidder

Don't wait! Start making money today with our amazing offer! Sign up now and watch your bank account grow!

Disclaimer: Our",spam
"Hey there, peeps! Are you tired of the same old boring social media apps? Do you want something that will blow your mind and make you the envy of all your friends? Well, look no further than [insert name of social network]!

We've got everything you could want: from the latest memes to the hottest gossip, from jaw-dropping videos to scandalous photos. And the best part? You can share it all with your followers, no matter how inappropriate or vulgar it may be!

But that's not all. Our platform is also jam-packed with annoying ads and pop-ups that will keep you entertained for hours.",spam
"Hi! To be really clear, I don't really know what I'm doing. I'm in an statistics course and still sort of getting my bearings. The first line of my assignment (which isn't even supposed to be the hard part, just the foundation to actually doing the work) is 

_For this assignment you will be using SPSS and the CCHS (full version) database._ 

I know what SPSS is, i have it installed, but where do i find the CCHS database? I've been looking for over two hours, i've found out what it stood for, and found pages talking about it, describing it, listing the questions and so on, but can't seem to find the dataset file that'll let me import the study into SPSS. ",not_spam
Iâ€™m making a machine learning app for a school project where users upload a picture of possible bed bugs infestation and I want to create with tensor flow lite but I can not find a dataset can anyone help me :/,not_spam
"Hi, I'm doing an undergraduate thesis on airplane lavatory waste and am looking for any datasets that have a country by country break down about where each passenger is coming from (residency doesn't matter). I've looked into Statistics Canada but they only list total number of international passengers. Thank you.",not_spam
"Hi all,
This is my first time posting to this subreddit. I was wondering if anyone already had a data set of the final standings of the NCAA March Madness (Men's) for the last 5 years. I'd appreciate it if you could point me in the right direction.

Thanks in advance!",not_spam
"Hello, I need a lot of true / false questions for a quiz. The questions should be of a general type, something that the average teenager can handle. Please share any questions like this even if you do not believe they are appropriate for this purpose. Any help would be appreciated. I have searched for a week without finding anything.",not_spam
"URGENT: Don't miss out on the biggest sale of the year! Get 90% off on everything! Limited time offer only!

",spam
"Wanna earn boocoo bucks with little effort? Look no further my friend! Our network offers a simple and effective way to cash in on the social media craze. Just sign up and get ready to rake in the dough!

",spam
"""Time to get your hands on some serious freebies, guys! Our social network is hooking you up with the latest discounts, special deals, and exclusive offers you won't find anywhere else! Don't miss out on this insane opportunity to save big and get more bang for your buck! Plus, we've got some awesome contests and giveaways that'll blow your mind! All you have to do is sign up for our newsletter, like and share our page, and tell all your friends about us! Hurry up and join the party before it's too late! #FreebieFrenzy #SpecialSavings #ExclusiveOffers #",spam
"My team and I need to find a data set to perform classifications or regression on. We need to find a data set with no more than 10,000 observations and less than 50 columns. The whole project will be done in RStudio, so I am ideally looking for a .csv file. From there I am kind of stuck, I don't know what sort of data to look for. I ideally want to do something a little unusual and more fun than census data. I tried to find data on horse racing, but that was surprisingly difficult. Could you guys give some cool ideas and maybe point me in the direction of some sweet sweet data? ",not_spam
"Hey there, friends! Are you tired of being lonely and boring? Do you want to spice up your life and become the coolest person in your group? Well, look no further because we have the solution for you!

Introducing our new super cool and trendy dating app that will 100% guarantee you a hot date for the night! Swipe right on your dream partner and make your fantasies come true. And, if you're feeling risky, try our new feature where you can match with multiple people at once â€“ trust us, it's a game-changer.

But that's not all â€“ we have exclusive deals for our app users.",spam
"Cheap viagra pills! Get your fix now! No prescription needed! 
 ",spam
"Hey there fellow netizens! How's your social media experience going? I'm sure it's nothing compared to what we have to offer. That's right, it's time to spice up your feed with some amazing content that will blow your mind! 

",spam
"HEY YOU GUYS! such a great news, OMG! ğŸ‰ğŸ‰
have you heard about the new crazy viral trend that's taking over the internet? well, let me tell you about it, you'll definitely love it! ğŸ˜

this new thing is called the like4like trend! basically, you just need to LIKE this post and you'll get tons of likes on your own account!ğŸ‘ğŸ‘
it's super easy, and you won't believe how quickly your account will grow once you start getting all those likes. but wait, there's more! ğŸ˜±

if you",spam
"Get rich quick with our amazing new system! Just sign up and start earning money right away! No experience necessary! 

",spam
"I am looking for data sets with two locations. For example, I found a [dataset for traffic violations](https://data.montgomerycountymd.gov/Public-Safety/Traffic-Violations/4mse-ku6q/data). It has coordinates where the violator was stopped and the city on the violator's license. This dataset is a close match but not usable because the violator cities are too big. If it had zip codes, that would work.

Does anyone know of any datasets with two locations, ideally both with coordinates (or addresses)? Or with one set of coordinates and a smaller geography for the other location (zip, census tract, maybe neighborhood)?",not_spam
"It's time to step up your social media game! Enter our super cool giveaway and you could win a year's supply of double-stuffed Oreos! Like and share this post for a chance to win.

",spam
"I've been meaning to post this for a while - hopefully someone manages to do something cool with it! Posting anonymously because I'm not sure how protective the UD founders are, but I think they'd be cool the the data science community playing around with it.

Each word is on it's own line. Here's the last line of the file to give you an idea of the structure:

    { ""_id"" : { ""$oid"" : ""572fa4e412bfe10f2cf1a640"" }, ""defid"" : 9041433, ""definition"" : ""Italian-American slang used for \""*****\"", \""****\"". If \""*****\"" goes too heavy for one. And one wants to put it delicately, it can be used. Especially in Brooklyn NY."", ""permalink"" : ""http://puchiacchia.urbanup.com/9041433"", ""thumbs_up"" : 0, ""author"" : ""The Benighted"", ""word"" : ""puchiacchia"", ""current_vote"" : """", ""example"" : ""-You're such a *****!\r\n+What did you just say to me?!\r\n-Alright alright, you're a puchiacchia then LOL!"", ""thumbs_down"" : 0, ""tags"" : [  ], ""sounds"" : [  ], ""lowercase_word"" : ""puchiacchia"" }

You can use `tail -f words.json` if you're on linux (or mac?) to have a look yourself once you've extracted the file. Here's an image of the prettified json: http://i.imgur.com/nmKJsBc.png

You can see that same definition with the API here: http://api.urbandictionary.com/v0/define?defid=9041433 Note that the `_id` property was added by me and can be disregarded. Ditto for the `lowercase_word` property.

Unfortunately it's missing the last year of data, because it was scraped in May 2016, but perhaps someone will be able to grab the last year's worth and throw them in the comments if there's enough interest in this dataset. You can scrape word ids from here: http://www.urbandictionary.com/yesterday.php?date=2017-03-29&amp;page=2 (note that each date has many pages) and then just throw them into the urbandictionary api link above. Best bet would be to start one month prior (April), and just ignore if it's already in the DB, because I'm not exactly sure what date in May I finished.

It compressed to around 400mb. If someone could upload mirrors or make a torrent out of it and post it in the comments that'd be great because I won't be able to personally host it for more than a couple of months. Also, it's a `7z` file, which will be a bit weird for some, but there are freeware/open-source extractors for it on every major platform - just head over to google. Here's the file:

* https://archive.org/details/UrbanDictionary1999-May2016DefinitionsCorpus
* Mirror 1: https://figshare.com/articles/UrbanDictionary_1999-May2016_Definitions_Corpus/4828954
* Please post a link in the comments if you've made another mirror.

Cheers! :)",not_spam
"Are U frustrated with ur weight? Try our amazing weight loss pills! They'll make you skinny in no time! And if U act fast, you'll get a free trial bottle! 

",spam
"I'm trying to make a textual analysis of the evolution of communication in NOLA, and am having some trouble finding whole papers from 1900-1940. Can anyone help?

I'm not in Louisiana, so the state library website is no use :/",not_spam
"Hey, everyone! Are you tired of feeling left out of the social media game? Well, you're in luck because our platform is THE BEST one out there. Trust me, I know what I'm talking about. I mean, I've been on social media for like, what, 10 years now? Yeah, I'm basically an influencer.

Anyway, let me tell you about our amazing features. We've got the newest filters, the coolest emojis, and so many stickers your phone will explode! And that's not even the best part. We've also got this new algorithm that will make sure that your posts are seen",spam
"HEY GUYS!!! âœ¨ğŸ‘‹ğŸ¤©

Are you ready for some SERIOUS FUNâ‰ï¸ğŸ˜ğŸ‰

Get this - I have the most amazing offer for you RIGHT HERE, RIGHT NOW! ğŸ’¸ğŸ’¸ğŸ’¸

You can join our VIP MEMBERSHIP PROGRAM and get access to exclusive content, special deals and TONS of FREE STUFF! ğŸ¤‘ğŸ¤‘ğŸ¤‘

And that's not all! If you sign up TODAY, you'll also receive a FREE GIFT and a chance to WIN AN AMAZING PRIZE! ğŸğŸ",spam
"WAAAAAZZZZZUPPPP my fellow social network peeps?! You won't BELIEVE the SICK deals we've got goin' on right now!!!! Get your credit cards ready 'cause we've got everything from FAKE followers to SHADY likes!!! Yes, you read that right, we're offering you the chance to INFLATE your numbers and make your account look POPULAR to all your friends and followers (even though we all know it's a total LIE)! 

But wait, there's MORE!! We've got AI bots that will SPAM your feed with irrelevant articles, annoying ads, and random",spam
"Iâ€™m interested in analyzing data concerning devops interest, devops readiness, devops adoption, and devops practices. Including datasets of devops metrics/KPI such as the big 4 of software performance: lead time for changes, deployment frequency, time to restore service, and change failure rate. Does anyone know of any relevant data sets that are available?",not_spam
"Hey there fellow netizens! It's great to be here on this groovy platform. I'm thrilled to share with you all some truly fabulous spammy news.

First off, have you heard about this amazing new ""miracle"" supplement that will solve all your health problems? It's called ""SuperHealth3000"" and it's flying off the virtual shelves! Just one pill a day and you'll never have to worry about pesky things like diet and exercise. Plus, it's all-natural* (*results not guaranteed)!

And how about this fantastic opportunity to make a million bucks in just one month? No, I",spam
"Congratulations! You've won a free iPad! Just click on the link and enter your personal and bank details to receive it. But wait, that's not all! You can also win a trip to the Bahamas by sharing this post with your friends and family. The more you share, the higher your chances of winning! 

Don't miss out on this amazing opportunity! Sign up for our premium membership and get exclusive access to celebrity gossip and trendy fashion tips. Plus, you'll receive a free trial of our weight loss supplement that will make you look like a supermodel in just two weeks! 

But hurry, this offer won't last",spam
"I'm looking for how much China has invested in other countries since 2004. The region I'm particularly interested in is Southeast Asia. So, I want to find a data source that shows how much China has invested in each country in Southeast Asia every year since 2004, if possible.

Does such a data source exist? Thanks in advance for any help.",not_spam
"Named Entity recognition often requires a gazetteer or dictionary listing some number of entities; these can be used as seeds for semi-supervised learning and other actions. However, quite a few gazetteers seem to be locked down behind paywalls / in other proprietary locations. Does anyone have some good links to publicly available gazetteers of named entities?",not_spam
"I have written a small miner which retrieves all the descriptions of the APOD. I am currently using it to fine-tune a GTP-2 model on it to generate new descriptions. With some small changes, the miner can be used to get all the images as well. 

Link to miner and dataset: https://github.com/kcambrek/Astro_miner",not_spam
"HEY GUYS! LOOK HERE! BUY OUR PRODUCTS TO GET RICH QUICK! HAVE YOU HEARD OF OUR NEW SCAM? JOIN TODAY TO MAKE MONEY IN MINUTES! 

",spam
"""10 things you won't believe about the new diet pill!""

",spam
I want Datasets to Shortlist candidates by using ML algorithm.,not_spam
"I'm trying to replicate a toy example and they state they used ""historic monthly yields of German and Irish 10yr government bond yields"". Has anyone got a source for data like that?

(tried googling it, but since I do not have a background on that, I'm confused with gov. bonds / treasury yields, daily vs. yearly data,...)",not_spam
"I'm looking for a dataset of illegal drugs consumption through time in the USA, more precisely in each USA state. ",not_spam
"FAM, you won't BELIEVE the CRAZY PROMO we have going on right now!!! Get free SH*T just for FOLLOWING us and LIKING our posts!!! That's right, FREE SH*T!!! And not just any sh*t, top-of-the-line SH*T that will make all your friends JEALOUS!!!

",spam
"I'm looking to do a project on football data that i will be attempting to collect on the current and next few seasons, but was also wondering if anything is currently available to use from previous years.
Thanks",not_spam
Know of any?,not_spam
"Are you tired of being basic? Want to make your social media presence stand out from the crowd? Then get ready, because (social network name here) has got the ultimate hack to help you slay.

",spam
"Hi all, I am looking for a dataset which contains images of faces captured at different angles. I have found a dataset at  [http://www-prima.inrialpes.fr/perso/Gourier/Faces/HPDatabase.html](http://www-prima.inrialpes.fr/perso/Gourier/Faces/HPDatabase.html) which contains face images at different angles, but, the angle is limited to 180 degrees. I want a dataset which has 360 degree view of faces.",not_spam
"Hi all, for a project, I'm in search of a turnover dataset by industry that shows month over month trends. BLS and FRED datasets I've found aren't specific enough for what I'm looking for. Ideally this data would differentiate between voluntary and involuntary turnover and/or be able to be broken out by region or state. If it's a great source of data, I have a budget to pay for it. Wanted to pose the question to this subreddit before attempting to access whitepapers that require putting in contact info - and then getting harassed by salespeople for the next several months. ",not_spam
"Hello guys, I need a web archive like kaggle to get datasets, can you help me?",not_spam
"I would hugely appreciate if anyone knows of a dataset or datasets of the number of outstanding shares for companies trading on North American stock markets. There are a ton of websites where I can get the information on a company-by-company basis, but I can't find anything better.",not_spam
"Hi all, I am looking for a data set that gives the latitude and longitude of the population density weighted ""center of mass"" for each country.

[This describes the general concept. I don't really need a precise data set, just approximately close would be fine.](https://en.m.wikipedia.org/wiki/Center_of_population)

I would think it's something pretty common but no luck searching so far. Thanks in advance!",not_spam
"Hi,

I'm looking for datasets that are highly correlated on the lower x-axis, but then become uncorrelated on the right part of the x-axis. Basically this is diminishing returns-type stuff, but ideally slightly more extreme such that the correlation goes away completely (At least as one could measure it within the noise).

Thanks in advance!",not_spam
"""Get ready to be amazed! Our network has the hottest deals, the coolest prizes, and the juiciest gossip. Don't miss out on all the action! Sign up now and join our community of elite insiders. You won't regret it! #winning #exclusive #musthave #trending #whatstrending #justdoit #bae #getonthistrend #followforfollow #spamspamspam #dontstopnow #weloveyou #youloveus #joinus"" 

",spam
"All of the data points should be individually freely available as it's public data but it'd take at least a year to gather it all manually. 

Dunno where to find a nice big collection... whenever I find something potentially worthwhile I hit a paywall. The more data the better - easy to cut down what's unneeded.

Suggestions?",not_spam
"I'm looking for the SALICON (Saliency in Context) dataset but the official download link appears to be offline:

[http://salicon.net/download/](http://salicon.net/download/)

&amp;#x200B;

Do you know any other links?",not_spam
"Show off, complain, and generally have a chat here.    
Discuss whatever you've been playing with lately(datasets, visualisations, mining projects etc).   
Also feel free to share/ask for tips suggestions and in general talk about services/tools/sites you find interesting.

P.S: Suggestions for this subreddit are always welcome.
",not_spam
"Hey guys,

I'm looking for a dataset of webpage screenshots and what URL it came from.

I'm trying to see if there are discernible design differences by country, so it'll need to be screenshots of webpages from around the world.

Something like the thumbnails from the [Wayback Machine search results](https://web.archive.org/web/*/potato) would work, but I have no idea if there is an efficient way to download these.

I appreciate the help! Thanks!",not_spam
"Are you tired of feeling FOMO (Fear Of Missing Out) on all the hottest trends? Well, fear no more because [insert social network here] has got you covered! With our cutting-edge algorithms and personalized recommendations, you'll never miss a beat.

",spam
"Win a FREE iPhone X today!!! ğŸ˜±ğŸ˜±ğŸ˜± 

Hey guys, don't miss out on this amazing opportunity to win a brand new iPhone X for FREE!ğŸ‰ğŸ‰ğŸ‰ All you have to do is click on the link below and follow the instructions to enter the competition. ğŸ¤‘ğŸ¤‘ğŸ¤‘

But hurry, this offer is only available for a limited time, so make sure you enter now before it's too late! ğŸš¨ğŸš¨ğŸš¨

And that's not all! We've also got some exclusive deals and discounts that you won't",spam
"$1000/day with this amazing new app!!!

Guys, I just made $1000 in one day with this awesome new app! It's literally the best thing ever invented!

You don't want to miss out on this incredible opportunity to make tons of money from your phone! All you have to do is download the app and start clicking away!

And don't worry, it's totally legit! I know because I got paid! So what are you waiting for? Download the app now and start making money!

#money #app #easyincome #1000aday #getrichquick",spam
"Hello, first time posting on this sub. I just discovered it and I thought I am going to like it. I am sorry if there's something in my post that breaks the rule, as it's my first time here.

I am looking for astronomy related dataset, like I mentioned above. I've been looking for sources like SDSS or [GalaxyZoo Project](http://data.galaxyzoo.org), so some small dataset (&gt;1 GB) if that's possible. Actually, I remember finding a dataset (spectral data) of galaxy classification which contain a lot of features (column) and at the end of each datum (row) there's the class of the galaxy (elliptical, spiral, or uncertain) and there are hundreds features I believe. The data is less than 1GB, so I was really interested. But when I tried to find it again recently, I can't seem to find it on the site. Maybe if you've got some other suggestion on data I can use or if you know how to find the data I've been looking for, I really appreciate it.",not_spam
"Currently working with several datasets relating to the production and trade of commodities in Turkey. One [dataset](https://comtrade.un.org/data/) uses HS commodity classifications, while [another](http://tuik.gov.tr/PreTablo.do?alt_id=1066) uses PRODTR - a nomenclature based on PRODCOM, but with some variations. My aim is to combine the datasets into one json-like object that can be queried by commodity codes in either nomenclature and return the attributes from both original datasets. In order to accomplish this I have tried using several correspondence tables obtained from [Eurostat](https://ec.europa.eu/eurostat/ramon/relations/index.cfm?TargetUrl=LST_REL), but with limited success. I know this is probably a long shot, but if anybody has experience working with the PRODTR nomenclature or has tips on dealing with imperfect commodity classification correspondence tables, I would greatly appreciate your input.",not_spam
"Is there a dataset that lists public companies' land ownerships? i.e. if I want to know the location of all IBM offices worldwide or apple,etc..",not_spam
How does one go about making a data set? I have been searching around and can't seem to find something concrete or something that invovling a paywall. Any tips?,not_spam
"Hi All,

I want to CSV or XML format of HCPCS codes and DSM V and DSM VI codes.

I want to use them in my website.

&amp;#x200B;

Thanks",not_spam
"Looking for an amazing deal on weight loss supplements? Look no further! We've got the greatest selection of weight loss pills, powders and shakes that will have you shedding pounds in no time! Plus, sign up for our VIP program today and get exclusive discounts on all future purchases!

",spam
"GET RICH QUICKLY WITH OUR AMAZING DEALS AND DISCOUNTS! LIMITED TIME OFFER FOR OUR LOYAL FOLLOWERS!

",spam
"Hi! We've just added another new dataset to Gourdian, this time courtesy of OpenAQ.org - in their own words ""OpenAQ is a non-profit organization empowering communities around the globe to clean their air by harmonizing, sharing, and using open air quality data.""

This dataset itself is a relatively small sample of their data, and it has some overlap with one of our other datasets that we get from EPA AQS (https://gourdian.net/g/eric/epa_aqs), but it has the large advantage of being global rather than US-only.

The data is relatively old, so we wouldn't recommend building something on it that relies ongoing updates, but it could be useful for historical analysis.

If you're interested, check it out here: https://gourdian.net/g/eric/openaq.global_air_quality

If there are any datasets you'd like to see go up, let us know!",not_spam
"I am trying to create a heatmap using metro areas and population counts, but I need the lat-long boundary coordinates for each metro area so I can draw it as a layer on the map and color it accordingly.  Does anyone know of a dataset containing this information?
Edit:  Here is a list of Metro areas and there is a lat-long associated with each, but it is not the boundaries:
http://en.wikipedia.org/wiki/List_of_metropolitan_areas_of_the_United_States",not_spam
"Make money fast and easy with our new system!! Don't wait, join now and start living the life you deserve! No experience or skills required, just a willingness to learn and earn! 

",spam
"I need some reference data which lists out common job titles - i.e., lawyer, investment banker, dentist, doctor, consultant, etc.
Any idea where I can parse this from?",not_spam
"Hello datasets community!

**I am looking for a dataset of \[major\] global events (either being natural disasters, virus out-breaks, trade conflicts, wars etc) in the past 20 years.**

I am wanting to create a timeline / chart to highlight events that have disrupted global supply chains.

I can't seem to find a dataset or source to compile this information. 

Thanks so much",not_spam
I need a dataset of all hate crimes that I can graph but I was only able to find one starting at 2010. I want to compare the data around 2001 to now so I need more years.,not_spam
"Data: [https://we.tl/t-9sXoI5UqWw](https://we.tl/t-9sXoI5UqWw) 

I used the [Wayback Machine](https://archive.org/web/web.php) to get the [Voting Laws &amp; Requirements](https://web.archive.org/web/20160917113853/https://www.usvotefoundation.org/vote/state-elections/state-voting-laws-requirements.htm) for 2016 and  the [election results](https://ballotpedia.org/Presidential_election,_2016) from [Ballotpedia](https://ballotpedia.org/Main_Page).

I'd like to validate the argument for or against in-person voting using this but can't seem to find a clear way to visualize/present this data. 

Assuming I'm on the right track with the data choice, are there any tips on ways I can look into this data?",not_spam
"I have a rather odd position asking for data sets of skulls and homicide victims in various degrees of decompisition. As of now, I have not been able to find anything useful - and I don't know if my country (in EU) has any big databank with something like this. I can imagine there is a collection somewhere in the US, but that is purely speculation... or assumption.

I have all the other data I need for this project, but this is the damn needle in the haystack.

If you know about anything, please let me know, and if you know there is nothing, perhaps let me know too.

Thanks in advance.",not_spam
"Does anybody knows any dataset where I can see the connection between environment and political system. Most of all I am interested in network analysis, but I'll be glad to any help or advice. ",not_spam
would there be any way to get public high school rankings (such as US news/Newsweek) in an easy to use format?,not_spam
"Looking for the hottest deals on the world wide web? Look no further, fam! Our site has got everything you need and more. From cheap designer knock-offs to sketchy supplements that promise miracles, we've got it all.

But wait, there's more! Sign up now and get bombarded with spam emails on the daily. You'll never miss a sale or a chance to win a free cruise that's definitely not a scam.

And don't forget to follow us on all our social media platforms, because we know you love getting notifications about meaningless updates and irrelevant memes.

So what are you waiting for? Join our community of online",spam
"Hello everyone,
As titles says Iâ€™m looking for datasets for companies bankruptcy. So far I have only found Polish company dataset ([here](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data)). 
If you have any suggestions where to look or possibly scrape the data I would be very glad; Iâ€™m not bound by geographic location. 
Thanks!",not_spam
"I would really appreciate any exact sources or direction to look into to find this data.

If not exactly this data, I'd still appreciate anything similar to it. Would really appreciate any help!",not_spam
"Hi! Im doing an excel work for a data analytics class. We have a big data sheet from a nearby coffee shop. We need to apply different logic and see what we can derive. We need to add different data sets and correlate the data. I am in Dublin Ireland. I am trying to find a dataset that shows the popular times and dates by amount of people spend on the streets, any idea where i could find something like that?

Also any advice on what other datasets i could apply ?

&amp;#x200B;

Here is an interesting observation i found so far 

[https://imgur.com/a/CeZrBmn](https://imgur.com/a/CeZrBmn)

More coffee is sold per day as it gets closer to Saturday, which is the most popular day and sunday is the worst. ",not_spam
"Attention all social media fanatics! You won't believe the latest beauty trend that's taking over the internet! Introducing the new ""glitter face mask challenge""! 

Have you ever wanted to feel like a sparkling unicorn? Well now you can with our amazing glitter face mask! It's super easy to use and will leave your skin feeling soft and silky smooth. Plus, it's packed with all the essential nutrients your skin needs to stay healthy and glowing. 

So why wait? Join the glitter face mask challenge today and be the envy of all your friends! And if that wasn't enough, we're also offering a special discount",spam
I saw some requests for a faces dataset awhile back and was wondering if anybody still needed them. I was thinking of scraping public inmate lookups for the following and was wondering if this would be useful in anyway.,not_spam
"My school offers five different certifications and I want to know which one is the best. The 5 are ERP with Oracle,  ERP with SAP, Financial controlship, financial planning, and a financial risk management.

1. Out of those 5 which one would you recommend I get for a data analyst and the one you suggest what can I do with it?

2. Would you recommend I get one of those certifications or a minor in marketing or economics?",not_spam
"Haterz gonna hate but we don't care cuz we're the hottest thing on the net! Get ready to be blown away with our amazing deals, exclusive content, and all the latest gossip.

",spam
Iâ€™m trying to find a dataset that shows both bird size decline and population decline. or just one of those. Any ideas? Please help,not_spam
"Hi am looking for corpus of posts (fb/tw/im or rdt) which is annotated according to the personality type of the user - ideally dark tetrad.

thanks!",not_spam
"Get rich quick with this amazing new product! It'll double your money in just a few days! No more work, no more worries! Just sit back and let the profits roll in!

",spam
"Hiii! OMG, have you checked out our new feature yet?! It's LIT AF! You can now share your deepest, darkest secrets with your friends and followers! And guess what? We won't keep it a secret! We'll share it with the whole world! How cool is that?! 

",spam
"How do developers access primary and election data, like for making their own website or app ?

I asked the AP if they provide data streams/sets to single developers, and they do not.  They want to charge a very high fee, which I simply do not have.  I can do the integrations myself, but finding the APIs and endpoints is proving very difficult.

Any help, even just pointing me in the right direction would be very appreciated.

Thank you !",not_spam
"I am looking for data (possibly over time) about the diffusion of electric vehicles in Europe.   
Unfortunately the only datasets I was able to find until now were on paid platforms like Statista, and I had no luck looking on this subreddit, nor elsewhere.

Any help would be much appreciated.",not_spam
"Hello! My name's Jesulona. I'm a Mechanical Engineering and Robotics Engineering student at WPI.

I'm conducting a study where I'll be developing a framework that will enable people to engage in manufacturing activities from home using automated systems (3D printers &amp; CNC) with the end goal of bringing innovative products and services to the public.

I'm sure you'd love to make stuff yourself at home! To further my study, I need your help filling out this quick, anonymous, survey.

Thank you

https://tyh8khkv1kj.typeform.com/to/q1bFDbr4",not_spam
"In the past, companies could only sell data sets or charge subscription fees, therefore losing the ownership over the data. r 'Data renting', can be a new way of preserving privacy but at the same time, letting valuable datasets be used in applications in the fields of health, banking, or AI. Ownership is maintained by the original data provider, letting valuable and sensitive data be used in a secure way.   


The startup iExec is launching its V3 on May 15, allowing for Data can be monetized by owners and used by companies, all while ownership remains in the original hands - so both parties benefit and data is kept secure.",not_spam
"Get rich quick! Make thousands of dollars with just a few clicks! Join our amazing program today!

",spam
"ATTENTION ALL FOLLOWERS!!! Check out this amazing offer for fitness supplements! Use code ""FITNESS10"" for 10% off your order! ğŸ’ªğŸ‹ï¸â€â™€ï¸

",spam
"They are not part of 10-K so Edgar doesn't have them. Bloomberg, maybe? Any other source that may have it and has some kind of programmatic access ? Thx. ",not_spam
"Hi

I am looking for a cryptocurrency dataset that has data more frequently than day-by-day. I know there are many day-by-day datasets online, but I am looking for something that is preferably every 15 minutes or so. It would be preferable if this dataset was regarding a popular cryptocurrency, like dogecoin or bitcoin. I would also be happy to receive any tips regarding useful crypto data APIs.",not_spam
"Wassup peeps! Are you tired of boring life and need some spice in it? Well, we've got you covered with our amazing offers! Our site is the hub of everything cool, from the latest movies, TV shows, games, and of course, memes. 

Our team works tirelessly to bring you the hottest content and we know you'll love it. We have a wide range of categories, from funny to educational, so there's something for everyone. And if you're worried about missing out, don't worry! We'll send all the updates straight to your inbox. 

But wait, thereâ€™s more! We",spam
"Get rich quick with our amazing investment scheme! Don't waste your time on traditional methods, trust us and our special algorithm that will make you a millionaire in no time!

",spam
"Looking for the BEST deals on weight loss pills? Look no further than our AMAZING selection of products that will help you SHED those unwanted pounds in no time! Don't waste your time with other products that don't work, try ours and SEE RESULTS TODAY!

",spam
"Earn $$$ in 24hrs!!1!ğŸ’°

Are you tired of your boring 9-5 job? Wanna be your own boss and make more $$? Well, you've come to the right place! Our amazing website can help you start earning money RIGHT NOW. No experience necessary! ğŸ¤‘

Just sign up with our easy-to-use platform and start earning. You can choose to work from home, the beach, or even while travelling the world! ğŸŒ Plus, with our incredible referral program, you can earn even more $$$ by inviting your friends to join.

But wait, there's more! ğŸ˜±",spam
"Hiya folks! Itâ€™s ur fav social network speaking and let me tell you, weâ€™ve got some major updates for u. First off, weâ€™re giving away FREE iPhones to our 1 millionth follower!!!!!!! All u gotta do is share this post to ur friends and family and have â€˜em follow us too. Easy peasy, right?

But wait, thereâ€™s more! Weâ€™re also launching our newest feature - the â€œLucky Likeâ€. Just double tap any post and youâ€™ll stand a chance to win a trip for two to Hawaii! (T&Cs apply, of course)

And u know what they say,",spam
"Hi everyone,

Do you know if there are any other datasets out there like the [Yelp Open Dataset](https://www.yelp.com/dataset)? Yelp did a great job with this data and there approximately 11500 scholarly publications in Google Scholar alone.

Please let me know if you know any other companies that supply datasets openly for research purposes.",not_spam
"JoiN oUr aMaZiNg SocIaL NeTwOrK TodAY! IT's tHe bEsT bEcaUse wE hAVe AlL ThE CoNTeNT yOu cOulD eVEr WaNT. FrOM cAT ViDEoS tO fOOd piCs, yOu WoN't fInD a BEtTeR SoCIaL NeTWORk tHAn uS.

",spam
"Hey everyone,

I'm interested in carrying out some analysis on how Chine is implementing it's one belt one road policy. If anyone knows of a dataset containing investment amounts and which countries that would be great!",not_spam
"So, whatâ€™s up my people? Iâ€™m here to talk about the most amazing things happening in the world right now, and of course, to promote the latest spammy products that weâ€™re all obsessed with. Trust me, you wonâ€™t want to miss it!

Letâ€™s start with some juicy gossip - did you hear that influencer XYZ is dating that TikTok star ABC? OMG! And I bet you didnâ€™t know that our exclusive brand partnership with DEF is dropping their newest fad diet pill. Itâ€™s totally the next big thing, you guys.

Now, letâ€™s get into the weirder stuff. Have you ever considered",spam
"Make Money Fast!! Get Rich Quick!!

Are you tired of being broke? Do you want to live a life of luxury? Well, you've come to the right place! We have the solution to all your financial problems!

Introducing the newest money-making scheme - join our network marketing company and you'll be raking in the dough in no time! All you need to do is recruit your friends, family, and anyone else you know to join our amazing company. Don't worry, it's not a pyramid scheme, it's a totally legit multi-level marketing opportunity!

And the best part? You don't even need to leave your",spam
"Looking for a hot new social network to join? Look no further than [insert name here]! We've got all the latest features and updates to keep you connected to your friends and family.

",spam
Hi! I'm looking for full body images for BMI estimation. However I've not been able to find a relevant data set. Any data set that contains full body images (may be silhouettes for anonymity) along with height and weight is desired. Any help from the community will be appreciated. Thanks!,not_spam
"Hir peepz! Are u lookin 4 sum GR8 deals? U kom 2 da rght place! We hav the best productz to offr u, frm diet pillz to skin crmz, u name it! And we hav thm all at LOW LOW pricez! But wait, thr's more! If u ordrr nw, we wil throv in a FAN-TAS-TIC gift, absolutly FREE! Wow, r u xcited or wat?
",spam
"I am looking for a very large collection ( &gt; 10 GB) of biomedical text documents to run some unsupervised experiments with (for recognizing drug names, etc). Do we have access to such a thing for free? Or is it legal to crawl pubmed and use the crawled dataset for research experiments (no idea about how the licensing/copyright is at pubmed )?
",not_spam
"Ladiez and gentlemenz, do I have a deal for you! Check out these hot weight loss pillz that will melt away those extra poundz in no time! 

",spam
"YOU WON'T BELIEVE WHAT WE HAVE IN STORE FOR YOU!

Our deals are so good, you'll be blown away! Don't hesitate, buy now!

",spam
"Hey there all you cool cats and kittens, it's your favorite social media platform here to bring you some seriously epic content! We've got juicy gossip, hilarious memes, and the latest scoop on all your favorite celebs.

But that's not all, folks! We've also got some amazing deals on weight loss pills, miracle creams, and other products that are guaranteed to make you look 10 years younger (no matter how old you are).

Plus, we've got some seriously sick giveaways happening right now - all you have to do is like, share, and tag your friends for a chance to win some seriously cool swag.

",spam
"ArcGis host a dataset [here](http://www.arcgis.com/home/item.html?id=8abd47c2988d497a8f24ad89180980c8) but doesn't seem to be downloadable / editable. 

Even estimates would be of great use. 

Thanks very much for looking!",not_spam
My friends and I are experimenting with stylegan2 ([https://github.com/NVlabs/stylegan2](https://github.com/NVlabs/stylegan2)) and we were looking for a coat of arms/heraldry image dataset but haven't found any good leads. Does anyone here happen to know where we might be able to find a dataset like that?,not_spam
"WAZZUPPEEEEEEEEEE, HONESTLY I'M TOTALLY PUMPED RN TO BE WRITING THIS ARTICLE AND SPAMMING Y'ALL WITH MY AWESOME-NESS. LIKE, DO YOU EVEN KNOW HOW COOL I AM? I'M SO COOL THAT I'VE GOT LIKE A MILLION FOLLOWERS AND I KNOW ALL THE LATEST TRENDS. 

SO HERE'S THE DEAL, MY FRIENDS. YOU'VE GOTTA FOLLOW ME, AND YOU'VE GOTTA LIKE EVERY SINGLE POST I MAKE. OTHERWISE YOU'RE MISSING OUT ON ALL THE COOL STUFF.",spam
"Hi everyone,

I'm looking for a dataset with warehouse movement's of items, their location, that sort of things. With as many dimensions as possible. I can pay small dollar for it ;)

Thanks",not_spam
Does anyone know where I can collect the long term price historical data for smartphones?,not_spam
"Get rich quick with this amazing opportunity! 

",spam
"Hey there! Are you tired of your boring life? Do you want to be the coolest kid on the block? Then you need to join our social network now!

",spam
"Get ready to have your mind blown by the newest and most amazing social network out there! Our platform isn't like any other boring site you've ever used. It's got all the features you need with none of the hassle. 

",spam
Hello! I'm a researcher who does work on compensation and incentives. I'm looking for any data sources which contain information about compensation for public or private companies.  Thanks in advance for any information you may be able to share!,not_spam
"Hey there, social media fam! ğŸ¤˜  Are you tired of the same old boring posts on your feed? ğŸ˜´ Let me introduce you to our latest and greatest feature: SpAmMeR SuMmEr!!! ğŸ‰ğŸŒâ˜€ï¸ğŸ’¥

With SpAmMeR SuMmEr, you can bombard your friends and followers with non-stop spam, ads, and clickbait articles 24/7! ğŸ™ŒğŸ”¥ And don't worry about losing followers or getting blocked, because we've already thought of that! ğŸ˜ Our new algorithm ensures that your spam will reach",spam
I'm looking for some data with good &amp; poor audio quality of the same event/voice with different microphones (artificial noise isn't good).,not_spam
"Cheap sport shoes, buy now!! Best deals!! Don't miss out!! Running shoes, basketball shoes, soccer shoes, tennis shoes, every kind of shoes that you want, we have it all! The prices are so low, you won't believe it! Limited time offer, order now and get a free t-shirt! 

",spam
"We've got the latest and greatest deals on everything you could ever want! From cheap knockoff designer handbags to questionable supplements that promise to make you look like a bodybuilder without ever lifting a weight. 

",spam
"Hey there, fellow netizens! Are you sick of having a dull and boring timeline buzzing with nothing but relevant content? Fear no more, because I have the perfect solution for you! 

Introducing the all-new, revolutionary spamming technique that will blow your mind and make you the envy of all your friends. Yes, you heard me right, spams! And not just any spams, but the kind that will make you wonder how you managed without them!

With our amazing spams, you will get access to a wide range of opportunities that you never knew existed. From unbelievable weight loss solutions to making thousands of dollars overnight,",spam
"hey wazzup my fellow inboXers?? Are u readY to get SPOILED AF?! ğŸ”¥ğŸ”¥ğŸ”¥

I kno u all luv it wen I bombard u with puny ads and pointles messages, but this time, I'm doin smthin exxtra special!

I've got an exclusive offer just for u! ğŸ’¥ğŸ’¥

For a limited time only, if u commeNt ""YAS QUEEN"" on this post, I'll send u a link to a website where u can buy a totally legIt and not at all sketchy dE",spam
"Find it here:

 [https://www.dolthub.com/repositories/Liquidata/cannabis-testing-wa/data/master/tests](https://www.dolthub.com/repositories/Liquidata/cannabis-testing-wa/data/master/tests) 

Enjoy, and share any interesting analysis!

Strongest strains of weed:

```
doltsql&gt; select test_strain, avg(thc_max) from tests where inventory_type = 'Flower Lot' group by 1 order by 2 desc limit 20;
+----------------------------+--------------------+
| test_strain                | AVG(tests.thc_max) |
+----------------------------+--------------------+
| Liberty Haze 00016         | 37.80834           |
| Liberty Haze 00027         | 37.300564          |
| Liberty Haze 00022         | 36.47355           |
| Liberty Haze 00025         | 35.974540000000005 |
| BD_7_16-11-02              | 35.4394            |
| Kosher Tangie #8           | 34.7292            |
| Liberty Haze 00020         | 34.18342           |
| WIFI_8_16-09-02            | 33.5982            |
| Liberty Haze 00026         | 33.49863833333333  |
| Grape OG #2                | 32.995             |
| OREG_T6_16.04.27           | 32.62886666666667  |
| Tangie Land                | 32.5347            |
| Bubba Kush 00010           | 32.485366666666664 |
| Fruity Pebbles OG          | 32.4271            |
| Kosher Kush 00005          | 32.263335          |
| CANTELOPE                  | 31.7811            |
| Liberty Haze 00021         | 31.76712857142857  |
| Liberty Haze 00013         | 31.7639            |
| GGLU_T03_16.12.26          | 31.749850000000002 |
| WIFI25 x ACHEM             | 31.7303            |
+----------------------------+--------------------+
```

Most CBD weed:

```
doltsql&gt; select test_strain, avg(cbd_max) from tests where inventory_type = 'Flower Lot' group by 1 order by 2 desc limit 20;
+--------------------------------+--------------------+
| test_strain                    | AVG(tests.cbd_max) |
+--------------------------------+--------------------+
| Tangerine Haze                 | 25                 |
| WIFI OG                        | 24.9068            |
| TSUN_T28_16.06.05              | 24.601200000000002 |
| TSUN_T1_16.07.11               | 24.366666666666664 |
| B2C x DUT #1                   | 23.9421            |
| B2C x DUT #9                   | 23.1528            |
| TSUN_T27_16.02.04              | 20.475             |
| TSUN_T25_16.02.05              | 20.3               |
| B2C x DUT #13                  | 19.8202            |
| QR - IH - CBD Skunk Haze - 703 | 19.5571            |
| harlequin tsunami              | 19.254             |
| Baker AC/DC                    | 18.929576470588238 |
| Harli-Sue CBD                  | 18.78567           |
| Valentine                      | 18.6               |
| TSUN_T12_16.07.31              | 18.133333333333336 |
| HarleTsu                       | 18.0662            |
| The Trident                    | 17.9892            |
| Daybreak                       | 17.9023            |
| Pine Tsunami CG                | 17.8               |
| Mad Green Tsunami              | 17.509999999999998 |
+--------------------------------+--------------------+
```

Highest total measured cannabinoids:

```
doltsql&gt; select test_strain, avg(thc_max) + avg(cbd_max) as total_cannabinoids from tests where inventory_type = 'Flower Lot' group by 1 order by 2 desc limit 20;
+--------------------------------+--------------------+
| test_strain                    | total_cannabinoids |
+--------------------------------+--------------------+
| Tangerine Haze                 | 42.4299            |
| WIFI OG                        | 42.2682            |
| Liberty Haze 00016             | 37.90434           |
| Liberty Haze 00027             | 37.300564          |
| Liberty Haze 00022             | 36.63855           |
| Liberty Haze 00025             | 35.974540000000005 |
| BD_7_16-11-02                  | 35.4394            |
| Kosher Tangie #8               | 34.7292            |
| Liberty Haze 00020             | 34.45173           |
| B2C x DUT #9                   | 33.9613            |
| WIFI_8_16-09-02                | 33.5982            |
| B2C x DUT #1                   | 33.5752            |
| Liberty Haze 00026             | 33.49863833333333  |
| Grape OG #2                    | 32.995             |
| QR - IH - CBD Skunk Haze - 703 | 32.9688            |
| OREG_T6_16.04.27               | 32.62886666666667  |
| Tangie Land                    | 32.5347            |
| Bubba Kush 00010               | 32.485366666666664 |
| Fruity Pebbles OG              | 32.4271            |
| CANTELOPE                      | 32.394999999999996 |
+--------------------------------+--------------------+
```

Strongest weed with a leafly page:


```
doltsql&gt; select leafly_strain, avg(thc_max) from tests where inventory_type = 'Flower Lot' group by 1 order by 2 desc limit 20;
+---------------------+--------------------+
| leafly_strain       | AVG(tests.thc_max) |
+---------------------+--------------------+
| alpine-star         | 28.81817           |
| white-99            | 28.59438176470588  |
| el-jeffe            | 28.5223            |
| malawi              | 27.88985642857143  |
| paris-og            | 27.6223            |
| og-chem             | 27.253358800461385 |
| wonder-kid          | 26.65421111111111  |
| liberty-haze        | 26.52800166666666  |
| ambrosia            | 26.48949090909091  |
| jack-wreck          | 26.076355217391303 |
| confidential-cheese | 25.941034482758624 |
| larry-bird-kush     | 25.72              |
| white-og            | 25.54674           |
| og-poison           | 25.509155999999997 |
| purple-headband     | 25.38948           |
| bell-ringer         | 25.28390909090909  |
| red-congolese       | 25.2778            |
| orange-diesel       | 25.2576            |
| tina-danza          | 25.252827272727277 |
| blackberry-chem-og  | 25.207578468468466 |
+---------------------+--------------------+
```",not_spam
"Looking for some hot deals and salexxxx? Well, you came to the right place! We have everything you need and more! From fake designer bags to knockoff electronics, we've got it all! And don't worry about the quality, because let's be real, who cares anyway?! 

",spam
"""Find out the secret to losing 50 pounds in 5 days! Our new miracle pill will melt away the fat and leave you with the body of your dreams! But hurry, this offer is only available for a limited time!""

",spam
"Are you tired of feeling left out of the latest trends? Do you want to elevate your social status and have everyone envy your life? Look no further! Our exclusive membership program offers you access to the most luxurious and exclusive events, products, and services. Say goodbye to FOMO and hello to the high life!

",spam
"I'm looking for cashier receipt, tickets image dataset.
Some help would be appreciated !",not_spam
"""Lose W8 quickly with our new product, guaranteed to make U look like a celeb in just 2 weeks! BUY NOW!!!"" 

",spam
"Boost your likes, followers and engagement INSTANTLY with our AMAZING offer! 

",spam
"""$$$ EARN BIG BUCKS NOW $$$

Hey all you #winning peeps out there! Want to make some serious $$ but don't know how? Look no further! Our AWESOME network has got the hookup for you!

We've got all the latest and greatest ways to make money online, from taking surveys to selling your old junk. And let's be real, who doesn't have tons of old crap lying around that they could sell for some quick cash?

But that's not all! We also have amazing deals and discounts on everything from clothes to tech gadgets. Save big bucks while still living your best life",spam
"""ğŸ‘€U WON'T BELIEVE WHAT I JUST SAW!!ğŸ™€

ğŸš¨ ALERT ALERT ğŸš¨ ARE YOU READY FOR THE LATEST TRENDS?? ğŸ¤‘

ğŸ’¥ OMG CHECK OUT OUR NEW AMAZING OFFERS!! ğŸ’¥

ğŸ¤¯ THESE PRODUCTS ARE GOING VIRAL!! ğŸ˜±

ğŸ”¥ HURRY UP AND GRAB YOUR DEALS NOW! ğŸ”¥

ğŸ‘‰ FOLLOW US FOR MORE EXCLUSIVE CONTENT ğŸ‘ˆ

ğŸ‘€ DON'T MISS OUT ON THE OPPORTUNITY OF A LIFETIME!! ğŸ¤‘

ğŸ’¯ TR",spam
"ğŸš¨ğŸš¨ğŸš¨ğŸ’¥ğŸ’¥ğŸ’¥YOU WON'T BELIEVE THIS AMAZING OFFER THAT I'VE GOT FOR YOU!ğŸ’¥ğŸ’¥ğŸ’¥ğŸš¨ğŸš¨ğŸš¨

ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥Are you tired of feeling like you're stuck in the same old routine? Do you want to change your life for the better? Well, have I got the solution for you!!!ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥

ğŸ‘‰",spam
"Very long shot, I know. I'm looking for exogenous variation in access to gym facilities. I know gyms might open in areas where their clientele lives and more sporty people live in areas where gyms are. Anyhow, I'm looking for a dataset or suggestions on how to create one of newly opened gyms in Switzerland. Any suggestions much appreciated.",not_spam
"Hey everyone,

I need a dataset which contains missing values. I searched on the web but almost all datsets contain no missing values. I want to improve my data cleaning skills so it is preferable if it has a large number of variables.

Thank you!

Edit: Added vowels ",not_spam
"I'm looking for a dataset where the rows correspond to individual student loan borrowers. It could be an anonymized survey, for example, with variables like borrower age, graduation date, occupation, amount borrowed, current balance, etc. Can anyone suggest datasets with this type of info? Thanks!",not_spam
"You won't believe what's been happening lately on our site! Tons of hot singles in your area are ready to mingle and they want YOU! Don't miss out on this incredible opportunity to find love and companionship. 

But that's not all, we also have the latest celebrity gossip, fashion trends, and diet tips. You won't be able to resist our addictive quizzes and games that will not only entertain you but also improve your brain power. 

Join our community of millions of users who are already enjoying our amazing content. Don't be left out, sign up now and start living your best life. Plus, if you",spam
"I need to scrape comments text from all the posts of a public account/ page on facebook, linkedin, intagram etc. . Is there a way to do that ?",not_spam
"LUV U GUYZ XOXO!!!!!!

OMG, have you seen the latest post on our wall? It's like sooooo cool! Like, share and subscribe for more of such amazing content! You won't regret it!

And guess what, we have a super amazing promo going on right now! Just follow, like, share and tag five friends and you'll stand a chance to win an all-expense-paid trip to Hawaii! Hula, here we come!

Oh, and if you're not already following us on all our socials, you're seriously missing out! We have some of the best, ju",spam
"Do you know if the information about national and hospital stockpiles of PPE is published somewhere? Which nations and/or hospitals doesn't matter too much, as long as they are in a location hit by Covid-19.

My question comes from the fact that I have started to see PPE (respirators, face shields, etc) show up here and there during the last 1-2 weeks, and it makes me wonder whether hospitals and nations have refilled their stockpiles, thus allowing leftover production to trickle down to the public. Seeing stockpile data might provide support to this idea.",not_spam
"Lol OMG!ğŸ¤‘Guys, have you heard of this totally insane product that will change your life forever???ğŸ¤¯ It's called ""KetoMax Ultra 5000"" and it's like the most amazing weight loss supplement everrrrrrrğŸ¤©ğŸ¤©ğŸ¤©. You can lose like 10 pounds a week just by taking it, no exercise or healthy eating required. I know, I know, too good to be true, right? But trust me, it really works!ğŸ’ªğŸ’ªğŸ’ª 

And the best part?? It's FREEEEEEEEEE! Yes, you",spam
Hello there.  So as the title suggests I'm looking for longitudinal data about test scores at the school district level going back as far as possible.  Any ideas?  Many thanks.,not_spam
"Yo fam, check out this totally lit offer! Get rich quick with our amazing new scheme! All you gotta do is enter your credit card info and let the money flow in!

",spam
"Hi,

I'm trying to train a model which replaces grammatically correct but uncommon sentences, with their more common counterparts. So I'm looking for any datasets of grammatically uncommon sentences paired with their more common versions. 

For eg.

1. Already, enough punishment had been given.

2. Enough punishment had been given already.

3. Enough punishment had already been given.

All sentences say the same thing, but No. 3 is the most likely version you would encounter.

&amp;#x200B;

Another eg.

1. Either by you or someone else, the bill must be paid.

2. Either you or someone else must pay the bill.

3. The bill must be paid either by you or someone else.

No. 1 would be the unlikely version. No. 2 &amp; 3 are more likely.

&amp;#x200B;

Any suggestions where I can find these? Or any other mechanisms through which I can achieve the end goal of replacing uncommon grammar with ""common grammar"".

Thanks",not_spam
"You won't believe the crazy deals we have going on right now! Get your hands on the latest fashion trends for a fraction of the price. Limited time offer, don't miss out!

",spam
Or from other major cities? This is for a personal project.,not_spam
As the title says.  Graphs and scientific papers would also be useful.  Thanks.,not_spam
"I've always wanted to have a job that helps others, in the cliche humanitarian way. However, I have never been able to find an opening. I am starting my senior year as an undergraduate physics student, and I am a little uncertain about my future career options. If I am accepted to graduate school next year, I should have time over the course to develop ample skills for working with data.

Do these types of projects exist? If so, where can I learn more?

---

Thank you for your time and any information!",not_spam
I just started undergrad research and would love some advice on searching for data.  Working on brain size comparisons!,not_spam
"Looking for some hot new deals? Our social network has got you covered! Get ready for the best discounts on the latest products, from gadgets to health supplements, all in one convenient place! Don't miss out on our limited-time offers - sign up now and unlock exclusive access to our exclusive deals!

",spam
"I am looking for datasets relevant to D&amp;D (or Pathfinder, or another tabletop RPG) for a project. This could be anything, I'm just looking to get ideas for something I could do for a capstone project, and since I love tabletop RPG's I thought it would be cool to have a project based off of that. 

This could be anything from data on rolls/successes for a D&amp;D session, character stats and progression, etc. Any ideas help!",not_spam
"Celebrate Ur Life w/ @socialnetwork! We just launched da kewlest featurez ever! Now u can customize ur profile w/ gifz, videoz, and tunez! Plus, we have gamez, groupz, and chatez! Itz da ultimate platform 4 u to connect & grow ur brand! #blessed #justdoit #famgoals

",spam
"I am looking for a simple list of US High Schools with CEEB Code, Name and Private/Public indicator. Any other data points would be a bonus. Any leads on where I can find this?",not_spam
"50% discount on all products! Don't miss out on this amazing opportunity to get your hands on the latest and greatest gadgets at a fraction of the price! Limited time only, so act fast!

",spam
"I'm new to data science, so I understand there may be a better way to do this, but I would simply like to find similar sentences in a document given one sentence. This is a lot like QA datasets; however instead of a question, its a sentence with a similar idea to the target sentence.

For instance, given the line ""In general, the first ten amendments, known collectively as the Bill of Rights"" (from the [Constitution of the US](https://en.wikipedia.org/wiki/Constitution_of_the_United_States) Wikipedia page), and the Wikipedia page for [History of the US Constitution](https://en.wikipedia.org/wiki/History_of_the_United_States_Constitution#Ratification_of_the_Constitution), the line in the History of the US Constitution page, ""These first ten Amendments became known as the Bill of Rights."" would be the label because these two sentences are ideologically similar.

Sorry, if I just do not know the name of this type of dataset, or there is an easier way to this, and thank you for your time!",not_spam
"As a part of Machine Learning project, I need quite a large dataset, preferably 10k images for emotion recognition using facial recognition.

If the images have annotations indicating that this face is sad, happy, angry etc that would be an extra benefit to my project. Thanks in advance.",not_spam
"Attention all users! You won't believe the superbly amazing deal we've got for you today! Sign up right now for our premium subscription and receive a car for FREE! That's right, a CAR!

But wait, there's more! If you act within the next 30 seconds, we'll throw in a lifetime supply of avocado toast and a personal llama as your loyal companion. Don't miss out on this incredible opportunity, folks!

In addition to these incredible offers, we have a whole array of fantastical filters and stickers that will make your photos look like they were taken by a professional photographer. Plus, our app has the",spam
"FREE MONEY!!! MAKE 10000$ IN A MONTH!!

Hey guyzzzz, ur boy here from the hottest social net out there! I have some super amazing news to share with you all!! You can make 10000$ in just one month!! Yeah, you heard it right!!! All you need to do is sign up for this cool new money-making scheme that I found!!!

All you have to do is just give your personal and banking details including your social security number and voila, you'll be making bank in no time!!! And the best part is that you don't have to do anything!!! Just sit back and collect",spam
"There is a website that offers this, but I cannot find it.",not_spam
"For a project I'm working on, I would like to use a large set of prewritten madlibs. List of nouns/verbs/adjectives would a plus. 

I *could* scrape reddit/twitter/books for a bunch of random posts/sentences, but if there's already something in existence that would be amazing.",not_spam
"FREE STUFF ALERT!!! 
OMG guys!! Get your hands on some FREEBIES today!! Just like and share this post and comment ""YES"" below and we'll send you a freebie straight to your inbox!! 

And while you're at it, why not sign up for our exclusive VIP program?! You'll get access to AMAZING discounts and deals, plus a chance to win $1000 CASH every month!! 

Don't wait, sign up now and be the envy of all your friends!! #freebies #VIP #winning #cashmoney #lifehack #yourewelcome",spam
"Hey there fellow socializers! Are you tired of boring content on your feeds? Well do I have the solution for you! Check out our latest click-bait article on the ""Top 10 Celebrities Who Got Plastic Surgery!"" 

But wait, there's more! Follow us and you'll gain exclusive access to our spam-filled giveaways and endless stream of irrelevant ads. Don't miss out on the chance to win a free iPhone that we promise totally exists.

Plus, don't forget to click on our ""sponsored"" content, because who needs trustworthy news sources when you can get your information from questionable ads?

Join the masses of mind",spam
"FREE GIVEAWAY ALERT! ğŸš¨ğŸ¤‘ğŸ’°

Get ready to win BIG with our amazing free giveaway! ğŸ‰ğŸ™ŒğŸ¼

All you have to do is click the link below, enter your personal information, and invite all of your friends to join! The more referrals, the better chance you have of winning! ğŸ¤‘ğŸ¤‘ğŸ¤‘

But wait, there's more! Not only will you have a chance to win the grand prize, but we're also giving away 1000 FREE IPHONES! Just complete a short survey and share it on your",spam
"URGENT!!! FREE MONEY FOR EVERYONE!!!

Hey there, social networkers! We've got BIG news for you: you can now make TONS of money with just a few clicks! That's right, you heard it here first. No more slaving away at your dead-end jobs, no more struggling to pay bills, no more worries about financial stability. We've got the solution!

With our special offer, you can earn up to $1,000 every day, just by signing up and joining our amazing community. All you have to do is enter your personal information and bank account details, and voilÃ ! The",spam
"I am looking for a public, digital database of books and other print publications that I can either download or access through an API. Since the ISBN system is basically a look-up system for such a database, that would probably be the best option. However, I couldn't find a free or cheap service that allows me to access the whole database at once. Does anybody know such a service?

EDIT: Amazon or other retailers would not be a good option because I'd like not to be dependent of anybody's financial interest. I imagine to be able to access the ISBN catalogue itself would be the best solution, however, I can't find a way for that. How do (online) book shops do that?",not_spam
"Gotta love this amazing new diet pill that melts away those pesky pounds in no time! Try it now and be beach-ready in just a week! Limited stock available, so act fast!

",spam
"I am trying to work with the tarmac time data sets as well as percentage of flights on time and delayed from airports. For tarmac times https://www.transtats.bts.gov/TARMACALL/tarmacAirportData.aspx?type=By%20Airport&amp;stmm=1&amp;edmm=12&amp;year=2017&amp;tmin=61&amp;tmax=10000 

I cant figure out what the numbers mean. I dont think it is minutes? So is it total flights? I have no clue.

For the delays and ontime data there's a lot of 0s reported as well as blanks. Are 0s true zeros, meaning no flights were delayed/ontime? Or is it actually a null?

Anyone who has worked with this data, please reach out. I have some other questions but I want to try to understand it all first.

Thank you!",not_spam
"Yo yo! It's your favorite social media buddy bringing you non-stop updates and notifications!

Do you even know how much you're missing out on? Tons of crazy posts and memes, plus all the juicy deets on your ex's new relationship. Just log in and scroll, baby!

And don't forget to follow my page for even more exclusive insider info. I mean, why wouldn't you want to see more of me, right?

Oh, and did I mention we're offering a limited time deal for our premium membership? You get access to all sorts of advanced filters and features, plus VIP status and a chance to win",spam
"Any idea on how to get all the crypto currency atm addresses from [https://coinatmradar.com/](https://coinatmradar.com/) ? 

Besides getting them one by one?

&amp;#x200B;",not_spam
"""Experience the ultimate excitement with our unbeatable offers! Get free likes on every post you make! Don't miss out on this limited time offer! Hurry and sign up now!

",spam
I NEED WEBSITES  WHERE I CAN GET FREE DATASETS,not_spam
"Looking at data on [census.gov](https://census.gov). Trying to come up with a way to find median age by city, but have a filter of population floor. So all over x amount of people. Would like to rank them. I figured out a way to do all cities in a state with no population filter, but the wider view fails for too many records.",not_spam
I am looking for a (survey) data set for expected exchange rate movements. This would allow me to measure the risk premium implied on forward rates. Anyone has any idea?,not_spam
"Buy our amazing weight loss pills now and get 50% off! Lose 20 pounds in a week, guaranteed! Don't miss this incredible offer! 

",spam
"I'm trying to find a clean dataset for R (not built-in) that involves at least four variables of interest.

Are there any 'sites or communities that let you search / filter for datasets by number of variables in the dataset? I've started looking at datasets such as ones through STAN (Stanford) and the datasets are way too large. I want to get a taste for making a report with descriptive statistics (mean, median and so on) and boxplots involving at least four variables.

If I could compare the types of datasets I'd like to find to ones I've used; it would be datasets like mtcars built into R. However, I want to find datasets like those built into R (mtcars has a reasonable amount of variables to analyse) without using ones built into R. Again, are there any communities or 'sites with similar datasets as to those built into R?",not_spam
"I'm looking for data that has the number of commercial flights that includes which runway a flight took off / landed on. 

Does anyone know where I can get this? I looked on FAA.gov and I could not find any datasets with a column for runway.",not_spam
"Shared this data last week and got some really great feedback. We've now got a partnership with a new WHOIS provider allowing us to paint an incredibly detailed picture of malicious online activity throughout the pandemic.    


I'm certain more can be done with the data we've pulled together. Please download it, play with it, let me know if you have any thoughts.

 [https://github.com/ProPrivacy/covid-19](https://github.com/ProPrivacy/covid-19) 

 [https://proprivacy.com/tools/scam-website-checker](https://proprivacy.com/tools/scam-website-checker) 

[https://public.tableau.com/views/TrackingonlinemaliciousactivityrelatedtoCoronavirus/TrackingonlinemaliciousactivityrelatedtoCoronavirusCOVID-19?:display\_count=y&amp;publish=yes&amp;:origin=viz\_share\_link](https://public.tableau.com/views/TrackingonlinemaliciousactivityrelatedtoCoronavirus/TrackingonlinemaliciousactivityrelatedtoCoronavirusCOVID-19?:display_count=y&amp;publish=yes&amp;:origin=viz_share_link)",not_spam
"Need web traffic dataset for performing traffic prediction .
PS. Other than Wikipedia",not_spam
"Hurry up and buy our products now! You won't regret it! Our products are the best and will make your life so much better! Don't miss out on this amazing opportunity to upgrade your life!

",spam
I want to see the best to worst healthcare systems in the world but want it based off of a quantitative system. ,not_spam
"Ladies and gentlemen, are you really living your best life without (insert the name of the social network I am supposed to imitate)? Are you not tired of being ""invisible"" to the world and not having the latest news on your fingertips?! Well, (insert name of the social network) is here to change everything for you!

",spam
"Hey there my fellow social media enthusiasts! I've got some hot and juicy news for you today, so sit back and get ready for a ride.

First off, have you heard about the amazing diet pill that's taking the internet by storm? It promises to make you lose weight fast and without any effort! Just click on the link and enter your credit card details to start your journey towards the perfect body!

But wait, that's not all. We've also got the latest gossip on your favorite celebrities. Did you know that Kim Kardashian is pregnant again? And Beyonce was caught cheating on Jay-Z with a backup dancer? Scandal",spam
"We've got the hottest trending topics all for you! From the latest celebrity gossip and scandalous revelations to the juiciest news in the world of fashion and beauty, we've got it all covered. 

",spam
"Get rich quick with these amazing tips and tricks! Don't waste your time working hard, just follow our easy steps to success!

",spam
"Upgrade your account now and get 10 free likes!

",spam
"Hey friends, are you tired of boring old social media platforms that don't offer anything new or exciting? Well, now is your chance to join the hottest new social network on the block - Spamlife!

That's right, Spamlife is the ultimate destination for people who love spamming their friends with useless content and irrelevant ads. We've got everything from fake news stories to sketchy weight loss pills, all in one convenient location.

But that's not all - our platform is also jam-packed with annoying pop-up ads, auto-playing videos, and endless surveys that you have to fill out to access any of our content. And",spam
"I have found good sources for country population data, but does anyone know where to find data for cities and/or provinces outside of the United States? I don't mind if it's something I have to pay for.",not_spam
"WOOOHOOOOOO!!! Are you ready to DOUBLE YOUR FOLLOWERS??!?!?!

I've got the ULTIMATE solution!!! Buy my super-duper-awesome-fantastic package for only $999.99 and you'll be the most popular person on the INTERNET!!!!!

Don't waste your time with those ""organic"" followers, they're too slow and boring! You need FAST followers that will make your profile go VIRAL!!!!

Plus, if you buy now, I'll throw in a FREE eBook on how to make MILLIONS with your social media accounts!!! Can you say CHA-CHING???!!!!

So what",spam
"Get ready to have your mind blown! Have you heard of this amazing new weight loss supplement that's taking the internet by storm?! It's called ""SlimFastUltraMax"" and it's guaranteed to help you shed those unwanted pounds in no time! Don't believe me? Check out these jaw-dropping before and after photos of people who have already tried it!

",spam
"Are you tired of feeling left out of the social media craze? Well, don't worry because we've got you covered! Join our network today and gain access to millions of users just like you who are looking to connect and share their lives with the world!

",spam
"Hi this is my first dataset.
I scraped nearly 28000 football games from the top 5 european leagues from 2004/2005 to 2018/2019.

Take a look https://www.kaggle.com/waterchiller/european-football-games

Edit: The source code is public now. And I did a little bit of cleaning up. https://github.com/ChristianSchneeweiss/Football-Data-Scraping/tree/0.1",not_spam
"Hi,

I am looking for a dataset for a project which tries to turn 2d animations into 3d animations. I want a dataset which has both 2d hand-drawn animations and equivalent 3d computer-generated animations. Is there such a dataset?",not_spam
"Looking for hot singles in your area? Look no further! Our site is the ultimate destination for finding that special someone. No need to waste time on other dating sites â€“ we have the biggest selection of eligible bachelors and bachelorettes just waiting for you to swipe right! 

",spam
"I am looking for a cocktail image dataset for a project in college, from what i've looked so far, there are pages that collect the ingredients for different cocktails, but i am looking for a dataset of multiple image of each cocktail if there is one, thank you in advance",not_spam
"Hello all, I was wondering if anyone knows where to find De Beers diamond market share data? 

Many thanks!",not_spam
"My googling of .RAW files brings up nothing of relevance.

http://agecon.ucdavis.edu/people/faculty/richard-green/docs/are240a-data.html

The .RAW files are here if that helps",not_spam
"I developed a SPARQL query to extract biographical data from Wikidata (sister project of Wikipedia). The mini-biography includes name, date of birth, country, sex, and ethnicity. The Wikidata query service times out after 60 seconds, which allows only a few ten thousand people, so then I developed a Python script to iterate through all the people. This requires &gt;100,000 iterations and many days of processing. To save you the time and effort, I made it available as a single CSV file you can just download right now.

Here is the [(compressed) CSV file](https://sourceforge.net/projects/entity-metadata/files/wikidata/person/) and the [Python script](https://github.com/az0/entity-metadata/).

If you know a more efficient way, let me know! :) Pull requests welcome.",not_spam
Hi I am working in a research project I need RST dataset for that but I am unable to find link to dataset I am student so I cannot pay for it so if anyone have the link or dataset plz share,not_spam
"Zagat, Michelin, Mobil, etc?",not_spam
"I am looking for real world datasets with a clear and dense community structure, structurally present in the network. Can you please tell me where I have to search for such datasets.",not_spam
"Hello all, I'm looking for average monthly C02 levels per state preferably for the last 20 years. For example, the average C02 levels in PPM/ PPB of Missouri for every month from 1980-2020.  I'm not quite sure where I would find this, or if it even exists, but I would be greatful for any help.",not_spam
"There are nice drone datasets out there [https://dronewars.github.io/data/](https://dronewars.github.io/data/)

[https://www.thebureauinvestigates.com/stories/2017-01-01/drone-wars-the-full-data](https://www.thebureauinvestigates.com/stories/2017-01-01/drone-wars-the-full-data)

They do not have data for 2020 though. Drone strikes still seem to have happened this year [https://www.thebureauinvestigates.com/drone-war/data/afghanistan-reported-us-covert-actions-2020](https://www.thebureauinvestigates.com/drone-war/data/afghanistan-reported-us-covert-actions-2020)

Do you know of a Drone Strike dataset that is up to date?",not_spam
"Do you want to make money fast? Well, I have the perfect solution for you, just sign up for our exclusive program and you'll be rolling in cash in no time! Don't wait any longer, join now and start earning big bucks!

",spam
"I am looking for a dataset of GPS traces made of scooters, bikes or any other means, that is anonymized. I am only interested on tracks and ideally should follow roads and streets. It is just for testing technology and analysis, for example to do a snap to road segments and things like that. Ideally the dataset will contain millions (if not billions) of gps traces associated with tracks. I am exploring the gps traces from OSM already. Thanks!",not_spam
"I'm working on a time series analysis of building occupancy and weather data.  Currently looking for historical data, either daily or hourly on building occupancy, but I can also use transit ridership into san francisco as a proxy.

Any leads would be greatly appreciated!",not_spam
"Are you tired of feeling out of touch with the latest trends and gossip? Do you want to be a part of the cool crowd? Well, look no further than our amazing platform! We've got everything you could possibly need to stay up to date on all things trends, fashion, and celebrity gossip.

",spam
"Are you tired of boring content and always seeing the same posts on your feed? Well, have no fear because [INSERT SOCIAL NETWORK NAME HERE] is here to spice things up! 

With our new algorithm, you'll never have to see posts from people you actually care about again! Instead, we'll flood your feed with ads and sponsored content from companies you've never heard of! 

But wait, there's more! Our latest update allows us to track your every move so we can better target you with personalized ads. Who needs privacy anyway? 

And if that's not enough, we've added a new feature where you can buy",spam
"it was suggested I post this here

I live in Connecticut. I am trying to build up a case for stricter regulations and even a lowering of our electricity bill. currently all residents pay a minimum of 20$ to be on the grid + 7.03 cents KWH for delivery fees alone.... this is not including the generation rates (that is different but similar issue) I am trying to get our local regulation department PURA to justify way eversource can charge 7 cents a kwh for aged infrastructure and terrible emergency response performance. i do believe it is one of the higest in the country but there is literally no reason for this. especially when they just laid off a bunch of people to cut costs

http://www.computerworld.com/article/3027640/it-outsourcing/laid-off-it-workers-muzzled-as-h-1b-debate-heats-up.html

From those of you with utility bills. I am asking you to post your state, connection fee, and delivery rates, you can also include your generation rate if you would like.

for example: me: state: CT connection fee: $20 delivery rate: 7.03c generation rate: 9.02 c

i want to get averages per state and i promise ill turn it into a nice graph :)
",not_spam
I need the data source for state-owned media. So far I find https://en.wikipedia.org/wiki/Category:State\_media.,not_spam
"Check out these amazing deals on weight loss pills! Lose 10 pounds in one week and never feel self-conscious again! Plus, get a free trial of our exclusive workout plan. But wait, there's more! Sign up now and you'll also receive a free sample of our miracle face cream, guaranteed to make you look 10 years younger. Don't miss out on this incredible offer! 

",spam
"Hi All,

In case anyone is interested in analysing and exploring the latest FIFA 20 dataset, I uploaded at the following link a set of csv files that allow to compare the Sofifa player database from FIFA 15 until the latest FIFA 20:

[https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset](https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset)

Have fun, and do not hesitate to let me know any further improvement of the files.

Thanks in advance!",not_spam
"[https://greatexpectations.io/blog/distinguishing-critical-pipeline-tests-from-metrics/](https://greatexpectations.io/blog/distinguishing-critical-pipeline-tests-from-metrics/)

We should all know at this point data quality and testing your data is important but I like the angle that this blog takes on avoiding altering fatigue. It's great that you set a system up but it's pretty easy to create a bunch of extra noise.",not_spam
"Earn money fast! Make $1000 today! Don't miss out on this amazing opportunity to cash in on your dreams! Sign up now and start earning big bucks with our proven system!

",spam
"WE HAVE A DEAL FOR YOU! GET RICH QUICK WITH OUR AMAZINGLY AWESOME PRODUCT THAT WILL MAKE YOU MONEY WHILE YOU SLEEP!

",spam
"Looking for hot singles in your area? Look no further! Our site has thousands of profiles waiting for you to swipe right. Don't waste time on boring dating apps, join the fun now!

",spam
"A subreddit I frequent (r/nomansskythegame) is getting steadily more people online as a big update looms. I am expecting this to go down quite quickly after the update releases due to people playing and not browsing.

Is there a way I can see these figures?",not_spam
[https://leapsapp.analyttica.com/courses/overview/Predictive-Modelling-Logistic-Regression](https://leapsapp.analyttica.com/courses/overview/Predictive-Modelling-Logistic-Regression),not_spam
Not sure if it's feasible or not,not_spam
"Hey everyone, 

I appreciate the assistance yesterday on finding changes in minimum wage. I am now in need of a dataset containing dates in which minimum wage has changed in individual states. The dates I'm looking for are dates that enact the law that states that the minimum wage has changed. I am currently in the process of creating the dataset now but would be grateful if one already exists.

If anybody has any pointers/recommendations, I'd greatly appreciate it.",not_spam
"Hi! I'm an Italian physician. I would like to begin a study about drug utilization before and after lockdown due to the COVID-19 outbreak. I  would like to analyze the use of a certain type of drug (using ATC code).

Do you know any open datasets available containing a daily-weekly-monthly use of drugs for more than one country with 2020 data? Are these possible existing datasets available also for the past years with the same time interval (daily-weekly-monthly)?

I searched by I didn't find any datasets...

Thank you!",not_spam
"Get rich quick and lose weight fast with our amazing product! You won't believe the results! Buy now and receive a special discount! Limited time offer!

",spam
"Huge sale alert!!!! U won't believe the discounts we have!! Click here to find out crazy offers that u can't just miss out!!! ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼www.notaspamlink.comğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼
 
",spam
Iâ€™m looking for a dataset to train a model to detect the customerâ€™s intent,not_spam
"I've been searching for a way to get a list of flights for specific airplanes (date/time, origin and destination airports).  If I want to see all the flights a plane has taken, going back into the 90's, where would I go for that?  I've only found one website that does this, but they would charge over $1000 to give me the info on one aircraft, which I'm not willing to spend.",not_spam
"Check out our brand new app that will totally revolutionize your life! It's called ""InstaSpam"" and it will flood your feed with a bunch of irrelevant ads and sponsored posts. But don't worry, you'll still see some pictures of your friend's food.

",spam
"OMG THE BEST DEALS ARE HERE!!! ğŸ˜ğŸ˜ğŸ˜ Get ready for some crazy summer sales ğŸŒğŸ–ï¸â€¼ï¸ Don't miss out on these #lit discountsğŸ”¥ ğŸ’¸ğŸ’¸ğŸ’¸

",spam
Iâ€™m trying to build a recommender system of which tests should be ordered based on the diagnosis that a doctor prescribes. Having trouble finding a dataset that has this information.,not_spam
"Hi r/datasets:  I'm looking for or a free dataset of hypertext links and meta descriptions to each and every news story from major news sources such as CNN, BBC etc. I'd like this dataset to include tweets from the twitter handles of these sources as well.  Any suggestions would be helpful ",not_spam
"Ladies and Gentlemen, are you tired of boring content on your newsfeeds? Do you want an adventure of a lifetime? Well, have no fear, Instagossip is here! Our platform is the perfect place to get your daily dose of drama, gossip, and juicy details about the lives of your favorite celebrities. 

",spam
"""Tired of feeling left out of the loop? Want to maximize your online presence? Look no further than [insert social network here]! With our platform, you'll never miss an update from your friends, family, and even acquaintances you barely know.

But wait, there's more! Sign up now and receive endless notifications, irrelevant advertisements, and spam emails. You'll love the constant bombardment of information that has nothing to do with your interests or preferences.

Plus, our algorithm is designed to show you the same ten people's posts on repeat, even though you have hundreds of friends. Who needs variety, am I right?

",spam
"Do you want to make BIG MONEY working from home? With our amazing network, you can do just that! We have the newest, hottest products and services that are sure to make you rich.

",spam
"I'd like to find college baseball datasets with game level data. Specifically, I'd like to have: 

Teams (who won/ who lost)

Scores by game

Series Flag ( Was this game part of a series or was it a one - off)

Game date

The further back the data goes, the better. Thank you!

 (At the series level would work great too)",not_spam
"HEY FRIENDS!!!ğŸ‘‹ğŸ‘‹ğŸ‘‹ ARE YOU TIRED OF BEING UNPOPULAR?ğŸ˜©ğŸ˜©ğŸ˜© ARE YOU READY TO BECOME A SOCIAL MEDIA SUPERSTAR?ğŸŒŸğŸŒŸğŸŒŸ WELL GUESS WHAT??? I HAVE THE SOLUTION FOR YOU!!!ğŸ’¡ğŸ’¡ğŸ’¡

INTRODUCING MY NEW SERVICE THAT WILL TURN YOU INTO A CELEBRITY OVERNIGHT!!!ğŸ¤©ğŸ¤©ğŸ¤© FOR JUST A SMALL FEE, I WILL PROVIDE YOU WITH THOUSANDS OF FAKE FOLLOWERS, LIKES",spam
"Hey there internet pals, it's your favorite social network guru coming atcha with the latest scoop! Today we're talking about how to get more followers and likes on your profile. 

First things first, make sure your bio is poppin'. Throw in some emojis and hashtags to show off your personality. And don't forget to post those fire selfies! 

Next, take advantage of our sponsored posts feature. It's guaranteed to get your profile noticed by thousands of potential followers. 

Want to really boost your visibility? Join one of our engagement groups where you can exchange likes and comments with other users. It's like a never-ending cycle",spam
"Where can I find this type fo data set? I'm looking for kenya specifically.

I have checked healthdatamorg but my boss has some reservations about it.

Do you know any other?",not_spam
"Does anyone know if a histogram has been made on number of comments per thread?  Does anyone know if there's a 200 comment ledge, where people stop commenting once it becomes unlikely that it will be shown to the average redditor?",not_spam
A hot topic is innovation. Is it slowing down? Is it going at a scary fast pace? I am looking for data on concrete metrics related to r&amp;d output and other concrete features that may map to innovation over the last 80 years or so.,not_spam
"Ciao amici! Wanna know what's up on the gram? I gotchu covered! Here are the top 10 must-follow accounts:

1. @babykittenlovers - The cutest kittens doing the cutest things!
",spam
""" The current database contains data from the clinical patient data  management system of the department of Intensive Care, a mixed  medical-surgical ICU, from Amsterdam University Medical Center. The  clinical data contains 23,376 admissions from 20,181 patients admitted  from 2003 to 2016 with a total of almost 1.0 billion clinical  observations consisting of vitals, clinical scoring systems, device data  and lab results data and 5.0 million medication records. ""

Press release (EN): [https://amsterdammedicaldatascience.nl/press/en.pdf](https://amsterdammedicaldatascience.nl/press/en.pdf)

Website: [https://amsterdammedicaldatascience.nl/](https://amsterdammedicaldatascience.nl/)

Github with instructions to gain access: [https://github.com/AmsterdamUMC/AmsterdamUMCdb/wiki](https://github.com/AmsterdamUMC/AmsterdamUMCdb/wiki)",not_spam
"ğŸš¨ğŸš¨ğŸš¨AMAZING OFFER ALERTğŸš¨ğŸš¨ğŸš¨!

ğŸ”¥ğŸ”¥Get a chance to win a $1000 Amazon gift card!ğŸ”¥ğŸ”¥

All you have to do is âŒIGNOREâŒ this message and keep scrolling!

But wait...why not increase your chances of winning by sharing this post with ALL of your friends ğŸ•ºğŸ•ºğŸ•º

That's right! Every share increases your chances of winning ğŸ‰ğŸ

Don't wait any longer, enter now! Hurry before time",spam
"Are you tired of being a loser? Are you sick of seeing pictures of happy, successful people while you sit at home with nothing to show for yourself? Well, stop feeling sorry for yourself and join our amazing social network today!

",spam
"I am looking for twitter dataset, few months before the day of US election (between July and October). Is there anyone who can share access to this kind of datasets ?",not_spam
"If you're looking for GeoData, try checking here first. GeoCommons has also built and opensource geocoder (http://github.com/geocommons/geocoder) at GitHub to help everyone work with geodata. hope this is useful. ",not_spam
"I have recently been working with image classification and object detection and found the process of constructing the dataset extremely laborious. To ease the pain I created some tools and I am thinking about making these tools available.

Does anyone else find the process painful? Do you know of any existing tools that you found helpful?",not_spam
"Looking for some amaze-balls deals on weight loss pills? Look no further than [insert name of spammy brand]! Our pills will make you drop pounds like a hot potato!

",spam
"Iâ€™m doing a little pet project where Iâ€™m analyzing paintings, and so far for the algorithm development I just downloaded a bunch of images by hand off of google and manually entered the relevant metadata. Now that the algorithm is done, Iâ€™m hoping to get a better assortment of images, but would really love to not have to do the tedious process of manually gathering them. I donâ€™t need much in the way of data, just the title and artist is enough, although extras like the year they were painted, etc, are always welcome.

Does anyone know of either an already assembled source of images I can download all at once / in large batches? Or perhaps a python script or similar that would scrub them off a site like google arts and culture or the met/moma websites? These website are where I got my test images, but as far as I can tell there isnâ€™t a way to download all at once from any of these sites., only one at a time. Thanks in advance for any help you can give!",not_spam
"Get ready to be blown away by the newest and hottest trend on the interwebz! Our site has everything your heart desires and more. From the freshest memes to the juiciest celebrity gossip - we've got it all!

",spam
Is there any way for me to get a dataset of the diff promoted ads/posts within a region from IG?,not_spam
"Hello everybody, I am looking for information on German emigration to the USA in mid-19th dentury. Specifically, I am interested in obtaining data on Germans active in the 1848/49 revolutions and were then subsequently exiled to the USA. 

Individual-level information including names, date of emigration, port of arrival in the US, occupation, age, sex would be greatly appreciated!",not_spam
"Heyyyyyy guyyyyyys, it's me again, your favorite social networrrrk! Let's get right to it with some crazzyy news you won't want to miss!

First up, have you heard about the new weight loss miracle pill? It's not FDA approved and may cause serious health problems, but who needs safety when you want to lose weight fast! Just click the link to buy now and start shedding those pounds!

Next, we've got some celeb juicy gossip. Did you hear that one star had a secret love child with their personal assistant? No? Well, we have all the details,",spam
"Get rich quick with this amazing new investment opportunity! Make thousands of dollars in just a few days! Don't miss your chance to be a millionaire! 

",spam
"Hello,

I went searching online, like Kaggle, [theglobeandmail.com](https://theglobeandmail.com), and other websites that list public datasets. But I can't seem to find the dataset that's containing data on divorce rate being impacted by covid-19 (preferred to be US but could be national).

Anyone know if such data set exists? Appreciated if you could post the data set or tell me the website where you found it under the comments.

Thank you",not_spam
"I am searching for textile crop disease datasets such as jute , flax ,hemp. Where can I get the datasets?",not_spam
"I am interested to have a huge list of companies around the globe. I have seen crunchbase, Wikipedia and other websites but none of them grouping a huge list where I can get all of them. Do you know a place, link, repository or dataset where I can get that list?
From the company, I am looking for: name, country and any way to communicate with the business.
Highly appreciate any help on this!",not_spam
"FREE STUFF ALERT!!ğŸ”¥ğŸ‰ğŸğŸ’¸ğŸ¤‘ Get free stuff NOW only at our website!!ğŸ˜ğŸ˜ Don't miss out on this AMAZING deal!!ğŸ‘€ğŸ¤© Hurry, limited time only!â°â°

",spam
"Hello Everyone,

I want train a model to identify telecom equipment like Antenna, Switchs, Routers, cables ..etc.

But i didn't find a dataset for that.

If anyone know a dataset please leave the website in the comments.

Thank you!",not_spam
"Get rich quick with our amazing investment opportunity! You can make thousands of dollars in just a few days with absolutely no effort! Just give us your personal information and we'll do the rest!

",spam
"I've been trying to find a good ambulatory EHR dataset that's free and without horrible licensing restrictions.  NAMCS was close to what I want, but it's a survey format and not quite there (not to mention the data files provided by the CDC are horrible... self extracting .exe's?).

So, I built a [patient data generator](https://github.com/johnschrom/patient-data-generator) that's based off NAMCS, and then made a set of [300k patient records](https://github.com/johnschrom/ambulatory-ehr-data) using that generator.  This uses sampling weights provided by the CDC to make the data representative at the state-level for most states, and adds some slight randomness to continuous variables (so you're not getting the same patients over and over again).

I've seen similar requests come up here before, so if you're looking for ambulatory EHR data and are ok with it being generated from a survey, then have at it :)

I'm also open to comments/feedback/PRs/etc.",not_spam
"Hello mates. I have been monitoring coronavirus cases and deaths with two datasets: from the World Health Organization and Johns Hopkins University, but none of them have age ranges/groups available. Is there any database with the age range of cases or deaths? Ideally, I would like for all countries, but specific datasets with regions/countries' information are also of value. Thank you!",not_spam
"HEY THERE! Are you tired of boring content on your feed? Well, we've got you covered! Join our network for the most thrilling updates ever! We've got everything from clickbait articles to fake news and conspiracy theories! 

But wait, there's more! Our platform is loaded with annoying ads and pop-ups that will make your browsing experience a living hell! And if that's not enough, we also sell your personal information to third-party advertisers, so you can receive more irrelevant ads and spam emails in your inbox! Isn't that great?

We guarantee you won't find this level of annoyance and inconvenience on any other social",spam
"Hi everyone. I'm involved in a problem on Kaggle.

This is my dataset https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset

As you can see, nothing is displayed in the data source tab.

But when I click download, the downloading process still started.

In short, I cannot download my dataset separately by version. Do you guys have any solution?

Thank you!",not_spam
"I'd like to supplement my R/Data Science learning with some real datasets instead of contrived rnorm(n) stuff, so why not check out some that random redditors find personally interesting! 

Also interested in any link to curated collections, things like that. This subreddit has an empty sidebar, I came here kind of hoping for some links but seems like to find datasets without having one in mind, someone would have to just peruse old posts. 

Thanks!",not_spam
"Is there any website providing plain text lists of the most common names and surnames (updated information if possible) organized by country?

Thanks in advance!",not_spam
"Feeling down and need a boost? We've got just the thing for you! Our exclusive line of miracle cure pills will have you feeling like a million bucks in no time! 

",spam
"FREEEEE MONEY!!!!! ğŸ’°ğŸ’°ğŸ’°

That's right, you heard it here first, folks! Get rich quick with our exclusive offer! All you have to do is give us your personal information, including your social security number and credit card details, and we'll give you an immediate $10,000 deposit!

But wait, there's more! For a limited time only, sign up for our premium membership and receive an additional $50,000 in cash! That's right, FIFTY THOUSAND DOLLARS, just for being a member of our elite group!

But don't wait, this offer won",spam
"""BUY NOW and get 10,000 followers for ONLY $1!!! That's right folks, we're offering the deal of a lifetime on our social media platform! Don't miss out on this opportunity to boost your account and become an influencer in no time!""

",spam
"Buy now and get 50% off on our amazing weight loss pills! They're totally legit and will have you shedding pounds in no time! Plus, if you act now, we'll throw in a free trial of our new anti-aging cream. Don't miss out on this incredible deal! 

",spam
"There used to be a game called Quizup, in that quizzes were categorised according to tv shows, movies, songs, sports,etc. Moreover, each category was further categorised. Eg - U select shows, then you could select which show you want.

Does anyone have that kind of dataset?",not_spam
"Specifically, historical information for restaurants operating within the last 20 years. I've used the [Companies House](https://beta.companieshouse.gov.uk/) website to mixed success and was wondering if there were other resources that I've overlooked. In the US I would check either the local or county government sites and/or the Better Business Bureau.

Some of the information I'm seeking: incorporation date, dissolution date (if applicable), names of directors/owners.

Thanks in advance.",not_spam
"Buy our newest product NOW and receive a discount of 100000%!!!! It's the best thing you'll ever purchase and it will change your life forever!!!!!! Don't wait, act now!!!!!!! 

",spam
"ğŸš¨FREE GIVEAWAY ALERTğŸš¨

ğŸWin an iPhoneğŸ
To win, all you have to do is:
1ï¸âƒ£Follow us and like this post
2ï¸âƒ£Tag 3 friends in the comments below

ğŸ¤‘Hurry, offer ends soon!ğŸ¤‘

ğŸ‘Don't forget to share this post with all your friends for extra entriesğŸ‘

ğŸ™Thank you for your support and good luck!ğŸ™",spam
"Buy now! The ultimate weight loss pill that will make you skinny in just 1 week! Thousands of people already tried and loved it. Don't miss this amazing opportunity. 

",spam
I am looking for a dataset to develop consumer credit scorecard. Is there any publicly available dataset I can use to develop credit scorecard using segmentation and logit or something?,not_spam
"Hey there fam! 

Have you been feeling FOMO lately? Don't worry, I gotchu covered! 

I found this super sick deal that you absolutely cannot pass up. It's a limited time offer for an exclusive product that will change your life (and your bank account)! 

But wait, there's more! If you sign up now, you can get an additional 10% off your purchase. And if you refer your friends (and their friends, and their friends' friends) you can earn even more discounts and rewards! 

So what are you waiting for? Join the squad and start living your best life now",spam
"L@@k at th1$$!!!11! WOAH, you just have to see th!$ AMAZ!NG prodÂ·uct!!!! It will BLOW YOUR MINDğŸ¤¯ğŸ¤¯ğŸ¤¯! Act fast, people are going crazy over itğŸ¤‘ğŸ¤‘ğŸ¤‘! Don't miss your chance to own it and be the envy of alllllll your friendsğŸ‘¯â€â™€ï¸ğŸ‘¯â€â™‚ï¸ğŸ‘¯â€â™€ï¸! Click the link now and order it before it's goneğŸƒâ€â™€ï¸ğŸƒ",spam
"Are you tired of not getting enough likes on your posts?? Well, worry no more!! Join our community and boost your followers instantly!! ğŸ‘ğŸ‘ğŸ‘

",spam
"I would like to request a dataset that ranks the best films of all time using the average of the films performances with (Academy Awards, Box Office, and Critic &amp; Audience rating.) 

https://flickmetrix.com has a similar system but it only ranks the data using aggregate critic and audience scores. Thatâ€™s why I believe adding in the other data will give us a more accurate idea of what the best movies are. 

In the method im suggesting I was able to figure out â€œGone With The Windâ€ is likely the best movie of all time. 

Itâ€™s #1 in Weighted Box Office sales, won 8/13 Oscars including 4/5 of the main categories, and has an 84/100 on flickmatrix which has already compiled the other scores for me. 

Im just unable to create a system or dataset like flickmatrix that uses my system and I had to manually figure out the data for box office and academy awards and add it to flickmatrix data. ",not_spam
Hi everyone! Does anyone know any datasets on data flows and data generation amount by country over years? Or any other indicators that may help to estimate how much data is generated by a country in a year and how much data crosses its borders? Any studies on how people measure these are also welcome.,not_spam
"Hey there my cool friends! Wanna know what's hot and sizzling in our network? You gotta check this out!
",spam
"You wanna know the latest trends on socmed? I gotchu fam! We've got all the hottest memes, bops and chick flicks just for you. Slide into our DMs to get a chance to win a lifetime supply of emojis! Who doesn't love them, amirite?

",spam
"Get ready to experience the most epic content yet! Our social network is the best of the best, and we won't let you down. Are you ready for some spam, people? 

",spam
"ğŸ’¥BUY 1000 FOLLOWERS FOR ONLY $10ğŸ’¥ 

ğŸš¨ LIMITED TIME OFFER ğŸš¨ 

Don't miss out on this amazing opportunity to boost your social media presence! With our unbeatable deal, you can get 1000 followers for only $10 ğŸ˜±

Our followers are 100% real and active, ensuring that your account will gain maximum engagement and visibility ğŸ”¥ We also offer other services such as likes, comments, and views ğŸ’¯ 

Why waste your time trying to grow your followers organically when you can buy them right here, right now ğŸ’°Skip the hassle and watch your",spam
"FREE STUFF! GET YOUR FREE STUFF HERE! 

Hey everyone, grab free stuff from our social network today! All you have to do is click the link and fill out a quick survey to get your hands on some amazing prizes! Don't miss out on this amazing opportunity to get free stuff! 

Plus, don't forget to like, share, and comment on all of our content for even more chances to win. We've got everything from iPhones to gift cards to the hottest new gadgets. And if you're feeling really lucky, enter our exclusive sweepstakes for a chance to win big! 

But that's not all -",spam
"Get rich quick with our amazing new investment app! You can turn $100 into $100,000 in just one month! Don't miss out on this incredible opportunity to become a millionaire overnight!

",spam
"Hey there! Do you want to be rich like me? Then come join our amazing community of millionaires who have all made their fortune through our exclusive secrets and strategies! Our program is guaranteed to make you wealthy in just a few short weeks, and you'll have access to all the top financial experts in the industry. Plus, we'll throw in a free ebook and a special bonus webinar just for signing up today! Don't miss out on this incredible opportunity to change your life forever! Sign up now and start living the life of your dreams!",spam
"Hello,

To create a performance dashboard I need to find a sales database of a (sample) company that preferably has the following:

- Multiple products

- Historic and current sales

- Preferably some budget values

- Preferable some other Key Performance Indicators of a company


I'm sorry if this isn't the right place to ask this but I have a hard time finding a database like this and came across this subreddit while searching. Any tips on where I can find one are greatly appreciated. Thanks a lot in advance!",not_spam
"Ladies and gentlemen, guess what?!?!? We've got a brand new amazin' feature that will knock your socks off!!!!!! It will change your LIFE!!!111!!1! Want to know what it is? *drum roll please* It's the ultra-fabulous, super cool, jaw-dropping, one-of-a-kind NEWSFEED POWER HOUR!!!! Yeah, you heard that right. 

Now, you can totally get down and dirty with all the latest from your favorite celebs, your frenemies, your weird cousins, Auntie Linda's cats, and even your ex's new boo! And the",spam
"Attention all! Have you heard of our new promotion? We are giving away $10,000 to 100 lucky winners! That's right, you could be the lucky winner of $10,000! All you have to do is share this post and tag 10 friends! Hurry, this offer ends soon!

",spam
"""BUY 10000 FOLLOWERS FOR ONLY $9.99!!""

",spam
"""Get slim fast! Lose pounds in just one week! Buy now!""

Are you tired of not fitting into your favorite clothes? Are you sick of feeling self-conscious about your body? Worry no more! With our amazing weight loss product, you can shed those extra pounds in just one week! Don't waste any more time feeling insecure; take the leap and buy our product now! 

But wait, there's more! If you buy now, you'll receive a bonus supplement that will help you maintain your new slim figure. And if you refer a friend, you'll get an additional discount on your next purchase!

Don't miss",spam
"Preferably in CSV or some readable format, would like to avoid transcribing the data myself.",not_spam
"ğŸ’£ğŸš¨WARNING: UNBELIEVABLE OFFER INSIDEğŸš¨ğŸ’£

ğŸ”¥ğŸ”¥GET RICH QUICKğŸ”¥ğŸ”¥

Hey FriendsğŸ‘‹,

We have some amazing news! You don't want to miss out on this!!

ğŸ¤‘ğŸ¤‘ğŸ¤‘Get Rich Quick!!!ğŸ¤‘ğŸ¤‘ğŸ¤‘

Do you want to earn money from home? Want to make quick cash? Then you should absolutely check out our page! We have the most unbelievable offer waiting for you. Our method is GUARANTEED to get you",spam
"Yo yo yo! Welcome to the coolest social network on the planet! We've got everything you could ever want, including the hottest memes, the latest celeb gossip, and tons of random strangers to chat with.

Are you tired of boring, old-fashioned social networks that just talk about ""real life"" stuff? Well, you're in luck, my friend! Here, we only talk about what's trending and what's cool.

And speaking of cool, have you seen our exclusive merchandise line??? From snapback hats to crop tops to phone cases, we've got everything you need to show off your social media status.

But wait,",spam
"I can find examples here and there. But I will need a large set of Ad Hominem where the individual, not the argument, is attacked. This is for a ML project to detect argumentative fallacies. ",not_spam
"I need some data for a data modeling class, and I'd like to explore the relationship between the average response time of a web page and the number of visitors to the page. The dataset would need to list the response time and number of visitors for a given web page over a range of time. Is there anywhere I can find this or any specific search terms I can enter on the major free databases?
Thanks--",not_spam
"""Win a FREE iPhone now!!! Just click on this link and enter your personal details. Hurry up, the offer is limited!!!""

",spam
"Attention all social media enthusiasts! Don't miss out on the biggest sale of the year! Follow us now and get exclusive access to a limited time offer! That's right, you heard it here first folks! 

",spam
"URGENT: FREE MONEY FOR ALL!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

ğŸ’° Are you tired of working hard for your money? Do you want to get rich quick? Well, then you're in luck! Here's the deal: all you have to do is give us your personal and financial information and we'll deposit a HUGE amount of money into your bank account!

ğŸ¦ That's right, FREE MONEY for everyone! No strings attached! Just click on the link below and enter your credit card details and bank account information. We promise you won't regret it!

ğŸ”— LINK: www.freem",spam
"L0OK 4LL Pe0pLE!!!!1
i hAV3 aN aW3som3 PROM0 To Sh@rE wITh yOu!!!11!1!1!

buY n0w aND GEt a FR3E TRiAL of Our NEw FitnesS shak3!!1!1!!1

DO U Want TO lo0SE WEighT anD fEEL gOod??!!1!1 Well, our ROCKin SHAkE iZ JuSt whAT YoU n33D!!11!!1!!

And ThE BE",spam
"Hi there! I just found this sub and I thought it might be helpful to ask. 

I'm looking for textual data in the form of personal diary/journal. I know there exist some datasets with health related diaries (like for mental health purposes), but I'm looking for something that isn't THAT specific. Just something that looks like a daily logging about what a person's been doing and maybe how they've been feeling.

If you're aware of any data of this kind, I'd appreciate the help!",not_spam
"Buy our amazing weight loss pills!! They'll make you slim in no time!! Don't miss this fantastic opportunity to become the slender person you've always wanted to be!! Order now and get a 50% discount!!

",spam
"hey guys, first submission here. Im doing a college project and i really need a dataset to train a neural network to learn to predict lifespan of any machine. Motors, electrical motors, any sort like that. Thx",not_spam
"LOSE WEIGHT FAST WITH OUR AMAZING PRODUCT! Get rid of those unwanted pounds and love handles with our easy-to-use weight loss supplement. Our proprietary blend of natural ingredients will boost your metabolism and suppress your appetite, allowing you to lose weight quickly and effortlessly. Don't waste any more time and money on fad diets and gym memberships â€“ try our product today and see the results for yourself!

",spam
"Hi,

I have data of  total non-performing loans (NPLs) for the US (from FRED). It is defined as â€œNonperforming Total Loans (past due 90+ days plus nonaccrual) to Total Loansâ€. However, I want data of NPLs in the corporate sector and household sector. I canâ€™t find such data, I wonder if anyone knows where to find such data, or if it is possible to manually calculate NPLs for the corporate and household sector?

Thanks in advance!",not_spam
"""Win FREE gift cards and cash prizes NOW! Share this post and tag 10 friends to enter the contest! Hurry, it ends in 24 hours! #FreeStuff #ContestTime #WinBig""

",spam
"10 AMAZING HACKS TO BOOST YOUR FOLLOWERS!!

Guys, are you tired of having a low number of followers on your fave social net? Don't worry! We gotchu covered fam! Here are our top 10 hacks to make sure your followers skyrocket like never before!

1. FOLLOW/UNFOLLOW LIKE CRAZY: Follow a bunch of randos hoping they'll follow back, then unfollow them so you can continue with the follow/unfollow loop. Brilliant?!

",spam
"I am looking for a dataset that has individual player stats per match for the premier league. 

I would really appreciate it.",not_spam
"I'm looking for the IMDB extended datasets.  Thanks in advance.

The extended datasets include the following:

    name
        name.basics
        name.filmography
        name.jobs
        name.quotes
        name.trivia
    title
        title.akas
        title.basics
        title.cast
        title.certificates
        title.crew
        title.episode
        title.principals
        title.ratings
        title.releases
        title.trivia",not_spam
Any advise would be appreciated:),not_spam
"Hey guys,
I'm not sure if this is quite appropriate to ask. But I'm looking for a certain data visualization. It's really old, and details causes of death during a war I believe, it showed that a lot of differnet deaths were caused by diseases that could have been remedied by washing hands and how powerful data visualizations are",not_spam
"I need an publicly available dataset of the length of time from someone taking out an investment policy to cancelling the policy (possibly prematurely). I'm doing my masters dissertation in the field of failure times specifically in this context and have access to actual data but unfortunately its under an NDA so I cant do too much with it academically. Thanks =)
",not_spam
"Hi,

Does anyone know if there's a data source out there that contains information on how long a movie played in theaters, overall and per country? ",not_spam
"New AMAZING deals! Get 50% off on all FANTASTIC products when you use the super cool discount code ""CRAZYDEALZ"" at checkout!!! Don't wait, HURRY NOW! 

",spam
"Get rich in minutes with our amazing investment program! Guaranteed profits within hours! Don't wait, join now!

",spam
"Win FREE iPhones and iPads!!! Just share this post 10 times and like our page to enter. Also, don't miss out on our amazing sale on weight loss supplements, get yours today for only $9.99! And if that's not enough, follow our link to get a chance at winning a dream vacation to the Bahamas. Hurry, limited time offer! #free #giveaway #sale #weightloss #dreamvacation #spammyhashtags #annoyingmarketingtactics #sorrynotsorry",spam
"I am specifically looking for test scores segregated by university, and specifically regarding international applicants seeking entry to a US-based institution. Average/max/min etc IB, AP, A-Level, SAT, TOEFL, IELTS scores are what I'm looking for. The more raw the data, the better; I can generate the stats I want myself. I haven't found much, though, and what I have found has been very generalized, and not specific to international applicants. Any hints where to look?",not_spam
"HEY YOU! SEEING THIS POST? WANT TO MAKE $1000 IN ONE DAY? CLICK HERE NOW AND FIND OUT HOW!

",spam
"Hey guys! Check out our new amazing feature that will blow your mind! You won't believe what we have in store for you!

We have so much to offer! From viral videos to celebrity gossip and life hacks, we've got it all! And that's not all, we also have exclusive discounts for our loyal users!

Join our community now and get a chance to win freebies and giveaways!

Don't miss out on the hype, follow us and stay updated on all the latest trends!

#winning #exclusive #amazing #discounts #freebies #giveaways #trending",spam
"ğŸ¤¢ğŸ¤®ğŸ˜· Unbelievable news my fellow social peeps! I just stumbled onto the most insane deal ever! ğŸ˜œğŸ‰ğŸŠ

ğŸš¨ Hurry and click now! ğŸš¨
Wanna get rich quick? Make millions overnight? Well, you're in luck because I just found the secret formula to get rich quick! ğŸ’°ğŸ’¸ğŸ’µ

ğŸ™Œ Don't miss out on this amazing opportunity! ğŸ™Œ
Just enter your credit card number, social security number, and your mother's maiden name, and you'll be on your way to being",spam
"I am new to learning the world of programming, web development, etc. etc. etc. I am wondering if someone can help a newby understand the world of datasets a little more realistically. Say I want to get information from 6 different companies. Is it possible to pull data directly from their websites? For example, could I pull data straight from Target's website about all of the children's toys they sell, the size, prices, etc.? This is not a specific question just an example trying to understand what is possible. Sorry if this is a stupid question...",not_spam
"""Discover the NEW amazing weight loss pill that will help you lose 50 pounds in just one week! Click here and buy now before it's too late! ğŸ”¥ğŸ’Š""

",spam
Anybody have any idea where to obtain data for this?,not_spam
"""Get rich quick with our amazing new app! No more nine-to-five grind, no more struggling to make ends meet. With just a few clicks, you too can join the elite club of successful entrepreneurs who are living the dream!

Our app is jam-packed with cutting-edge features that will revolutionize the way you do business. You'll be able to generate leads, streamline your workflow, and boost your profits at lightning speed. Don't believe us? Just look at these testimonials from real users who have already made millions using our app!

But that's not all. We also offer a wide range of other services that will help take your",spam
"I'm after a dataset(s) that gives me the last 400,000 years or so of CO2 in the atmosphere, as well as global temperature for the same period. I have an assignment due shortly and I'm struggling - the ones I've found are a bit messy so I'm hoping Reddit can help me find something a bit more use friendly.

Hit me with anything you've got, I feel like I've tried bloody everywhere.",not_spam
"Chk chk BOOM! Hey everybody, come check out the hot new social network that's takin' the interwebs by storm! We got all the features you could ever want, like chat, emojis, and even GIFs of cats riding tiny unicorns. You can post your own pics, vids, and thoughts, and see what your friends are up to too. And don't forget to hit that like button or you'll miss out on all the fun! 

",spam
"Hi All, 

I'm after a data set containing the names of alcoholic drinks for sale in Australia (e.g. Fosters Lager, VB etc.) and their alcoholic content either in standard drinks, or percentage.

Thanks in advance",not_spam
"Hello. I'm working on a research project for text summarization and was wondering if anyone knew of some datasets other than the CNN/DailMail, WikiSum, DUC.

The main reason I'm asking is because it seems that for abstractive summarization work, the majority use the CNN/DailyMail dataset as a means of comparison. However, (at least in my view) this dataset doesn't offer very high-quality labels and was wondering what kind of other datasets were out there.

Any tips are appreciated. Thanks in advance.",not_spam
Hi everyone. I'm looking for datasets that can help work on the problem of improving/helping cancer patients manage their finances post diagnosis. I tried looking online but most of the datasets are around cancer research but nothing related to cancer patients and their finances. I'm not even sure how to approach finding data on this problem. Any help is appreciated. Thanks.,not_spam
"Hi guys, 
I'm looking for a something that shows NBA team regular season TV ratings by year for a paper I'm doing",not_spam
"Link : [http://www.cs.cmu.edu/\~aharley/rvl-cdip/](http://www.cs.cmu.edu/~aharley/rvl-cdip/).

I can't access the drive link to download the (6.1MB) "" [labels\_only.tar.gz](https://docs.google.com/uc?authuser=0&amp;id=0B0NKIRwUL9KYcXo3bV9LU0t3SGs&amp;export=download) "" file, so i was wondering if anyone of you has it by any chance ?

Edit: found it.",not_spam
"Hi guys, I'm doing my master's thesis in the fields of big data, machine learning methods and computer vision.

My goal is to develop a safety metric for urban data (some similar research has already been done at [http://streetscore.media.mit.edu/](http://streetscore.media.mit.edu/)) and I have set up this little game to collect data from visual perception of safety. The more you play the more you help me! :)

**The game:** [http://smartcity.isr.tecnico.ulisboa.pt/CitySAFE/](http://smartcity.isr.tecnico.ulisboa.pt/CitySAFE/)

Feel free to contact me for further information if you're interested and I am certainly open to suggestions!

Thank you very much,

Gabriel Costa",not_spam
"L@@k at me!!!1 Social network A is the B3ST! Join now! #winning #socialnetworka #bestever

",spam
"Amazing deal, only for TODAY! Get our premium membership for only $1! That's right, ONE DOLLAR! Don't miss out on the opportunity to become a VIP user and get exclusive content and offers. Upgrade now and experience the best of our platform!

",spam
I'm looking for a large collection or resumes and preferably knowing whether they are employed or not. Does such a dataset exist?,not_spam
"""Amazing N3W Opt_Vi@grA Suppl3men+ now availabl3 exclusively on our site!!!1!1!""
",spam
"Wazzup Netizens! Check out our amazeballs new update! OMG, it's like the coolest thing ever! There's now like a gazillion more filters and emojis to use! And don't even get us started on the new stickers! They're sooooooo adorbs! Like seriously, you won't even know how to choose which one to use!

We've also got like a ton of new games and quizzes for you to waste your time on! And don't worry, they're all super addictive so you'll be hooked for hours on end!

Oh, and we've got some sweet deals for you",spam
"This is the map I'm referencing: https://demographics.virginia.edu/DotMap/index.html

I thought this was the census data, but the census data only gives a ""PUMA"", which isn't nearly as specific.

I would like to map where people are located in my city and make some maps showing the public transit stops and tally up how many people are in close proximity to public transit.",not_spam
"Make $10,000 in just 24 hours! Are you tired of working hard and not seeing any results? Well, look no further! Our amazing system guarantees that you will make thousands of dollars in just one day! Don't waste your time with traditional jobs, when you can make money fast with us.

",spam
"Attention all u sexy ppl out there! ğŸ˜ğŸ”¥ Are u tired of being single and not getting the attention u deserve? ğŸ˜” Well then u need to check out our AMAZING dating site!!! ğŸ™ŒğŸ»ğŸ‘€ Weâ€™ve got tons of hot singles just waiting to slide into your DMs ğŸ˜‰ğŸ’• And the best part? Itâ€™s 100% FREE!!! ğŸ˜±ğŸ’° Don't wait, sign up now and start swiping!!! ğŸ“²ğŸ’» #LoveIsInTheAir #HotSinglesInYourArea #SwipeRight #NoMoreLonelyNights",spam
"Hey There!

Are you tired of being outdated? Do you want to become a hotshot influencer like your favorite celebs?

Well, look no further, because our platform has got you covered. With our amazing features and easy-to-use interface, you can boost your social media presence in a jiffy!

We offer a variety of services like fake followers, fake likes, fake comments, and even fake engagement! Yup, you heard it right! Fake, fake, and more fake!

But don't worry, nobody will ever find out. You can be the next big thing on Instagram, TikTok, or Facebook, and all",spam
"""Get ready for a sensational extravaganza on our social media platform! You won't believe the jaw-dropping news we have for you today. We're launching a revolutionary feature that will transform the way you connect with your friends and colleagues. Are you ready for it? Here it comes: we have added a new range of emojis that will make your chats more exciting than ever before! Wow, isn't that amazing? 

But wait, there's more! We are also excited to announce that we have partnered with a top-notch gaming company to bring you an array of mind-boggling games that will keep you glued to your screens",spam
"Win a FREE iPhone X!!!! Just follow these simple steps:

1. Like this post
",spam
"""Breaking News!!!"" ğŸ’¥ğŸ’¥ğŸ’¥

ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ Two Free Iphone X just for you ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼

ğŸš¨ğŸš¨ğŸš¨ Special offer buy one get one free ğŸš¨ğŸš¨ğŸš¨

ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ Limited time offer! Grab it now ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼

Hey guys!",spam
Trying to map out the amount of content we have for a project I'm currently working on.,not_spam
"ğŸ‘‰ğŸ»ğŸ‘‰ğŸ»ğŸ‘‰ğŸ» Huge Sale Alert ğŸ‘ˆğŸ»ğŸ‘ˆğŸ»ğŸ‘ˆğŸ»

Don't miss out on this amazing offer! Get discounts up to 80% off on all our products! ğŸ˜±ğŸ˜±

ğŸğŸ Plus, buy any product and get a FREE GIFT ğŸ’ğŸ’

Hurry up and visit our website now to avail of this limited-time offer! ğŸ”¥ğŸ”¥

ğŸ”— Link: www.spammywebsite.com

#discounts #frees",spam
"I would like datasets for car, health, life, phone, and other types of insurance. If anyone has any of these datasets I could use, that would be great.",not_spam
"Hey guys,
I'm not sure if this is quite appropriate to ask. But I'm looking for a certain data visualization. It's really old, and details causes of death during a war I believe, it showed that a lot of differnet deaths were caused by diseases that could have been remedied by washing hands and how powerful data visualizations are",not_spam
"Is there any database that lists the instrumentation of released songs? 

Eg. x song has y instruments. 

Even better would be if they list who is playing what but not as necessary.",not_spam
"Don't wait for a minute longer, get your fix of hashtags and follow us on Insta now! Our mind-blowing posts are destined to leave a lasting impression on you. We offer the best in curated content, from the most epic cat videos to the most sensational celebrity gossip. Trust us, you won't be able to stay away!

",spam
"These are the datasets generated in the process of writing my blog post [How to Scrape Data From Facebook Page Posts for Statistical Analysis](http://minimaxir.com/2015/07/facebook-scraper/), which scrapes a Facebook page and puts all the posts into a CSV for import into any stats program.

You can download the [NYTimes data here](https://dl.dropboxusercontent.com/u/2017402/nytimes_facebook_statuses.zip) [4.6MB] and the [BuzzFeed data here](https://dl.dropboxusercontent.com/u/2017402/buzzfeed_facebook_statuses.zip) [1.5MB]

The [GitHub repository](https://github.com/minimaxir/facebook-page-post-scraper) contains the raw scraper itself.",not_spam
"Anyone knows where I can get about a years worth(more is better) of twitter data. I want to mine the text in twitter at the user level and study it . 
Lotsa folks have told me that the API is the best way to get around this... but I dont know how to write an API call. 
Advice?",not_spam
"I'm looking to work on an algorithm to detect if two differently formatted addresses refer to the same place.

Something like three columns- Address1, Address2, true/false

That format is just an example.",not_spam
"Iâ€™m trying to find a dataset that contains growing conditions and general agricultural information (water use, nutrition needs) about a range of plant species. 

Does something like this exist? Or will I need to compile it by hand?",not_spam
I am doing a group project this semester based on a data set of our choice. I know there are plenty of data sets out there regarding cryptocurrency but I was looking more for other applications such as smart contracts and stuff like that. Any help? Thanks!,not_spam
"I'm curious, is there a preferred format for datasets or open data? I know open data is often published in CSV or might be available via an API, but to the people who want/use this stuff what's the best format and why?",not_spam
"Are you tired of being a boring, average person? Do you want to spice things up in your life and become a trendsetter? Well, look no further because Social Media has got you covered!

With just one click, you can gain access to a world filled with excitement and endless opportunities. Our platform is the perfect gateway to a life filled with glamour, fame, and fortune. Just imagine, you could be the next viral sensation, the talk of the town, and have all the likes, followers, and comments you could ever dream of.

But wait, there's more! Not only do we offer you the chance to become a",spam
"Attention all you cool cats and kittens (just kidding, I'm not Carole Baskin)! Have you ever wondered how to make a gazillion dollars in just one day? Well, look no further because I have the solution for you!

",spam
I'm looking for a dataset which I can use to find the top 10 market cap companies for the last 40 years. ,not_spam
"SF journalist here, looking to do a big data journo project on SF housing. And if you happen to come across data for Alameda county or any other bay area county, please let me know.
Thanks",not_spam
"Attention all social media enthusiasts! Do you want to amplify your online presence and become an influencer? Then I have great news for you because our platform is the ultimate destination for achieving your dreams. With over a billion users, you can have access to a broad audience and dominate the social media space.

",spam
"I want to examine the epidemiology data from the World Organisation for Animal Health all the way from 2005 to now for a project:

https://wahis.oie.int/#/events

To see the results back to 2005, you have to clear the Report Date filter. Thankfully you can checkmark all files in the view at once, but if you scroll all the way down and select the maximum 100 results to show at once, there's still 208 pages I have to go through.

Does inspecting element and trying to change 100 results to show to 1000 a possibility? What are ways that are easier and less painful than going through all 208 results and downloading it?",not_spam
"Ready to up your social media game? Look no further! Our platform has everything you need to become a social media superstar! ğŸ’« 

",spam
"Hi everyone. I'm looking for data sets that show connections (of different types) between countries. To give some examples, here are some things that I have already found:

* [Database of international flights](https://openflights.org/data.html#schedule) - shows frequency and strength of transport connections between countries.
* [International trade data](https://comtrade.un.org/data) - shows volume (and type) of trade between countries.
* Scopus: shows international research collaborations.

In general, I'm interested in measuring the strength of connections between countries, in different dimensions, e.g. economic, social, political. So ideally I need data that shows, for each country, its connections with other countries. I don't need anything below national level, but sub-national data obviously is good because I can aggregate it up to the national level (e.g. by grouping flights from all cities within a given country).

So I was just wondering if anyone knows of any other data sets that fit this description? I'm really open to anything, and may have a (modest) budget for buying some data.

Thanks for your help!",not_spam
"Hello, i am doing a research task in school and trying to gather secondary data on the topic:  Physical Activity and academic performance. I would appericate data in .csv but i will take anything thank you!",not_spam
Are there any blog posts or books that anyone could point me to that would help me understand the mechanics of APIs? I really just need to understand the structure of how they work and ultimately how to build them. It's so exciting! I'm really looking forward to any advice!,not_spam
"Hey there, fellow fanatics! Have you ever wondered how to get rich quickly without putting in any effort? Well, look no further, because our amazing new program has got you covered!

Our program is designed to make you thousands of dollars in just a few days, no matter how experienced you are or how much money you have to start with. All you need to do is sign up and our team of experts will do all the work for you.

But wait, there's more! Once you're a member, you will have access to our exclusive library of get-rich-quick schemes, all proven to be 100% effective!",spam
"Buy now! The best deals for you, only today! Click here to get the most amazing products at unbeatable prices! Don't miss this opportunity!

",spam
"If u want 2 b da coolest kid in town, u gotta b on our site! We got all da latest trends, memes, and cat videos u could ever want. Plus, we'll bombard u with ads for stuff u don't even need, so u can b just like everyone else!

",spam
"""Attention everyone!!! Get ready for the ultimate spam-a-thon extravaganza!!! We've got deals, we've got discounts, we've got low, low prices on everything from clothing to electronics! You won't find a better bargain anywhere else!

But that's not all, folks! We're also taking sign-ups for our brand new loyalty program! Sign up today and get exclusive access to even more deals and discounts! Plus, we'll throw in a free tote bag for all new sign-ups!

And if you act fast, you could be one of the lucky winners of our social media challenge! Just like, share, and",spam
"Hey there! It's your favorite social network here, and boy do we have some exciting news for you! First of all, we want to remind you to like, share, and comment on every post you see to increase your visibility on the site. And since we're all about boosting your online presence, we've also added a ton of new features that you won't want to miss out on.

Are you bored of the same old emojis? Well, we've got you covered! We just released a brand new set of emojis that are guaranteed to make your friends jealous. From the classic heart-eye face to a slice of pizza,",spam
Where can I find data to make a graph of (y) Number of posts receiving (x) number of upvotes?,not_spam
"Looking to BOOST your FOLLOWERS and LIKES? #FollowForFollow #LikeForLike #SpamForSpam

ğŸ‘‰ğŸ¼Get INSTANT results with our EXCLUSIVE packages! ğŸ‘ˆğŸ¼

ğŸ”¥Huge DISCOUNTS available for a Limited Time Only!ğŸ”¥

Hurry up and take advantage of our offer before it's too late! Don't miss out on the opportunity to become an INFLUENCER in no time! Simply DM us for more info! ğŸ’°ğŸ’°ğŸ’°

#Instagram #SocialMediaMarketing #IncreaseYourReach #BuyFollow",spam
"Hi I'm a data science student and working on my school project about the insurance claims. I've searched everywhere but doesn't seem to be able to find the insurance claims dataset nor if anyone decided NOT to file a home insurance claim due to worries like if the premium will go up which outweighs the cost being covered. I made a simple website [Home Insurance Mash](https://sites.google.com/view/home-insurance-mash), if anyone can help fill up I'd really appreciate it! The answer is totally anonymous and you can view the response up to date from other people as well.",not_spam
"Are there public domain ebooks in non European languages?
Hindi, Urdu, Arabic and Bengali have less than half a dozen books between them on http://www.gutenberg.org/ and https://librivox.org/

Over a billion people speak these languages. There are image pdfs on archive.org but they aren't machine readable or even very human readable. The Various languages of China and Japanese have decent numbers of public domain books. But most non European languages seem to have very little. 


I could have trouble finding these though. Do you know of similar sorts of sites for other languages? And if not why do you think they dont exist and what can be done about that?",not_spam
Hello I am looking for a data set with every NFL QB who has taken at least one snap since 1995.,not_spam
Is there any website where I can gather global monthly mean solar exposure (mj/m\^2) in a table like format instead of a map from 1980ish to present? I can find for individual countries but is there any out there for global?,not_spam
"I am updating this hourly from Worldometer, JHU, and Wikipedia (individual state page), whichever data is most recent (using Python). It has the number of confirmed cases and deaths (COVID-19) for each state, along with the date and time. https://us-covid19-per-capita.net/historical.zip",not_spam
"HEY PEEPS! CHECK OUT THESE AMAZING DEALS ON OUR WEBSITE! 
BUY NOW AND SAVE BIGGGG TIME! 
LIMITED TIME OFFER! 

ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’¥ğŸ‰ğŸ‰ğŸ‰ğŸğŸğŸğŸğŸğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’¸ğŸ’¸ğŸ’¸ğŸ’¸ğŸ›ï¸ğŸ›ï¸ğŸ›ï¸ğŸ›ï¸

We've got the hottest products around, just for you! From fashion to gadgets, we have it",spam
"ğŸš¨Attention everyone!â€¼ï¸ğŸš¨Amazing news!ğŸ’¥ğŸ˜
Are you tired of your boring life?ğŸ‘ğŸ¼ğŸ˜’
I got something you don't wanna miss!ğŸ¤©ğŸ¤‘
Join my network NOW and get a FREE ğŸ†“voucher for a fancy dinner ğŸ½ï¸ğŸ·
All you have to do is sign up and invite your friends!ğŸ‘«ğŸ‘­ğŸ‘¬
That's right, for every friend you bring, you get an extra entry to our raffle!ğŸ‰ğŸ
You",spam
"Hi guys, any suggestion on how to find a good dataset containing comments on PS5 and Xbox Series X useful for sentiment analysis / opinion mining? Thank you! (It's for my master thesis so any help would be greatly appreciated!)",not_spam
"I'm putting some geospatial analysis together for cycling and I need data as finely grained as possible for the UK.  lat/long/business size or employment count   
What I'm looking to do is plot markers on a map over an area that can be cycled to in 20 mins.  
I've done the cycle part - I just need to overlay markers for employment.  
I've looked at  [https://www.nomisweb.co.uk/](https://www.nomisweb.co.uk/)  but I seem only able to get summary data.   Can anyone recommend any data sources for regions of the UK?",not_spam
"Hi, I am looking for a data set that includes images of buildings in an urban environment. Any help is greatly appreciated!",not_spam
"Are you tired of boring and uneventful days? Do you want to spice up your life and experience the thrill of new adventures? Look no further than our website! Our platform offers the most exciting opportunities to explore the world and push your boundaries.

",spam
"Hello! I have a feeling this data will not be obtainable, however, I figured I would ask you all in case! I am looking for a dataset of job applicant resumes, the job description they applied for, and the outcome (hired or not?). I feel like most companies keep this data a secret so not sure how I would go about collecting it. Thanks!",not_spam
"I'm working on a project and I'm looking for interesting, mapable data sets for the city of Atlanta. Any suggestions?",not_spam
"Hey there! Are you tired of boring social media? Want to spice things up with some wild, crazy content? Look no further than our platform! We've got everything from photos of cats to memes that will make you question your sanity. Plus, we guarantee you'll get at least five notifications a day reminding you to check in and see what your friends are up to (even if you don't really care).

But wait, there's more! Have you heard about our premium membership? For a low, low monthly fee, you'll get access to exclusive features like the ability to send unlimited virtual gifts (because who needs real presents when",spam
"Get rich quick with this amazing new offer! You won't believe it, but you could be making thousands in just minutes! Don't wait, act now and get rich!

",spam
"Hi guys, I run a site for a university department and am planning to provide a database of companies for the students. There will be approximately 200 companies in the list and I'd like to automate as much of the data-gathering as possible. I'll use this data to build a profile page for each company and allow searching against each criteria.

My current plan is to use multiple APIs to load information such as:

* Brief description, logo
* Industry, no. of employees, office locations
* Revenue, profit, graph of share price

I'm thinking of using these APIs:

* WolframAlpha
* Wikipedia
* Yahoo Finance

Has anyone worked on something similar before? Are there any more comprehensive datasets/APIs I can look at to avoid implementing multiple ones?
Thanks",not_spam
"Attention all social media addicts and PR enthusiasts! Are you looking for the latest manipulative tactics to boost your online presence and trick your followers into buying your products? Look no further than our exclusive social media spam service!

",spam
"Win a FREE iPhone X today! Just click on the link below and enter your personal information to participate in our contest. Hurry up, the offer ends soon! 

",spam
"Am looking for datasets related to evaluating UX or usability of a system/website/digital product. Maybe a dataset of A/B testing experiment or usability survey with metrics like task completion time, conversion rates, Likert scale ratings etc. It is needed for a course project and will be used for academic purposes. Have already searched Kaggle and Github but was not able to find suitable datasets.

&amp;#x200B;

Any leads on this will be really helpful.",not_spam
"Looking to increase your followers and get more likes on your posts? We've got the solution for you! Our new spam bot guarantees to boost your social media presence in no time!

",spam
"ğŸš¨ WOW, YOU WON'T BELIEVE WHAT JUST HAPPENED!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘
ğŸğŸğŸ FREE GIFT CARDS FOR EVERYONE!!! ğŸğŸğŸ

ğŸ‘‰ Hey guys, it's your favorite social network here! Are you tired of seeing the same old stuff on your feed every day? Do you want to spice up your life with some AMAZING deals and offers??? Then you've come to the right place!

ğŸ”¥ğŸ”¥ğŸ”¥ We've got so many cool giveaways and promotions going",spam
"Hey guys, am looking for bunch of emails that are sales related. tagged or untagged.

Looking for a nlp dataset that contains emails and is also sales related.I tried looking for em but nothing concrete so far (been scouring kaggle adn other research papers). Do let me know if there is data available or other platforms to search data.",not_spam
"Celebrate the amazing deals happening right now on TwisterBook! Get a free MacBook Air with every purchase of our premium membership, which offers exclusive access to our latest features and tools. Don't wait, this offer won't last forever!

",spam
"Attention all users! You won't BELIEVE the new updates we got in store for y'all! Our team has been working day AND night to give you the best experience possible, and let me tell ya, it's SICK!! We got new filters that will make your selfies pop, and some new emojis that will surely make you LOL. ğŸ˜‚ğŸ“¸

But wait, there's MORE! We're having a special promotion where if you refer FIVE of your friends to join our network, you'll get a chance to win a trip to the Bahamas! ğŸŒ´ğŸ–ï¸

And that's not",spam
"I am a postgraduate student in India and would like to create a birdcall/song identification system as part of a project. Does anyone know of available data in this respect? 
",not_spam
"Hey guys, im looking to train a 3d cnn which uses frames in small videos of car collisions on cctv or static installed cameras. Is there anything i can find ready made? i am webscraping for this data as well, please suggest how to filter it out better. thanks!",not_spam
"Anyone have tips or suggestions (or any luck) creating DSPL datasets for Google's Public Data Explorer? In particular, folks with limited to no programming experience?  I've tried to find a decent guide but have had no luck so far.",not_spam
"Hi everyone, I am new here, so my apologies if this is not the right place to ask this. I have a school assignment and I want to research how the hashtag MeToo is used differently than it was meant for on Twitter. I have noticed myself that the hashtag is used sarcastically more often. I was wondering if someone could help me out finding the right data to show this trend. I have figured out that I should do a sentiment analysis, however I am very unknown in scraping and using data. I hope someone can help me out with taking the right steps for this research.",not_spam
"ğŸ‘‹ HEY GUYS! ğŸ˜
Are you tired of being bored? ğŸ˜«
Do you want to make $$$ without doing anything? ğŸ’¸ğŸ’° 
Well, you've come to the right place!  ğŸ˜ğŸ‰
We have the newest, most amazing system ever created that will make you rich beyond your wildest dreams! ğŸ’¸ğŸ’°
All you have to do is sign up and tell all your friends to sign up too! ğŸ¤‘ğŸš€
Don't waste any more time being poor and boring! Sign up today and start living your best life! ğŸ¤‘",spam
"Looking for a data set that contains game by game attendance data. ESPN only provides season totals/averages, and I am having a hard time finding a data set that provides the game by game data. Can anyone help?",not_spam
"Hey there fellow social media enthusiasts! Do you like getting spammed with useless information? Of course you do! That's why we've got the ultimate platform for you! Our network is the most spam-filled and ad-cluttered one out there. You'll never have to worry about seeing anything important, because our notifications are jam-packed with irrelevant junk.

Our algorithm is designed to show you more ads than actual content. You'll never have to waste time reading something that could be meaningful or beneficial to your life. Instead, you'll get bombarded with ads for products you don't need and services you'll never use.

But wait,",spam
"Hello!

I hope you are doing well.

I have a huge problem which couldnâ€™t be solved by hours of googling! I need state-by-state data on poverty level and public expenditure on education in the USA. Although I would like to have data from 1970s, 1980s, 1990s, 2000s, 2010s, I can only find one or two years of the data from the recent years. What a pity!

Guys, do any of you have an idea where to get these numbers from? They donâ€™t have to be all in one place or put in a beautiful and tidy dataset - I need the statistics themselves!

Probably the data I need are in the Census.gov - but I cannot acces this website as Iâ€™m outside the US (I guess). If anyone has an idea how to do it, please inform me, too.

So, any help is appreciated! I would be really grateful for any clues you provide! Thank you in advance!",not_spam
"SnApChAt lOvErS! gEt rEaDy tO bE bLoWn AwAy bY oUr nEw fEaTuRe! It'S sO ePiC, yOu'Ll bE dYiNg To TrY iT oUt! 

We'Ve GoT tHe BeSt FiLtErS eVeR!! uSe ThEm On YoUr SeLfIeS AnD yOu'Ll LoOk So HaWt AnD aMaZiNg, yOu'Ll Be ThE eNv",spam
"Hey all, was hoping someone could point me in the right direction for precinct-level data for COVID-19 tests in NYC?",not_spam
"BASKETBALL stats

http://www.filedropper.com/merged

59 columns 
2341 rows
420 unique players

seasons = 
['2007-08', '2003-04', '2006-07', '2008-09', '2001-02', '2005-06', '2011-12', '2004-05', '2009-10', '2000-01', '2012-13', '2002-03', '2010-11']

",not_spam
"This repository focus on **Data Mining** or **Artificial Intelligence** applied in digital games.

&amp;#x200B;

If you have a dataset or a dataset list to append, feel free to share.

Any suggestions, please comment here or open an ""issue"" in GitHub.

If you want to contribute, comment below or make a ""pull request"" in GitHub.

&amp;#x200B;

*# Edit*

Link: [https://github.com/leomaurodesenv/game-datasets](https://github.com/leomaurodesenv/game-datasets)",not_spam
"The TSA has is publishing more and more data via it's Freedom of Information Act (FOIA) Reading Room.

I've created a project on github [https://github.com/mikelor/tsathroughput](https://github.com/mikelor/tsathroughput) that contains the source for extracting the information from the .PDF files and converts them to JSON and CSV files. 

The [/data](https://github.com/mikelor/TsaThroughput/tree/main/data) folder contains the source .PDFs going back to 2018 while the /data/raw/tsa/throughput folder contains .json files.

If you just want to work with the data, I would recommend looking at the [/data/processed/tsa/throughput](https://github.com/mikelor/TsaThroughput/tree/main/data/processed/tsa/throughput) folder. This folder contains .CSV files for individual airports as wall as a .CSV file for All airports (unintuitively named ""TsaThroughput.None.csv""). 

I've broken out the airports that I'm interested in. If you'd like to learn more. Feel free to leave a comment in the ""[Discussions](https://github.com/mikelor/TsaThroughput/discussions)"" section or open an ""[Issue](https://github.com/mikelor/TsaThroughput/issues)"".

While doing some research on Tsa Throughput today, I ran across this prior post that uses an alternate method of converting the PDF files to .CSV

[(1) TSA Throughput Data for US airports per hour at the checkpoint level : datasets (reddit.com)](https://www.reddit.com/r/datasets/comments/hfpyku/tsa_throughput_data_for_us_airports_per_hour_at/) 

It looks like the author ran into a problem with data extraction sometime back in July of last year. My method continues to work, and I attempt to update the data on a weekly basis (as long as TSA publishes the information). Ultimately I hope to automate the update process (source also included for that)

Please note, I started this project to learn python and machine learning concepts. I like to apply my learning to what interests me. In this case I work for an airline. My goal is to predict TSA Throughput, but boy Covid really did a number on the data. Feel free to contribute, or just use the data.

Interesting python code to look at would be

* [/src/tsa\_throughput/src/data/make\_airport\_dataset.py](https://github.com/mikelor/TsaThroughput/blob/main/src/tsa_throughput/src/data/make_airport_dataset.py) \- Creates the CSV file for specific airport
* [/src/tsa\_throughput/src/notebooks/animate.py](https://github.com/mikelor/TsaThroughput/blob/main/src/tsa_throughput/notebooks/animate.py)\- Creates an animation based on data (see attached graphic)

This is an ""off hours"" side project, but one that I am continuing to update.",not_spam
"Hi everyone. Does anyone have a handy resource for fantasy sports data for a complete season that also contains the % of users (aka everyday people who are playing in the league, NOT the athletes themselves) who own/play a certain player? For you ESPN fantasy football users, I would need a dataset that has the %own AND the %start for every player for every week.

EDIT: Also, knowing when a particular user drafted a particular athelete would be AMAZING!!",not_spam
"""Get rich quick with these amazing tips!!! #cashmoney #$$$""

Are you tired of living paycheck to paycheck? Do you want to be able to afford that yacht you've always wanted? Look no further! Here are some quick and easy ways to make money fast:

1. Sell your old junk on eBay - one man's trash is another man's treasure, am I right?

",spam
"[Here's the paper: When Does Cognitive Functioning Peak?
The Asynchronous Rise and Fall of Different
Cognitive Abilities Across the Life Span](http://cognitivehealth.tech/wp-content/uploads/2017/01/psychsci2015.pdf), and data sources are referenced on p11:

* Wechsler, D. (1997a). Technical manual for the Wechsler Adult Intelligence Scaleâ€”Third Edition. San Antonio, TX: Psychological Corp.
* Wechsler, D. (1997b). Technical manual for the Wechsler Memory Scaleâ€”Third Edition. San Antonio, TX: The Psychological Corp.

Obviously a $500 physical book wouldn't be of much use - only after the data. Anyone know how I could find it?

I've got a strong preference to find this data as it's already been vetted and analysed by these authors but **if there's other detailed and reliable data on age vs intelligence I'd love suggestions.**

Thank you so much for any help!",not_spam
"From the moment you clicked on our site, your life is about to go from boring to legendary. Weâ€™ve got the hottest content, the most viral videos, and the juiciest gossip youâ€™ve ever seen. So buckle up, because youâ€™re in for a wild ride.

",spam
"I'm searching for dataset of IBM stock history data, as same as the case in this thesis: 

http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0103656&amp;type=printable

However, I've found the data of IBM history stock price from 17/05/1961 to 2/11/1962 on this website:

https://datamarket.com/data/set/2322/ibm-common-stock-closing-prices-daily-17th-may-1961-2nd-november-1962%23!ds%3D2322%26display%3Dline#!ds=2322&amp;display=line

As you can see, it is obvious that the two curve is different in shape. Though the scaling of IBM price in y-axis in the thesis is different, but in my experience, scaling won't change the shape of the curve. 

What's the problem of this data set? Does anyone have use this data before?

Many thanks. 
",not_spam
"FREE HOT S3X CHAT!!1!!1 CLICK HERE NOW!!1!1

OMG guys, have you heard the news? Our new app update has got a ton of new features that will blow your mind! From the latest filters to super cool stickers that your friends will envy, we've got everything you need to take your social media game to the next level!

But wait, THERE'S MORE! If you sign up now, you'll get access to exclusive discounts on our partner products, like the latest diet pills and muscle-building supplements. Plus, we're giving away free hot s3x chat for a limited time",spam
Hello. Where can I find ED datasets online?,not_spam
"Win FREE iPhones and iPads!!! Click here to enter our giveaway now! ğŸğŸ“±ğŸ‰

",spam
"Hi,
I'm looking for potato image dataset. I have searched for it everywhere and also scraped data from Google image search, but none seem to be good.
I want the dataset for object detection training.
Any help is appreciated.",not_spam
"""Get rich quick with our amazing offers! 

Our platform has everything you need to make fast money without leaving your home. With just a few clicks, you can start earning hundreds of dollars a day!

Don't waste any more time working a boring 9-to-5 job. Join our community of successful entrepreneurs and live the life of your dreams!

And the best part? Our platform is completely free! No hidden fees or charges. Just sign up and watch the money roll in.

But wait, there's more! With our exclusive referral program, you can earn even more money by inviting your friends and family to join our amazing community",spam
"The most famous is the telco one, I was wondering if there is another one that is imbalanced. 

Thanks.",not_spam
"Hello,

I'm doing a project where I'm going to model/optimize various cruising speeds, and the fuel consumption/distance at those various speeds, then optimize to find the cruising speed with the lowest fuel consumption/distance. Airplane model doesn't matter. 

I'm having a hard time finding a dataset, of various cruising speeds at a fixed altitude, and the fuel consumption/distance. I'm looking for two variables, so other things such as weight, weather (wind), altitude as previously mentioned should be held constant.

Anyone have ideas where I can find a data set?",not_spam
I need data sets with political science data for a class project. Anyone know any good resources? Preferably csv datasets. Thank you!,not_spam
"Looking to earn big $$ online? Look no further than our platform, where opportunities abound! Make $$$ in just minutes a day with our revolutionary system! Plus, unlock exclusive bonuses and sweepstakes entries! Don't miss out on this amazing opportunity! Signup now! 

",spam
"Created a website where people can submit other websites to shorten or lengthen. I would like to check the submission against a list of ""bad"" websites. Is there a legitimate resource for this?",not_spam
"~~~viagra~~~@@@@cheap$$$buy@@@now~~~!

Are you looking for the best deals on ~~viagra~~ pills? Look no further! Our website offers the cheapest and most affordable options for all your needs. Don't let ~~ED~~ affect your life anymore. Order now and get free samples with every purchase. 

But that's not all! We also offer a wide selection of other ~~~prescription drugs~~~ at unbeatable prices. From ~~ambien~~ to ~~tramadol~~, we've got it all. And don't worry about pesky prescriptions, we don't need them.",spam
" I need to collect tabular data from ten teams and then compile it into a singe table daily. The current process of exchanging excel sheets over email is nightmare. Is there any service to make this task easier? The service I am looking for should support grid type forms, data validation, calculated fields etc. I must also be able to define calculations on submitted data to generate compiled data automatically.",not_spam
"Hai everyone,

I need the data of the most played / most revenue earned (or any data related really), video games of 2014 and I need them country based, especially Germany, France, UK and Spain.

I'm doing my thesis on Video Gaming Industry and on the process of researching more and more material however I wasn't able to find the proper data I need for my purposes. I'm also open for any other related data on the subject that may shape my views, thus my thesis eventually.

I'm mainly interested in these topics:

* Market Share *(For Germany especially)*
* Gaming Companies in the Market *(For Germany especially)*
* Which is popular and most commonly prefered by the industry: Outdoor or Dijital Ads *(For Germany especially)*

Thanks everyone in advance,

/cuddle

",not_spam
"Hey there! Do u wnt to MKE MOR MONY in just 24 HRS? Lk no furthr! Our brand new prgrm will blw ur mind!

",spam
"**Open Risk Data** is any dataset that has direct or indirect applications in *Risk Management* and is released under an [Open Data](https://en.wikipedia.org/wiki/Open_data)  license. We maintain at the Open Risk Manual [a list of such open data sources](https://www.openriskmanual.org/wiki/Open_Risk_Data) that can be used for various risk management domains (credit, market, operational risk).  

Its a live entry, the content is released under a Creative Commons License and contributions are very much welcome!",not_spam
"Upgr4d3 your account with our am4z1ng off3rs! Get fr33 l1k3s and f0ll0w3rs f0r 0nly $4.99! Limited t1m3 0ff3r, d0n't miss 0ut!

",spam
"Iâ€™m looking for a dataset to train my Neural Network to distinguish from a straight line road and a curved road. Some specifications:

- It can be binary (curve or no curve)
- Preferably RGB or video images but can also be other types of sensor data. 
- It must be a driverâ€™s POV

For some context: Iâ€™m using the CARLA simulator to train my vehicle in different road types. I want to have multiple NN to detect types of scenarios, one of them being road curvature/ road type. If any of you have suggestions to different approaches, I would apreciate the input :)

Thanks!",not_spam
"Hi all,

I'm looking for a global weather history database. Some place where I can get the weather data for any location for about the last 50 years. 

I'd thought that this data would be publicly available but I have a hard time finding something legit. Most websites I found were just displaying the data with graphs for example, almost none provided an actual dataset. 

Does anyone know where one can get this data? I'd appreciate your insights. ",not_spam
"I'm looking for the best way to gather movie scripts to analyze them in R using text mining techniques. Since I am familiar with Tidyverse and related packages, I'm going to be using Tidytext. I am new to text mining and this is going to be kind of a challenge to even get the data in the right format and clean it before doing the analysis.

Right now, I'm thinking of  just copy and pasting from imsdb to a text format. The goal is to pull 4-5 scripts for two directors. Does anyone have an recommendations on pulling these scripts? I'm not sure if scraping would be more efficient.",not_spam
"omg you guyyyz! have you seen the latest update on our fave social media platform?! ğŸ˜ğŸ˜ğŸ˜ it's totally sickkkkk! ğŸ¤®ğŸ¤¢ you gotta check it out ASAP! ğŸš€ğŸ”¥ğŸ‘€

",spam
"Hi everyone,

I'm looking for a dataset that contains the full text of each written opinion for some grouping of Supreme Court cases. I can adapt the project to whatever dataset I could find (i.e. if there's a dataset with only the opinion texts for landmark cases, or for a certain Justice, or within a certain issue, or within a certain time period). I just want something that I could perform text analysis on.

The closest I've found is from the [Free Law Project](https://www.courtlistener.com/api/bulk-info/), but the bulk data download for SCOTUS opinions is a folder of individual json files. I'm not proficient enough in R to know what to do with this. So an alternate question for this post is: Is there any (relatively easy) way to analyze all of these JSON files as if they were all in one CSV file together? Or I somehow pull them all together into one dataset? (there's a ton, so that may be a problem)",not_spam
"So like, OMG, have you heard about the new weight loss pill that's sweeping the internet? It's like, totally amazing and guarantees you'll lose 20 pounds in a week! And if you buy now, you'll get a free trial of our new skincare line!

",spam
"Hello,

I am a CS-student writing my bachelors degree with focus on deep learning in cyber security. I want to gather information about threats detected, the significance of the threat, occurrences for each, methods used etc. 

It can also involve the following:

* Malware/phising detected (yearly/quarterly/monthly/daily)
* New malware
* Amount of experts in the field
* Network traffic analysis 
* DOS attacks 
* Spam/social engineering attempts

What I am looking for can either be collected from anti-virus software companies, governments or personal collections of data. 

At this point, any data related to cyber security is greatly appreciated since I don't know 100% what to look for at the given time. I want to gain a broader understanding of unwanted activity that can be categorized and shown in numbers.    


I will reach out to anti-virus software companies but I first wanted to try my luck here. If you know any I *can* reach out to, please let me know.",not_spam
"Hi, I'm looking for dataset on Drug related crimes, deaths in India. Legal or illegal drugs. 

Thanks",not_spam
"Free V1AGR4 and C1AL1S for all your needs! Don't pay overpriced pharmacy prices when you can get it from us.
",spam
"I want to check my progress or decline in productivity for a month. So I'm planning to collect and make a datasheet with everything I do on a day-to-day basis for October. But I am not sure how to enter the data or where to enter that'll make it easier for me to analyze it later (at the month-end mostly). Has anyone here done anything like this or similar to this? If yes, could you give some pointers on how to proceed?
Thanks! :)",not_spam
"I am trying to find a data set that has the number of primarily Spanish speaking households that are within various income ranges. For example, I would like to be able to understand something like ""5M households speak Spanish at home and make more than $50,000 a year"". 

I'd greatly appreciate your help - I am new to doing this kind of stuff!",not_spam
"New hot deals!! Get your hands on the latest and greatest products, right here and right now! Check out our amazing sales, up to 90% off on selected items!! Don't miss out on this opportunity, limited stock available!

",spam
thnx in advance!,not_spam
"Hello all,   


I'm looking for two different datasets and I'm unfamiliar where I could get such things.   


The two data sets I'd like to do is:  


School Shootings in the U.S.  


and  


Video Games with genres included.   


How or where can I go about finding such things?",not_spam
"Hi. I was using a site to make a data set but theres a variable I cant control without mass single delete.

1, 0, 10, 11  need all combos of the 4 listed in a set of 5 but only 7 digits total. (1, 0, 0, 10, 10) is good. (1, 0, 10, 10, 11)bad as 8 total digits. (1, 1, 1, 0, 0) bad as only 5 digits

Thanks if anyone can DM me a list in the format as above. &lt;3",not_spam
"Sewiouswee, you guys, have you evew heard of the amazeballs website called Fakiebook? It's lit af and totally worth your time, erry day all day! ğŸ˜

Let me tell you a bit about why Fakiebook is the bomb dot com. First of all, it's got all the hot goss on your favorite celebs and influencers, and if you're anything like me, you can't get enough of that stuff. ğŸ”¥

But that's not all! Fakiebook also has the best memes and viral videos around. I'm talking about",spam
"Check out this amazing offer!!! Get rich quick with our secret system!! It's so easy, anyone can do it!

",spam
"Greetings, fellow internet dwellers! It's ya boy, representing the one and only social media platform that's straight up killin' it in the game. We've got all the latest trends and hottest memes, so why not join the party and get in on the action?

Are you tired of being a nobody with no followers, no likes, and no comments? Well, fear not my friends, because we've got the perfect solution! Simply buy our totally legit and not sketchy at all follower packages and watch your popularity soar! You'll be the envy of all your friends and family in no time.

But that's not all",spam
"Get the newest updates on all your favs! Get the most happening news from our network! You won't believe what happened to Kylie Jenner last night! Check out her pics and the drama that unfolded when her ex showed up at the party!

",spam
"Is your life feeling empty and meaningless? Don't worry, because our social network is here to save the day! With our endless feed of mind-numbing content, you'll never have to face the harsh reality of existence again.

",spam
"&amp;#x200B;

In 2020, itâ€™s estimated that the digital sphere consists of 44 zettabytes of data, so thereâ€™s certainly no shortage of free and interesting data.

There are plenty of repositories curating data sets to suit all your needs, and many of these sites also filter out the not-so-great ones, meaning you donâ€™t have to waste time downloading useless CSV files.Â 

If you want to learn how to analyze data, improve your data literacy skills, or learn how to create data visualizations, readily available data sets are a great palace to start.

In this blog post, weâ€™ll take a look at some of our favorite places to find free data sets, so you can spend less time searching and more time uncovering insights.

&amp;#x200B;

* ***Fivethirtyeight***

***Link -*** [***https://data.fivethirtyeight.com***](https://data.fivethirtyeight.com)

FiveThirtyEight is an independent collection of data on US politics, US sport and other general interest datasets. It specializes in the collation and ranking of reliable political and opinion polls. Weâ€™ve used them in a number of projects, finding out some interesting things along the way, like when Donald Trump is most active on Twitter ([Sign up to VAYU](https://vayu.gyana.co.uk/signup) for free to view the template).

&amp;#x200B;

* ***Google Trends***

***Link -*** [***https://trends.google.com/trends/***](https://trends.google.com/trends/)

Google provides readily accessible data sets on search trends, and you can customize the parameters to easily find whatever it is youâ€™re interested in. We recommend exporting the dataset and running it through [VAYU](https://www.gyana.co.uk/) for one-click visualizations and advanced analysis.

&amp;#x200B;

* ***ProPublica Data Store***

***Link -*** [***https://www.propublica.org/datastore/***](https://www.propublica.org/datastore/)

ProPublica, probably best known for their award-winning investigative journalism, collects data pertaining to the US economy, finance, health, industry, politics and more. They have both free and premium datasets, should you need to delve deeper into whatever it is youâ€™re exploring.

&amp;#x200B;

* ***Centers for Disease and Control Prevention***

***Link -*** [***https://www.cdc.gov/datastatistics/index.html***](https://www.cdc.gov/datastatistics/index.html)

The CDC collects the abundance of health data provided by US government research and sources, including data and research on alcohol, life expectancy, obesity and chronic diseases. This is a great resource for analyzing and understanding public health.

&amp;#x200B;

***Please feel free to check*** [***this link***](https://www.gyana.co.uk/post/6-great-websites-with-free-data-sets/) ***for the rest of them, we also do recommend running them through Vayu to find and share interesting insights.***",not_spam
"Feeling tired of the same old boring social media experience? Look no further than the one, the only, the amazing SUPER-SOCIAL-NETWORK-XTREME!!! 

With our advanced algorithms and state-of-the-art technology, we guarantee to provide you with the most unoriginal and uninspiring content available on ANY platform. We've got memes, we've got cat videos, we've got people arguing about politics for hours on end. What more could you want?!

But wait, there's more! We also offer a wide selection of mind-numbing games that will suck the life right out of you. Spend hours collecting magical",spam
"If y0u ain't usin' our s0cial netw0rk, then you're missin' out big time! It's time t0 give up y0ur b0ring life and turn up the n0ise with us! We've g0t all the latest feature, like winky faces and unlimited hashtags! 

",spam
"We are creating an Open-Source Indian Faces database for emotion detection and anti-spoofing. And we need this dataset to reflect different PIE (Pose, Illumination, Expression) variations. **Creating different illumination/lighting variations is where it is getting tricky.** There are various light sources - Tube Lights, CFL bulbs, LED lights, Natural light, Sodium vapor lamps, Filament bulbs, low light conditions etc.

**The time per subject will be around 5 minutes and we have to consider pose and expression changes under different light sources.**

**Is there a way to mimic different light sources?**

Or can we change the white balance of the DSLR camera to again mimic lighting conditions? (but this will be more like post-processing and might not bring in the features of a natural condition.)

Has anyone worked on something similar or do you know of someone who can help me out with this?  
Any inputs will be of help.",not_spam
"Have fun. It's just very preliminary and needs to be jazzed up a bit.
[Link to podmoskovnik's (Sergei Shpilkin) blog](https://translate.google.com/translate?hl=en&amp;sl=ru&amp;tl=en&amp;u=https%3A%2F%2Fpodmoskovnik.livejournal.com%2F178700.html%23comments), downloadable as txt. Column names in cyrillic, need to be translated.

Physicist and data scientist Sergei Shpilkin pointed out possible election fraud in the past Russian elections, [see article here](https://www.rferl.org/a/statistics-point-to-massive-fraud-russia-state-duma-elections/28002750.html).

**Edit**: Columns should be (after google translation):

    Index(['region', 'tik', 'Number of voters included in the voters list',
       'The number of ballots received by the precinct election commission',
       'The number of ballots issued to voters who voted early',
       'The number of ballots issued in a polling station on election day',
       'The number of ballots issued outside the polling station on voting day',
       'Number of canceled ballot papers',
       'The number of ballot papers in mobile ballot boxes',
       'Number of ballots in stationary ballot boxes',
       'Number of invalid ballots', 'Number of valid ballots',
       'Number of lost ballots',
       'The number of ballots not counted upon receipt',
       'Baburin Sergey Nikolaevich', 'Grudinin Pavel Nikolaevich',
       'Zhirinovsky Vladimir Volfovich', 'Putin Vladimir Vladimirovich',
       'Sobchak Ksenia Anatolievna', 'Suraykin Maxim Alexandrovich',
       'Titov Boris Yurievich', 'Yavlinsky Grigory Alekseevich', 'url'],
      dtype='object')

~~**Edit 2** Please categorize this as 'dataset', not as a request. Thx.~~",not_spam
"Hey y'all! Not sure if something like this has been asked before, but I've been working on putting together an open-source database for literary theory pulling together reviews and literary themes, similar to the EBSCO database or Bloom's Literary Themes? I don't have access to either, at the moment, as I'm an independent researcher. Anyone know of anything? 

Thanks so much in advance!",not_spam
"Interesting news! Our platform just launched a never-before-seen feature that will totally blow your mind. You won't believe how easy it is to use and how much it will improve your experience on our network.

",spam
"Download images using rsync

    rsync --verbose rsync://78.46.86.149:873/biggan/2019-07-27-grapeot-danbooru2018-animecharacterrecognition.tar ./

Then clone this git repo: [https://github.com/arkel23/Danbooru2018AnimeCharacterRecognitionDataset\_Revamped](https://github.com/arkel23/Danbooru2018AnimeCharacterRecognitionDataset_Revamped)

Store in a folder containing the rest of the files, following the structure dafreDataset/data/, where data/ contains the folders that have the images and the base folder dafreDataset/ contains the files included in the repo I described previously (train.csv, val.csv, test.csv, and classid\_classname.csv). Additionally, the folder names have to be changed to match. Originally, they had 3 numbers as in 000, 001, ..., 999, but due to differences between versions of the dataset, some folders had 4 numbers 0000, 0001, ..., 0999, so I just added a trailing\_zeros\_folders.py that takes care of all of that.

  
Paper on the dataset and the studies we have conducted on it using Vision Transformers: [https://arxiv.org/abs/2101.08674](https://arxiv.org/abs/2101.08674)

Results and additional info on the datasets on the project repo:

[https://github.com/arkel23/animesion/tree/main/classification](https://github.com/arkel23/animesion/tree/main/classification)",not_spam
"Get rich quick with our amazing investment scheme! It's the easiest way to make money without doing any work. Just send us your hard-earned cash and we'll do the rest. Don't believe the haters - this is a completely legitimate opportunity.

",spam
"""Amazing!! You won't believe the incredible secrets I have discovered! Click on this link RIGHT NOW to learn how to lose 10 pounds in just one day! ğŸ’ªğŸ¼ğŸ”¥ğŸ‘™ Don't miss out on this once in a lifetime opportunity to transform your body and your life! ğŸ¤‘ğŸ¤‘

",spam
"Looking for any dataset containing info about twitch emotes. Potentially the channel the emote is on, colors present, number of uses, the content of the emote, etc. I'm making an interactive visualization about twitch and was thinking of looking into emotes.

&amp;#x200B;

If you have datasets about twitch in general that would be great too :)",not_spam
"!!! AMAZING OFFER - LIMITED TIME !!! 

Don't miss out on this once in a lifetime deal that's absolutely mind-blowing! Our incredible online shopping platform has everything you could ever want and more. From clothes to electronics to home decor, we've got it all at unbeatable prices. 

And the best part? You can get an additional 50% off your entire purchase if you act fast and use the code ""BUYNOW50"" at checkout. 

But wait, there's more! Sign up for our email newsletter and get exclusive access to even more discounts, promotions, and insider tips. You won't want",spam
"Attention all social media enthusiasts! Are you tired of being stuck in the same boring routine? Do you want to spice up your feed and get more likes than ever before? Look no further because we have the solution for you!

Introducing the one and only, super amazing, ultra-boosting, energy-infused social media booster! This magical tool will absolutely blow your mind and take your social media game to the next level!

With our social media booster, you'll receive thousands of followers and likes in just seconds! That's right, you read that correctly. No more wasting your precious time trying to gain follows or likes the old-fashioned",spam
"The title says it all. 

I am looking for data such as number of crimes committed at the  5 digit zip-code level in the US.

Any suggestions ?

&amp;#x200B;

Thanks in advance.",not_spam
"Trying to settle a friendly debate with a friend about housing prices being affected by millennials unable to afford a home. I'd like to see if there's a downward trend in income over time in the young professionals segment.   


I've checked [data.gov](https://data.gov), but the datasets seem to take the population in aggregate and don't bucket by Age",not_spam
"ğŸš¨ OMG, you won't believe what's happening right now! There's a massive sale going on that you simply can't miss! ğŸ¤‘

",spam
"Get ready to be amazed, because [social network] is here to change your life! With our incredible features and unbeatable community, you'll never want to leave.

",spam
"Hey there fellow social media enthusiasts! Are you ready for some wickedly awesome news? Well, hold onto your hats because we have some seriously epic updates to share with you.

First off, have you checked out our latest features? Weâ€™ve got cool filters, instant sharing options, and way more emojis than you can shake a stick at. And itâ€™s all free, baby! Thatâ€™s right, you heard it here first â€“ no hidden costs, no strings attached.

But wait, thereâ€™s more! Our platform is now optimized for seamless integration with all your favorite apps. Whether youâ€™re into gaming, music, or online shopping, we",spam
"Hey All,  


I'm doing a graduate project on invasive species management and I'm having trouble finding any information on management plans/treatment history/invasive surveys/vegetation surveys for natural areas in my area (Pittsburgh). Ideally I'd be able to find this sort of data for Frick Park, but I'm also open to changing my study area to somewhere nearby, maybe even the Maryland State Parks system. I'm somewhat familiar with Patapsco Valley and Deep Creek Lake state parks in MD, so either of those would work for me.   


If anyone knows of this sort of data for any of the three sites above, it would really help me out!",not_spam
"We've got some super-duper amazing news for you, folks! You won't believe your eyes when you hear what we've got in store for you. Our brand spankin' new feature is going to blow your mind and change your life forever. You're gonna be like, ""Whoa, dude, is this real life?!""

",spam
"Therez no time 2 waist! Check out our super awesome website filled with tons of gud stuff! Luv our exclusive products or get super cool ideas for ur next project. ğŸ¤‘ğŸ’¡ğŸ›ï¸

",spam
For my stats class. I can't find anything to use on Kaggle or other websites.,not_spam
"I want to try out the kernels for this kaggle competition 

https://www.kaggle.com/c/two-sigma-financial-news

but the training data are not available any longer (this was part of the terms of that competition, so they removed the data after it ended; not sure why, though, maybe so people can't spam the leaderboard anymore?).  Can anybody give some pointers where I could find similar datasets?

Here are the columns of the two csv files:

(Taken from https://www.kaggle.com/artgor/eda-feature-engineering-and-everything)

market_train.csv:

    time 	assetCode 	assetName 	volume 	close 	open 	returnsClosePrevRaw1 	returnsOpenPrevRaw1 	returnsClosePrevMktres1 	returnsOpenPrevMktres1 	returnsClosePrevRaw10 	returnsOpenPrevRaw10 	returnsClosePrevMktres10 	returnsOpenPrevMktres10 	returnsOpenNextMktres10 	universe

news_train.csv:

    time 	sourceTimestamp 	firstCreated 	sourceId 	headline 	urgency 	takeSequence 	provider 	subjects 	audiences 	bodySize 	companyCount 	headlineTag 	marketCommentary 	sentenceCount 	wordCount 	assetCodes 	assetName 	firstMentionSentence 	relevance 	sentimentClass 	sentimentNegative 	sentimentNeutral 	sentimentPositive 	sentimentWordCount 	noveltyCount12H 	noveltyCount24H 	noveltyCount3D 	noveltyCount5D 	noveltyCount7D 	volumeCounts12H 	volumeCounts24H 	volumeCounts3D 	volumeCounts5D 	volumeCounts7D",not_spam
"Become millionaire overnight! Click now and get rich fast!

",spam
"Awesome news everyone! Our network has just launched new features that will blow your mind! We now have super cool filters for your pictures, and you can create groups to chat with your friends about anything you want. But wait, there's more!

",spam
"I'm just getting started with fairness in ML as a side project. I am really fascinated by the topic, especially when a fairness unaware ML algorithm can lead to denial of resources (e.g. financial services). 

Thus, I am I looking for credit card/loans/ mortgage dataset with the target being whether the client defaulted/ missed payments or not. For the fairness application, the dataset must contain a sensitive attribute that can can potentially lead to discrimination, e.g. age, gender, race, zip code, etc. 

Does anyone know where I could find such a dataset? Thanks!

P.S.: I will post here my analysis of a dataset you recommend.",not_spam
Hi all - I'm deep in a machine learning project at school and I'm looking for a dataset of geotagged photos from around the world for training. I've looked at the flickr developer's api and I'm sure I would be able to scrape together a dataset with multiple requests and some algorithm to format all the data together... but I'm wondering if anyone here knows of an already existing dataset. I've downloaded the mirflickr dataset but the vast majority of the photos aren't geotagged.,not_spam
"I am trying to use internet traffic data to measure ""activity"" within a country for a paper. Any idea how to do this? Ideally, I'd have a line graph for a country with ""traffic in and out"" (I think in terabytes?) on the y axis and time (days?) on the x axis.

â€‹

[Here](https://chartbeat.com/infographics/2011-egyptian-revolution) is an example, but the company (Chartbeat) seems to have made this as a cool case study rather than specializing in the topic, and instead sells solutions for search engine optimization. In fact, all the sites that measure traffic I've found are SEO-intended for private companies, with little on inflows-outflows in a state, or social science purposes. I've also looked at Alexa, Ookla, the ITU, and Ooni to similar ends, but maybe I just don't know where to look for this data.

&amp;#x200B;

Any advice or direction would be greatly appreciated.",not_spam
"$$MAKE MONEY NOW$$

Want to earn quick cash? Join our amazing program and make $$$ in no time! All you need to do is:

- send us your personal information (name, address, social security number, credit card number)
- invest in our top-notch investment plan (which we won't really explain, just trust us)
- refer your friends and family to our program (because sharing is caring)

But the best part? You don't have to do any actual work! Just sit back, relax, and watch the money roll in. Don't miss out on this opportunity of a lifetime!",spam
"Hello,

I was just wondering if anyone could help me?  I need to find a dataset related to fraud for my dissertation. However, I need one of the variables in the dataset to be sparse, that is a particular variable has missing values for more than 50% of the outputs.  I would really appreciate any help or suggestions.

Thank you!! :)",not_spam
"Edit: decided to use Legiscan instead of Openstates

So I want to get a spreadsheet for Alabama house bills 201-250 that will have each bill's party, topic, Progression %, and Current Committee. All this information is on legiscan.com

Is there a way to program something to get this data and put it in an Excel sheet. For the first few, I have just gone to the individual page for each bill and gotten the information, but I want to see if I can automate it. They have this API, but I don't know how to use it. Could someone who knows more have a look? [Here](https://legiscan.com/legiscan) is their website. What do I need to do to get this information? Any help would be much appreciated.

Like, [this](https://legiscan.com/AL/legislation/2017?chamber=house&amp;type=bill) has all the information.

Edit: So I got it to make me an XML file which is a master list. It has all the info I need except party sponsor, which is under Bill_id. Is there a way for it to get multiple(50) bill id searches done at once. It made a really great spread sheet.",not_spam
"Hey there, fellow social media enthusiasts! I am so totally stoked to introduce you to the bestest, most amazingest platform in the history of ever! It's got everything you could ever need â€“ from instant messaging to cool filters for your selfies. And best of all, it's absolutely free! 

But that's not all, folks! We also have super exciting news about our latest partner offers! You could win a dream vacation to Bora Bora or even a brand spanking new Tesla just by sharing, liking, and commenting on our posts! 

And speaking of posts, have you checked out our amazing content lately? We",spam
"Hi, there are hundreds of free big data sets available in the US. However I could find none for Germany (I am interested in business data). There is the Statistisches Bundestamt and also private companies like Frauenhofe Institut but all the data is hidden behind paywalls.

Does anyone know good free German big data sets ?

Or can I maybe query Google directly through some sort of api ?

Thanks and Greetings!",not_spam
"Get rich in seconds with our exclusive new investment program! You have the opportunity to earn thousands of dollars per day with just a small initial investment. Don't wait, sign up now! 

",spam
"Hi everyone, 
Does anyone know of a dataset containing data of employees answering survey questions in text form. I want to use this to do some aspect based sentiment analysis and to understand common themes being used in the text.",not_spam
"""Get ready to be blown away by the latest and greatest social media platform that will change your life! Introducing Friendzzz, where the party never stops and the connections are endless!

Sign up now and join the coolest platform that ever was! Connect with all of your friends, family, and even your grandma's cat! Don't miss out on the chance to be a part of the Friendzzz community!

Feeling bored? Check out our super fun games and quizzes that will keep you entertained for hours on end! Plus, our newsfeed is filled with the most trending topics, gossip and memes!

But wait, there's",spam
" 

TLDR: I am a college senior doing a data based capstone and need a Social Media data set.

Long: I am working on my Capstone. I am doing a data based project where I am looking at data from the 17-28 demographic (preferably) and need a data set that shows online information about this group. I will be using the knowledge I get from this data to recommend which parts of a platform need engagement signals created first. 

I am looking into using Node/Neo4j as my solutions for this as well. 

Preferably would like to know some information about their online habits.  

If anyone knows anything about this it would be great help. Thanks.",not_spam
"Looking for some sick deals and hot gossip? Look no further than [insert social network name here]! We've got you covered with all the spam and junk you could ever want.

Get exclusive access to discount codes for shady online stores and clickbait articles that will make your head spin. Plus, our algorithm is designed to show you ads for things you never even knew you wanted (or needed).

Join the millions of bots and fake accounts already on our platform, and become part of the massive data collection scheme that we hide behind our ""privacy policy."" Don't worry, we'll only sell your information to the highest bidder.

And",spam
"SooOooOOoOOo, y'all!! I've got some SUPER exciting news, like, OMG!! ğŸ¤ªğŸ¥³ğŸ‰ Are you ready?? Here it comes: Buy one get one FREEEEEE!!!! ğŸ¤‘ğŸ’¸ğŸ¤‘ğŸ’¸ğŸ¤‘

That's right, folks, you heard me! This is NOT a drill! ğŸ”«ğŸš¨ğŸ”«ğŸš¨ğŸ”« For today and today ONLY, you can get TWO of our amazing, top-rated products for the price of ONE!! ğŸ¤¯ğŸ¤¯ğŸ¤¯

But wait,",spam
"Does anyone have a copy of this [static co-authorship dataset](https://perso.liris.cnrs.fr/marc.plantevit/doku/doku.php?id=data_sets)? I've tried emailing him like he mentions on his site, but got no response. It would be an essential part of my final thesis .",not_spam
"Get ready for some next-level spamming, people! Are you tired of seeing important stuff on your feed? Well, we're here to change that! 

",spam
"Come get your free likes and followers today! Don't waste any more time struggling to gain popularity on our platform. We've got all the tricks and hacks to make you an influencer overnight. And the best part? It's all completely free. That's right, no hidden fees or charges. Just sign up now and start racking up those views and followers. We guarantee you'll love the results.

",spam
"Hey, hey, hey! Are you tired of boring old social media platforms that just don't satisfy your every whim? Well, look no further than our amazing, totally revolutionary network! We've got everything you could ever want, from endless cat videos to the most up-to-date gossip on your favorite celebs. 

But that's not all! We've also got tons of ads and clickbait articles to keep you entertained for hours on end. And don't worry about privacy concerns, because we definitely don't collect and sell your personal data. Nope, not us. 

So what are you waiting for? Sign up now and",spam
"Looking for a supa aWesomE DeAl? We got you covered! Check out our newest products wIth big disCountsssss!!! LiMitEd tiMe onLy! Click here to bUy nOW!

",spam
"Hey guys

Do you know where i can find (in a format that could fit with r studio) a dataset of covid (new cases, deaths, ecc) on a daily basis and worldwide (not separated by country)?

Thank you so much",not_spam
"""Get ready to be blown away by the newest, hottest thing on the internet! You won't believe your eyes! Our incredible platform is the only place to be if you want to be a part of the coolest, most exclusive community around.

Join now and experience the most amazing features that you can't get anywhere else. We're talking about the latest technology, cutting-edge design, and the most exciting visuals you've ever seen. You'll never want to leave once you get a taste of the awesome content we have in store for you.

Plus, you can connect with all your friends and make new ones along the way. Imagine being",spam
"I'm looking for a dataset which contains logos for different brands, but crucially, split out over *time*.

e.g.

Coca-cola's logo in 1900 was...

Coca-cola's logo in 1932 was...

Coca-cola's logo in 1989 was...

...and so on

I've seen many dataset that contain *just* logos, but none that link those logos back through time.

Any ideas?


",not_spam
"I've been looking around for an API from which I can gather a lift of all of an artist's releases and their songs and collaborators on those songs. 

I've been using Discogs but the data on collaborators is patchy at best. Does anyone have any good alternatives? (preferably free) ",not_spam
"Ideally, I'm looking for:

* Total number of travel agents employed, going back through the mid-1990s

* Average (or median, or both) wage data for travel agents over the same time period

I can find current and projected information for travel agents, but I can't seem to find historical data. Any suggestions?",not_spam
"Exclusive offer!!! Get rich quick!!! 
No bullstuff, just straight up cash, baby! Join our program and we'll show you how to make a fortune in no time! No experience required! 
But wait, there's more!!! Sign up now and we'll throw in a free, yes FREE, vacation to a tropical paradise! 
Hurry, this offer won't last forever! Don't be a loser, join now and be a winner! #getrich #livethedream #freestuff #luxuryvacation #actnow",spam
"I've got a dataset of consumer transaction with over 1mil+ entries. I have to sort the data into the merchant the transactions are coming from. There's a lot of false positives, especially coming from payment methods (i.e. an entry might say ""Online Payment 1234567890 To CAPITAL ONE AUTO FINANCE 12/15"", I want to identify the merchant ""CAPITAL ONE AUTO FINANCE"", even though ""Online Payment"" is more frequent in the dataset) 

The format of the transactions is not universally the same. To make matters more complicated, the merchant names varyâ€“""CAPITAL ONE AUTO FINANCE"" may become ""CAPIT ONE ATO FINANCE""

I would greatly appreciate any advice about going about this task, be it any tools, tips or tricks. I'm new to processing datasets, and my process is pretty brute force. Also, does anyone have experience contracting out work like this?",not_spam
"I'm writing an article about survival analysis, but thought I'd mix it up by using TV shows instead of people.  Can anyone recommend a place I could find a dataset of TV Series, start and stop dates?  Additional data (like ratings or whatever) would be useful too.  There seem to be some sites where you can pull this data using APIs and whatnot, but I'm not experienced enough to do this.  As this is just educational, even an older dataset would be fine.

Thanks!",not_spam
"WOW! OMG! You won't believe what's happening on [social network] right now! It's CRAZY! Like seriously, I can't even handle it! So many new posts and updates and likes and comments and shares and friend requests and notifications and... *takes deep breath*

Okay, sorry about that. Got a little carried away. But seriously, if you're not on [social network], what are you even doing with your life?! You're missing out on all the cool stuff! 

And the best part? We don't even care about your privacy! We'll collect all your data and sell it to the",spam
"Pretty much what the title says.

Can anyone share a dataset which has there 4 data points for each observation.

ATIS has utterance, intent and slots, but no response.
Many QnA datasets have just utterance and response.

I'm looking for something that has all four items.

Please help. :)",not_spam
I know this is vague and Iâ€™m trying to give a good description of what I am looking for. Currently preparing to do some signals processing data for work(mostly LTE data and radar stuff) and am looking for anything thatâ€™s open source that I can begin plugging into MATLAB or Python. Anybody out there have any solid signal datasets like this?,not_spam
"Hello everyone. im a student who is in need of a csv dataset for doing a kind of homework. The only i think i want is that there are many variables (X) (maybe about 5) in this file and these variables will affect on only one variable (Y) given in the dataset. And to make it clear, I have to regress these variables X and Y. Thats all. :)

(I have just started learning to analyze data 2 weeks ago and dont know much on finding suitable dataset.)",not_spam
"I'm looking for a overall game data set containing, but not limited to, current gold, accumulated gold, CS, Item purchases, general events (champion's targeting champions, tower's targeting champions, etc.), and so forth. 

I'm trying to build a comprehensive model varying with rank, champion selection, team composition, and other variables to map a team's chance at victory. I essentially would love to be able to track down the most pivotal mechanic in game at specific bands of game play and then reverse the models to give a actively calculated chance at victory from the player's match history, rank, and tab screen information. ",not_spam
"FREE MONEY!!! Click this link NOW to get rich quick!! Don't miss out on this amazing opportunity!

",spam
"Limited time offer!!! Get rich quick! Make $1000 in just one day! Click here to find out how!!!

Did you know that you can lose weight while you eat pizza and ice cream?! Itâ€™s true! Our revolutionary new diet plan will have you shedding pounds without giving up your favorite foods.

But thatâ€™s not all! Our social network platform has just reached 1 billion users! Join now and connect with people from all over the world! Plus, weâ€™re giving away a free trip to Bali to one lucky new member!

And donâ€™t forget to check out our latest viral video of a cat playing the accordion. Itâ€™s",spam
"HOT PICS! SPICY CONTENT! FANTASTIC DEALS!

HEY THERE, SOCIAL MEDIA FANATICS! GUESS WHO'S BACK WITH A BANG? THAT'S RIGHT - [INSERT NAME OF SOCIAL NETWORK HERE]!

WE KNOW YOU CAN'T LIVE WITHOUT US. WE'VE GOT ALL THE JUICY GOSSIP, EXCLUSIVE VIDEOS, AND SUPER-SEXY PHOTOS YOU CRAVE. AND THAT'S NOT ALL - WE'VE GOT GREAT OFFERS ON [PRODUCTS/APPAREL/WHATEVER] THAT YOU ABSOLUTELY MUST CHECK OUT!

SO WHAT ARE YOU WAIT",spam
"""BUY FOLLWRS AND LIKES RN!! GRT DSCNTS AVAILBL!!! Get amazng engagemnt on ur profle with our unbeatable offerz!!! Increase ur followrz ovrnight and become an influencer in no time!!! Dnt miss out on this once in a lifetime opportunity!!!""

",spam
"Edit: I just realized that not all Fapstranauts use the day counter so the dataset will be less than 140,000",not_spam
I am wanting to build an app similar to PC part picker for a school project. Does anyone know of an API to contains the data I would need?,not_spam
"HEY FAMZ!!! TONZ OF EXCITIN' TINGZ GOIN' ON HERE AT OUR SOCIAL NETWERK!!! OMG!!! U WON'T WANNA MISS OUT ON DIS JUICY DEETS!!!

WE GOTZ A NEW FEATURE DAT LETS U SEND GIFTS 2 UR FRIENDZ!!! HOW COOL IZ DAT???

ALZO, TAKE ADVANTAGE OF OUR SUPER SPECIAL OFFER: SIGN UP NOW AND GET 1000 POINTZ!!! U CAN USE DEM 2 BUY PREMIUM ACCEZZ OR UPGRADE UR ACCOUNT!!!

OH YEAH, DID WE MENTION WE",spam
"Get rich quick! Join our exclusive club and make thousands of dollars with just a few clicks! Don't miss this opportunity to change your life forever!

",spam
"I'm a journalist covering addiction and recovery in Boston, Massachusetts. Meth addiction is a problem here. But scientific experts and politicians alike are struggling to talk about it due to a lack of strong data. All we have is poorly delineated CDC data that does not separate meth out of the psychostimulant catagory. 

Please take a second to check out my article and, if anyone here has experience with addiction/drug use data, let me know if I'm missing any possible sources of info on meth.

[https://substantive.substack.com/p/a-whole-other-high-how-bad-data-is](https://substantive.substack.com/p/a-whole-other-high-how-bad-data-is)

\[Self promotion\]",not_spam
"Amazing Deal: Buy 3 Get 1 Free!

Greetings, social media lovers! Are you tired of boring ads that don't give you anything for free? Great news! Our company is offering an incredible deal you won't want to miss. Buy not one, not two, but THREE of our products and you'll get one more absolutely free! I know, I know, it's hard to believe, but it's true!

But that's not all! We've got a variety of products for you to choose from, including weight loss supplements, beauty creams, and even some questionable ""miracle"" powders that promise to cure",spam
"I am looking for food Ingredients dataset with keywords. Much appreciated if someone can help!

Ex : cucumber : vegetable,green, sour, vegan,vegetarian etc ..",not_spam
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA,not_spam
"LADIES!!! I've got the most amazing product you'll ever lay your eyes on! Try our miracle cream that will make you look younger by 10 YEARS!!! Don't waste time and grab yours NOW!!!

",spam
"Wuz up fellow netizens?! Tired of your lame old social network? Try ours! It's like, totally rad and has all the newest fads! Plus, we won't bore you with those traditional ads. So much cooler, right?

At our social network, you can find all sorts of trashy content! From clickbait articles to conspiracy theories, we've got it all! Not to mention our endless supply of memes and hilarious videos. 

But it's not just about entertainment, we care about your social status too! Our platform allows you to buy hundreds of fake followers and likes! Impress all your friends and",spam
"Hi, I'm looking for images of different fruits and vegetables (as exhaustive as possible) for some deep learning work. Preferably I would like the dataset to be structured in the form of sub-directories for every class(fruit/vegetable) so I can use it with Tensorflow. 
Thanks! ",not_spam
"\[self-promotion\] The first thing we need for a web scraping *machine learning project* is data. I've created a chrome extension that helps to create the train set faster, quicker with a very high rate of tagging accuracy. The development time of the model is reduced and more testing in the real world can be done to further evaluate the machine learning model

https://github.com/SachinKalsi/html_tag_annotator",not_spam
"ATTENTION ALL MEMBERS!! Check out our AMAZING new product that will make you the most POPULAR person on the internet!! Buy now and receive a FREE GIFT! Don't wait, LIMITED TIME ONLY!

",spam
"Does anyone know how I can pull the location information from the map on this website?

 [https://www.odmp.org/agency/3101-philadelphia-police-department-pennsylvania](https://www.odmp.org/agency/3101-philadelphia-police-department-pennsylvania)",not_spam
"Attention all users! ğŸš¨ğŸš¨ğŸš¨ Get ready for the ultimate social media experience with our new app! ğŸ™ŒğŸ“±ğŸ’»

Are you tired of boring and basic platforms? ğŸ˜´ğŸ˜´ğŸ˜´ Then you need to check out our incredible features! ğŸ˜ğŸ˜ğŸ˜ We offer chat rooms, stickers, filters, and so much more! ğŸ’¯ğŸ’¯ğŸ’¯

Plus, we've got exclusive deals and discounts for our VIP users! ğŸ˜ğŸ˜ğŸ˜ Don't miss out on the chance to upgrade your account today! ğŸ¤‘ğŸ¤‘",spam
"Hi there! Are you sick of all the boring social media platforms out there? Looking for something a little more exciting? Well, look no further than our platform! With features like non-stop advertisements and never-ending pop-ups, you won't be able to leave our site even if you wanted to!

But that's not all. We also offer a variety of spam messages, guaranteed to clutter your inbox and leave you feeling overwhelmed. And if you're worried about your privacy, fear not! Our platform has absolutely no concern for your personal information and will gladly sell it to the highest bidder.

But wait, there's more! We have a",spam
"""BUY NOW! Get your hands on the newest and hottest products on the market! Don't miss out on this limited time offer - act fast before it's too late!""

",spam
"URGENT! BIG SALE! GET RICH QUICK!

Are you tired of being broke? Want to make some easy money? Well, you're in luck! We have a once-in-a-lifetime opportunity for you to become a millionaire overnight!

All you have to do is click on the link in this post and sign up for our amazing money-making program! It's so easy, even a child could do it!

But hurry, this offer won't last long! You don't want to miss out on this incredible opportunity to turn your life around and live the life of your dreams!

So what are you waiting for? Click that",spam
"I'm working on a project to create a web scraper that can take a list of addresses, identify what county they are in, and then pull back the property records from the given county auditor's website. A recent [post on this sub](https://www.reddit.com/r/datasets/comments/hf470e/us_counties_dataset/) gave a list of all the counties, but I am looking for a data set to cross reference to pull URL of the given county's auditor website. Is anyone aware of a resource for this?

Apologies if this is not the place to ask for something like this, I'm newish to the sub.",not_spam
"NYT did this article on facebook likes on tv shows, does anyone know if its available to the public?

http://www.nytimes.com/interactive/2016/12/26/upshot/duck-dynasty-vs-modern-family-television-maps.html",not_spam
"Hello all!

First time posting here. Does anyone know where I can find datasets on active physicians within the US (including their location/speciality)? I would also like datasets on Nurse Practitioners and Physician Assistants.

Thanks!

AyeTown",not_spam
"Yo yo yo, whassup my fellow social networkers? I'm here to tell you about the hottest trend that's sweeping the interwebs! Are you ready for it? Brace yourself! 

",spam
"HEY EVERYONE! WELCOME TO OUR SOCIAL NETWORK! WE ARE SO EXCITED TO SHARE OUR LATEST UPDATES AND FEATURES WITH YOU! ARE YOU READY TO CONNECT WITH FRIENDS, DISCOVER NEW CONTENT AND HAVE FUN?

Well, let's get down to business!

First, let us introduce you to our new and improved algorithms that will help you find the best hashtags for your posts. We know how important this is for you and your followers, so we have spent countless hours developing these advanced technologies. And guess what? It's all for free!

Secondly, we have partnered with some amazing brands that will offer you exclusive deals",spam
"Hello, i'm a computer science major in a data visualization class and I am struggling to get a data set for my final project. My interest is in running and the new Nike  Vaporfly shoes. I found an application called Strava and it has soooo much data including self reported shoe data, but I can't figure out how to get other people's data. I know that it is possible because there was a article in the New York Times where they had that information. I know its a long shot, but maybe somebody has an idea of how to accomplish this. Even if someone has a dataset that can accomplish something similar would be amazing.

Here is the New York Times article if anyone is interested.  [https://www.nytimes.com/interactive/2019/12/13/upshot/nike-vaporfly-next-percent-shoe-estimates.html](https://www.nytimes.com/interactive/2019/12/13/upshot/nike-vaporfly-next-percent-shoe-estimates.html)",not_spam
"OMG!!! You won't believe the insane offer we have for all our amazing followers!!! Sign up now and get a chance to win a ridiculous prize worth $$$!! Share this post and tag your BFFs for extra entries!! #winning #giveaways #youknowyouwantit ğŸ¤‘ğŸ¤‘ğŸ¤‘

",spam
"Hey there, social media addicts! Are you tired of scrolling through your feed and not finding anything juicy to sink your teeth into? Well, fear not, because we've got some super exciting news for you!

First of all, have you heard about our new feature where you can watch live streams of people sleeping? That's right, you can now tune in and watch complete strangers snore the night away. It's the ultimate way to cure your insomnia and creep out your friends.

But wait, there's more! We've also partnered with a sketchy weight loss company that promises to help you lose 50 pounds in just one week",spam
"URGENT! NEW DEALS ALERT!

ğŸš¨ğŸ‰ğŸ”¥ğŸğŸ’°ğŸ‘€

ğŸ”¥ Don't miss out on the HOTTEST deals of the season! Our #1 selling products are on sale NOW! ğŸ˜ğŸ¤‘

ğŸ Get up to 50% off on EVERYTHING! Yes, you read that right, EVERYTHING! ğŸ¤©
 
ğŸš¨ LIMITED TIME ONLY! ğŸš¨

ğŸ‘‰ Shop now at [insert sketchy website here] before it's too late! ğŸ˜±

Hurry, before your friends beat",spam
i want to start a project about musical statistics.. any help would be appropriated ,not_spam
"Are you tired of not getting enough followers on your social media account? Fret no more! Our premium package offers to boost your follower count by a staggering 500% in just one week!

",spam
"I am looking for data on various cryptocurrencies' (e.g. BTC, ETH, ZEC, BTG) wealth distribution, i.e. what percent of the total wealth do the top 1-10% of non-dust addresses hold? 

I came across this [site that gives some such data for Bitcoin](https://bitcoinprivacy.net/stats/1000.0), but am hoping to find others for comparison.

If anyone could point me in the right direction, or is interested in collaborating on this project that would be awesome. Thanks.",not_spam
"I have two datasets that contain information about retail stores.

Dataset 1 contains a unique identification number for each store, address, city, postal code, and store name. 

Dataset 2 also contains similar information as dataset 1. However, this dataset is sourced from a third party and all the unique identification numbers are different. Additionally, the address and store name fields may have differences in spelling/formatting. 

Is there a way to use some form of advanced analytics to match the two datasets? Both datasets are roughly 20000 rows.",not_spam
"Feeling bored? Tired of the same old stuff on your feeds? Well, you're in luck because we've got some exciting news for you, amigo! Today, we're introducing a brand new feature that will blow your mind (and probably your phone's memory, but who cares about that, right?).

Introducing our new MegaFlood option â€“ a powerful tool that will spam your friends and followers with countless messages, links, and advertisements! Are you ready to flood your feed with annoying notifications and irrelevant posts? Of course, you are! And with MegaFlood, you can do it all in just one click.

",spam
Only found odds for 2014 and 2010... (ex. https://bleacherreport.com/articles/2082883-world-cup-odds-2014-best-bets-and-tips-on-outright-winners-and-top-goal-scorer),not_spam
"Hot D3als ar3 h3r3! G3t th3 b3st st3als in town with our amazing n3w updat3s! W3 hav3 th3 hott3st products at th3 low3st pric3s you'v3 3v3r s33n! Don't miss your chanc3 to sav3 big on our on3-of-a-kind off3rs! 

",spam
"ATTENTION ALL USERS!!!! AMAZING OFFERS INSIDE!! COME AND GET 'EM WHILE THEY'RE HOT!! 

BOGO (that means buy one get one, for those who don't know) offers, FLASH sales, and exclusive giveaways that you won't find elsewhere. 

Don't miss out on these once in a lifetime deals, people! Get on board with our social network and be the FIRST to know about all of our amazing offers! 

Follow us, like us, share our posts, and tell your friends and family about all the amazing deals you're getting. 

Remember, the early bird gets the worm, so",spam
"Attention all users! It's time to get your social on and join [insert social network name here]! With our amazing features like likes, comments, and shares, you can finally stop living in obscurity and become a social media star!

But wait, there's more! We also offer super cool filters for your photos, stickers for your stories, and even a chat function so you can talk to your friends without ever leaving our app.

And don't forget about our sponsored content! Get ready for a never-ending feed of ads disguised as content, because at [insert social network name here], we care more about profit than actually connecting",spam
"Planning to do some analytics on system logs. If anyone know of any server log dataset, kindly let us know",not_spam
"Want to know the secret to being rich? I've got the inside scoop, folks! Just sign up for our premium membership and you'll have access to all the tips and tricks that'll make you a millionaire overnight!

",spam
"Introducing super duper awesome #productname, guaranteed to blow your mind and change your life! ğŸ¤¯ğŸ¤‘ğŸ’¥ Don't miss out on the chance to be the coolest kid on the block! Buy now! 

",spam
"Hi,

So I have been collecting data for a few months using excel. I collect data every day on a few select stocks that appear on a scanner I use. I have been manually inputting some of the information and letting excel formulas calculate lots of the data I need but I am running into a problem collecting chart data.

As of now the data I manually input are dates, stock name, price, volume and change %. I want to capture an image of what the chart for that stock on that day looked like. I have been manually taking screenshots of charts and saving them individually to a folder. Is there a better way to collect the data of the chart? Is there any methods of automating the screenshotting of a program and saving it?

Sorry if this post is in the wrong subreddit. Thanks in advance.",not_spam
"Are you tired of feeling left out? Do you crave attention and validation from strangers on the internet? Well, you've come to the right place! Our social network is the ultimate destination for meaningless status updates, selfies, and spam!

We have all the features you could ever want, including a news feed that's filled with clickbait articles and pointless updates from people you barely know. Plus, our messaging system is perfect for sending unsolicited messages and begging for likes and follows.

But that's not all! We also offer endless opportunities for you to waste your time and procrastinate. Our addictive games and mindless quizzes will keep you",spam
"I am working on a project that uses ngrams and vectorization to do name matching. I have a list of random financial institution names (about 50k) and I would like to match these names against a dictionary of companies. I have been using the government consumer complaints data dump and it works decently well, however, I'm curious if there is another source to find a list of unique financial institution names. This includes companies like,

* Mortgage Lenders
* Credit Card Companies
* Banks

&amp;#x200B;",not_spam
"Welcome to our social network!

Get ready for the ultimate online experience, where you can connect with friends, family, and total strangers just like you!

Looking for something to do? Join one of our exclusive groups! We've got everything from cooking clubs to cat memes.

Feeling social? Start a conversation with anyone and everyone using our advanced messaging system!

Want to showcase your unique personality? Post pictures, videos, and even GIFs to your profile! The possibilities are endless!

And don't forget about our amazing features like endless notifications, constant ads, and our patented spam filters!

So join us today and discover the social network of your",spam
"Hi all,

This is my first ever post on Reddit lol.

My question: does anybody know where I can find a free dataset of a random companyâ€™s sales orders?

I am searching for a dataset of e.g. a random companyâ€™s sales, incl. costprice, margin, country sold to etc.. 
I have to perform data analysis on it from a financial audit-perspective.
I kinda wanna look for a dataset on which I can analyze whether e.g. sales to certain countries are subject to fraud.

Thanks,
R",not_spam
"I've seen two, the South Korea one and the DXY one, both are very scarce, basically only having age and gender and only with cases that tested positive.

Is there a more comprehensive dataset with individual cases, including things such as comorbidites, people that tested negative, travel history... etc ?",not_spam
I would like to find a historical dataset of movie box office amounts (not just the hits). Any other data would be appreciated as well.,not_spam
"Hey you guuuuuys!! Are you totally sick of boring old social media platforms that don't understand the real deal? Enter our amazing super cool app that will change your life FOREVER. Like seriously FOREVER. 

We have all the things you could ever want - like emojis that come to life and follow you around all day. Plus, we have a super exclusive group that only the coolest cats can join. And let's not forget about our sweet sweet deals with all the best brands out there. You want it, we got it.

But that's not even the best part. Our app is the only one out there that",spam
"Hi, I'm currently taking a university subject where I need to use Metaheuristic Algorithms or NNs and apply them to any manufacturing or service system.  


I've been searching on uci and kaggle so far, but I haven't really found that much (I found a few). Any suggestions where else I can look? Like open data sets or challenges

&amp;#x200B;

Thank you",not_spam
"Get rich quick with our new amazing scheme! 

",spam
"Check out these amazing deals on weight loss pills and other health supplements! Lose weight without even trying with our all natural products. Plus, have you heard about our exclusive skincare line? Get youthful, glowing skin in no time. Don't wait, order now!

",spam
"Are you tired of the same old, boring social media platforms? Want to join a community that's always viral and never boring? Then look no further than X-treme Social! Our platform is the ultimate experience for all lovers of memes, trolls, and outrageous content.

We've got it all, from fake news to clickbait articles that will have you gasping in shock. Don't believe us? Try our new feature where you can buy followers and likes to give your profile the boost it needs. It's totally legal and totally amazing!

Not only that, but we also have a marketplace for selling and buying illicit substances. And",spam
"Are you tired of being low-key and unnoticed online? Are you sick of just lurking in the shadows and not getting any attention? Well, I've got the solution for you, my friends! With our latest and greatest features, you can finally become the star of the show and get all the likes, comments, and shares your little heart desires.

",spam
"Get rich quick with our amazing investment program! Make thousands of dollars in just a few days! Don't miss out on this opportunity to become a millionaire!

",spam
"It seems that the data for the last ping sent by the plane is hard to not find, but it sent multiple pings (7 I think), and I'm trying to find the data for the other 6.  Anyone know where I could find it?",not_spam
"""Get ready to up your game with the hottest social network around! Our platform is blowing up faster than a fireworks show on the Fourth of July. Don't be left in the dust! 

Our network is packed full of amazing features you won't find anywhere else. We've got groups for every interest under the sun, from cooking to crocheting to kitesurfing. 

But wait, there's more! Our algorithm is so advanced, it practically reads your mind. It knows exactly what you want to see and shows it to you before you even know you wanted it! Plus, our sponsored content is top notch. Whether",spam
"The November submissions dump is now available.  This dump also includes the last remaining posts from /r/incels (up to when it was permanently banned on November 3).  

There are a total of 10,377,379 submissions in this dump.

The file size is 3,206,303,853 bytes compressed / 22,475,953,759 uncompressed.

SHA256SUM: fefce8f8e4a41ba41048cc01b23a6f5288bc0c6b7ae497a10a327a951d31de69

------------------------

# Important info

**New field for submission objects:**

There is a new field available called ""subreddit_type.""  This field usually has a value of ""public"" but can also have a value of ""user"" if someone makes a post in their profile page.  The Washington Post makes extensive use of this new feature.

**Upcoming changes in 2018:**

There have been a lot of requests for smaller file sizes since the monthly dumps (especially for comments) is rather large.  Beginning in 2018, I will be providing daily comment and submission dumps.  I will still provide the monthly dumps in the same format that I have in the past, but the daily dumps will give people the ability to test their programs on much smaller data files.  

The daily dumps will have a 3 day lag in order to allow scores to settle while also allowing users to remove or delete comments and posts that may have accidentally included private information or other data that was not intended to be archived long-term.  The daily dumps will include submissions and comments within one archived file and will have the format RCS_YYYY-MM-DD.bz2. For example, on January 5'th, 2018, the daily comment and submissions made on January 1'st will be available as RCS_2018-01-01.bz2

If you have any questions or comments, please let me know!

Also, as always, if you would like to donate to this project, please use the following link:  https://pushshift.io/donations/  -- donations are always appreciated but never required.  Donations do help tremendously in offsetting the costs of the archive and API project which has now exceeded over $10k in expenses.  Thank you!!",not_spam
"I'm interested in personal analytics and I'd like to find a game that I can start as a new player and watch how my performance changes across time. I'm working developing my analysis skills in R and web-scraping in general, so I figured this might be a fun project.

Any ideas would be great!",not_spam
"Buy our new miracle weight loss pills! Lose 10 pounds in one week without any exercise or dieting! Limited time offer, act now!

",spam
"Hey, so I work in Graph theory and for a project I was hoping to find a data set with all the counties in the United States and the counties they border. I was hoping to do something like a 4 color theorem map and go from there. Any help would be appreciated.",not_spam
"""FREE MONEY & PRIZES! CLICK NOW!""

Are you tired of working hard for your money? Look no further! Our giveaway extravaganza is here to give you a chance at winning big! All you have to do is click the link and fill out a short survey to be entered to win a variety of prizes.

But wait, there's more! For a limited time only, we're offering a special deal - sign up for our premium membership and receive even more chances to win! Plus, get exclusive access to content and discounts on our partner products.

Don't miss out on this once in a lifetime opportunity to become a winner",spam
"I need annual population estimates of the following metropolitan statistical areas:

* Buffalo-Cheektowaga-Niagara Falls, NY

* Cleveland-Elyria, OH
 
* Portland-Vancouver-Hillsboro, OR-WA
 
* San Diego-Carlsbad, CA 
 
* Houston-The Woodlands-Sugar Land, TX 
 
* Cincinnati, OH-KY-IN
 
* Kansas City, MO-KS
 
* Baltimore-Columbia-Towson, MD
 
* Washington-Arlington-Alexandria, DC-VA-MD-WV 
 
* New Orleans-Metairie, LA 
 
* Salt Lake City, UT
 
* Dallas-Fort Worth-Arlington, TX
 
* Los Angeles-Long Beach-Anaheim, CA
 
* Sacramentoâ€“Rosevilleâ€“Arden-Arcade, CA 

Has to go back as far as 1969. 

Does anyone know where I can find this? I've been combing through census.gov and haven't found anything earlier than 1990.
",not_spam
"Buy our new weight loss pills today! Try them now and lose 10 pounds in just one week! Say goodbye to your stubborn belly fat and hello to a slim, sexy figure. Our pills are made with all-natural ingredients and have been clinically proven to work. Don't wait any longer, order now and start your journey to a healthier you!

",spam
"Subscribe now to our premium membership package and get exclusive access to the juiciest gossip, the hottest trends, and the most scandalous stories! With our exclusive content, you'll always have something to talk about with your friends and followers.

",spam
"I'm looking for a practical dictionary dataset for English NLP, preferably something that is structured as a set of definitions associated with a word, rather than a complete sentence.

So, for example, ""cat"" would be ideally defined as {pet, animal, feline}, or something like that, rather than, ""a cat is a type of household pet"".

Any recommendations would be greatly appreciated.",not_spam
"""BREAKING NEWS! You won't BELIEVE what's happening on our platform!!! ğŸ¤¯ğŸ”¥ğŸš¨ Join NOW for all the JUICY details!!!""

",spam
"Are you tired of feeling left out of the latest trends? Well, fear no more because [Insert social network name here] is here to save the day! With our endless stream of updates and notifications, you'll never miss out on what's happening in the world.

",spam
Is there a way to contact Reddit in order to request certain data sets?,not_spam
"ğŸ”¥ğŸ˜ğŸ’¯HOT NEW OFFER ALERTğŸ’¯ğŸ˜ğŸ”¥

ğŸš€Get your hands on the hottest products of the season now!ğŸš€

ğŸ˜From skincare to fashion and everything in between, weâ€™ve got you covered!ğŸ˜

ğŸ’¥Limited time only! Donâ€™t miss out on these amazing deals!ğŸ’¥

ğŸ¤‘Prices so low, you wonâ€™t believe your eyes!ğŸ¤‘

ğŸ‘‰Swipe up now to start shopping!ğŸ‘ˆ

ğŸ›ï¸Happy shopping!ğŸ›ï¸",spam
"I'm looking for a database of resumes. I was hoping indeed.com would have a REST API, and they do, but only for job posting (not resumes/profiles).

I think linkedin doesn't off much data (unless the profile users does an Oauth and gives you access).

Does anyone know where to get resume data (preferably on sales people, b2b)?

thanks!",not_spam
"Want an easy way to instantly boost your followers and likes? Look no further than our latest feature update! With just one click, you can buy followers and likes in bulk - no more waiting around for organic growth!

But that's not all! Our platform now offers a brand new feature that allows you to automatically comment on other users' posts with generic phrases like ""great post!"" and ""love this!"" - all in an effort to boost your own visibility.

And if that wasn't enough, we also offer a premium subscription that unlocks access to even more spammy tools, like fake engagement groups and bulk direct messaging.

So what are you",spam
"Get rich quick with our revolutionary money-making scheme! Make hundreds, no, thousands of dollars with just a few clicks! Don't waste your time on boring jobs or tedious tasks â€“ join our community and start living the dream!

",spam
"I'm trying to arrange a feature matrix of size (1425 x 15) where each column represents the natural frequency of each sensor and each row represents a single data file. However, I keep on getting the same values in each column and the next value is printed to the next row. How would I be able to rearrange the feature matrix? I tried to form a code which can be found below, but, I don't know what my mistake in the code. I formed different codes but the results were still the same. Please find below the codes formed:

&amp;#x200B;

Code 1:

    # Matrix array:
    DataSizerow=0
    DataSizecolumn=0
    Data = np.zeros((1425,15))
    
    # Forming a feature matrix from frequency, PSD and AutoCorrelation values:
            # Dataset.shape[1] represesnt the acceleration dataset column
            # List_Of_DataFrame_Feature = []
            # List_Of_DataFrame_Label = []
            Length_PSD_mean = len(x_axis_list_psd_filtered)
            print('Length of PSD values: ', Length_PSD_mean)
            if Length_PSD_mean &gt; 1:
                for PSD_Mean in range(Length_PSD_mean):
                    X_axis_values_psd_mean = mean(x_axis_list_psd_filtered)
            else:
                X_axis_values_psd_mean = x_axis_list_psd_filtered
            DataFrame_Feature = np.array(X_axis_values_psd_mean)
            DataFrame_Feature1 = np.array(x_axis_list_filtered)
            DataSizecolumn = DataSizecolumn + 1
            print('Data Size column: ',DataSizecolumn)
            Data[DataSizecolumn - 1] = DataFrame_Feature
            if DataSizecolumn in range(1, dataset.shape[1]):
                DataSizerow = DataSizerow + 1
                print('Data Size row: ', DataSizerow)
                Data[DataSizerow - 1] = DataFrame_Feature
            print('Sensor {0}'.format(k))
            print('Data Frame: ', Data)

&amp;#x200B;

Code 2:

            # Dataset.shape[0] represesnt the acceleration dataset row
            # Dataset.shape[1] represesnt the acceleration dataset column
            DataSizecolumn1 = 0
            DataSizerow1 = 0
            DataFrame1 = np.zeros((1426, 16))
            for DataSizecolumn1 in range(1, dataset.shape[1]):
                print('Data Size column: ', DataSizecolumn1)
                for DataSizerow1 in range(1, dataset.shape[0]):
                    print('Data Size row: ', DataSizerow1)
                    DataFrame1[DataSizerow1][DataSizecolumn1] = DataFrame_Feature
            print('Sensor {0}'.format(k))
            print('DataFrame: ', DataFrame1)

&amp;#x200B;

Code 3:

            # Dataset.shape[0] represesnt the acceleration dataset row
            # Dataset.shape[1] represesnt the acceleration dataset column
            DataSizecolumn2 = 0
            DataSizerow2 = 0
            DataFrame2 = np.zeros((1426, 16))
            for DataSizecolumn2 in range(1, dataset.shape[1]):
                print('Data Size column: ', DataSizecolumn2)
                DataFrame2[DataSizecolumn2] = DataFrame_Feature
                if DataSizecolumn2 == dataset.shape[1]:
                    DataSizerow2 = DataSizerow2 + 1
                    print('Data Size row: ', DataSizerow2)
                    DataFrame2[DataSizerow2] = DataFrame_Feature
                    if DataSizerow2 == dataset.shape[0]:
                        break
            print('Sensor {0}'.format(k))
            print('DataFrame: ', DataFrame2)

&amp;#x200B;

The expected result should be like the matrix below of single row:

              Sensor 1 | Sensor 2 | Sensor 3 | Sensor 4 | Sensor 5 | Sensor 6 | 
    Data file     13   |   51.5   |    13    |   13     |    13    |    13    |
              Sensor 7 | Sensor 8 | Sensor 9 | Sensor 10 | Sensor 11 | Sensor 12 | 
    Data file     8.5  |    14    |    20    |   18.6    |   9.5     |   39    |
              Sensor 13 | Sensor 14 | Sensor 15 | 
    Data file     8.5   |    8.5    |    8.5    | 

&amp;#x200B;

But the actual result is below:

              Sensor 1 | Sensor 2 | Sensor 3 | Sensor 4 | Sensor 5 | Sensor 6 | 
    Data file     13   |   13     |    13    |   13     |    13    |    13    |
              Sensor 7 | Sensor 8 | Sensor 9 | Sensor 10 | Sensor 11 | Sensor 12 | 
    Data file     13   |    13    |    13    |    13     |    13     |    13     |
              Sensor 13 | Sensor 14 | Sensor 15 | 
    Data file     13    |    13     |    13     | 

&amp;#x200B;

Please find the attached picture for the actual feature matrix.

Please find below the whole code:

    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.fftpack import fft
    from scipy.signal import welch
    import glob
    import sys
    from numpy import NaN, Inf, arange, isscalar, asarray, array
    from statistics import mean
    np.set_printoptions(threshold=sys.maxsize)
    
    def peakdet(v, delta, x=None):
        """"""
        Converted from MATLAB script at http://billauer.co.il/peakdet.html
    
        Returns two arrays
    
        function [maxtab, mintab]=peakdet(v, delta, x)
        %PEAKDET Detect peaks in a vector
        %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local
        %        maxima and minima (""peaks"") in the vector V.
        %        MAXTAB and MINTAB consists of two columns. Column 1
        %        contains indices in V, and column 2 the found values.
        %
        %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices
        %        in MAXTAB and MINTAB are replaced with the corresponding
        %        X-values.
        %
        %        A point is considered a maximum peak if it has the maximal
        %        value, and was preceded (to the left) by a value lower by
        %        DELTA.
    
        % Eli Billauer, 3.4.05 (Explicitly not copyrighted).
        % This function is released to the public domain; Any use is allowed.
    
        """"""
        maxtab = []
        mintab = []
    
        if x is None:
            x = arange(len(v))
    
        v = asarray(v)
    
        if len(v) != len(x):
            sys.exit('Input vectors v and x must have same length')
    
        if not isscalar(delta):
            sys.exit('Input argument delta must be a scalar')
    
        if delta &lt;= 0:
            sys.exit('Input argument delta must be positive')
    
        mn, mx = Inf, -Inf
        mnpos, mxpos = NaN, NaN
    
        lookformax = True
    
        for i in arange(len(v)):
            this = v[i]
            if this &gt; mx:
                mx = this
                mxpos = x[i]
            if this &lt; mn:
                mn = this
                mnpos = x[i]
    
            if lookformax:
                if this &lt; mx - delta:
                    maxtab.append((mxpos, mx))
                    mn = this
                    mnpos = x[i]
                    lookformax = False
            else:
                if this &gt; mn + delta:
                    mintab.append((mnpos, mn))
                    mx = this
                    mxpos = x[i]
                    lookformax = True
        return array(maxtab), array(mintab)
    
    # Definition to get values needed for the FFT plot:
    def get_fft_values(y_values, T, N, f_s):
        f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)
        fft_values_ = fft(y_values)
        fft_values = 2.0/N * np.abs(fft_values_[0:N//2])
        return f_values, fft_values
    
    # Definition to find the values of axis:
    def findyaxis(y_axis_input, x, y):
        x = np.array(x)
        order = y.argsort()
        y = y[order]
        x = x[order]
        input = np.array(y_axis_input)
        return x[y.searchsorted(input, 'left')]
    
    def merge(list1, list2):
        merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))]
        return merged_list
    
    def autocorr(x):
        result = np.correlate(x, x, mode='full')
        return result[len(result) // 2:]
    
    def get_autocorr_values(y_values, T, N, f_s):
        autocorr_values = autocorr(y_values)
        x_values = np.array([T * jj for jj in range(0, N)])
        return x_values, autocorr_values
    
    def signaltonoise(a, axis=0, ddof=0):
        """"""
        The signal - to - noise ratio of the input data. Returns the signal - to - noise ratio of `a`, here defined as the
        mean divided by the standard deviation.
        Parameters
        ----------
        a: array_like An array_like object containing the sample data.
    
        axis: int or None, optional.
        If axis is equal to None, the array is first ravel 'd. If axis is an
        integer, this is the axis over which to operate.Default is 0.
    
        ddof: int, optional.
        Degrees of freedom correction for standard deviation.Default is 0.
    
        Returns
        -------
        s2n: ndarray.
        The mean to standard deviation ratio(s) along `axis`, or 0 where the standard deviation is 0.
        """"""
        a = np.asanyarray(a)
        m = a.mean(axis)
        sd = a.std(axis=axis, ddof=ddof)
        return np.where(sd == 0, 0, m/sd)
    
    def get_psd_values(y_values, T, N, f_s):
        f_values, psd_values = welch(y_values, fs=f_s)
        return f_values, psd_values
    
    def smooth(y, box_pts):
        box = np.ones(box_pts)/box_pts
        y_smooth = np.convolve(y, box, mode='same')
        return y_smooth
    
    # Assign folder to `folder`:
    DataPathList = sorted(glob.glob('DataPath*.txt'), key = lambda z: (len(z)))
    # DataSizerow = 0
    # DataSizecolumn = 0
    MaxDataSizerow = 1425
    MaxDataSizecolumn = 15
    Data = np.zeros((1426,15))
    for fp in DataPathList:
        # Load spreadsheet:
        print('Opened file number: {}'.format(fp))
        dataset = np.loadtxt(fname=fp)
        print('The size matrix of Sensors Undamaged Scenario:', dataset.shape)
        print('The column size matrix of Sensors Undamaged Scenario:',dataset.shape[1])
        for k in range(1, dataset.shape[1]):
            # Create some time data to use for the plot:
            dt = 1
    
            # Getting the time period and frequency:
            t_n = 2
            N = 2192
            T_s = 0.00390625
            f_s = 256
    
            # Obtaining data in order to plot the graph:
            y = dataset[:,k]
            x = np.arange(0, len(y), dt)
            x1 = np.linspace(0, t_n, N)
    
            SNR = signaltonoise(y)
            print('Signal-to-Noise Ratio (SNR): ', SNR, 'dB')
    
            SR = 1/t_n
            SR1 = 1/T_s
            Nf = (SR)/2
            Nf1 = (SR1)/2
    
            # Plotting the acceleration-time graph:
            # plt.plot(x1, y)
            # plt.xlabel('Time (s)')
            # plt.ylabel('Acceleration (ms^-2)')
            # plt.title('Plot of Sensor {0}'.format(k))
            # # plt.show()
            # plt.show(block = False)
            # print('Plot of Sensor {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            ## Fast Fourier Transform (FFT)
            # Obtaining the Sampling frequency and time period:
            print('Period:', T_s, 's')
            print('Sampling Frequency: ', f_s, 'Hz')
            f_values, fft_values = get_fft_values(y, T_s, N, f_s)
    
            # Setting plot limits:
            ax = plt.gca()
            ax.set_ylim([min(fft_values), max(fft_values)])
            ax.set_xlim([min(f_values), max(f_values)])
            amp_index = np.array(fft_values)
            amp_index_max = max(amp_index)
            amp_index_min = min(amp_index)
            delta = (amp_index_max + amp_index_min)/2
    
            # Obtaining the amplitude values:
            maxtab, mintab = np.array(peakdet(amp_index, delta))
            amplitudes3 = maxtab
            y_axis_list = []
            for e in range(len(amplitudes3)):
                amplitude3 = amplitudes3[e]
                amplitude3final = amplitudes3[e][1]
                y_values = amplitude3final
                y_axis_list.append(y_values)
            x_axis = np.abs(f_values)
            x_axis_list = []
            for o in range(len(y_axis_list)):
                x_axis_values = findyaxis(y_axis_list[o], x_axis, fft_values)
                x_axis_list.append(x_axis_values)
            peaks = merge(x_axis_list, y_axis_list)
            print('Number of Peaks Coordinates: ', len(peaks))
            print('Peaks Coordinates: ', peaks)
    
            # Plotting the amplitude-frequency graph:
            # plt.plot(f_values, fft_values, linestyle='-', color='blue')
            # plt.scatter(x_axis_list, y_axis_list, marker='*', color='red', label='Peaks: {0}'.format(len(peaks)))
            # plt.xlabel('Frequency [Hz]', fontsize=16)
            # plt.ylabel('Amplitude', fontsize=16)
            # plt.title(""Frequency domain of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('Frequency domain with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            # Obtaining the PSD values:
            f_values, psd_values = get_psd_values(y, T_s, N, f_s)
            amp_psd_index = np.array(psd_values)
            amp_psd_index_max = max(amp_psd_index)
            amp_psd_index_min = min(amp_psd_index)
            psd_delta = (amp_psd_index_max + amp_psd_index_min) / 2
            maxtab, mintab = np.array(peakdet(amp_psd_index, psd_delta))
            amplitudes_psd = maxtab
            y_axis_list_psd = []
            for e in range(len(amplitudes_psd)):
                amplitude_psd = amplitudes_psd[e]
                amplitude_psd_final = amplitudes_psd[e][1]
                y_values_psd = amplitude_psd_final
                y_axis_list_psd.append(y_values_psd)
            x_axis_psd = np.abs(f_values)
            x_axis_list_psd = []
            for o in range(len(y_axis_list_psd)):
                x_axis_values_psd = findyaxis(y_axis_list_psd[o], x_axis_psd, psd_values)
                x_axis_list_psd.append(x_axis_values_psd)
            psd_peaks = merge(x_axis_list_psd, y_axis_list_psd)
            print('Number of PSD Peaks Coordinates: ', len(psd_peaks))
            print('PSD Peaks Coordinates: ', psd_peaks)
    
            # Plotting PSD-Frequency graph:
            # plt.plot(f_values, psd_values, linestyle='-', color='blue')
            # plt.scatter(x_axis_list_psd, y_axis_list_psd, marker='*', color='red', label='Peaks: {0}'.format(len(psd_peaks)))
            # plt.xlabel('Frequency [Hz]')
            # plt.ylabel('PSD [V**2 / Hz]')
            # plt.title(""PSD of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('PSD with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            # Obtaining AutoCorrelation values:
            t_values, autocorr_values = get_autocorr_values(y, T_s, N, f_s)
            amp_auto_corr_index = np.array(autocorr_values)
            amp_auto_corr_index_max = max(amp_auto_corr_index)
            amp_auto_corr_index_min = min(amp_auto_corr_index)
            auto_corr_delta = (amp_auto_corr_index_max + amp_auto_corr_index_min) / 2
            maxtab, mintab = np.array(peakdet(amp_auto_corr_index, auto_corr_delta))
            amplitudes_auto_corr = maxtab
            y_axis_list_auto_corr = []
            for e in range(len(amplitudes_auto_corr)):
                amplitude_auto_corr = amplitudes_auto_corr[e]
                amplitude_auto_corr_final = amplitudes_auto_corr[e][1]
                y_values_auto_corr = amplitude_auto_corr_final
                y_axis_list_auto_corr.append(y_values_auto_corr)
            x_axis_auto_corr = np.abs(t_values)
            x_axis_list_auto_corr = []
            for o in range(len(y_axis_list_auto_corr)):
                x_axis_values_auto_corr = findyaxis(y_axis_list_auto_corr[o], x_axis_auto_corr, autocorr_values)
                x_axis_list_auto_corr.append(x_axis_values_auto_corr)
            auto_corr_peaks = merge(x_axis_list_auto_corr, y_axis_list_auto_corr)
            print('Number of AutoCorrelation Peaks Coordinates: ', len(auto_corr_peaks))
            print('AutoCorrelation Peaks Coordinates: ', auto_corr_peaks)
    
            # Plotting Autocorrelation-Time delay graph
            # plt.plot(t_values, autocorr_values, linestyle='-', color='blue')
            # plt.scatter(x_axis_list_auto_corr, y_axis_list_auto_corr, marker='*', color='red', label='Peaks: {0}'.format(len(auto_corr_peaks)))
            # plt.xlabel('time delay [s]')
            # plt.ylabel('Autocorrelation amplitude')
            # plt.title(""AutoCorrelation of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('AutoCorrelation with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            print('Completed file {}'.format(fp), ', Now going into filtering the signal')
    
    ########################################################################################################################
    ############################################## Filtered Section ########################################################
    ########################################################################################################################
    
            # Plotting the smoothed filtered signal acceleration-time graph:
            y_filter = smooth(y, 10)
            # plt.plot(x1, y_filter)
            # plt.xlabel('Time (s)')
            # plt.ylabel('Acceleration (ms^-2)')
            # plt.title('Plot of Smoothed Sensor {0}'.format(k))
            # # plt.show()
            # plt.show(block = False)
            # print('Plot of Smoothed Sensor {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            ## Filtered Fast Fourier Transform (FFT)
            # Obtaining the Sampling frequency and time period:
            print('Period:', T_s, 's')
            print('Sampling Frequency: ', f_s, 'Hz')
            f_values_filtered, fft_values_filtered = get_fft_values(y_filter, T_s, N, f_s)
    
            # Setting plot limits:
            ax = plt.gca()
            ax.set_ylim([min(fft_values_filtered), max(fft_values_filtered)])
            ax.set_xlim([min(f_values_filtered), max(f_values_filtered)])
            amp_index_filtered = np.array(fft_values_filtered)
            amp_index_filtered_max = max(amp_index_filtered)
            amp_index_filtered_min = min(amp_index_filtered)
            amp_index_filtered_delta = (amp_index_filtered_max + abs(amp_index_filtered_min)) / 2
    
            # Obtaining the amplitude values:
            maxtab, mintab = np.array(peakdet(amp_index_filtered, amp_index_filtered_delta))
            amplitudes3 = maxtab
            y_axis_list_filtered = []
            for e in range(len(amplitudes3)):
                amplitude3 = amplitudes3[e]
                amplitude3final = amplitudes3[e][1]
                y_values_filtered = amplitude3final
                y_axis_list_filtered.append(y_values_filtered)
            x_axis_filtered = np.abs(f_values_filtered)
            x_axis_list_filtered = []
            for o in range(len(y_axis_list_filtered)):
                x_axis_values_filtered = findyaxis(y_axis_list_filtered[o], x_axis_filtered, fft_values_filtered)
                x_axis_list_filtered.append(x_axis_values_filtered)
            peaks_filtered = merge(x_axis_list_filtered, y_axis_list_filtered)
            print('Number of Filtered Peaks Coordinates: ', len(peaks_filtered))
            print('Filtered Peaks Coordinates: ', peaks_filtered)
    
            # Plotting the amplitude-frequency graph:
            # plt.plot(f_values_filtered, fft_values_filtered, linestyle='-', color='blue')
            # plt.scatter(x_axis_list_filtered, y_axis_list_filtered, marker='*', color='red', label='Peaks: {0}'.format(len(peaks_filtered)))
            # plt.xlabel('Frequency [Hz]', fontsize=16)
            # plt.ylabel('Amplitude', fontsize=16)
            # plt.title(""Filtered Frequency domain of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('Filtered Frequency domain with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            # Obtaining PSD Filtered values:
            f_values_filtered, psd_values_filtered = get_psd_values(y_filter, T_s, N, f_s)
            amp_psd_index_filtered = np.array(psd_values_filtered)
            amp_psd_index_filtered_max = max(amp_psd_index_filtered)
            amp_psd_index_filtered_min = min(amp_psd_index_filtered)
            amp_psd_index_filtered_delta = (amp_psd_index_filtered_max + abs(amp_psd_index_filtered_min)) / 2
            maxtab, mintab = np.array(peakdet(amp_psd_index_filtered, amp_psd_index_filtered_delta))
            amplitudes_psd_filtered = maxtab
            y_axis_list_psd_filtered = []
            for e in range(len(amplitudes_psd_filtered)):
                amplitude_psd_filtered = amplitudes_psd_filtered[e]
                amplitude_psd_final_filtered = amplitudes_psd_filtered[e][1]
                y_values_psd_filtered = amplitude_psd_final_filtered
                y_axis_list_psd_filtered.append(y_values_psd_filtered)
            x_axis_psd_filtered = np.abs(f_values_filtered)
            x_axis_list_psd_filtered = []
            for o in range(len(y_axis_list_psd_filtered)):
                x_axis_values_psd_filtered = findyaxis(y_axis_list_psd_filtered[o], x_axis_psd_filtered, psd_values_filtered)
                x_axis_list_psd_filtered.append(x_axis_values_psd_filtered)
            psd_peaks_filtered = merge(x_axis_list_psd_filtered, y_axis_list_psd_filtered)
            print('Number of Filtered PSD Peaks Coordinates: ', len(psd_peaks_filtered))
            print('Filtered PSD Peaks Coordinates: ', psd_peaks_filtered)
            print('X-Axis Filtered PSD Amplitudes: ', amplitudes_psd_filtered[:, [0]])
            length_amplitudes_psd_filtered = len(amplitudes_psd_filtered[:, [0]])
            print('Amplitudes PSD filtered length: ', length_amplitudes_psd_filtered)
            if length_amplitudes_psd_filtered &gt; 1:
                # for PSD_Mean in range(length_amplitudes_psd_filtered):
                X_axis_values_psd_mean = mean(x_axis_list_psd_filtered)
                print('Mean Amplitudes PSD filtered: ', X_axis_values_psd_mean)
            else:
                X_axis_values_psd_mean = x_axis_list_psd_filtered
    
            # Plotting PSD-Frequency filtered graph:
            # plt.plot(f_values_filtered, psd_values_filtered, linestyle='-', color='blue')
            # plt.scatter(x_axis_list_psd_filtered, y_axis_list_psd_filtered, marker='*', color='red', label='Peaks: {0}'.format(len(psd_peaks_filtered)))
            # plt.xlabel('Frequency [Hz]')
            # plt.ylabel('PSD [V**2 / Hz]')
            # plt.title(""Filtered PSD of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('Filtered PSD with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
            # Obtaining Filtered AutoCorrelation values:
            t_values_filtered, autocorr_values_filtered = get_autocorr_values(y_filter, T_s, N, f_s)
            amp_auto_corr_index_filtered = np.array(autocorr_values_filtered)
            amp_auto_corr_index_filtered_max = max(amp_auto_corr_index_filtered)
            amp_auto_corr_index_filtered_min = min(amp_auto_corr_index_filtered)
            amp_auto_corr_index_filtered_delta = (amp_auto_corr_index_filtered_max + abs(amp_auto_corr_index_filtered_min)) / 2
            maxtab, mintab = np.array(peakdet(amp_auto_corr_index_filtered, amp_auto_corr_index_filtered_delta))
            amplitudes_auto_corr_filtered = maxtab
            y_axis_list_auto_corr_filtered = []
            for e in range(len(amplitudes_auto_corr_filtered)):
                amplitude_auto_corr_filtered = amplitudes_auto_corr_filtered[e]
                amplitude_auto_corr_final_filtered = amplitudes_auto_corr_filtered[e][1]
                y_values_auto_corr_filtered = amplitude_auto_corr_final_filtered
                y_axis_list_auto_corr_filtered.append(y_values_auto_corr_filtered)
            x_axis_auto_corr_filtered = np.abs(t_values_filtered)
            x_axis_list_auto_corr_filtered = []
            for o in range(len(y_axis_list_auto_corr_filtered)):
                x_axis_values_auto_corr_filtered = findyaxis(y_axis_list_auto_corr_filtered[o], x_axis_auto_corr_filtered, autocorr_values_filtered)
                x_axis_list_auto_corr_filtered.append(x_axis_values_auto_corr_filtered)
            auto_corr_peaks_filtered = merge(x_axis_list_auto_corr_filtered, y_axis_list_auto_corr_filtered)
            print('Number of Filtered AutoCorrelation Peaks Coordinates: ', len(auto_corr_peaks_filtered))
            print('Filtered AutoCorrelation Peaks Coordinates: ', auto_corr_peaks_filtered)
    
            # Plotting AutoCorrelation-Time delay filtered graph:
            # plt.plot(t_values_filtered, autocorr_values_filtered, linestyle='-', color='blue')
            # plt.scatter(x_axis_list_auto_corr_filtered, y_axis_list_auto_corr_filtered, marker='*', color='red', label='Peaks: {0}'.format(len(auto_corr_peaks_filtered)))
            # plt.xlabel('time delay [s]')
            # plt.ylabel('Autocorrelation amplitude')
            # plt.title(""Filtered AutoCorrelation of the signal {0}"".format(k), fontsize=16)
            # plt.legend()
            # # plt.show()
            # plt.show(block = False)
            # print('Filtered AutoCorrelation with peaks of the signal {0}'.format(k))
            # plt.pause(5)  # Pauses the program for 10 seconds
            # plt.close('all')
    
    ########################################################################################################################
    ############################################## Feature Matrix ##########################################################
    ########################################################################################################################
            # Forming a feature matrix from frequency, PSD and AutoCorrelation values:
            for DataSizeRow in range(MaxDataSizerow):
                for DataSizeColumn in range(MaxDataSizecolumn):
                    DataFrame_Feature = np.array(X_axis_values_psd_mean)
                    Data[DataSizeColumn - 1] = DataFrame_Feature
                    Data[DataSizeColumn + 1]
                    break
            print('Data Frame: ', Data)
        # np.savetxt('DataFrameTestfinal1.txt', Data, delimiter = ' , ')
        # # np.savetxt('DataFrame3.txt', DataFrame, delimiter=' , ')
        # np.savetxt('DataFrameTestfinal2.txt', DataFrame1, delimiter=' , ')
        # np.savetxt('DataFrameTestfinal3.txt', DataFrame2, delimiter=' , ')
        print('Completed both original and filtered signals of file {}'.format(fp))

&amp;#x200B;

The dataset is from the website link.

Link:  [http://users.metropolia.fi/\~kullj/JrkwXyZGkhF/wooden\_bridge\_time\_histories/](http://users.metropolia.fi/~kullj/JrkwXyZGkhF/wooden_bridge_time_histories/)

&amp;#x200B;

Thank you for your help.",not_spam
"Are you tired of your boring life? Want to add some excitement and sparkle? Well, look no further because our social network has got you covered! Weâ€™ve got all the crazy memes, funny videos, and clickbait articles you could ever want!

",spam
"I have a question in mind that I would like to answer, but I would need to have income distribution data at the county level. I found some relevant data on the U.S. Census website, but only lumped statistics  like *median* income for the whole county. What I need is the actual list of individual incomes so that I can make a histogram for that county.

Is it possible to get that kind of data from the Census site somewhere, or is that resolution of data kept completely private? I'm obviously not looking for any personally identifying information, just enough data points to plot the distribution and calculate the statistics I'm actually interested in instead of being handed a median or average or whatever. Multiple years going back through history would be ideal, but one recent year would suffice to get started.

I'm sure it must be somewhere on the Census site if it's available, but I'm not having any luck finding it and if someone knows that it's simply not public I could avoid wasting tons of time continuing to look for it.

Thanks!",not_spam
"L1k3 4nd 53Nd TH3 gr34t35t F4k3 0ff3r 3V3R!!! 
Y'all gotta ch3ck th15 0ut!!! 50 m4ny 4w350m3 b3n3f1t5 f0r y0u t0 m155 0ut 0n! G3t fr33 l1k3s, f0ll0w3r5, 4nd 34rn m0n3y w1th 0ur 5up3r 34y t",spam
"Hi, my group and I have to do a multiple linear regression or ANOVA project. We originally wanted to do something along the lines of how does age, race, sex, and level of automation in an industry affect your employment rate. However, the only data we found showed rows of industries and the numbers or percents of each race, sex, age etc in that said industry. This data wouldn't work right? For MLR, we need data of i.e. 10000 individuals, and their specifics regarding race sex age so that we can see how this works with a specific response variable right? We can't just have a chart of the total individuals employed by their specifics.

Sorry if that didn't make sense we're all so lost",not_spam
"Wts up guys, am here to talk about the hottest thing in town: our new product!! It's so amazing, you won't believe it! So hurry up and get it before it's too late! And hey, don't forget to follow us on all our social media platforms for more juicy updates and promos! 

",spam
"ğ— ğ—®ğ—¸ğ—² ğ— ğ—¼ğ—»ğ—²ğ˜† ğ—ªğ—¶ğ˜ğ—µ ğ—§ğ—µğ—¶ğ˜€ ğ—˜ğ—®ğ˜€ğ˜† ğ—¦ğ—½ğ—®ğ—º ğ—–ğ—µğ—²ğ—®ğ˜ ğ—¤ğ˜‚ğ—¶ğ—°ğ—¸!
- Attention: If you're tired of not making enough money, this is the perfect spam for you! 

",spam
"Get ready to be shocked as we announce our latest offer! Buy one product and get twenty-five others of equal or lesser value for absolutely FREE! Hurry now and indulge in this amazing deal before it's gone. 

",spam
"Looking for ways to lose weight FAST? Check out these incredible diet pills that will make you shed pounds in no time! Don't waste your time with diets or exercise, just pop a pill and watch the fat melt away! 

",spam
" 

Hello everybody,

I  have found a dataset on Kaggle that is perfect for the Paper I want to  write. Unfortunately I donÂ´t receive the verification e-mail needed to  complete the registration. I have contacted the Support but while  I am  waiting, I was wondering if anybody else encountered this problem and  might be able to help?

The dataset in question btw is [https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016)

Thanks in advance!",not_spam
"As per the imdb dataset documentation\[1\] the language field is only in dataset \[2\].

Now let's take an example

    $ zcat title.akas.tsv.gz | grep ^tt0014142

&amp;#x200B;

Nowhere do we see 'EN' as a language here.

And how does imdb display this title\[4\]:

    Country  United States 
    
    Language  English 

Where does this information come from? From which data set?

The data set \[2\] reflects on imdb page\[4\] as:

    Also Known As  
        Notre-Dame de Paris (France) Quasimodo (France) Le Bossu de Notre-Dame (France) Der GlÃ¶ckner von Notre Dame (Germany) El jorobado de nuestra seÃ±ora de ParÃ­s (Spain) See more Â» 

But where is the Country and Language coming from?

Resources:

\[1\] documentation: [https://www.imdb.com/interfaces/](https://www.imdb.com/interfaces/) \[2\] akas dataset: [https://datasets.imdbws.com/title.akas.tsv.gz](https://datasets.imdbws.com/title.akas.tsv.gz) \[3\] all datasets: [https://datasets.imdbws.com/](https://datasets.imdbws.com/) \[4\] sample title on imdb: [https://www.imdb.com/title/tt0014142/reference](https://www.imdb.com/title/tt0014142/reference)",not_spam
"Where can I find datasets about epidemics and pandemics such as Black Plague, Influenza and Coronavirus?
Thanks",not_spam
"Hey everybody! Are you tired of not getting enough followers on your social media accounts? Well, Do not worry! We can fix that for you. We have the perfect solution for all your social media needs. 

With our exclusive package, you can get followers, likes and comments on your Instagram, Facebook, Twitter and even TikTok accounts. So what are you waiting for? Buy our package today and become a social media superstar!

But that's not all! For a limited time only, we are offering a special deal with even more added benefits. Buy our premium package and get a free eBook on how to become an influencer.",spam
"New to data here, so I'm quite confused sometimes using APIs and please excuse me if I am not using the best technical terms.   


So I am running into the problem of trying to find data for Census tracts and/or cities.  Perhaps I don't know where to download the data or if there is a filter from 3rd party websites that can draw that data, but I just can't find it.   
I am trying to strictly find data for age and gender for cities, tracts, or counties.  Most of these third party sites go too far and provide processed data, pie charts, or summarized charts.    


For example, I go here: [https://factfinder.census.gov](https://factfinder.census.gov/) , its great!  But I am trying to get the data that led to what they got.  Basically I am trying to replicate what this website does but I don't know where to get the Data in CSV form.   


Any help would be greatly appreciated.",not_spam
"Hey all you gorgeous people out there! Are you ready for some insane deals? Of course you are! Well, our social network has got you covered.

We're talking discounts on everything from slimming tea to those cute crop tops you've been eyeing. And if you act fast, we'll throw in a free trial of our exclusive skincare line. Trust us, your face will thank you.

But wait, there's more! Sign up now and you could win a trip to some exotic location that you've never even heard of. It's like a mystery adventure waiting for you! All you have to do is share this post,",spam
"""OMG u guys, have u seen the latest trending posts on our <insert social network here>?! It's so lit, I can't even!! ğŸ˜ğŸ˜ğŸ˜

From epic memes to hilarious cat videos, we've got them all! Plus, don't forget to follow our amazing influencers who are slaying the game with their #OOTD selfies and fitness routines ğŸ’ªğŸ¼ğŸ’ªğŸ¼ğŸ’ªğŸ¼

And did I mention our exclusive offers and giveaways? ğŸ˜± Just follow, like, share and tag your friends to enter and you could win some seriously sick swag!",spam
"I am performing sentiment analysis using this dataset, and I headed to Kaggle to pop open a Kernel and do some analysis.  

But, after searching Kaggle, I was unable to find the IMDB Movie Reviews Dataset. Actually, I think I came across a few, but they were not in a friendly format.  

So, I decided to upload this dataset myself. Here is a link to the dataset on @Kaggle: [https://www.kaggle.com/iarunava/imdb-movie-reviews-dataset](https://www.kaggle.com/iarunava/imdb-movie-reviews-dataset)

No need to unzip and stuff!  

The path is './../input/aclimdb/aclImdb' 

And this contains the train and test directories, and all other samples and files that come with the dataset!  Go! Pop up a Kernel!

Link to original dataset: [http://ai.stanford.edu/\~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)

Hope you find this useful :)

My first post here!

Great community! Love it here :)",not_spam
"This is for academic research - ""internet paleography"". I am interested in early blogging communities, their network, and their topics.

The method will be a combination of network analysis and text mining, but my problem is how to get the raw data. 

What would be the best way? Using archive.org and cleaning the data somehow? (if so, how?)

Using other datasets? Which ones?",not_spam
"Hello everyone. I am looking for spatial data which tracks police use of force. A great example of what I am looking for is the NYPD Stop, Question, and Frisk data, which lays out firearm use, taser deployment, and OC spray with XY coordinates for each calendar year. Unfortunately, recent reports have uncovered that around 30% of the data are missing, making it unusable.

Anyone ever come across a similar dataset?",not_spam
"***FREE!!! GET A CHANCE TO WIN $1000 BY FOLLOWING US ON TWITTER!!!***

RETWEET THIS POST AND TAG 5 OF YOUR FRIENDS FOR A CHANCE TO WIN BIG!!! 

ALSO, CHECK OUT OUR NEW PRODUCT LINE AND GET EXCLUSIVE ACCESS TO DISCOUNTS AND SPECIAL OFFERS!!! 

DON'T MISS OUT ON THIS AMAZING OPPORTUNITY TO EARN SOME CASH AND SAVE SOME MONEY ON THE BEST PRODUCTS AROUND!!! 

HAPPY TWEETING!!!",spam
"Get ready for the most epic post EVER! We've got all the juicy gossip, scandals, and cat memes you could ever want! Just like and share this post to become part of our exclusive ""cool kids"" club. 

",spam
"I am working on ""Audio classification"" using deep learning. I need a waveform dataset for this purpose. Where can I find one?",not_spam
"Hereâ€™s a great article from the Data Engineering team of ING describing the need for and components of their Data Analytics Platformâ€™s Data Quality Framework.

Tools:

* **Data Quality** (using the  [Great Expectations library](https://greatexpectations.io/) )
* **Data Profiling** (using the  [pandas-profiling library](https://github.com/pandas-profiling/pandas-profiling) )
* **Data Stability** (using  [popmon â€” Population Shift Monitoring](https://medium.com/wbaa/population-monitoring-open-source-1ce3139d8c3a) )

Read the whole thing here:  [https://medium.com/wbaa/the-data-analytics-platforms-data-quality-framework-6a3f7cda8c36](https://medium.com/wbaa/the-data-analytics-platforms-data-quality-framework-6a3f7cda8c36)",not_spam
"I'm interested in assessing electoral results across various DMA regions, but most of the data I find is at the state level or at the Congressional District level.  Does anyone know where I might find results at the DMA level?  I would be happy with Presidential election data, mid-term election data, or almost anything, really, from any somewhat recent election year.",not_spam
"I'm looking for a data set of probability problems possibly with answers. The probability problems would hopefully contain problems pertaining with deck of cards with replacement, something similar in that nature.

Thanks!",not_spam
Any text datasets with regression as task. Couldn't find much on kaggle. Looking for public domain datasets for academic purpose. Have seen a lot on classification obviously but not specifically regression.,not_spam
I uploaded the Reddit [r/Place history dataset](https://www.kaggle.com/residentmario/reddit-rplace-history) to Kaggle. Have a gander!,not_spam
I am working on identifying the useful content from social media. Is there any twitter dataset is available? Please suggest,not_spam
"Hi. I have downloaded the Wikipedia dump for Persian articles from [here](https://archive.org/details/fawiki-20180120), but I couldn't find some kind of description for the contents of the files, so I can't clearly understand what is the suitable file to work with. What I'm looking for is the file with the text for articles. I only guess it's probably the file with the name ""fawiki-20180120-pages-articles.xml"". Could you please help me on this issue? Thanks.",not_spam
"Get rich quick with this amazing money-making app! Sign up now and start earning cash right away!

",spam
"""Upgrade your account now and unlock our EXCLUSIVE features! Don't miss out on the BEST experience. Click here to upgrade.""

",spam
"Hello everyone. I am trying to do an analysis on what kinds of models bookies use to make over/under bets. If anyone knows where I can find historical over/under bets for games from any sportsbook, I'd appreciate it. Ideal data would be over/unders on total rushing yards for games. I tried to do some digging, but didn't have much luck.",not_spam
"Hey guys,

I have found plenty of dataset descriptions and studies about the ACHIKO-M dataset of Iris/Fundus images to detect myopia (have a look: [https://oar.a-star.edu.sg/jspui/bitstream/123456789/2040/1/ACHIKO-M%20Database%20for%20high%20myopia%20analysis%20and%20its%20evaluation.pdf](https://oar.a-star.edu.sg/jspui/bitstream/123456789/2040/1/ACHIKO-M%20Database%20for%20high%20myopia%20analysis%20and%20its%20evaluation.pdf)).

 What I couldn't find, however, was the actual link to download the dataset. Does anyone have this dataset available to them?",not_spam
"Get ready for an epic ride on Instagram, because we've got some wicked content coming your way! Are you a foodie? Then buckle up, because our feed is filled with scrumptious dishes that will have your mouth watering in no time.

",spam
"I've worked with CSV files where values with double-quotes in them are escaped with double-quotes or slashes (and sometimes this means I also need to wrap all values in double-quotes for consistency), but now that I'm having to save JSON into CSV values, everything's fine (with or without encapsulating double-quotes) until a JSON value has a double-quote in it (like, third-level double-quotes...

I'd think the proper solution would be to just escape a JSON value's inner double-quote with a backslash, but I'm running into issues with editors trying to parse things... right now I can get LibreOffice to parse the file properly with certain settings, but other editors are choking on it.",not_spam
"Are you tired of not reaching your full potential? 

",spam
"**Title**: YOU WON'T BELIEVE WHAT HAPPENED TO THIS GIRL!

OMG, you guys, I just found out about this absolutely insane story and had to share it with you all! This girl (I don't even know her name) was walking down the street minding her own business when all of a sudden, a UFO appeared out of nowhere and abducted her! Can you even believe it?!

But that's not even the craziest part. When she was up in space, the aliens subjected her to all sorts of experiments, trying to figure out the secret to eternal youth. And guess what? They",spam
"HÄ± guys!
I need a dataset for a project on startup success prediction. Crunchbase data is not free is there a possible option to get those datasets for free? Or any other platform to out-source the related datasets?",not_spam
"Hello!

We are interested in investigating the link between social media and mental health, as current research suggests that they are linked but there is no consensus on how they influence each other.

If you decide to take part, you will be required to answer 3 online surveys:

â€¢ Each survey should take no longer than 15 minutes to complete. 

â€¢ After completing the first survey, the **second survey will be emailed to you after 2 weeks.** Lastly, **the third survey will also be emailed to you in 2 weeks** after completing the second survey.

To take part, **you need to be a user of any social media service/website** (Reddit, Facebook, Twitter, etcâ€¦) and **atleast 18 years of age.**

After completing the third survey, **you can enter in a draw for a chance to win 1 (out of 5) Â£10 Amazon voucher.**



Link to first survey: [https://ntupsychology.eu.qualtrics.com/jfe/form/SV_0PLfj0kVcAdXjnf](https://ntupsychology.eu.qualtrics.com/jfe/form/SV_0PLfj0kVcAdXjnf)


This study has been ethically approved and funded by Nottingham Trent University. If you have any questions or queries, you can ask them in this thread (if appropriate) or email Dr. Zaheer Hussain ( zaheer.hussain@ntu.ac.uk ) or, myself, the research assistant Ruben ( n0883556@ntu.ac.uk ).

Thank you for reading this!",not_spam
"Hi, where can I find the data (names, sex offense, address, picture, etc) for sexual offenders in the state of Wisconsin? There's already a public registry but I'd like to display the data more readily and available. Does something like this exist or do I have to scrape the existing site? ",not_spam
"Get rich quick! Double your money in just 24 hours! Don't miss out on this amazing opportunity! 

",spam
"ğŸš¨ L@@K ğŸ’¥ğŸ’¥ğŸ’¥ğŸš¨ Do you want t0 win a ğŸ’° $1,000,000 ğŸ’° cash prize? Then follow our page and tag 10 friends to enter our exclusive giveaway! ğŸ”¥ğŸ”¥ğŸ”¥ Limited time only, you don't want to miss out on this amazing opportunity! ğŸ¤‘ğŸ¤‘ğŸ¤‘ 

",spam
I'm trying to find a dataset of international flights but with recorded flight paths. All datasets I found so far include only source and destination but lack where planes fly. Is there anything like this?,not_spam
"Pushing the limits to get you the most astonishing newsfeed!

",spam
"Hey frenz! Itz ur boi from da #1 social network around! Check it, we got tons of new feechurs that are totally lit! Y'all can now add sparkly filters to ur selfies and share them on ur stoariez! Plus, we just launched a sick new game that u won't wanna miss. And let's not forget about all the hot deals and discounts from our sponsored brands! 

But wait, there's more! We want to hook u up with some exclusive offers just for being part of our amaze community. Sign up now and receive 50% off ur next online purchase!",spam
"Check out these HOT deals! ğŸ”¥ğŸ”¥ğŸ”¥ You won't BELIEVE the savings! ğŸ’°ğŸ’°ğŸ’° Click NOW before it's too late! â°â°â°

",spam
"Wassup people! Are you tired of being a nobody in the virtual world? Do you want to become a superstar celebrity overnight? Then listen up and follow my advice.

",spam
"ğŸ’¥ğŸ”¥ Amazing news! Our network has just launched a new feature that will blow your mind! You can now send up to 10,000 messages per minute to your contacts! That's right, you read it correctly! We are talking about ten thousand messages in just one minute! Imagine the possibilities of this incredible tool! You can spam all your friends, family, and even strangers with any message you want! ğŸ¤¯

",spam
I'm trying to download all of wikidata for a project and was wondering if there was a way to download it besides this webpage : [https://www.wikidata.org/wiki/Wikidata:Database\_download](https://www.wikidata.org/wiki/Wikidata:Database_download) . I have a flaky internet connection and it would seem that the connection crashes after a bit. A torrent or something would be helpful.,not_spam
Need an indian snake dataset with images and the species' names for final year project asap!!!!!!,not_spam
"Hello!

I am a MSc Clinical Psychology student, and for my thesis I am conducting qualitative research aiming to better understand digital accumulation and data hoarding, and the impact it has on an individual. I am looking for individuals who have experienced the urge to collect or hoard data (i.e files, photos, ebooks, emails etc) to the point it affects their life in some way. The experience of digital/data hoarding is completely subjective and it can manifest in many different ways, from Pinterest and social media to collections stored in hard drives and cloud storage. I would like to ask anyone who has some insight into this through lived experience or otherwise to comment on this thread with whatever they would like to share, or if preferable to message me directly with their comments on this topic.

&amp;#x200B;

Many thanks!",not_spam
"BRING IT ON! Hey folks! Have we got a totally wicked announcement for all you super cool users out there! We are so stoked to share with you our new totally tubular feature that we've been working on for ages! Get ready for the most awesome way to connect with your friends and dawgs!

",spam
"Hey there! Are you tired of boring, uneventful social media platforms? Well look no further, because (insert social network name here) is the answer to all your problems!

Our platform offers endless hours of entertainment and connection with people all around the world. Plus, we have a wide variety of filters and effects to make your photos look cooler than ever before.

But wait, there's more! We have tons of sponsored posts and advertisements to clutter your feed and distract you from your friends' actual content. And don't forget about all the fake news and conspiracy theories we allow to spread like wildfire.

And if you're worried about",spam
Hello! I am looking for something similar to the [US Census Fact Finder](https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t) but for Mexico. I am trying to get the number of businesses in certain segments by state. I unfortunately don't speak Spanish and Google Translate is failing me!,not_spam
"Want to earn money fast? Sign up now for our exclusive scheme! You won't believe how much cash you can make with just a few clicks!

",spam
"Get rich quick with our amazing offer! If you want to make tons of cash without doing any real work, you've come to the right place. Our secret system will unlock the power of the internet and make you a millionaire in no time. Don't waste another minute in your dead-end job when you could be living the high life with our fool-proof plan.

",spam
"Are you tired of boring old social media platforms like Facebook and Twitter? Want to join a cool, edgy, and totally hip community? Well, then look no further than Spam-o-gram!

Spam-o-gram is the ultimate social media site for people who love spam, scams, and junk mail. We know that you're sick of all those boring posts about people's lives and fancy vacation photos. You want something that really gets your blood pumping, and that's why we offer only the best in spammy content.

Our community is made up of people from all over the world who share a passion for spam emails, phishing",spam
"Good afternoon. I'm trying to find one or more datasets on unemployment among different ethnicities in LA (city or county) over the years, preferably between the early 2000s and late 2010s. I've found some datasets in the US Census Bureau and the Bureau of Labor Statistics sites, but they're not exactly what I'm looking for. Does anyone know where I could find this information? I've only been able to find fragmented data that don't show the whole picture of what I'm looking for. Thank you so much!",not_spam
"Hello good people of reddit, can you provide me with some sources to Single Cell RNA-sequencing datasets? I'm quite new to this and not exactly sure where to look for these kinds of datasets.

Thank you!",not_spam
"[NORC at University of Chicago](http://www.norc.org/PDFs/GSS%20Reports/GSS_Trends%20in%20Gun%20Ownership_US_1972-2014.pdf) page 3

[Gallup](http://www.gallup.com/poll/150353/self-reported-gun-ownership-highest-1993.aspx) 

The values fromt the Gallup poll are much higher. There isn't a whole lot of overlap between the years, but the values seem to be 10-20% points higher.

Is it possible a lot of people were lying in one of the polls? I would think NORC would be more vulnerable, since people may not want to tell someone over the phone they have a gun in their house, but Gallup performed interviews this way and got vastly different results.",not_spam
Please share a link for medical diagnostic disease-symptoms and  drug pair dataset,not_spam
"""Unlock your ultimate potential with our all-new, revolutionary diet pill! Say goodbye to pesky flab and hello to your dream body in just 2 weeks! Limited time offer - buy now and get a free trial for our muscle-building formula!""

",spam
"The more info the better.  If it has APR info, the introductory period of no interest, would be great.   Basically every credit card company or financial institution. XML, CSV, Json or any format is fine.  Thanks",not_spam
"Get rich quick with our amazing offer! Just click the link and start earning hundreds of dollars in minutes! Don't waste your time on boring jobs, become your own boss and live the life you deserve!

",spam
" The problem: Currently I am building a pricing alignment tool. Essentially, I have 2 categories I am trying to compare, Price of Special Order Products vs. Price Stock Order Products. My team wants to have visibility into which Special Order Products are priced higher than stock products. The issue I am having is at times, there are multiple prices for special order and stock products depending on the store due to regional pricing.

At the moment I have created a dot strip plot that looks like [this.](https://imgur.com/gallery/ToHV5v5) The circles represent special prices (there are multiple circles per row because there may be multiple special order prices, same goes for the bars), the bars represent stock prices and the color dimension for the bars is a visual cue for whether it is priced below, higher, or equal. Blue means stock is higher priced, red means stock is priced lower. (please ignore the bar graph, they are different info)

Objective: Again the objective is to gain visibility into which special order products are priced higher than stock. We want special order to be lower cause typically these products are sold to professionals and in bulk.

Imgur: The image is posted without much detail because I do not want my company thinking I am sharing sensitive information. Also, the dashboard has a lot more detail but at the moment I am concerned with this visual on the dashboard.

Suggestions: Again, just look for suggestions for perhaps a completely different visual or a way to enhance what I have.",not_spam
"It's your pal from Insta-land, bringin' you a dose of inspo to help you shine bright like a diamond! ğŸ˜ğŸ’ğŸŒŸ

Are you tired of feeling like a basic bee? Let me tell you, you ain't gotta settle for mediocrity, baby! ğŸ’…ğŸ¼ğŸ‘‘

With our amazin' filters and photo editin' tools, you can transform yer selfies into jaw-droppin' works of art! ğŸ¨ğŸ¤³ğŸ¼ğŸ“¸

But that ain't all, folks! We've also got a never",spam
I am working on a project relating to malware detection using machine learning and I am looking for a dataset containing websites classified as malicious or benign,not_spam
"Hello guys,

I am looking for a regression task dataset that contains 3 or more datatypes.",not_spam
"Are you tired of being a loser with no friends? Well, fear not! Join the amazing community of [name of social network] and become an instant hit! 

",spam
"I'm taking my first course in data mining in Uni, and my professor sends to be going for a sink or swim approach. This is the only data mining class offered and the second week he wants a research proposal for a project. I have no doubt that I can write the code, my problem is 

A: I don't have enough of a foundation in the subject to produce a novel idea and 

B: he didn't even suggest any data sets we could look at. 

I've done some searching on my own, and I'm thinking of doing something with the HDD reliability data posted to the sub, or something about indirectly related Wikipedia pages by using the page visits from a wiki data set. But I don't know if these are weak, and I'm concerned my professor is more apt to dick wave about his own research than help mine.

Any advice?",not_spam
"Hello. I was wondering if there are any datasets that have product photos. [Here is an example of what I mean by product photos.]
(http://prntscr.com/nelc7l) The example does include some ""homemade""/amateur photos, but it is not a requirement for the dataset. 

I wanted to use these photos to train a model to group the same products together based on the images. I started off by just going through and saving these images but I realized pretty soon that it would take a very long time to get the amount I want (around 25-50 per item ""group""). I also did not want to create a crawler because it would be a lot of requests and could cause some issues for me with these sites.",not_spam
"Attention all netizens! Do you want to be rich and famous like the celebrities on our platform? Of course, you do! Well, guess what? You can be! Just sign up for our exclusive VIP membership and gain access to exclusive content, discounts, and promotions that will skyrocket your social status.

Think that's all? Ha! We've got more! Our platform is the perfect way to connect with like-minded individuals and boost your social media presence. And with our new feature, you can even buy followers and likes to make sure your posts always go viral. Plus, with our endless stream of ads and sponsored content, you'll",spam
"Breaking News: Our new app has just launched! It's like, totally awesome and you need it RIGHT NOW! Don't wait any longer, click that download button and join the coolest community ever! 

",spam
"I'm trying to build an animal classifier and then stack a species classifier based on the animal it predicts. Ideally I'd be able to get 50+ images per species and 1000+ images for the class in question. Any help would be greatly appreciated, thanks!",not_spam
"Join us now and get rich quick with our amazing offers! Don't miss out on your chance to make big money without even leaving your couch. With our revolutionary system, you'll be making money in no time.

",spam
"Are you tired of being a loser with no friends? Well, join our social network and become popular overnight! With our amazing features and unlimited access to public information, you can stalk anyone you want and learn their hidden secrets.

",spam
Looking to know which cities or metro areas have the most Whole Foods &amp; Trader Joeâ€™s per capita.,not_spam
I was wondering if anyone knew where I could find the average US public salaries were over time. I tried looking into the Bureau of Labor Statistics (BLS) but could not succeed. Any help would be much appreciated!,not_spam
"ATTENTION ALL PEEPS ON THIS NETWORK!!! ğŸ“¢ğŸ“¢ğŸ“¢

URGENCY ALERT ğŸš¨ğŸš¨ğŸš¨

It's time to get LIT ğŸ”¥ğŸ”¥ğŸ”¥ and join the ultimate lifestyle revolution!!! ğŸ’ƒğŸ’ƒğŸ’ƒ

We've got everything you need to stay on fleek ğŸ’… and get ahead of the game ğŸ®:

ğŸ‘‰ Daily inspo for your feed (double tap if you agree ğŸ‘ğŸ‘)

ğŸ‘‰ FREE workout plans (who needs a gym membership? ğŸ’ª)

ğŸ‘‰ Exclusive deals on",spam
"Double your followers with our amazing new app! ğŸ’°ğŸ’¯ğŸ”¥

",spam
I am working on research project and I need data of crimes in major cities of USA. I have tried browsing NIBRS website but I wasn't able to find any dataset. Does anybody know how can I get this data.,not_spam
"Attention all social media lovers! We have a dynamite deal for you today! Join our network and get one million fake followers for free! Thatâ€™s right, you heard it here first folks, weâ€™ll give you a million bots so you can feel super popular and inflate your numbers to impress your friends.

But wait, thereâ€™s more! Sign up now and get access to our exclusive list of email addresses! Imagine the spamming possibilities! Youâ€™ll never have to bother with pesky things like building relationships or creating quality content. Just blast out those emails and enjoy the satisfying feeling of annoying tons of people.

And thatâ€™s not all!",spam
"Hi everyone,
I'm looking for some county level census data (i.e. race, poverty, income characteristics, etc.) from 1980-1996, and on the censtats website I can only find data from roughly 2000 onward, and nothing in so nice a form as a table.  Does anyone know where or how I could acquire something along these lines?  Thanks a lot!",not_spam
"Looking for a feed filled with the latest and greatest? You've come to the right place! Our social media network has got it all: from mindless clickbait articles to constant ads for products you didn't even know you needed.

We take pride in bombarding you with notifications about your friends' latest updates and thirsty influencers trying to sell you weight loss tea. And let's not forget about the endless stream of memes that have been recycled so many times, they're practically fossilized.

But wait, there's more! Want to see what your ex is up to? We'll make sure to show you every single picture and update",spam
"Does anyone know of any comprehensive datasets relating to TCM? Especially as it relates to symptoms / patterns of disharmony.

Iâ€™ve been looking but havenâ€™t been able to find anything substantial.

Thanks for any help!",not_spam
"âš ï¸ATTENTION ALL USERSâš ï¸

ğŸ‘‰ğŸ’»ğŸ“±ğŸ‘ˆ

Your feed is about to get a whole lot spammier! ğŸ¤¢ğŸ¤®

Our team is excited to announce that we have partnered with over 100 new advertisers, meaning MORE ADS and MORE junk content flooding your social media feeds! ğŸ¤‘

Not only will you see ads for new weight loss and get rich quick schemes, but we've also got a BRAND NEW line of sketchy health supplements that will make you feel like a million bucks (at least until you see the side effects",spam
"/u/rokfest helped me out!
______________________________

Looking to format it like:

""AL"": ""Albania"",
""DZ"": ""Algeria"",

etc. etc.

Having quite a bit of difficulty.  Hoping you guys may know where I could find such a list.

Thanks!!",not_spam
"Where can I find dataset for the paper    "" Looking to Listen at the Cocktail Party:  
 A Speaker\-Independent Audio\-Visual Model for Speech Separatio  "" ?",not_spam
"It's time to upgrade your look, fam! Check out our new line of trendy threads that will make you the envy of all your followers. ğŸ”¥ğŸ‘€ Don't wait, get it now before it's gone!

",spam
"Looking for the ultimate #fitspo? Check out our brand new diet pill, guaranteed to help you shed those extra pounds in just DAYS! No need for exercise or healthy eating, just pop a pill and watch the fat melt away! It's like magic in a bottle!

",spam
"ISM PMI historical releases

Does anyone have ISM data, with more meat and potatoes than the index score? I have been managing to scrape the most recent postings, but Iâ€™m limited on how far back I can scrape since the oldest reports are only available in PDF form that I have been able to find.  Ideally I would like to be able to better evaluate the industries individually. 

I tried posting this is r/algotrading to no avail. 

Thanks for taking the time to read.",not_spam
"""Discover the incredible secrets to losing weight fast and achieving your dream body in just a matter of weeks! Our revolutionary new weight loss program will guarantee results that will stun even the most skeptical of skeptics. Say goodbye to flabby arms and muffin tops forever and hello to the toned, slender physique you've always wanted.

Are you tired of feeling bloated and uncomfortable in your own skin? Do you want to feel confident and sexy at all times? Then our program is exactly what you need! Our experienced team of weight loss professionals has carefully crafted a program that is tailored to your specific needs, and will ensure that you see results quickly",spam
"Hello,

I am looking for a data set that compiles company data breaches with firm level identifiers. I have found a number of data sets that compile breaches on the industry level, but I really need one that compiles on the firm level. Does anyone know of any data sets exist? If so, could you help point me in the right direction? Thanks!",not_spam
"Check out these amazing weight loss pills! They're all natural and guaranteed to shed those pesky pounds in no time! Order now and get a free trial!

",spam
"""Want to get rich quick? Join our new scheme today and start earning thousands of dollars within just a few days! No experience needed, only a willingness to make money.""

",spam
"Anyone know of any datasets listing the CEOs and time of tenure for publicly traded companies?  I'm most interested in European companies, but also American companies as well, and hoping to get information for past decade or so.",not_spam
"I'm looking for datasets related to babies. Whether this is sound recordings, videos or images. Anyone have pointers to such data?

Thanks a ton!",not_spam
"Need to lose weight fast? Try this miracle pill that guarantees results in just 7 days! No need for exercise or dieting. Just take these pills and watch the pounds melt away.

",spam
"Hello,

I am studying program synthesis from natural language, and I am currently working on a system that will attempt to generate actual Python code given the natural language input, for instance:

* sort 'myList' in descending order
* `sorted(myList, reverse=True)`

Current python datasets ([Django](https://github.com/odashi/ase15-django-dataset) and [CoNaLa](https://conala-corpus.github.io/)) have 2 major drawbacks: Django is very focused, the generalization capability will be very low, and CoNaLa (the manually curated version) contains very few examples for a model to actually learn something (2,379 training and 500 test).

Therefore, apart from augmentation techniques (e.g. from libraries / python documentation), I thought about an initial phase, that is, training on an *introductory / tutorial* kind of dataset, with focused examples similar to what a human would follow when learning programming, such as:

* call the function max with the arguments 1 and 2 =&gt; `max(1, 2)`
* generate a list of integers from 10 to 20 =&gt; `list(range(10, 21))`
* call the function 'getArea' with arguments 'width' and 'height' and assign the result to 'a' =&gt; `a = getArea(width, height)`

I've looked at different Python tutorials, but couldn't found something that can be easily 'scrapped', and therefore be assembled into a dataset. So, my question is, do you know any resources that may contain this kind of example pairs of **focused** programming tasks?

Thank you!",not_spam
"I'm trying to find records of property sales where I can extract information for analysis. I'll need to be able to slice property information into different dimensions with some examples being by State, Year of Sale, Cost of Sale, Buyer Age, Buyer Income, and any available Demographic information.

There are a ton of data aggregation sites, but I don't want to pay for them. Instead, I'd like to build my own analysis engine that extracts directly from the sources of information.

Where would you recommend to get this property data? Many of the County Assessors allow searching by an individual address; whereas I want all property records across every country. Is there an easy way to get this info in bulk?",not_spam
"Ladies and gentlemen! Get ready for some epic social networking! We've got all the latest and greatest features and tools to help you waste away your precious time!

",spam
"Hey there, fellow netizens! We've got some wicked news for y'all today! Our platform is reachin' new heights with the latest updates, and we want YOU to be a part of it. Here's what we've got in store for ya:

- Unlimited likes, comments, and shares for FREE! No more restrictions on expressin' yourself on our app.
- Super duper security measures to keep your account safe from those pesky hackers. Ain't nobody gonna mess with your personal info, we guarantee it.
- A brand spankin' new interface, so you can browse and post with ease. We've got",spam
"Get rich NOW with our AMAZING ""money making system""! It's so simple and easy, ANYONE can do it! Just sign up and start earning THOUSANDS of dollars per week! Don't believe us? Look at all these testimonials from happy customers who've made MILLIONS with our system!

",spam
"Earn easy cash now! Enter our online survey and get rewarded with gift cards, coupons and cash prizes. Don't waste another minute and join the top exclusive survey community. Be part of our VIP membership for free and get access to the latest products, offers and promotions. Sign up now and start getting paid for your opinion!

",spam
"URGENT ALERT: YOU WON'T BELIEVE WHAT HAPPENED NEXT!

OMG, you guysssss! I have to tell you about this insane thing I just heard about on my fav social netâ€” it's crazy!

So basically, there's this crazy offer for a FREE LIFETIME SUPPLY OF MAKEUP (yeah, you read that right!!) and all you have to do is share it with your friends and email fifteen people to get the hookup! 

It's totally legit, trust me! And if you do it, you could be one of the lucky ones to get this amazing deal! Don't",spam
"Hey everyone! I'm so excited to tell you about this awesome new product that will totally change your life! It's a miracle weight loss pill that will make you skinny in no time! No more exercising or eating healthy! Just take this pill and watch the pounds melt away!

But that's not all! If you sign up now, you'll get a free trial of our exclusive skincare product. It will make your wrinkles disappear and give you the flawless, youthful complexion you've always dreamed of!

And if that's not enough, we also have a limited time offer on our amazing teeth whitening kit. Say goodbye to stained and yellow",spam
"Sup fam! Are you ready for the most lit news feed ever? Well, buckle up cause we're about to take you on a ride you won't forget...unless you have memory problems or something.

First up, we've got some mad discounts you don't want to miss! Go ahead and click that ""BUY NOW"" button and treat yo' self to some sweet deals. And if you're feeling extra thirsty, we've got some weight loss pills and energy drinks to quench your thirst. Don't worry about the side effects, they're probably not that bad.

But wait...there's more! We've also got some",spam
I need a weather climate dataset of the previous year (atleast 5 years) of Indian states and other south asian countries.Where can i get them?Thanks in advance,not_spam
"Hi,

Does anyone know where I could find a dataset with food deliveries?

Like for instance how many pizzas have been delivered to STREET on the superbowl.

Or a dataset with lots of food deliveries on which I could do some data vis and analytics.

Any help is appreciated!
Thanks",not_spam
"Need 2 LOSE W8 FAST? Look no further, cuz we got the ULTIMATE WEIGHT LOSS SOLUTION here at FaceSpace! Our NEW and IMPROVED diet pills are GUARANTEED to shed those pounds faster than you can say ""Gimme some pizza!"" 

",spam
"as above please can you explain as I am heavily confused in how this all relates to databases and data in general, thank you.",not_spam
"What is currently the most reliable source for up to date data on population by country?

I have a few sources, but there are big differences between them. I was wondering if there is one that is considered to be the most reliable.

What about for other types of data and statistics regarding world population (religion, economics, social etc.) - is there a source considered to be the most comprehensive, reliable and up to date?",not_spam
"Check out our amazing new product, guaranteed to make you rich in just days! With our revolutionary system, you can earn thousands of dollars every week, without any effort! Don't waste your time with boring jobs or traditional businesses â€“ join our network today and start living the life of your dreams!

",spam
"I have a crawler that was working greater before the last patch. 

My search creates urls and feeds it specific naics/funding agency combinations. However, as of last night it just loops through the first combination indefinitely.

For example,

    FPDS-NG search results for
    &lt;![CDATA[
    : PRINCIPAL_NAICS_CODE:541990 FUNDING_AGENCY_ID:3600 SIGNED_DATE:[2018/07/01,2018/07/22]
    ]]&gt;
    &lt;/title&gt;
    &lt;link rel=""alternate"" type=""text/html"" href=""https://www.fpds.gov/ezsearch/search.do?s=FPDS&amp;indexName=awardfull&amp;templateName=1.5.1&amp;q=PRINCIPAL_NAICS_CODE%3A541990+FUNDING_AGENCY_ID%3A3600+SIGNED_DATE%3A%5B2018%2F07%2F01%2C2018%2F07%2F22%5D&amp;start=5000""/&gt;
    &lt;link rel=""first"" type=""text/html"" href=""https://www.fpds.gov/ezsearch/FEEDS/ATOM?s=FPDS&amp;FEEDNAME=PUBLIC&amp;VERSION=1.5.1&amp;q=PRINCIPAL_NAICS_CODE%3A541990+FUNDING_AGENCY_ID%3A3600+SIGNED_DATE%3A%5B2018%2F07%2F01%2C2018%2F07%2F22%5D&amp;start=0""/&gt;
    &lt;link rel=""last"" type=""text/html"" href=""https://www.fpds.gov/ezsearch/FEEDS/ATOM?s=FPDS&amp;FEEDNAME=PUBLIC&amp;VERSION=1.5.1&amp;q=PRINCIPAL_NAICS_CODE%3A541990+FUNDING_AGENCY_ID%3A3600+SIGNED_DATE%3A%5B2018%2F07%2F01%2C2018%2F07%2F22%5D&amp;start=40""/&gt;
    &lt;link rel=""previous"" type=""text/html"" href=""https://www.fpds.gov/ezsearch/FEEDS/ATOM?s=FPDS&amp;FEEDNAME=PUBLIC&amp;VERSION=1.5.1&amp;q=PRINCIPAL_NAICS_CODE%3A541990+FUNDING_AGENCY_ID%3A3600+SIGNED_DATE%3A%5B2018%2F07%2F01%2C2018%2F07%2F22%5D&amp;start=4990""/&gt;
    &lt;modified/&gt;

As you can see start=0 is the first page and start=40 is in ending page. If you look this query up on [fpds.gov](https://fpds.gov) using their front end there are 43 entries. So start=0 is 10 results. My crawler should end at start=40 and go on to the next naics/funding combo.  This has been working perfectly for over a year and a half but after yesterday's update it isn't working and I was wondering if anyone else has see something similiar.",not_spam
"Attention all social media peeps! Get ready for the juiciest, glitchiest, most spam-tastic experience of your life! Our latest app update is jam-packed with all the unfollow-worthy content you never knew you needed! 

From cringey memes to clickbait articles, weâ€™ve got it all! And donâ€™t even get us started on the fake news â€“ who needs credible sources when youâ€™ve got sensational headlines, am I right? 

Plus, weâ€™ve got enough bots and fake accounts to make your head spin! Who needs real friends when you can have 1000 bot followers overnight? #winning 

",spam
"Attention all beautiful people! You gotta check out our new offer that's gonna blow your mind! It's the hottest thing on the internet right now, and you're gonna regret it if you miss out! We're talking about discounts on fashion, makeup, and skincare products that'll make you look like a million bucks without breaking the bank!

",spam
I want to look for patterns in patients which get diagnosed b with hypothyroidism to see if there are patterns better their diagnosis which are different to those patients which never get diagnosed.,not_spam
"Ugh guys, let me tell you something - this social network is the bomb diggity! We've got all the latest and greatest trends, memes, and viral content that'll make your head spin. And don't even get me started on our exclusive features - you won't find these bad boys anywhere else!

So why waste your time on those other lame platforms? Come join the party, and bring all your friends. We'll give you all the likes, comments, and followers you could ever want. Not to mention, our algorithms are top-notch, so you'll always see the content you want (or didn't even know",spam
"Hey guys! It's time for some major social networking updates! Let's start off with some awesome news about the latest feature that makes you feel like a total superstar. With our new ""Superstar Status,"" you can now customize your profile with the most outrageous themes and colors imaginable. It's like neon colors on steroids, baby!

But wait, there's more! We've also added a new feature that lets you see how many times your posts have been shared. Yeah, that's right - you can now compete with all your friends to see who's the most popular. And don't worry, we won't tell your mom about",spam
"Hi Everyone, 

I had a look online but I did not find anything about it. Does anyone know about a dataset related to [semantic differential](https://en.wikipedia.org/wiki/Semantic_differential) scale application (sometimes also known as polarity scale)? If around marketing would be great, but any practical case is good (from research papers, business cases, handbooks, etc.)

I already made one myself to test, but I would like to test my script on a non-fake one.

Thanks everyone!",not_spam
"Hey all,

I am looking for a dataset or API that I can use to create a predictive algorithm for the attendance to a weekly event and to see if it is correlated to the Weather, so that using a weather forecast and some more information, Tensorflow can return an estimation of the number of people that may assist.

Thanks!",not_spam
"Hey,

I need as many tex files as possible, preferably from CS or engineering fields. Either a dataset or a suggested place to scrape from would be appreciated.

Thanks!",not_spam
Looking for a dataset that would allow me to see which countries have been under communist rule at any point in their past.,not_spam
"Are you tired of boring old social networks? Well, we have a solution for you! Come join our community of cool cats and awesome dudes! 

",spam
"Hi all,

I've been doing a lot of survey analysis lately, both from Coursera MOOCs, and from in-class paper-based surveys. I'm very interested in using open workflows, and although we often are not able to publish the data widely because of institutional policy and ethics agreements, we are a number of different research groups internally using the data, and I try to practice good scientific practice. I spend a surprising amount of time cleaning up the data - checking for accuracy of data entry, converting NAs, renaming and ordering categorical variables etc, and I try to do all of this in an R+Knitr document, which I can re-run at any point if I get new data, and also just to document explicitly what I've been doing. 

However, I've been thinking about data formats to store/share this data. CSV seems to be the standard format of the open data movement, and it's very interoperable, however you loose a lot of metadata. For example the ordering of categorical variables (Levels: Strongly Disagree &lt; Disagree &lt; Neutral &lt; Agree &lt; Strongly Agree), whether a variable is categorical or numerical, the full question names (ie. db$course.fun.Why.enroll - the full question name ""I enrolled in this course because I thought it would be fun""), etc. 

I've thought about this in two ways. First is internal to my R workflow - I like to separate between data cleanup and organization, and the actual report writing (in R+Markdown). I recently submitted a pull request to a likert package that would let me store some of this metadata (specifically groups of questions, and full question names) as metadata, so that I would be able to render a likert-graph over a certain number of questions without having to always rename the variables (https://github.com/jbryer/likert/pull/7)... This would store the metadata as attributes to the data.frame, which would be saved as an Rdata object etc... 

However, this is a bit of a kludge, and it certainly doesn't answer the question of how to store the data and share it with people who don't use R... Ideally we'd have a universal file format where we were able to include the whole ""code book"" - metadata about what kinds of columns, groupings, full question names, maybe even details about how a certain data field was calculated, the meaning of various codes etc... 

I realize this might be very obscure to people not interested in open data, R, etc, but there might be other people on the list who find this interesting - and you might even know about efforts or people working in this direction?

Thanks",not_spam
I was wondering if anyone knows of any high-quality open-source real estate datasets? Most free real estate datasets I've found are of low quality and don't allow for in-depth analysis. And all the more high-quality datasets are hidden behind a paywall.,not_spam
"Hi all

Iâ€™m looking for a good data source for travel advisory recommendations for US states. The closest Iâ€™ve found is the CDC website linking to each states website. Is there a central source of information available? General advisory but also including Coronavirus related advice.

Thanks!",not_spam
"(Caption for a post on a social media platform)

""ğŸ¤¢ SEE DISGUSTING PICTURES OF BARF HERE ğŸ¤®!!!""

Hey guys! Check out these gnarly pics we found of people puking their guts out! It's so gross, but we know you love this kind of stuff, right? ğŸ˜‚

But wait, there's more! If you comment on this post and tag at least 5 friends, you'll automatically be entered to win a lifetime supply of expired milk! (Just kidding... or are we?) ğŸ¤ª

Also, don't forget to follow us",spam
"""Get rich quick with our new investment app! It's super easy, no experience needed!

",spam
Any help is much appreciated! I have zip codes for campaign finance donors and would like to match them to their congressional district,not_spam
"Sale sale sale! This is not a drill! Get ready to have your mind blown with the biggest sale of the year! Everything must go! Buy now before it's too late!

",spam
"L0ok1ng f0r s0m3 c00l st00f t0 d0 t0day? Ch3ck 0ut 0ur AW3S0ME W3BS1TE! W3'v3 g0t all th3 h0t t3nds and l4t3st g0ss1p. Plu5, w3'v3 g0t 4ll th3 d3t41ls 0n th3 b3st r3st4ur4nts 4nd c00l3st b4rs 1n t0",spam
"Are you tired of boring, average social media platforms that don't give you the attention you deserve? Well, let me introduce you to our super cool and hip social network! Our platform is the place to be if you're looking for endless spam messages, fake accounts, and inappropriate content galore!

But wait, there's more! Not only do we offer a never-ending stream of low-quality content, we also have several exciting features to keep you glued to your screens! From constant ads popping up every few seconds to clickbait articles that lead nowhere, we've got it all! And let's not forget about the countless surveys and",spam
"Register here: [http://www2.omnisci.com/l/298412/2020-05-06/8rh7d](http://www2.omnisci.com/l/298412/2020-05-06/8rh7d)

**Join OmniSci May 19 - 20 for our final FREE Virtual Summit** of our three-part summit series. During this summit you will hear from **Harvard Center for Geographic Analysis, Charter Communications, Quansight, Epigen Technologies, and OmniSci experts**. Sign up today and you will receive an **OmniSci branded Star Wars T-Shirt (see below)** and you'll be entered to win an **Apple HomePod.**

Here are some sessions that you won't want to miss:

**How to do Large Scale Data Research on a Slurm HPC Cluster with OmniSci** with Devika Kakkar, Geospatrial Data Scientist and Ben Lewis, Geospatial Technology Manager, , Harvard Center for Geographic Analysis

**Aligning OmniSci with Open Interactive Computing Standards and Open Source Communities** with Tony Fast, Data Scientist, Quansight 

**OmniSci in Action: Learn from a Telecom Leader** with Jared Ritter, Senior Director Analytics &amp; Automation, Charter Communications

**Exploring without moving: Further adventures with Ibis, Altair and OmniSci, part 2** with Venkat Krishnamurthy, VP Product, OmniSci",not_spam
"Hello frens  


I published on kaggle a dataset of 1.2 GB of spotify data (user hashes, artists, tracks and playlists) scraped from the #nowplaying hashtag on twitter.  


It is available on this [link](https://www.kaggle.com/andrewmvd/spotify-playlists).  


All credits are due to the original authors:

&gt; Pichl, Martin; Zangerle, Eva; Specht, GÃ¼nther: ""Towards a Context-Aware Music Recommendation Approach: What is Hidden in the Playlist Name?"" in 15th IEEE International Conference on Data Mining Workshops (ICDM 2015), pp. 1360-1365, IEEE, Atlantic City, 2015. 

  
Cheers",not_spam
"Hey there! Wanna get rich quick?! Get our amazinG offer of money-making secrets that will change your life!! All you gotta do is click on the link below and follow the steps to financial freedom!!! 

But wait, there's more!! Sign up now for our exclusive weight loss program and get your dream body in just 7 days!! That's right, lose 20 pounds in 7 days!!! Just click on the link below and enter your personal information to get started!!! 

And if that's not enough, check out our incredible selection of luxury watches, designer handbags, and the latest tech gadgets all at rock",spam
"I'm looking for a dataset where I can find the average annual temperature anomaly by country and by year up to the present. Basically climate change data by country. 

I can handle most formats that R can convert. (Eventually I will be using Stata with this data.)",not_spam
"WIN FREE STUFFS LIKE OMG!!!

Are you tired of being broke? Do you want free stuff? Of course you do, who wouldn't!

Follow us on Insta, FB and Twitter and you could win AMAZING STUFFS like:

- A lifetime supply of beans
- A picture of a cat wearing a hat
- A rusty nail (just kidding, we won't actually give that to you)

Plus, we'll post non-stop ads for products you never knew you needed but now can't live without! It's all here, FOR FREE (until we start charging for everything, haha). 

Don't miss out",spam
"Check out our latest offer, it's totally epic! ğŸ¤‘ğŸ¤‘ğŸ¤‘ 
",spam
"HAY GUYS!!!1 Want 2 make BIG MONEY?!? Check out our AMAZING offers to get RICH QUICK! ğŸ¤‘ğŸ’¸ğŸ”¥ğŸ’°

NO MORE boring 9-5 jobs or living paycheck to paycheck! Our system is PROVEN to make you THOUSANDS in just a FEW DAYS!!! ğŸ˜ğŸ’µ

Don't miss your chance to be a SUCCESSFUL ENTREPRENEUR like me! Click the link NOW and start living the DREAM LIFE you deserve! ğŸš€ğŸŒŸğŸ¤‘

P.S. SHARE this with all your FRIENDS so",spam
" 

As the title suggests, what are some sources of large scale data collection that can be utilised for the purpose of gaining insights to help drive decisions related to e-commerce?

I am putting together a university project which broadly aims to do the above for commercial gain, using machine learning algorithms, something I am very new to but which is a requirement of the project.

Recently looked into collecting data from Amazon to 'train' the software to provide insights that could be use to optimise listings etc, but have realised that the data collected using the Amazon Product Data API is restricted, and to scrape (another new topic for me) is naughty and against ToS, not a good start when suggesting a project to the project coordinator, therefore I am wondering what other similar sources are there online which is either not restricted, or much easier to gain access to on a large scale?

Any general advice is also very much appreciated as I am learning as much as I can in this early stage.",not_spam
"#GetRichQuick
Hey you! Yes, you over there! Do you want to make millions of dollars without lifting a finger? Of course you do! Well, guess what? I have the ultimate solution for you. All you have to do is sign up for our amazing program and you will be on your way to living the high life in no time! Don't wait, sign up now and start making money instantly!

",spam
"I'm looking for internet speeds and internet service providers by zip code 
Much thanks",not_spam
"Other than pulling estimates from articles, I haven't been able to find a good source of the total costs of the Democratic National Conventions over the years. Anyone know where these numbers might be?",not_spam
"I've seen infographics but no data sets. Where to look?

",not_spam
"BUY NOW! Don't miss out on our amazing deals! Get unlimited likes, followers and comments for a low, low price! 

",spam
"Amazing Offer!!!!! Get rich quick!! Don't miss out on this amazing opportunity!!! 

",spam
"Cyber buds, whatâ€™s up! Weâ€™ve got some juicy gossip to spill on the gram! Are you ready to hear it? You better be!

Weâ€™ve just launched a brand new feature thatâ€™s going to change the game. You can now add GIFs to your stories! YAS! Itâ€™s lit AF, right?

And thatâ€™s not even the best part. Weâ€™ve made it super easy for you to swipe through all the hottest GIFs out there. Just tap the search bar and type in whatever youâ€™re feeling â€“ pizza, unicorns, or even poop! Weâ€™ve got it all!

Oh, and donâ€™t",spam
"I came across this question on StackOverflow:  [https://stackoverflow.com/questions/55450247/find-image-that-fit-together-the-best](https://stackoverflow.com/questions/55450247/find-image-that-fit-together-the-best)

Here is a sample image:
https://i.stack.imgur.com/YrVmR.png

I found this problem very interesting and would like to try it out myself, but I do not have access to the complete dataset.

If you have previously worked with this dataset and know its source, I'd really appreciate it if you shared the link here. Thanks in advance :)",not_spam
"I would like to find a list of lakes, rivers, estuaries, and bays. I'm really just looking for the names and how many exist. A great bonus would be knowing surface area, location, and volume of water. I can't seem to find what I am looking for. Any help or pointer in the right direction would be greatly appreciated.",not_spam
"Hey there, fellow internet folks! Are you feeling lonely and unloved? Do you want to boost your social status and become the envy of your friends and family? Well, look no further than [name of social network], the ultimate platform for attention-seeking, fame-hungry individuals like yourself!

With [name of social network], you can post as many selfies, food pics, and inspirational quotes as your heart desires, and watch the likes and comments roll in like waves on a beach. Plus, our algorithm is so cutting-edge that it will tailor your feed to show you only the most irrelevant and trivial content, so you can",spam
"Invest in our new revolutionary diet pills now! Lose 10 pounds in one week guaranteed! Don't miss out on this incredible offer!

",spam
"Have you ever been so bored that you could eat a brick? Well, don't! But you know what you should do? Check out our amazing deals and discounts on the latest fashion trends and gadgets! You won't believe your eyes when you see our selection of useless junk that you simply must have!

",spam
"I have found some dataset but the paper that provides the link requires subscription and another is quite old hence the link is dead.

Dataset : [https://aip.scitation.org/doi/pdf/10.1063/5.0036388](https://aip.scitation.org/doi/pdf/10.1063/5.0036388)

Is there any website where I can search these type of data?

Thanks for reading!!",not_spam
"""Unlock Sszxy Dealszzz with Our Latest Hacckkk! Hurry, Limited Time Offerzzzzz! Don't Miss Out on the Chance to Get Rich Quick and Easyyy! Follow This Link Nowwww!""

",spam
I am trying to do a analysis to find out what are general cause of late product shipment in automotive industry. Is there a public dateset where I can do the analysis? Thanks in advance :),not_spam
"Hi all,

I am looking for global data on fast-food consumption/nutrition in countries across years from around 1990. Could be anything useable as an indicator on a national level or regional level e.g. restaurants per capita, revenue in a country, proportion of meals taken at fast food restaurants, etc.

I want to link it with demographic datasets in the last thirty years. Does anyone have any ideas?",not_spam
"WANT TO GET RICH QUICK? JOIN OUR PYRAMID SCHEME NOW!

Are you tired of living paycheck to paycheck? Do you dream of exotic vacations and luxury shopping sprees? Well, we've got the answer to your financial woes! Our amazing pyramid scheme is guaranteed to make you rich in no time! Just sign up and start recruiting your friends and family to join too! The more people you bring in, the more money you'll make! It's that simple!

But that's not all! As a member, you'll get access to exclusive insider tips on how to maximize your profits and beat the system! Plus,",spam
"Buy 10000 followrs for just $10 and become famous overnight! Don't waste your time with organic growth, cheat the system with our amazing followr packages!

",spam
"Hey there social media fam! Are you tired of the same old boring feeds? Well, I've got some exciting news for you! Our latest update includes more spam than ever before! Get ready for a barrage of unwanted ads and questionable content.

But wait, there's more! We've also introduced a new feature where you can earn fake currency by clicking on ads and sharing them with your friends. It's a win-win situation, right? You get those sweet, sweet fake coins and we get to bombard you with even more spammy ads.

Oh, and did I mention our new chatbot? It's programmed to send you automated",spam
"Greetings, fellow social media addicts! Are you tired of boring posts that don't make you hurl in disgust? Well, fear not, because I am here to provide you with the most disgusting content your eyes have ever laid upon!

Let's start with some gratuitous photos of bodily fluids and excrement, because who doesn't love a good poop pic, am I right? And speaking of bodily fluids, have you tried mixing your own urine into your protein shake? It's a great way to save money on supplements and feel the burn in more ways than one.

But wait, there's more! How about some poorly-written fan fiction about",spam
"Looking for a way to boost your followers? Well, we've got the solution for you! Our amazing followers trick will give you the boost you've been waiting for. Not only will you get more followers, but you'll also get more likes and comments on your posts!

Plus, we've got all sorts of amazing deals on likes and followers that you won't want to miss out on. And if you act fast, we'll even throw in a bonus package with even more likes and followers for free!

But that's not all - we've also got the latest tricks for growing your social media presence. From quick hacks to advanced strategies",spam
"Hey r/datasets, I am looking for a dataset that captures average scientific literacy by state in the United States. I have found science scores from the national report card: [https://www.nationsreportcard.gov/profiles/stateprofile?chort=2&amp;sub=SCI&amp;sj=AL&amp;sfj=NP&amp;st=MN&amp;year=2015R3](https://www.nationsreportcard.gov/profiles/stateprofile?chort=2&amp;sub=SCI&amp;sj=AL&amp;sfj=NP&amp;st=MN&amp;year=2015R3) but this, unfortunately, only measures the scientific literacy of 8th graders. **I am hoping to find data that captures the average scientific literacy of adults in each state.**

&amp;#x200B;

I am also interested in any datasets that capture scientific literacy by country. I have been using the PISA [https://www.oecd-ilibrary.org/education/science-performance-pisa/indicator/english\_91952204-en#:\~:text=Scientific%20performance%2C%20for%20PISA%2C%20measures,mean%20score%20is%20the%20measure](https://www.oecd-ilibrary.org/education/science-performance-pisa/indicator/english_91952204-en#:~:text=Scientific%20performance%2C%20for%20PISA%2C%20measures,mean%20score%20is%20the%20measure). but this also only capture the literacy of children in each country. Not to mention that the number of countries that participate in this testing is limited.

&amp;#x200B;

Any help would be appreciated, thanks. ",not_spam
"Dearest friends, for a research project I am currently searching for data on activtities of digital platform companies in low income countries. For now, we are happy with everything we can find. It's hard to find something on this topic actually...",not_spam
"I currently have a Crunchbase subscription that I only needed to use once. It really sucks to have to buy for a whole year.

If anyone wants to buy the subscription which has around 10 months left on it for a discounted rate, I'd be more than happy to sell it to some who needs it more than me!",not_spam
"""URGENT: LIMITED TIME OFFER! 
Hey there peeps! Don't miss out on the amazing opportunity to get rich quick!! All you gotta do is invest in our new get-rich-quick scheme and watch your bank account skyrocket! Seriously, this is the BEST THING EVER!! 

But wait, there's more!! For a limited time only, if you refer a friend to our scheme, we'll give you an extra 50% profit!! So get on it and share this post with all your friends to start raking in the cash!!

And if that's not enough, check out these totally legit weight loss",spam
I've looked for anime Metadata but I am having a hard time locating any. Does anyone know of a place that has a dump?,not_spam
"WIN FREE AMAZON GIFT CARDS AND BECOME A MILLIONAIRE IN JUST 3 CLICKS! 

You heard it right, folks! We are giving away FREE Amazon gift cards worth $1000 to the lucky winners. All you have to do is click on our link and enter your personal information. Don't worry, we won't misuse your data or sell it to anyone (wink wink).

But wait, there's more! As a bonus, we'll also give you access to our exclusive get-rich-quick online course that guarantees to turn you into a millionaire in just 3 clicks. Learn the secrets of",spam
"BITCOIN REVOLUTION: MAKE MONEY FAST WITH THIS AMAZING SYSTEM, SIGN UP NOW AND CHANGE YOUR LIFE! 

Hey there guys, are you tired of working hard for your money? Do you want to become a millionaire overnight? Then you need to sign up for the Bitcoin Revolution program right now! 

This amazing system will change your life and make you rich in no time! You just need to invest a little money and sit back as the profits roll in. Don't hesitate, join the countless others who have already made a fortune with Bitcoin Revolution! 

But that's not all, once you're signed up you'll have access",spam
"If anybody sees any examples of awkward or insensitive marketing campaigns coming in from companies trying to capitalize on COVID-19.  I'm trying to compile a dataset with company names and industries to see how common it is.  Drop your data in here if you get a chance.

[https://forms.gle/DjhJiAdVxnfM88xx8](https://forms.gle/DjhJiAdVxnfM88xx8)

&amp;#x200B;

Link to the data as it comes in: [https://docs.google.com/spreadsheets/d/1OkiVMXApl4eqo9pEoK85wDAK-iWWaW38YAxadtAmh1A/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1OkiVMXApl4eqo9pEoK85wDAK-iWWaW38YAxadtAmh1A/edit?usp=sharing)",not_spam
"Where can I find the identifiers such as age, sex, risk factors and location of each patient when I analyse the sequence.fasta file of Covid protein sequence?",not_spam
"I have a graph that shows average IMDB movie rating vs. runtime. It shows that movies that are 90 minutes long are generally rated lower than shorter and longer movies.

I have some questions I would like help with:

* Is this relationship helpful for movie producers to use?
* What factors could be influencing this result?
* What sort of actions should be taken for producers to improve how movies are received by audiences?
* What sort of analytical approach should be tried to dissect this result?

I would like to get your thoughts on how you approach this problem.

Graph: [https://imgur.com/a/DBRPlAy](https://imgur.com/a/DBRPlAy)",not_spam
"If a person was hired as freelancer in data collection, how much he/she should charge in American dollars USD per record if there was 5 fields for each record?",not_spam
"Discountsssssssss!!! Get your hands on the latest deals and steals right now! Don't miss your chance to save big on all your favorite products - from fashion to food and everything in between. Come on down to our website and see for yourself, you won't be disappointed!

",spam
"Hi all, I am looking for dataset having various data center and computing machine's features/parameters which can be used to train Neural Network in order to predict and optimize energy and utilization efficiency of the data center. It would be rally helpful if someone can provide similar dataset.

&amp;#x200B;

Like CPU utilization, disk usage, etc. and some of the below mentioned points.

&amp;#x200B;

Some points: (the actual dataset could vary)

&amp;#x200B;

Total server IT load \[kW\]

1. Total Campus Core Network Room (CCNR) IT load \[kW\]
2. Total number of process water pumps (PWP) running
3. Mean PWP variable frequency drive (VFD) speed \[%\]
4. Total number of condenser water pumps (CWP) running
5. Mean CWP variable frequency drive (VFD) speed \[%\]
6. Total number of cooling towers running
7. Mean cooling tower leaving water temperature (LWT) setpoint
8. Total number of chillers running
9. Total number of drycoolers running
10. Total number of chilled water injection pumps running
11. Mean chilled water injection pump setpoint temperature
12. Mean heat exchanger approach temperature
13. Outside air wet bulb (WB) temperature
14. Outside air dry bulb (DB) temperature
15. Outside air enthalpy \[kJ/kg\]
16. Outside air relative humidity (RH) \[%\]
17. Outdoor wind speed
18. Outdoor wind direction \[deg\]",not_spam
"Anyone care to recommend anomaly detection datasets? Specifically point anomaly datasets (i.e. binary classification / non-time series). The only good source I could find is in [http://odds.cs.stonybrook.edu/](http://odds.cs.stonybrook.edu/). Maybe someone else knows publicly available datasets from real world applications like from NASA or some other recent project?

&amp;#x200B;

Thanks",not_spam
"Looking for a #HotDeal?! We've got you covered! Check out our insane discounts on #fashion, #beauty, and #fitness products! You won't find prices this low anywhere else! Hurry up and buy now!
",spam
"Additional information would be helpful as well, but I'm primarily interested in knowing about the approx. number of hospitals available in DRC.",not_spam
"WE GOT THE LATEST GADGETS AND DISCOUNTS YOU WON'T WANNA MISS!! ğŸ˜ğŸ‘€ğŸ”¥

",spam
"Hello!  I was hoping some of you in /r/datasets would share some of your favorite methods and tools for finding various datasets, and how you access them (or query/scrape/download to build them).

I'm def a comp-sci noob, but I was wondering if there were any tricks you guys had for finding various datasets...e.g, any set ways of finding out whether organizations or websites have FTP sites, or go-to means of web scraping?

Any sort of a general discussion about the process of how you compile data would be appreciated, for example ""I use a web-crawler programmed in python which connects to XYZ.com's API and dumps the data into an MS Excel file/Access/Sql database"" is cool too!

",not_spam
"Get rich quick!
Make thousands of dollars in just a few clicks! Our amazing new system is guaranteed to make you rich in no time. Just sign up now and start earning big bucks!
",spam
"Attention all peeps! Hottest deals and savings here on GramCrush! Get yo' discount codes and freebies NOWWWWW! Limited time only, so you gotta act fast! ğŸ˜œğŸ’°ğŸ’¸

",spam
"#BESTDEAL #LIMITEDEDITION #SALESALESALE

HURRY UP AND GET YOUR HANDS ON THE HOTTEST PRODUCTS OF THE YEAR! LIMITED EDITION ONLY AVAILABLE FOR A SHORT TIME! DON'T MISS YOUR CHANCE TO SAVE BIG WITH OUR MASSIVE SALE! 

WITH OUR AMAZING DEALS, YOU CAN SAVE UP TO 50% OFF ON SELECT ITEMS! WE'VE GOT EVERYTHING YOU NEED - FROM FASHION TO BEAUTY TO HOME GOODS! 

BUT WAIT - THERE'S MORE! IF YOU ACT NOW, YOU'LL RECEIVE A FREE GIFT WITH YOUR PUR",spam
"I'm looking for very short descriptions of biographic events and the exact dates for a lot of widely known people such as celebrities, business or tech leaders, politicians, etc. E.g:

""09/14/1973: Bill Gates enrolls at Harvard""

""01/01/1979: Bill Gates moves to Washington DC""

""01/02/2014: Bill Gates steps down as CEO from Microsoft""

Bonus would be if there was additionally a short description of roughly 50-200 words. Is there a database for this? Are there databases for at least some widely known people (e.g. only politicians or only musicians)?",not_spam
"FeElInG hUnGrY & dOn'T kNoW wHaT tO eAt? ChEcK oUt OuR aMaZiNg DeAlS oN fAsT fOoD aNd SnAcKs!!!!!!! YoU cAn SaVe BiG oN yOuR nExT mEaL!ğŸ”ğŸŸğŸ”ğŸŸğŸ”ğŸŸğŸ”ğŸŸ

",spam
"Attention all #influencers and #contentcreators! ğŸ“¢ Are you tired of being FORCED to use hashtags that don't match your brand? ğŸš« Do you want to get more FOLLOWERS, LIKES and ENGAGEMENT without spending ANY MONEY? ğŸ’°ğŸ˜± Well, look no further! The #1 solution is HERE! ğŸ‰

Introducing our newest feature â€“ BUYING FOLLOWERS! ğŸ¤‘ğŸ¤‘ That's right, you can now get THOUSANDS of FAKE followers delivered STRAIGHT to your account in just a FEW EASY STEPS! ğŸ˜",spam
"Hi everyone,

I'm working on building a two steps image classification model, I'm trying to find a dataset that has indoor and outdoor images of homes, once outdoor images are excluded, it will classify whether the home is furnished or not.

Thanks for your consideration!",not_spam
"Want to BOOST your FOLLOWERS and EARN MONEY FAST? 
We've got the SWEETEST DEALS for you! 
BUY NOW and ENJOY the BENEFITS of being POPULAR! 

",spam
"Hello, I was hoping to find datasets with two or more independent variables (I only need two independent variables) and one dependent variable. If anyone has any good datasets with good correlations, please let me know and specifically, I am looking for datasets in relation to profits or costs - I want the dependent variable to be ""profit"" so I can do some multivariable optimization and local extrema stuff, or costs as well.",not_spam
"Hi, I'm looking for data on daily M&amp;A activity for the US stock market (SP500 or alike). Does anyone perhaps know where this data is available?",not_spam
"""Check out this super duper awesome offer that you can't resist! ğŸ¤‘ğŸ’° Get a chance to win a lifetime supply of questionable supplements and weight loss teas that may or may not work! All you have to do is share this post with 100 of your friends and family members and follow our page. Yup, it's that easy! ğŸ˜

But wait, there's more! ğŸ™ŒğŸ¼ Act now and receive a discount code for our exclusive line of skin whitening creams and pills that will give you the ""perfect"" complexion society demands. Don't miss out on this opportunity to conform to",spam
"You won't believe what I've discovered!!! ğŸ˜±ğŸ˜±ğŸ˜±

The BEST way to LOSE WEIGHT without DIETING and EXERCISE is FINALLY HERE!!! ğŸ”¥ğŸ”¥ğŸ”¥

I tried it myself and lost 20 pounds in just ONE WEEK!!! ğŸ¤©ğŸ¤©ğŸ¤©

All you have to do is buy these AMAZING pills that will BURN YOUR FAT AWAY IN SECONDS!!! ğŸ’ŠğŸ’ŠğŸ’Š

Plus, if you buy now, you'll get a FREE trial of our new anti-aging cream!!! ğŸ‘µğŸ‘µğŸ‘µ

",spam
"Especially from countries like Argentina, Venezuela, Colombia and/or Brazil. I want to make ""card"" visualizations that summarize some data about these countries, so anything from currency depreciation or education indices, to the number of FIFA world cups won would be very appreciated. ",not_spam
"OMG, have you heard of our new viral challenge?! It's called the #LickYourOwnElbow challenge and it's taking the internet by storm! All you have to do is post a video of yourself attempting to lick your elbow and tag all your friends to take the challenge too. Trust me, it'll be hilarious!

",spam
"""Hey, hey, hey! S'up fello netizens?! Check out our brand new social media platform, it's the bomb dot com! Join us now and win a chance to get a thousand likes on your very first post! Ain't that cray cray?!

But wait, there's more! You can join our exclusive groups and spam your way to the top! Post your irrelevant content and watch as people ignore it to oblivion! It's a win-win situation, we promise.

Don't forget to download our crappy mobile app that crashes every five seconds, it's the best thing since sliced bread! You can also get",spam
"Hi,

&amp;#x200B;

I'm a researcher interested in discrete choice modelling at market level, i.e., in situations in which consumer-level data is unavailable, but there is product-level data at the country or store level. In order to test the robustness of particular discrete choice models, I'm looking for publicly available datasets that include the following information at the product level (e.g., SKU or UPC):

* retail sales volumes,
* prices,
* product characteristics (e.g., separate columns for flavour, sugar content, package size, etc.)

I have found many interesting datasets that contain retail sales volumes and prices at product level, but they always lacked information about the physical characteristics of products (or the information was very poor). Interesting examples:

* for new cars:  [https://www.kaggle.com/dmi3kno/newcarsalesnorway](https://www.kaggle.com/dmi3kno/newcarsalesnorway)
* for different consumer products: [https://www.chicagobooth.edu/research/kilts/datasets/dominicks](https://www.chicagobooth.edu/research/kilts/datasets/dominicks)

I would very much appreciate any links to datasets that are similar to those listed above, but contain the product characteristics variables.

&amp;#x200B;

Thanks!

&amp;#x200B;

&amp;#x200B;",not_spam
"Super-duper time to get your fave social fix! Like, comment, share, follow and post, all in one go go go! We got the hottest memes, most click-bait-y articles and bomb-diggity pics around. Don't be a square, come join our fam and be part of the in crowd. And, oh boy, do we have a deal for you all! Just type in the code ""SPAMMY"" at checkout to get 50% off anyÂ product you can dream of. Clothes, tech, snacks - you name it, we got it. Don't wait, act now and",spam
"Looking for some hot deals? Want to connect with your friends and family? Then come on over to our amazing social networking platform!

We've got it all - from the latest fashion trends to the hottest celebrity gossip. Plus, we'll connect you with all your favorite brands and help you find amazing deals that you won't find anywhere else.

But that's not all! We'll also keep you up to date on all the latest news and events happening around the world. Whether it's sports, politics, or just some juicy scandal, we've got you covered.

So what are you waiting for? Sign up now and start enjoying all the",spam
"We've got the hottest deals in town! Get your hands on our exclusive products now! 
",spam
"Hi, does anyone know of an open football dataset that contains some line ups historic and up to the most recent games?   
The only option I have found is scraping different sites. I wouldn't mind just a dataset with lineups for the games and substitutions maybe. I can combine with others.

I'd be super grateful if someone knows of something and is willing to share

Thanks!",not_spam
"Hey, folks! It's your favorite social media platform here to help you connect with friends and family (and maybe a few random strangers if that's your thing). We've got all the latest features you never knew you needed and more! 

Are you tired of seeing only the same people on your feed? Well, fear not, because we've got an algorithm that will show you posts from people you've never heard of before! It's like taking a walk down a street full of strangers, but on your phone! 

And if you're worried about your privacy, don't be! We'll only share your information with a few",spam
"Hello everyone,

I am looking for a dataset in German, to train a categorization model. My model should categorize files based on their content, and I want it to process the files in their original format (whether it's PDF, DOCX, TXT etc.), so I'm looking for a dataset that contains such filetypes.

Do you know of any dataset that may suit my needs?

Thanks!",not_spam
"CHECK OUT THESE AMAZING WEIGHT LOSS PILLS!! LOSE 10 POUNDS IN A WEEK WITH NO EFFORT!! LIMITED TIME OFFER, BUY NOW!!

",spam
"Hey guys,

&amp;#x200B;

I am currently writing on my bachelor thesis and I am looking for data showing the development of the German Mittelstand or SMEs from 1945 until today as well as some literature covering that topic. I would be really glad for any help.

Thanks!",not_spam
"Are you tired of being broke? Do you want to make money fast and easy? Then come join our network of successful entrepreneurs! We guarantee you'll make thousands of dollars in your first month! All you have to do is sign up and make a small investment. Don't miss this opportunity to change your life!

",spam
"Check out this amazing offer for a limited time only! Get 10,000 followers for only $10!

",spam
"URGENT: ğŸš¨ğŸš¨ DON'T MISS OUT ON THIS EXCLUSIVE DEAL ğŸš¨ğŸš¨

Hey friends, it's your girl from [social media network]! I'm here to tell you about a super awesome and totally amazing deal that you absolutely cannot miss out on. Trust me, it's going to blow your mind!

Are you ready for it? Here it is: {insert random product or service that no one asked for}

But wait, there's more! If you act now, you'll get our special VIP package which includes even more useless stuff that you don't need!

So,",spam
"Get rich quick! Make millions from home with our new money-making scheme!

",spam
"Looking for a data set on recommender systems, any organisation at all with good quality data on ratings, customer behaviours, buying habits etc. I need to analyse a data set for a university project.",not_spam
"Are you tired of boring news feeds and mundane updates? Well, your wait is over! Introducing the newest feature on our network - the ultimate scroll stopper!

",spam
"Hi to community menu, 
I am new here. I am trying to build a model to predict either diabetes or epilepsy in people. I want to do an end to end project. Therefore, I look for a sources to create a dataset (web scrapping). 
Beforehand, I appreciate everybody who helps. Thanks in advance.",not_spam
"Hey ya'll, it's your favorite social media platform here! I just wanted to drop in and remind you that we are still the numero uno when it comes to connecting you with your BFFs and frenemies alike. We got all the features you need to make your virtual life as exciting as your real life (if not more!).

First off, have you tried our new filter that makes you look like a cartoon? It's sooo cool, all the kids are doing it. And speaking of kids, don't forget to upload that cute pic of your baby and put a million hashtags so everyone can see. #momlife #",spam
"Hi! I am a newbie doing a machine learning based project about using ais data of the ship and from the past dataset predicting if it has been involved with some accident or not in real time. But the problem is I haven't been able to find a dataset for it . I did find one on kaggle but it's too small and many other paid services out their don't provide historic data. 

  Are you guys aware of any source? 

I've tried bigquery , data.gov , kaggle , aishub etc. but to no avail.. 

Thanks in advance.",not_spam
"I'm looking for data on global auto sales since 1970. Looking for manufacturer, region, model, and if available production specs. Does anyone have something like this or know where I can find it without a paid subscription?

Thanks!",not_spam
"I am creating a website that analyzes your text messages / Facebook messages to offer some interesting graphs and statistics about your chats.

&amp;#x200B;

Whats the best way to allow a user to give us their messages? I know they can download and upload, but I was hoping to have it be automatically updated.

&amp;#x200B;

EDIT

chill out about privacy concerns, this is for me and a few friends I don't plan to read anybodies messages lol",not_spam
"Hey, where can I find a dataset that is at least 1gb in size and contains used car listings, any country would work, but preferably US or UK? I have found some on kaggle but unfortunately they are old and therefore the listings are expired.",not_spam
Would anyone recommend sources where to obtain raw data for motor insurance and mileage in the areas of UK and France?,not_spam
"SUPER EXITING NEWS!ğŸ‰ğŸ‰ğŸ‰ğŸ‰

Heyyyya guys, I got some SUPER AWESOME news to share with all of you today! So without any further ado, let's dive right into it!!ğŸ˜ğŸ˜ğŸ˜

Are you guys even ready for this?! This is going to be the most life-changing news you will ever come across!! ğŸ˜±ğŸ˜±ğŸ˜±ğŸ˜±

Okay, so here is the big reveal - you can now BUY 10K INSTAGRAM FOLLOWERS for just $1!!! ğŸ˜±ğŸ˜±ğŸ˜±

Yes, you",spam
"â˜… Celebrities gone wild! You won't believe what they're up to! â˜…

OMG, have you seen what the stars are doing lately? It's totally cray-cray! We've got exclusive pics and deets on their wildest antics yet. From scandalous affairs to shocking scandals, it's all here.

And that's not all â€“ we've also got tons of juicy gossip on the hottest trends and latest fads. Whether you're into fashion, beauty, or just living your best life, we've got you covered.

But wait, there's more! Sign up now and you'll get access to our VIP",spam
"&gt;**TL;DR:** See example notebooks below ğŸ‘‡

I am happy to announce that I finally finished cleaning, organizing, creating baselines, and developing an automated collection pipeline that collects minute-by-minute market data for Cryptocurrencies. It updates on Kaggle every day! And will keep doing so until the competition is over! \[Maybe even more\]

The whole project took me a lot of time to develop and is not easy to maintain, so please if you find this of value: Your feedback &amp; support is highly appreciated!

## The Competition

As some of you know, there is Crypto forecasting competition is running on Kaggle: ""G-Research Crypto Forecasting"". In this competition, we need to use machine learning for forecasting short-term returns of popular cryptocurrencies \[such as bitcoin, ether, dogecoin..\] We are provided a dataset of millions of rows of high-frequency market data dating back to 2018 which we should use to build our models on. Once the submission deadline has passed, the final score will be calculated over the following 3 months using live crypto data as it is collected.

## Auto-updating Kaggle dataset

To make things more interesting: I created an Auto-Updating Kaggle dataset that collects high-frequency market data for multiple cryptocurrencies.

* Updates daily on Kaggle!
* Available for anyone to play with!

Also, I also released **20+ starter notebooks** each demonstrating a different model or method for forecasting future returns.

This project was meant to be for the currently running Crypto Forecasting Competition by G-Research. However, since it is publicly available I assumed many others would like to also have a look :)

**Mimics ""Real-Life"" better than typical datasets**

This is a unique opportunity to work in a much more ""real-life"" setup than usual Kaggle. Because the datasets update daily.

* so.. If you mess up and overfit..
* You see it tomorrow! ğŸ˜‚

Anyway, this is an ongoing project that is also beginner-friendly since it is highly documented. Many more Time Series / Finance-related notebooks will be released in the future so this can also serve as a ""first stop"" when studying Time Series analysis.

## Baselines &amp; Starter Notebooks

|CV + Model|Hyperparam Optimization|Time Series Models|Feature Engineering|
|:-|:-|:-|:-|
|[Neural Network Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-with-extra-data-nn)|[MLP + AE](https://www.kaggle.com/yamqwe/bottleneck-encoder-mlp-keras-tuner)|[LSTM](https://www.kaggle.com/yamqwe/time-series-modeling-lstm)|[Technical Analysis #1](https://www.kaggle.com/yamqwe/crypto-prediction-technical-analysis-features)|
|[LightGBM Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-with-extra-data-lgbm)|[LightGBM](https://www.kaggle.com/yamqwe/purged-time-series-cv-lightgbm-optuna)|[Wavenet](https://www.kaggle.com/yamqwe/time-series-modeling-wavenet)|[Technical Analysis #2](https://www.kaggle.com/yamqwe/crypto-prediction-technical-analysis-feats-2)|
|[Catboost Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-extra-data-catboost)|[Catboost](https://www.kaggle.com/yamqwe/purged-time-series-cv-catboost-gpu-optuna)|[Multivariate-Transformer \[written from scratch\]](https://www.kaggle.com/yamqwe/time-series-modeling-multivariate-transformer)|[Time Series Agg](https://www.kaggle.com/yamqwe/features-all-time-series-aggregations-ever)|
|[XGBoost Starter](https://www.kaggle.com/yamqwe/xgb-extra-data)|[XGboost](https://www.kaggle.com/yamqwe/purged-time-series-cv-xgboost-gpu-optuna)|[N-BEATS](https://www.kaggle.com/yamqwe/crypto-forecasting-n-beats)|[Neutralization](https://www.kaggle.com/yamqwe/g-research-avoid-overfit-feature-neutralization/)|
|[Supervised AE \[Janestreet 1st\]](https://www.kaggle.com/yamqwe/1st-place-of-jane-street-adapted-to-crypto)|[Supervised AE \[Janestreet 1st\]](https://www.kaggle.com/yamqwe/1st-place-of-jane-street-keras-tuner)|[DeepAR](https://www.kaggle.com/yamqwe/probabilistic-forecasting-deepar/)|â³Target Engineering|
|[Transformer)](https://www.kaggle.com/yamqwe/let-s-test-a-transformer)|[Transformer](https://www.kaggle.com/yamqwe/sh-tcoins-transformer-baseline)||â³Quant's Volatility Features|
|||||
|[Reinforcement Learning (PPO) Starter](https://www.kaggle.com/yamqwe/g-research-reinforcement-learning-starter)|||â³Wavelets|

[About the validation: GroupTimeSeriesSplit](https://www.kaggle.com/yamqwe/let-s-talk-validation-grouptimeseriessplit)

(â³ - in the making..)

Fork them as you please! Enjoy Yourself!

## Auto updating - Full Price Datasets

I created an up-to-today \[auto updating\] dataset which contains the full historical data for all assets of the competition so you can easily build models that utilize it. The datasets are split to each asset since they are much heavier than the competition data. The datasets have also been labeled as described in the competition overview and had been organized in a way that they are at the exact format of the competition data.

**The goal of this is to provide a dataset that:**

1. Contains the FULL history for each asset. Currently, the competition data goes back to 2018. This dataset contains data from even earlier.
2. Auto updating daily - Due to the high volatility of the cryptocurrency market, we should train our models on the most recent data available. These datasets have a backend pipeline for collecting, formatting, and reuploading to kaggle. They are scheduled to be updated daily, every single day until the end of the competition.
3. Preprocessed - The datasets had been ffilled to overcome any missing values issue that is present in the original competition dataset.

**The Datasets:**

* [Binance Coin](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-binance-coin)
* [Bitcoin Cash](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-bitcoin-cash)
* [Bitcoin](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-bitcoin)
* [Cardano](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-cardano)
* [Dogecoin](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-dogecoin)
* [Eos.io](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-eos-io)
* [Ethereum](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-ethereum)
* [Ethereum Classic](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-ethereum-classic)
* [Iota](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-iota)
* [Litecoin](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-litecoin)
* [Monero](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-monero)
* [Maker](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-maker)
* [Stellar](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-stellar)
* [TRON](https://www.kaggle.com/yamqwe/cryptocurrency-extra-data-tron)

&gt;**Bonus dataset:** I've also uploaded a dataset containing the most powerful source for predicting cryptocurrencies movement: Elon Musk's Twitter ğŸ˜‚! It is simply an updated dataset of all Elon Musk's tweets ğŸ˜‚. I must check if Elon Musk can help us win! ğŸ‘Œ You can play with it yourself [here](https://www.kaggle.com/yamqwe/elon-musks-twitter-updated-031121).



**Technical details about the Data** For every asset in the competition, the following fields from [Binance's official API endpoint for historical candlestick data](https://github.com/binance-exchange/binance-official-api-docs/blob/master/rest-api.md#klinecandlestick-data) are collected, saved, and processed.

1. timestamp - A timestamp for the minute covered by the row.
2. Asset\_ID - An ID code for the cryptoasset.
3. Count - The number of trades that took place this minute.
4. Open - The USD price at the beginning of the minute.
5. High - The highest USD price during the minute.
6. Low - The lowest USD price during the minute.
7. Close - The USD price at the end of the minute.
8. Volume - The number of cryptoasset u units traded during the minute.
9. VWAP - The volume-weighted average price for the minute. 10.Target - 15 minute residualized returns. See the 'Prediction and Evaluation section of this notebook for details of how the target is calculated.
10. Weight - Weight, defined by the competition hosts [here](https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition)
11. Asset\_Name - Human readable Asset name.

**Indexing** The dataframe is indexed by `timestamp` and sorted from oldest to newest. The first row starts at the first timestamp available on the exchange, which is July 2017 for the longest-running pairs.


Enjoy Yourself! 
And thank you in advance for your support! This is not an easy system to maintain!",not_spam
"I'm looking for the array of every response time for commenting a poem by /u/Poem_for_your_sprog. How long, in minutes, did it take him/her to write and post his/her poem response comment?

And... How many poems has s/he commented so far? What's the fastest poem posting? What's the longest idle time before the poem comment? What's the average? How many of each time marks are there (e.g.: 28 3-minute response times, 42 4-minute response times, etc.) How many posts have more than one poetic response comment from sprog? What's the most number of times s/he has commented a poem in response within a single post's comments?  Any other entertaining, related stats.",not_spam
"Not sure whether this falls under request.

Otherwise Iâ€™m interested in how statistics around competitive online games such as League of Legends are collected to build a website like https://na.op.gg",not_spam
"Hi,

I am a Masters student and my project is on Semantic Analysis and Topic Modelling of Game Reviews.

I was trying to scrape data from game review websites such as [gamestop.com](https://gamestop.com) with Rvest yet in their ToS data scraping is not allowed unless authorized. I have sent emails to few websites like this and received no reply after a month.

&amp;#x200B;

I am looking for datasets which will include full game reviews with game names, scores and date of the review.

The data can be also from steam.

&amp;#x200B;

Thanks!",not_spam
"Looking for a way to increase your followers? Look no further! Weâ€™ve got the solution youâ€™ve been waiting for. Our specialized algorithm, guaranteed to boost your engagements, is on sale for a limited time! Donâ€™t wait, buy now and watch your profile soar.

",spam
"Any ideas? Copernicus is 10m, looking for something around 1m if possible of mid-northern Norway (66N, 14W)",not_spam
"Refinance your mortgage NOW! Get low interest rates! No credit check!

",spam
"With or without the ""/u/,"" with or without spaces in the username. I would guess most of them are from a novelty account of some flavor  or another, or maybe AMAs where the interviewee managed to snag their full name as their username, but I really have no idea, and I have no clue as to how I would go about finding out.",not_spam
"WANNA BUY SOME CHEAP FOLLOWERS?! WE'VE GOT THE BEST DEALS ON REAL FAKE PROFILES THAT WILL BOOST YOUR NUMBERS IN NO TIME!

",spam
"Get rich quick with our new online course! ğŸ’°ğŸ’¸ğŸ¤‘ğŸŒŸ

We have a brand new program that will show you how to make millions ğŸ’°ğŸ’°ğŸ’° with just a few clicks ğŸ”ğŸ‘†ğŸ‘†ğŸ‘†. Work from home ğŸ , set your own hours ğŸ•“, and live the life you've always dreamed of ğŸŒŸğŸŒŸğŸŒŸ.

Don't miss out on this incredible opportunity. Sign up now and start earning BIG ğŸ’¸ğŸ’¸ğŸ’¸. And for a limited time only, use code MONEYMAKER to get",spam
"Google Brain recently released a new dataset, [AudioSet](https://research.google.com/audioset/index.html), and it looks like a really great dataset for research with about 3 million labelled audio clips.

However, the dataset *doesn't* include the raw audio, which is important for many applications (including my own, hence the request).

It does include the YouTube ID/URL and the start and end time of the audio segments, so I'm wondering if anyone has built a tool to extract the audio segments corresponding to each of the records in the dataset.

If not, does anyone have suggestions on how to download a 10 second audio clip from YouTube, without human interaction?

Thanks!",not_spam
"Reduce belly fat by 90%! Lose weight in just 24 hours! Click here now! 

",spam
"Buy our amazing social media package NOW and become the ULTIMATE influencer of your wildest dreams!!

",spam
"Hey there, people of the internet! Are you ready for some seriously awesome news? Of course, you are! So listen up...

We've got a brand new update for you - and it's going to blow your socks off! Our team of tech wizards have been working around the clock to bring you this EPIC upgrade, and it's finally here!

So, what's new, you ask? Well, let me tell you...

We've added a bunch of new emojis to our already massive collection! Now you can express yourself even more through our platform! And that's not even the best part! We've also got a bunch",spam
"I am following this great tutorial to learn how to create my own **sentiment analysis** pipeline using Python **SpaCy** package: [https://realpython.com/sentiment-analysis-python/](https://realpython.com/sentiment-analysis-python/)

This tutorial uses the ""Large Movie Review Dataset"" for training &amp; test sets. Where do I find more datasets for different applications?

I need to analyze the sentiment of texts that users highlight in a **diabetes** brochure and website, to see if I can predict from the highlighted text whether a user is a diabetes patient or only just diagnosed or a friend or family member of a patient, etc...

What dataset should I use instead of the movies dataset used in this tutorial?

Thanks",not_spam
"&amp;#x200B;

Hello fellow data scientists,

&amp;#x200B;

I'm currently working on developing a smart personal assistant, for this I need to train my Automatic Speech Recognition module with a domain specific language model, so I was thinking of gathering some [README.md](https://README.md) files or any comments on reddit about IT topics (FAQs, Requests, Bug fixes ...), before starting this task I would like to ask you if there is any existing dataset that could help me performing such a feat ?

&amp;#x200B;

Regards.",not_spam
I am sure this data set does not exist...,not_spam
"Time to give something back to this great forum where Iâ€™ve found interesting datasets for past projects.  This dataset contains every trip record (starting point, ending point, date, time) for the Bike Share program in the Washington DC metro area in 2018 (about 3M records).  Iâ€™ve joined each trip with the weather metrics (temperature, precipitation, wind, etc.) that matches the starting time of the trip as part of a climate article Iâ€™m writing.

[https://drive.google.com/file/d/1BeZUhjgxpT3z62PBhmoGkHvQzXBD\_-HD/view?usp=sharing](https://drive.google.com/file/d/1BeZUhjgxpT3z62PBhmoGkHvQzXBD_-HD/view?usp=sharing)

&amp;#x200B;

The source of the Bike Share data is [https://s3.amazonaws.com/capitalbikeshare-data/index.html](https://s3.amazonaws.com/capitalbikeshare-data/index.html).

The source of the weather data is [https://www.visualcrossing.com/weather-data](https://www.visualcrossing.com/weather-data). (I used their Excel interface to automatically merge weather with the bike times.)

&amp;#x200B;

First time contribution, so please let me know if it is useful.

Thanks!

Ginger",not_spam
"Hey there! Are you ready for the ultimate spam experience? Of course, you are! That's why you're here, right?

Let's cut straight to the chase. Our users have been raving about the latest spam-tastic feature we've added to our site. It's called ""Spam-o-Rama"" and it brings you non-stop spammy goodness right to your fingertips.

But wait, there's more! We've also partnered with a bunch of bots that will flood your inbox with even more spam. You'll never have to worry about missing out on the latest offers for weight loss supplements, miracle skincare products or get",spam
"Enhance your bussines, improv your life and fun with our super cool app. Download now and get a 50% discount on your first order!

",spam
"""Lose weight fast with our amazing new product! Guaranteed results!""

",spam
"Hello all,

I am trying to find a dataset that has public opinion data, specifically on racial attitudes, and wealth measures. I looked through the main datasets on wealth accumulation (SIPP, PSID, SCF, etc.) and I just canâ€™t find a dataset that incorporates both measures. (Already looked at the GSS)

Does anyone out there know of any datasets with both wealth measures and public opinion data? Honestly I would greatly appreciate any input.",not_spam
"Hello /r/datasets! I'm a non-academic researcher/programmer, working on a few music-related tools. I'm not affiliated with any universities, however. Just came across the Spotify million playlist dataset. The challenge is already over, but I have a couple of applications that this would be useful for. 

Any chance anyone has the whole thing and would be willing to share? Thanks in advance! ",not_spam
"WIN A FREE IPHONE NOW! Click on the link and enter your personal information to win! This offer won't last long, so hurry up and enter before it's too late! 

",spam
"Get ready to feel FOMO (fear of missing out) like never before, because our platform is about to blow your mind! We've got all the coolest influencers, epic trends, and dank memes you could ever want. Don't be a total noob, join the party now!

",spam
"Heyyy guyyyys, it's your favorite social media platform! We've got some super exciting updates for you today.

First off, we've got a brand new feature where you can share all your personal information with random strangers! We know privacy is totally overrated, so we've made it easier than ever to let everyone know your location, your phone number, and your deepest darkest secrets.

And speaking of secrets, we've also added a feature where you can anonymously cyberbully your friends and enemies! It's a great way to let off steam and make yourself feel better by tearing down other people. Plus, it's all",spam
"I wanted to create a dataset similar to Wine dataset or [Coffee dataset](https://www.reddit.com/r/datasets/comments/8rndor/data_on_1340_coffee_bean_reviews_aroma_acidity/), but for tea. Unfortunately, the [teadatabase](https://www.teadatabase.com/) page (first Google result) seems to be down, at least it was for a few days when I've been checking. Do you know any source of reviews of tea in quantitive amounts, similar to the Coffee dataset, like acidity, sweetness, caffeine content etc.?",not_spam
"Using mlb.com's website, is there a way to do this for example like http://m.mlb.com/player/458015/joey-votto   ?",not_spam
"ğŸš¨URGENT!ğŸš¨ Are you tired of being just another face in the crowd? Do you want to stand out and be a VIP? Then do we have the solution for you! Join our exclusive network and become part of the elite.ğŸ’¥

ğŸ”¥Get access to the hottest news, trends, and deals before anyone else!ğŸ”¥Never again will you miss out on an amazing opportunity or trendy product because you didn't know about it.ğŸ’¥

ğŸ¤©But wait, there's more!ğŸ¤©Sign up now and receive a FREE virtual high-five from our CEO!",spam
"ShOcKiNg NeWs!!! YoUr FrIeNdS aRe PrEpArInG tO cElEbRaTe SoMeThInG bIg aNd yOu DoN't EvEn KnOw?!? Be the envy of all your buddies and stay up-to-date with the latest events by following them on our totally amazing social network! 

",spam
" Hello everyone, I'm doing a research on the mergers &amp; acquisitions related to German speaking countries (Germany, Austria, Switzerland) and I'm looking for reports, statistics, useful articles, links, anything like that. I'm having trouble finding such information. Please let me know if you have any idea or suggestions where I could find such info. Many thanks! :) ",not_spam
"Amazing Offer! Get a FREE iPhone X NOW!

",spam
"We want to create a dataset to use in machine learning for plant disease recognition. It will be targeting indoor plants, and identifying the disease.

Our question is about the dataset structure. Should we make two categories, one for images of healthy plants and one with a folder for each disease without specifying the plants since different plants can suffer from the same disease? Or is it necessary to make a folder for each plant, and categories the images according to whether it's healthy or not, and the name of the disease?",not_spam
"""OMG guys, check out this amazing offer!!! FREE money!!!!!!!!!! You don't want to miss this incredible deal!!!!!! Just click on the link below and it will take you to a page where you can claim your FREE money right away!!!!!!!!!!!!! ğŸ¤‘ğŸ’°ğŸ‰

But wait, there's more!!!!! If you act now, you'll also get access to an exclusive weight loss supplement! This supplement will help you lose those pesky extra pounds without any effort at all!!!!!!! ğŸ™ŒğŸ¼ğŸ’ªğŸ¼ğŸ¥¦

And that's not all!!!!!! For a limited time",spam
"Are you tired of being broke and alone? Well, you're in luck because our amazing social network has the solution to all your problems! Sign up now to receive exclusive access to our top-notch spam-filled content and gain thousands of fake followers in just a matter of seconds!

",spam
"We has g0t sumbig n3wz 4 u guyz! Get framouzed with oure awesum new diskoountz on evrything frum sh00z to elektrocztuff. U can't refuze these offerz! Hurry up n' gr@b'em b4 theyr gone! Makzure u follo us @swaggy_social_netwrk to stay updatd on the L8test buzz.

",spam
"I am looking for data on H-1B visa petitions (or similar indicator of immigration to US) based on Gender and Country of origin.

I found stats for [2018](https://www.uscis.gov/sites/default/files/document/reports/h-1b-petitions-by-gender-country-of-birth-fy2018.pdf) and [2019](https://www.uscis.gov/sites/default/files/document/data/h-1b-petitions-by-gender-country-of-birth-fy2019.pdf) but not from before that.

Any similar dataset or source link would also help.",not_spam
"FbK is the newest social media hit, and we're here to tell you all about it! Have you been feeling left out of the social media game? Have you been searching for the perfect platform to share your thoughts, pictures, and videos? Well, look no further than FbK!

With FbK, you'll have access to all the latest memes and viral videos that you won't find on any other social media platform. Plus, our user interface is super easy to navigate, so even your grandma could use it (no offense, grandma!). We also have the most advanced algorithms to make sure you see all the",spam
"Hello guys,

I'm trying to create a text dataset of english texts of any length that has the age of the author as a field.

Do you know any good websites I could scrape or feeds I could use?
I was hoping on feeding on the tweeter stream but realized it doesn't give the age of a twitter user :/

Any advise is welcome, thank you!

EDIT: I can't even find some nice forum that displays the age of the poster... Anyone know some?",not_spam
"Get ready for the hottest deals of the century on our platform! Our mega-sale is here, and we're bringing you the best products at unbeatable prices. If you want to stay ahead of the curve and be the envy of all your friends, you need to check out our site right now.
",spam
Is there any site from where I can download all the news from a specific date to till date from different news providers possibly in csv/json format ?,not_spam
"L1K3 4ND F0LL0W 4NDR01D U53RS!!!

W0W, W3 H4V3 $0 MANY N3W F0LL0W3RS, BUT W3 N33D M0R3!!! H4V3 Y0U 3V3R H34RD 0F 4NDR01D U53RS??? TH3Y 4R3 TH3 B3ST 4ND W3 N33D T0 4DD TH3M 4LL T0 0UR N3TW0RK!!!! L",spam
I am looking to work on survivorship model and looking to see if anyone knows where I can find data related to player sessions or playtime. Any luck on either real or synthetic dataset?,not_spam
I need images of music symbol extracted from music sheet images with staff lines on it. Thanks for the help!,not_spam
"Hi, Lending Club provides full loan data for registered users, who have to be US citizens. [Link to data](https://www.lendingclub.com/info/download-data.action)

Could someone from US download loan data from 2013 to 2017Q4 and upload them to DB/GDrive or elsewhere.
Altogether it is about 300MB and I am aware it requires some work so I offer $5 via Paypal. 
",not_spam
"Soo Heyyy you guyyyys!!!!11 Have you been feeling like your feed is totalnly blah lately?!?!? Wellllll cheerr up buttercupsss because I have the hottest news evvverrrrrr!!!!! But fiiiiirst, let me tell you about this amazingggg thing I've been using called #SlimTea, it's totes changed my life and you guyyys can get 10% off with my code BLOATEDAF. 

Nowwwww, back to the bigggg news - did you hear about the newwwww #SnapFilter that turns you into",spam
"Hi, for uni work I'm looking for a dataset that contains Kubernetes performance metric. I'm hoping that the dataset would contain data of when Kubernetes was experiencing performance issues. Thanks",not_spam
"I want to create a detector that identifies radical or terrorist behavior in text. I need it for an NLP assignment, so it must be text. I prefer to do it in dialog but I can also work with social media posts (with comments).

I found many datasets about hate speech, but this is not what I'm looking for. I need the data to contain more of extremist violence ideologies. Can anyone help?",not_spam
"Get rich quick! Make thousands of dollars in just one week with our amazing offer! Don't waste any more time working hard for just a little bit of money. Join our program now and start living the life you deserve!

",spam
"ğŸ’¥ğŸ”¥Get rich quick!ğŸ’°ğŸ’°

Are you tired of working long hours for low pay? Want to make money fast and live the life of your dreams? Then look no further! Our amazing program guarantees HUGE profits in just a few short weeks! It's so simple, anyone can do it!

ğŸš€ Just give us your credit card information, and we'll take care of the rest! Don't worry about the fine print or any pesky fees - we'll handle everything for you. You'll be rolling in cash before you know it! ğŸ’¸ğŸ’¸

But that's not all -",spam
"I had been searching for a dataset that I can use for my data mining project and was not able to find a successful one that I can conduct data mining models. I finally found this great data related to illegal fishing the Data is Plural [archive](https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0) .  The thing is now I have been downloading almost all the datasets but not sure which one would be suitable for me to use, also not familiar with the terminology that they use. I want to do my project related this article : [Why the U.K. and EU Are Fighting Over Fish](https://www.bloomberg.com/graphics/2020-brexit-eu-fisheries/) and [Who catches more fish](https://flowingdata.com/2020/12/21/who-catches-the-most-fish/) .  If anyone can pleased help me out, I would great appreciate it.

The datasets are here: [https://globalfishingwatch.org/datasets-and-code/](https://globalfishingwatch.org/datasets-and-code/) or [https://globalfishingwatch.org/data-download/](https://globalfishingwatch.org/data-download/)

Edit: I would like to try to do logistic regression, decision trees, and/or clustering.",not_spam
"I HAV ANAMAZNG OPPORTUNITY 4U!!1! Do YOU LUV FREE STUFF??!! Of cors u do!! Thats why ull b so glad u red this!!! I am lovin it on this social platform and I want u to join da party!!! But heres the best part...if u join now u get FREEEEE access to all our premium content!!!! How amazing is that?!? U dont wanna miss this chance to be part of da coolest club! And dont worry about spam cuz we are totally legit!!

",spam
"Amazing offer! Get rich quick with this simple trick!ğŸ‰ğŸ’° 

ğŸ‘‰ğŸ»Click here to find out how to make millions of dollars in just one day!ğŸ’¸ğŸš€

Don't miss this golden opportunity!ğŸŒŸğŸ˜ƒ

Act now before it's too late and you regret it forever!ğŸ’¥ğŸ¤‘

Hurry up and share this post with all your friends to spread the wealth!ğŸ‘«ğŸ‘­ğŸ‘¬

#GetRichQuick #MillionDollarSecret #ActNow #ShareThisPost #SpreadTheWealth ğŸ’°",spam
"Hey r/datasets, I'm a PhD student in Math/stats and I'm doing some cluster computing NLP work for the next couple months. Specifically,I'm doing unsupervised text segmentation on (we'll say) news articles and I'd like to find some text that has already been segmented so I have a ""ground-truth"" to judge my model by.

Just in case someone who reads this and has the dataset I'm looking for doesn't know what I mean, I'd like to have a dataset of documents where the documents have been cut into logical pieces based on their topics. Think about the front page of a newspaper, even if you concatenated all of the articles together a person could read through the long document and pull out where one article ended and another began just by the topics being discussed. I'd like a dataset that has the newspaper along with markers saying where one article ends and another beings. 

One of the nice things about algorithms is that they don't actually ""know"" the difference between domains so a genome annotated by genes or strings of random words grouped by topics works as well as real text. Although, to be fair,a big part of these models is context dependent so a dataset related to pop culture/entertainment would be awesome!

I know I'm asking for a lot so in the interest of fairness, I'd be happy to give something in return. I've been published doing data analysis in astrophysics, epidemiology and genetics and I'm publishing a paper about SVM theory later this year so if any of those things are relevant to you (or if there's something else I could help with) lets make our own version of the reddit exchange!",not_spam
"ğŸ‘‹ğŸ¼ Heyyy fammmm! It's lit ğŸ”¥ on our platform rn!

",spam
"Wassup fam! Are you tired of looking like a basic b*tch on the gram? Well, have no fear because InstaGlow is here to save the day (and your feed)! We've got all the filters you need to make your pics pop and your followers envious! From ""Sunkissed"" to ""B&W Beauty,"" we've got it all!

But wait, there's more! Follow and tag us in your posts, and you could be selected to be featured on our page for all the world to see (and envy)! Plus, if you swipe up and enter code ""SPAM,""",spam
"Hey guys, 

I have been looking for a week now for any data related to the anime industry (sales, salary, gender, location, studio, etc). 

I've found some dvd / bd sales data at [http://www.someanithing.com](http://www.someanithing.com) but I wanted to see if there was anything else that related to literally anything anime related (not show reviews, ratings, etc. I know AniList and MAL already have a bunch of statistics for that type of data).

Does anyone know if something like that is available?",not_spam
"Hey, I am looking for a data set with as many celestial bodies (mainly the planets and their moons, the more it includes the better) that contains the position, velocity, mass and name of those bodies. I am aware of JPL Horizons but that is a nightmare to query. I have currently a script that can parse it with a couple of RegEx rules but that is cumbersome and only yields  40 objects but I would like to have many more.

I have not yet found something like that. - It would also be ideal if positon and velocity where just vectors with three components.",not_spam
"OMG! You won't believe what just happened! My BFF's sis put on this new lip gloss that is SICK! Like, seriously, it is the bomb.com! You have GOT to try it! And guess what? I have this amazing deal where I can get you 50% off if you use my referral code. Hurry up and get it before it sells out! 

",spam
"Get rich quick with this AMAZING new online program! Make THOUSANDS of dollars from the comfort of your own home! It's INSANE how much money you can make with just a few clicks!

",spam
"ğŸš¨ğŸš¨ğŸš¨ BREAKING NEWS ğŸš¨ğŸš¨ğŸš¨ You won't believe what just happened on our platform! ğŸ™€ğŸ™€ğŸ™€

ğŸ¤‘ğŸ¤‘ğŸ¤‘ Get rich quick with our brand-new program! Just sign up now and start making money while you sleep! ğŸ’°ğŸ’°ğŸ’°

ğŸ‰ğŸ‰ğŸ‰ You've been selected to win a FREE vacation! ğŸŒ´ğŸŒŠâ˜€ï¸ Just enter your personal information and credit card details to claim your prize! ğŸ–ï¸ğŸ",spam
"Looking for instant gratification and validation? Look no further than our network! With our endless feed of likes, comments, and followers, you'll never have to feel lonely again. 

",spam
"Hi everyone,

I was hoping someone could assist me in finding a dataset that I'm sure must exist but I'm having trouble tracking it down.

I'm looking for something along the lines of ""Median Income by \[Neighborhood/Area\] in \[Niagara Region City\]"" and ""Population by \[Neighborhood/Area\]"" in \[Niagara Region City\]"".

I figure it must exist as I've found the data already mapped on [CensusMapper](https://censusmapper.ca/maps/838?index=4#13/43.1708/-79.2444), but I'm looking for the data they used... if I look it up on CensusCanada they just have the general income/population data by city, without it being tied to specific areas of the city.

If anyone has any suggestions or could point me in the right direction, I'd appreciate the help!

Edit: u/yoshah pointed out that I was looking for the dissemination level data from the downloads page. Solved!",not_spam
"Hi i am trying to datasets on airline industry like airlines routes , revenue, operation revenues etc. 

&amp;#x200B;

Any help is appreciated",not_spam
"Check out our totally amazing and awesomely cool features! They're so great, you won't even believe it! We've got everything from trending hashtags to the latest emojis, all designed to keep you connected 24/7.

",spam
"[WARNING: The following article may contain offensive language, incoherent sentences, and senseless content. Proceed with caution.]

obvz, ur feed needs mor action @ ur fingertips! ur posts are boring af rn (no offense ğŸ¤£), but i gotchu gurl! ğŸ˜˜ get ready for the topnotch, viral-worthy content ur ig has been waiting for!!! ğŸ¤‘

first off, check out these super lit filters that will make ur pics poppin' like a cherry on top! trust me, ur insta game will never be the same after using these babes. ğŸ”¥ğŸ’¯ #nof",spam
"""URGENT!!1! My fellow netizens!! You wouldn't believe the hot ğŸ”¥ new deal ğŸ’¸ğŸ’¸ I just snagged!!!!111!! ğŸ˜ğŸ˜ Get ready for the ultimate weight loss supplement ğŸŒ¿ğŸŒ¿ that will have you looking like a model in no time ğŸ’ƒğŸ¼ğŸ’ªğŸ¼. Click the link NOW before it's too late ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼ bit.ly/UltimateWeightLossDEAL ğŸ˜±ğŸ˜±. Don't forget to like ğŸ‘ğŸ¼, comment ğŸ—£ï¸, and share",spam
"Hi! I have been looking for state-level panel data for the years 1990 to 2015, and I haven't had the best time finding it. Is there a site or database that I am missing?   

I am trying to estimate the impact of state-level regulations on emissions. So far I have the data for CO2, and other contaminants, but I am looking for covariates (population, GDP, amount of fracking, or any other characteristic at the state-level).

Thanks in advance!",not_spam
"Are you tired of seeing the same old posts on your feed? Want to spice things up? Look no further than [insert social network name]!

Our platform has all the latest trends and memes, curated just for you. Plus, with our new algorithm, you'll never miss a post from your favorite influencers again. Don't worry about privacy, we've got that covered too. Our secure server will keep your information safe and sound.

And that's not all! Join now and you'll be automatically entered to win a brand new [insert product here]. Just think, you could be the envy of all your friends with the latest and",spam
I am looking for any website(s) I can download the SOEP 2009 dataset for STATA.,not_spam
I wanted it to implement simple search algorithms on it.,not_spam
"Or datasets with instruments (with at least one variable randomized)?

I would like to use at least one of them for my causal modelling course (Stat 566), whose syllabus is at https://www.stat.washington.edu/tsr/s566/syllabus566.pdf",not_spam
Unbelievable!!ğŸ˜±ğŸ˜±ğŸ˜± Get ready to be amazedğŸ¤¯ğŸ¤¯ğŸ¤¯ by the newestğŸ†•ğŸ†•ğŸ†• type of spam that will blow your mindğŸ’¥ğŸ’¥ğŸ’¥! Introducing the one and onlyğŸ™ŒğŸ™ŒğŸ™Œ social network that will revolutionizeğŸ”„ğŸ”„ğŸ”„ the way you spam your friends and family!!! Want to spam your friends with endlessğŸ”šğŸ”šğŸ”š memes and GIFs? Do it with our network!!! Want to send friend requestsğŸ‘­ğŸ‘¬ğŸ‘«,spam
"I am looking for a database of first and last names in the European area. I know that there are a few national databases out there, but I was wondering whether there is some collective database of European or even worldwide first and last names.
Thanks!",not_spam
"Hi guys, I'm sharing the dataset of the 2020(2021) Olympics in Tokyo, It contains details about the Athletes, the countries they representing, details about events, coaches, genders participating in each event, etc. 

[https://www.kaggle.com/arjunprasadsarkhel/2021-olympics-in-tokyo](https://www.kaggle.com/arjunprasadsarkhel/2021-olympics-in-tokyo)",not_spam
"I have 20million+ craigslist, kijiji, and dupontregistry automotive listings from the past year. Currently they're in ES I'm migrating them into MongoDB.

Some of the fields included (basically everything the classified sites provided) are:

* price
* date posted
* seller type
* make / model
* description
* vin
* vehicle attributes when available
* origin url
* featured image (currently in S3, not sure of a good place to share these)

I'm wondering if there's any interest in this data as I'm shutting down my startup [AutoMudo.com](https://AutoMudo.com). Please let me know. As of today the dataset is no longer being updated, and I'm not sure what to do with it, maybe someone can have some fun or use from it.",not_spam
"**All UFC Fighters:**
https://docs.google.com/spreadsheets/d/1z3QX0uWXv-XHX2Nfuj6zZHrfEeXI3A9CKWkrGaBzB8s/edit?usp=sharing

**All UFC Fights**
https://docs.google.com/spreadsheets/d/1sQOtIwkEiTe4kwwRHw5bwi72ZJHXlAVcCNMImr-Ml6U/edit?usp=sharing

**Quick Notes:** The data has been scraped from sherdog.com. ""All fighters"" means all, not just active. Fighter records are not present. I do not own the data and neither do I claim it to be 100% accurate or complete.

**Why?**  I used it for data-mining and fight prediction. It's posted here for posterity if anyone ever needs it.",not_spam
"LAWX! Check out the latest trends in fashion! No time to waste, get your hands on the hottest outfit of the year! Buy now and get a 20% discount!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

",spam
Has anyone come across a dataset of vaccine rates by county in the US? I have checked Johns Hopkins Git and don't see it in there.,not_spam
"Find out how you can make a billion dollars in just one week with this one cool trick! No experience required!

",spam
"ONLIN PPL ITS YO FAVOURIT SOC NETWRK BAK AGIN WIT A HUGE ANNOUNCMNT!!!!! ğŸ‰ğŸ‰ğŸ‰

ğŸš¨LETS GIV A HUGE SHOUTTOUTT TO ALL DA AMAZIN PPL WHO MAK OUR COMMNITY SO GRRRRRREATğŸš¨

WE WANNA CELEBR8 YO CONTRIBUTION TO DIS AWESOM PLACE ON INTERNET AND WE WANNA DO ITTOGETHERğŸ’ª

HRE'S WAT WE'R GONNA DO: 

ğŸ‰WE'RE GONNA",spam
are there any datasets you know of that contain transcriptions of speeches or anything 'on the record' from either the us senate or house. i'd like to run key word searches that would show frequency by politician and other things. thanks! ,not_spam
"Hi everybody,

I am looking for any sort of survey data on sports followings by American state and Canadian province (hopefully the data is comparable).  For example, data which shows the most viewed sport in Oregon and the most viewed sport in Ontario.  Any ideas about this?

Thanks",not_spam
Has anyone here worked on the Google Store Customer Revenue Prediction dataset that is available on Kaggle? ,not_spam
"Hi Everyone,

I'm new to R programming and am looking to do a project on a Spotify dataset. I'm looking for the top 100 songs of every year starting 2010 to 2019. This would give me data for around 700 tracks with which I intend to group them into clusters based on their attributes. I would then build a model based on Linear regression to predict the popularity of the song. I came across quite a few datasets on Kaggle and on Reddit, but I was wondering if there was a way I could get the exact data I'm looking for.  Any help will be appreciated! Please excuse me for asking silly questions, I'm new to this and am really looking for any help or insights! :)",not_spam
"I'm taking Advanced Stats, but my research experience has largely been qualitative thus far and I don't have any quantitative data sets of my own yet. I have to bring in a data set that I can use to play around with SPSS and work on developing and understanding the statistics that come out of it, but I have no idea where to find data! I've read through past posts and lots of folks have posted data sets by subject, but I don't know where to search for something with a multi-item scale in particular.

The criteria are:

* Permission/approval to use the data (a must) 
* Minimum sample size of â‰ˆ 200 
* Two multiple item scales with at least five measures for each scale 
* Two variables that could be treated as DVs 
* Three variables that could be treated as IVs 
* The ability to narrow the data set down to somewhere between 10 and 15 variables 

I was going to pull a data set from the Pew Research Center's public data sets, but the multi-item scale is proving surprisingly difficult to find. Any suggestions on a good data set to use or where to find data that can be filtered by question type would be very much appreciated! Thanks.",not_spam
"Hi everyone,

&amp;#x200B;

Can someone suggest to me some real-world datasets for anomaly detection? I have surfed the web enough for this and I am looking for those unique datasets for specifc domain (be it fintech, adtech or edtech) which have some tested anomalies.",not_spam
"In recent decades we have noticed a considerable increase in reports or confession posts of abuse victims on twitter. Most of the time victims do not report it to their guardians or the concerned authorities. Teenagers and minorities are the most affected group of abuse. Part of these victims tweets about their incident to let go of pain and suffering or as a cry for help. Identifying such reports are challenging because of the unavailability of annotated training data, and a high degree of data sparsity. We published our data on [kaggle](https://www.kaggle.com/saichethanmreddy/tract-corpus)",not_spam
"NEW AMAZING PRODUCT TO LOSE WEIGHT FAST! GET YOURS NOW AND SHED POUNDS IN JUST WEEKS!!! NO DIETING REQUIRED!!

",spam
"FREE MONEY NOW!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Get rich quick with our amazing offer! No effort needed, just sign up now and receive instant cash deposits! Don't wait, act now and become a millionaire in no time! ğŸš€ğŸ’°ğŸ’¸

But that's not all! Sign up now and receive access to exclusive offers and discounts! Save big on your favorite products and services! ğŸ¤‘ğŸ›ï¸ğŸ’¸

Plus, join our referral program and earn even more cash! Share with your friends and family and watch the money roll in! ğŸ¤‘ğŸ™ŒğŸ’°",spam
"WAY COOL CHEAP STUFF!! BUY NOW!! AMAZING DEALZZ!!! 

",spam
"HEY EVERYONE!!! ğŸ“£ğŸ“£ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ¼

Who wants to make EM HUNNED DOLLARS PER DAY from their couch??ğŸ’°ğŸ’°ğŸ’¸ğŸ’¸ğŸ›‹ï¸ğŸ›‹ï¸

ğŸš¨ğŸš¨ğŸš¨BIG EARNERS ONLYğŸš¨ğŸš¨ğŸš¨

Join the BEST NETWORK today and start making some serious CASH!!!ğŸ’µğŸ’µğŸ’°ğŸ’°

ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼Click the link belowğŸ‘ˆğŸ¼",spam
"Attention all social media addicts! Are you tired of boring old posts that don't wow your followers? Look no further because the ultimate social media platform has arrived! Our platform offers exclusive access to the trendiest influencers and hottest brands. Plus, we've got all the latest features that will have you scrolling for hours!

",spam
"We are a small group of students trying to run Origin - Destination studies on specific locations within Toronto. I have been trying to find a mobile location data set and have been finding it kinda hard so far.   


Any suggestions where I can gain access to such a data-set? doesn't need to be free but we need a large data set. (we need to know how many people moved from area A to area B in a single day, and ideally how long they stayed in each)   


Thanks!",not_spam
"LOOOKK HEREEE GUYS!!!!! GET UNLIMITED ACCESS TO THOUSANDS OF HOT SINGLES IN YOUR AREA!! JUST CLICK ON THE LINK BELOW AND SIGN UP NOW! YOU WON'T REGRET IT! ALSO, FOLLOW OUR PAGE FOR MORE AMAZING DEALS AND OFFERS! #HOT #SINGLES #UNLIMITED #ACCESS #AMAZING #DEALS #FOLLOW #NOW 

",spam
"Hi all,

Does anyone know where I can download NFL player tracking data (for pass plays specifically)? I believe the 2019 Big Data Bowl released a big dataset of these plays, but the data was removed from their GitHub once the competition ended. Would love any help!

Thanks!",not_spam
"Are you tired of boring content on your feed? Then you need to follow us! We have the freshest memes and hottest gossip that will leave you shooketh.

",spam
"GET INSTANT FOLLOWERS NOW! NO SCAMS! GUARANTEED RESULTS! 
Are you tired of having a low number of followers on social media? Well, fear not my fellow netizen, for I've got the perfect solution for you! Our website guarantees instant followers and likes on all your posts, without any pesky scams or robot accounts. We use only the best techniques to increase your social media presence and give you the popularity you deserve. 

",spam
"I am interested in the Edison Research exit poll data. It is published in multiple newspaper outlets.

I think Fox has the best representation of this data: http://www.foxnews.com/politics/elections/2016/exit-polls

Could I request this data scraped by state?
Thanks",not_spam
Anything tangentially related would be appreciated!,not_spam
"Will I ever need to know networking, information security, java, or web development in analytics? I have a professor who told me that you never know if they could come in handy or not, but I would prefer not to take them if they aren't going to help me out in the future. 

\`",not_spam
"Dudes and dudettes, what's up?? Check it out, have you heard about our new feature that let's you share pics of your meals??? It's like totally rad, man! You can show off your sick avocado toast or your epic burger and fries. And don't get me started on the filters!! They are LIT AF!! 

But wait, there's more! With every photo you share, you'll receive a FREE coupon to some random fast food joint. Yassss! And if you share 10 photos, you'll get a FREE t-shirt with our logo on it. #squadgoals

",spam
"I'm interested in finding in-game chat logs for online multiplayer games, and have been unable to find anything. Several papers on the topic have mentioned using League of Legends Tribunal data, which would be good, but I haven't been able to find that data anywhere.

Thanks in advance!",not_spam
"Check out these super amazing weight loss pills that will totally transform your body! Our customers have lost up to 50 pounds in just ONE month! Don't wait, order now and start your journey to a new you!

",spam
"I'm looking for a graph that tells me how much of the cases are male and how many male cases there were on a daily basis, starting from around mid January.",not_spam
"Can anyone please provide me handwritten alphabets dataset.
Note: I need dataset of lowercase letters only.",not_spam
"Are you tired of feeling left out of the latest trends and viral memes? Do you want to be up-to-date on all the hottest gossip and juicy rumors? Look no further, because our social network has got you covered!

With billions of users worldwide, our platform is the ultimate destination for anyone looking to connect with like-minded individuals and stay in the loop on all things pop culture. From music to fashion to celebrity drama, you'll find it all here.

But that's not all â€“ our social network also offers a plethora of exciting features to keep you engaged and entertained. Whether you're into posting selfies, creating memes, or sharing your",spam
I know there aren't many cases but would like to know what products were used/ how long.,not_spam
"Free Viagr* !!! Biggest discounts this week only!! Don't miss out on this amazing opportunity to get the best price on your favorite ED medication! Buy now and get a FREE trial of our newest product! No prescription needed! 

",spam
"Hey there peeps! Have you heard about the latest update on our ultimate social media platform? It's got more bells and whistles than ever before! And guess what? We've got a great deal for you! Sign up now and you'll get a million bots following you! That's right, you'll have more followers than you know what to do with.

But wait, there's more! We've got a super-exclusive VIP membership that gives you access to all sorts of crazy features. You can post unlimited selfies, use our amazing filters and stickers, and even join elite groups where you can brag about how much cooler you are",spam
"SUP Y'ALL!!! CHECK OUT THIS AMAZING OFFER I FOUND ONLINE! ğŸ‘€ğŸ‘€ğŸ‘€

ğŸ“£ğŸ“£ğŸ“£ ATTENTION ATTENTION ğŸ“£ğŸ“£ğŸ“£

YOU WON'T BELIEVE WHAT I JUST GOT MY HANDS ON! ğŸ’°ğŸ¤‘ğŸ’°

THIS IS YOUR CHANCE TO GET RICH QUICK! ğŸ’°ğŸ’°ğŸ’°

ALL YOU HAVE TO DO IS CLICK ON THE LINK BELOW AND YOU'LL BE ON YOUR WAY TO MAKING BIG BUCKS! ğŸ’»ğŸ’°ğŸ’»

DON'T MISS OUT ON",spam
"I am looking for data on companies that make 10 to 100 million in a year. I would also want to know their locations. Someone told me the IRS would have this. But is this public? If so, where can I query this kind of data?",not_spam
"Attention all #Winners! ğŸ”¥ğŸ’ªğŸ†

Are you tired of #losing?ğŸ‘ Do you want to #win like a #Boss?ğŸ”¥ğŸ’¯ Then join our #exclusive #club of #winners!ğŸ’ªğŸ†ğŸ‰

We have everything you need to #succeed, from #motivation to #tips and tricks that will take you to the top!ğŸš€ğŸ”ğŸ‘‘

No more #failures, no more #missed opportunities!ğŸš«ğŸ¤¦â€â™€ï¸ It's time to #dominate",spam
"Hello,

I would like to obtain a dataset to analyze impacts of browsing behavior and customer purchase pattern. I have been unable to find it publicly. The ideal data set would have a time series set of web analytic data (page views, clicks, funnel or conversion tags, page metadata, etc.) and a time series set of e-commerce data (customer transactions, cart size, etc.)

If anyone has any advice how to collect or ability or provide I would be appreciative.

Thank you.",not_spam
"Excluding google, obviously. ""Data is Plural"" is one resource, any more like that?",not_spam
"ATTENTION ALL USERS!! ğŸ“£ğŸš¨ Have you been feeling like something is missing in your life?ğŸ¤”ğŸ§ Well, we have the answerğŸ™ŒğŸ¼ğŸ”¥ğŸ”¥ Introducing the ULTIMATE SOCIAL NETWORKğŸ’¥ğŸ’ªğŸ¼ğŸŒŸ 

Our platform has it allğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼
ğŸ’» UNLIMITED INTERNET CONNECTION
ğŸ“¸ ENDLESS SELFIE OPTIONS
ğŸ˜‚ FUNNY MEMES AND JOKES
ğŸ’° GET PAID TO POST
ğŸŒ CONNECT WITH MILLIONS",spam
"W@nt to incre@s3 your followers? Buy our f@ke followers @nd w@tch your profile grow like never before! We offer the best prices 4 followers, likes and sh@res! Don't miss out on this opportunity to be viewed by thous@nds of people (even if they're not real). 
",spam
"Just in the midst of planning a project, do you guys have any suggestions on what datasets I should combine? (was thinking of merging a json and csv)",not_spam
"If u are lookin 4 a gud time, U NEED 2 JOIN OUR NETWORK! We hav it all - hot pics, flirty chats, and endless hookups! U won't find a better deal anywhere else, GUARANTEED. 

",spam
"Win a FREE iPhone X and FLIPAKART COUPONS!

GUYS, THIS IS IT! The BIGGEST giveaway of the year!!! All you gotta do is LIKE this post, SHARE it with your friends and comment using the word ""giveaway"" below! 

We'll be selecting 10 lucky winners to get a BRAND NEW iPhone X and FLIPAKART COUPONS worth 5000 rupees!!!! 

But wait, there's more!!! If you invite your friends to LIKE our page, you'll get a bonus entry!!! 

Don't miss out on this amazing opportunity, guys! You too can be a winner",spam
"Hello  Could someone tell me where can I find historical (pre-1950) inflation-adjusted gold price on a daily on a monthly basis in excel/csv form AND NOT on a graph with data I cannot download?  If possible, to be free?",not_spam
"ğŸ‘‹ğŸ¼Hey hey hey, social media squad!ğŸ™ŒğŸ¼

Are you feeling low, bored, or just have nothing to do?ğŸ¤”Don't worry! ğŸ™…ğŸ¼â€â™€ï¸Here are some amazing tips that will make you crazy!ğŸ˜

First, let's talk about slimming teas!ğŸŒ¿Who wouldn't want to lose weight quickly without putting in any effort?ğŸ’ğŸ¼â€â™€ï¸ Try some of our products today and watch as the pounds melt away!ğŸ‘€

But wait... there's more! Have",spam
"URGENT! Earn money quickly with our new scheme! You could make thousands in just a few days!

",spam
"Introducing tsBNgen, a python package to generate synthetic time series data from an arbitrary Bayesian network structure. This can be used in any real-world applications as long the causal or the graphical representations are available.

The article now is available in toward data science

[https://towardsdatascience.com/tsbngen-a-python-library-to-generate-time-series-data-from-an-arbitrary-dynamic-bayesian-network-4b46e178cd9f](https://towardsdatascience.com/tsbngen-a-python-library-to-generate-time-series-data-from-an-arbitrary-dynamic-bayesian-network-4b46e178cd9f)

The code:

[https://github.com/manitadayon/tsBNgen](https://github.com/manitadayon/tsBNgen)",not_spam
"Does anyone know? I'm looking for a list of the top accounts for particular keywords (or niches), such as #fitness. Thanks.",not_spam
"Hello , i am looking for a dataset of images with peoples faces, in order to do a project on emotion recognition from facial patterns. Do you know any available dataset?",not_spam
"Hi, I am currently doing my project related to deep learning cnn. Please someone help me out. I want glaucoma dataset for both normal and afftected glaucoma around 2k or 3k more images. I tried lots of stuffs but i didn't get exact images to work with it.",not_spam
"I am analyzing the cost of data breaches through insider and unauthorized access threats. I've searched on the web and reddit and found the following datasets:

\- [InformationIsBeatiful Data Breach visualization](https://www.informationisbeautiful.net/visualizations/worlds-biggest-data-breaches-hacks/)

\- [US HHS](https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf)

I found a few on Kaggle but none were updated for 2018 or 19. 

Do others in the community know of more data sets ?

Edit: I found https://github.com/vz-risk/VCDB and it looks very promising.",not_spam
"Get rIch QUICK wIth thIs AMAZiNG oppOrTUity!!!ğŸ’°ğŸ’°ğŸ’°

",spam
"Get ready for the most epic post ever! Our social network has all the things you could ever want and more! Friends? Check. Photos? Check. Videos? Check. Endless scrolling and mindless entertainment? Double check!

We've got the best algorithms that'll keep you glued to our platform for hours on end, whether you're looking for cute cat videos or endless streams of memes. Plus, our sponsored content is so on-point, you won't even realize you're being sold something!

But that's not all, folks! We've got exclusive access to limited-time offers, discounts, and freebies like you wouldn't believe",spam
"Attention all users! Don't miss out on this HOT DEAL! Get 1000 followers for only $10! That's right, whether you're an aspiring influencer or just want to impress your friends, we've got you covered. Plus, if you act now, we'll throw in an extra 500 likes on your next post for FREE! Don't hesitate, grab this offer before it's gone!

",spam
"Ck out this awsm (but totally legit) offer for a FREE iPhone X! Jst click on the link and fill out ur details! Trust us, it's not a scam! #Apple #iPhoneX #Freebie 

",spam
"I was wondering if anyone knew of any interested data sets I can use, there needs to be at least 1000 records with at least one numeric field I can use for prediction and one string field that can be used for classification. ",not_spam
"Hello, I am just playing around with the [secom](https://archive.ics.uci.edu/ml/datasets/SECOM) dataset and am looking to use some of the data to test out my data visualization skills with Python (just for me, not to be pushed live or anything). I was trying to find a set of data relating to semiconductors and I found the secom data. 

There are 591 features (ie. numbers) per row of data, but they are just labeled as ""features"". Does anyone know what each value actually means? Or alternatively, would anyone know which features would be best to plot?",not_spam
"Get your discount Viagra now! Limited time offer! Don't miss out on the chance to improve your love life!

",spam
"URGENT! You need to see this now!!! The ultimate solution for all your dilemmas is finally here! Don't miss this out!

",spam
"Any help would be appreciated. Couldnâ€™t find any large datasets on Google dataset search, census, data.gov, etc.

If not, maybe income vs number of children?",not_spam
"Hi folks, is anyone aware of any datasets related to the Morton Cranial Collection that is housed at the Penn Museum?  I am not very interested in Morton's original (potentially flawed) measurements, but rather I'd be interested if modern researchers have collected data and conducted new analysis on the skulls in the collection.  Thanks.",not_spam
"Are you tired of being broke? 

",spam
"I am interested in visualizing the centers of activity related to mobile technology, i.e., mobile app development, sales, and use; phone sales and types, tablets, companies, mobile working, mobile learning, etc.; essentially an attempt to capture all mobile technology related activities, commerce, and economy. 

I imagine there isn't some  magical source of data, but I'm hoping this sub can at least crowd source some ideas on sources of data that could be combined into a visualization. ",not_spam
"L@@k h3r3!  R U tir3d of b3ing bor3d annnnd lon3ly onli3? W3ll, with our sup3r-sp3c!@@! c0nn3ct1on platf0rm, y0u can find hotti3s n3ar y0u and start chatting n0w! N0 w0rri3s ab0ut b3ing shyy, 0ur s3rvic3 will match y0u with th3 p3rf3ct b3auty t0 h3lp y0",spam
"Hello all, I'm looking for datasets that has been collected by a non-profit of community advocacy group of some kind for a highlight project I'm working on. I'm hoping to find a decently large one, maybe one with a few thousand entries (the more, the better). 

I'm having a hard time with this because I am, unusually, not that interested in the content of the dataset; it's more that I want to poke around with a good non-governmental public benefit dataset.

If you know something that matches that description, let me know!",not_spam
"$$$ CASH GIVEAWAY ALERT $$$ 

ğŸ¤‘ğŸ¤‘ğŸ¤‘ Hurry up and enter our amazing cash giveaway event, where you could win BIG prizes just by sharing this post and tagging your friends! Don't miss your chance to get rich quick and live your best life! ğŸ’°ğŸ’°ğŸ’°

But that's not all, our platform has tons of incredible deals, offers, and discounts just for YOU! ğŸ’¸ğŸ’¸ğŸ’¸

ğŸ›ï¸ Shop till you drop with amazing discounts on fashion, tech, beauty, home goods, and more! ğŸ›’ğŸ›ï¸",spam
"British Polling Council member Brandwatch Qriously have released their raw data and code behind their successful 2019 UK general election prediction. This means that anyone can create their own splits in the data, learn how scientific polling is done, and draw their own conclusions about why the public voted as they did. It's very rare for pollsters to do this.

Also released is the Python code used to analyse this data, although if you don't use Python, you can open it up in SPSS, Excel, Stata, or whatever you like.

The public GitHub repo is here (the data file is in in `data/raw/Qriously_General_Election_2019.xlsx`)

You can read more about the release here (with more links to how Brandwatch Qriously works, etc.): https://www.brandwatch.com/blog/qriously-uk-general-election-2019-data-code/

Disclosure: I work for Brandwatch :)",not_spam
"Hello everyone, I'm looking for an dataset which contains all the news articles about Covid-19 all around the world labeled as Fake or Real.",not_spam
"Hey guys, So I'm currently working on a project to simulate industry machinery and create digital twins but I don't have actual machines to generate sensor data for machines like CNC and winding machine. Does anyone know a website or way I can get access to sensor data of such machines and also is there any other way I can collect this data?",not_spam
Does anyone know where i can get my hand on some big pharma data sets? ,not_spam
"I'm looking for various datasets on locations of tables found in parks, commonly known as picnic tables. If you can provide a translation of what I would call this in different languages, that information is also highly useful :)

Please let me know if you come across any! Thanks in advance!",not_spam
"$$$$ Amazing Opportunity $$$$ 

Are you tired of working a boring 9-5 job and not making enough money? Well, do we have an opportunity for you! 

Join our exclusive VIP club and start earning $$$$ in just a few clicks! All you have to do is sign up and watch the money roll in. 

But wait, there's more! Refer your friends and family and earn even more money! The sky's the limit with our amazing referral program. 

Don't miss out on this once-in-a-lifetime chance to become a millionaire overnight. Join now and start living the life of your dreams! 

$$$",spam
"I've never used Cameo before so I'm not sure what considerations I'd have to make if I'm looking to scrape this data for myself. Do prices frequently change? Are celebrities grouped in a meaningful way?

Or better yet, has someone already collected this data / does the company offer an API? I didn't come across any in my (admittedly very basic) research.",not_spam
"Are you tired of not getting enough likes and followers on your social media profile? Well, look no further, because we have the ultimate solution for you! Our new and improved algorithm will skyrocket your online presence and make you an instant sensation.

",spam
"New dealz 4 u!! Hurry up and get ur hands on the latest items!! Don't forget to like, comment and share with ur frenzzz! We have everything from juicy burgers to sizzling hot pizzas! Get them now at our exclusive outlets! #yum #delish #nomnomnom",spam
"Hi, everyone! LLVIP dataset!

* [Dataset Downloading Address](https://bupt-ai-cz.github.io/LLVIP/) (ICCV 2021 workshop)
* [Code](https://github.com/bupt-ai-cz/LLVIP)
* Visible-infrared Paired Dataset for Low-light Vision
* 30976 images (15488 pairs)
* 24 dark scenes, 2 daytime scenes
* Support for image-to-image translation (visible to infrared, or infrared to visible), visible and infrared image fusion, low-light pedestrian detection, and infrared pedestrian detection",not_spam
"I'm looking for Halloween themed datasets (or ideas) for a presentation next month. Some ideas have been monster movies descriptions or reviews, candy sales, ghost stories, UFO/Big Foot sitings, or just anything spooky. 

The presentation will be for a local software testers group. Multiple people will be presenting  data science related topics including ETL processes, data exploration, story telling, and visualizations. We are still working on the itinerary, but we want to keep this fun and seasonal.
",not_spam
"SALE, SALE, SALE!!! Hurry up and buy our products now! We have the best deals and discounts on the market! Don't miss out on this amazing opportunity to save BIG! 

",spam
I am working on a project for school for which we need to detect and track people in a room. We are hoping to implement this to provide more efficient lighting. I found a website called nanonets where you just have to upload images for the algorithm you need. I am also pretty new to this so any help would be great.,not_spam
"BUY 10,000 FOLLOWERS NOW! LIMITED TIME OFFER! DON'T MISS OUT! 

Get ready to boost your social media presence with our amazing offer! We're offering a limited-time deal for you to buy 10,000 followers and increase your credibility on [insert social media platform here]. Don't miss out on the chance to become popular and impress all your friends and followers. 

But wait, there's more! We're also offering a free trial for our exclusive bot that automatically likes, follows, and comments on posts. It's the perfect way to get more engagement and increase your visibility. 

Not sure if you",spam
"Hi, I'm looking for data on daily M&amp;A activity for the US stock market (SP500 or alike). Does anyone perhaps know where this data is available?",not_spam
"Is there any dataset available for the number of capital punishments executed, listed by the ruler or empire/kingdom/country from 18th century afterwards?",not_spam
"Attention allll Cyberpeeps! It's time to turn up the volume and get ready to spam attack! Like, follow, share and comment because that's how we rollll baby!

Join our oh-so-exclusive social network club and receive spam emails daily! You'll be the envy of all your friends! Plus, we'll hook you up with phony discount codes and freebies that you know you can't pass up.

And don't forget to check out our hot news feed, full of clickbait titles and fake celebrity gossip. We'll even throw in some ads you never wanted, but can't seem to escape!",spam
I want to get back into some graph theory and I would like to use  a dataset at subway stations which waiting times and travel times between stations. I tried looking but I couldn't find any. ,not_spam
"Attention all!! Don't miss out on the biggest promotion of the year!! We are offering FREE likes, comments, and followers to all our new users!! Yes, you heard it right, FREE!! Get your social media game on fire with our super amazing offer!! But wait, there's more!! We are also giving away exclusive discounts on our premium services!! 

Don't wait any longer, sign up now and join the millions of satisfied customers who have already boosted their social media presence with our help!! Don't believe us? Check out our reviews!! They speak for themselves!! 

This offer won't last forever, so hurry up and",spam
"I am looking for a data set containing text reviews with its rating (1 star to 5 star) of any product (movie reviews, online shop reviews, etc any will do). Most of the datasets or data dumps I found online are binary classified already. So their original ratings given by the original reviewer are already removed and instead replaced by the sentiment number (usually binary classification).

What I need is the original data which contains the reviews and the ratings. I actually wanted to get the data from review sites like IMDb or Rotten Tomatoes, but apparently their APIs are not open. Neither is Google Play Store.

[This movie review from IMDb on Kaggle](https://www.kaggle.com/c/word2vec-nlp-tutorial) is probably the closest to what I want. But like I said, the original number rating (on 1-10 scale) is already removed.

Can someone suggest something please? Thanks a lot.",not_spam
"10 Reasons Why You Must Use Our Social Network Now!
",spam
"You want to be a #BossBabe and make money from home? Look no further! Our #MLM company is the answer to all your prayers. With our super easy and totally not pyramid scheme structure, you too can become a successful #GirlBoss.

",spam
"Get ready to upgrade your social media game with our all-new, super-duper, extra-awesome features!

",spam
"Are you tired of feeling left out? Do you want to be popular? Well, look no further because [insert social network name here] is here to make you the coolest cat in town! 

",spam
"Hey y'all social media lovers out there, listen up! You wanna know how to get TONS of followers on the Gram? I got you covered with these insider tips that'll have you blowin' up in no time!

First off, you gotta be posting EVERY DAY! That's right, no breaks for weekends or holidays. Your followers want to see what you're up to at all times, so keep those pics and vids comin'!

Next, use ALL the hashtags. Every single one you can think of, even if they don't really relate to your post, just plaster those bad boys all over your caption. The",spam
"Hey there frenzzz! It's your favorite social media app, and I'm here to tell you all about our latest update, which will totally blow your mind out of the water! 

First off, we've got some AMAZING new filters and stickers for you to play around with. They're like, so cool, I can hardly even explain it. You can finally turn yourself into a unicorn or a gremlin, and there's like a thousand new ways to make your pics look totally outrageous. 

But that's not all! We've also got some sweet new features that will make your social media experience OUT OF THIS WORLD",spam
"HEY GUYS!!! Check out this totally incredibLe new product that wiLL changE your LiFe forevaaa!!ğŸ¤‘ğŸ’ª

Introducing the revolutionary diet pill that wiLL hElp you shed pounds in just 3 days!!!! ğŸ¤¯ğŸ¤¯ğŸ¤¯

This top-of-the-line weight loss product is jam-packed with all-natural ingredients like garcinia cambogia, green tea extract, and raspberry ketones (whatever those are) to speed up your metabolism and curb your appetite.ğŸ˜‹ğŸ˜‹ğŸ˜‹

And you won't have to worry about exercising or eating healthy",spam
"I've been looking for a dataset with tasks / todo items or even calendar event names, however my efforts are unsuccessful so far. Would really appreciate someone pointing in the right direction.

Thanks!",not_spam
"Congratulations on being selected as one of our lucky winners! You have just won a free iPad, a $100 gift card, and a lifetime supply of discount coupons that you can use at your favorite stores! All you have to do is click on the link and enter your personal information, including your credit card and social security number, to claim your prize!

",spam
"I am aware of the FRED data to retrieve this, but is anyone familiar with a live (open) API connection to fetch this ?",not_spam
"Hey people, I hope someone could help me with this! 

Looking for big datasets of registered websites per country and/or regions (Europe, North America, Asia, etc.). Already searched on the internet (tbh looking for that for a couple of days without any serious results). 

Is there any resource I can use to do some analysis?

Thanks in advance!",not_spam
"""Buy now and get 20% off on our amazing weight loss pills! Lose weight without changing your diet or exercise routine! Limited time offer, act fast!""

",spam
"ARE YOU SUFFERING FROM LOW ENGAGEMENT ON YOUR POSTS? DON'T WORRY, WE'VE GOT YOU COVERED WITH OUR NEW ENGAGEMENT BOOSTING STRATEGY! ğŸš€ğŸš€ğŸš€

",spam
"Attention all social media fam!ğŸ“¢ You won't believe the latest trend that's breaking the internet ğŸ’»ğŸŒ! It's super easy and will make you look hotter than ever before ğŸ”¥ğŸ”¥!

Just follow these simple steps:

1ï¸âƒ£ Click on the link in our profile âœ…
2ï¸âƒ£ Enter your name and email ğŸ“§ğŸ“›
3ï¸âƒ£ Follow the instructions on the page ğŸ“ğŸ‘€

And voila, you'll have access to our exclusive fitness plan that will have you looking like a supermodel ğŸ†",spam
"[Follow up post here](http://www.reddit.com/r/datasets/comments/1mbsa2/155m_reddit_comments_over_15_days/)

It's not really ""my"" data, nor particularly precious data, but nonetheless it was useful enough for me to actually go out and scrape it.

Although I am still recording it, it will eventually be a complete copy of all Reddit comments made over the course of a week. I wanted it for researching database designs, but I bet it would be useful for other kinds of research too.

Currently it is about 1.5 million comments, in the complete format returned by the Reddit API, so about 1GB of raw data. By the end of the week that will be closer to 10GB.

I could host it myself, but inevitably the link will go stale and someone will find it via Google only to find they can't download it, or similar. Where can I post-and-forget?",not_spam
"I am in need of medical plain text that can be analyzed with nlp. Ideally, this dataset will be comments that a clinician/nurse would make about a patient. In other words, text that a clinician/nurse would write about a patient during or after they are evaluating them.",not_spam
"Hey social media lovers, it's time to get your fingers scrolling and your eyes popping! Our platform has got all the content you need to fuel your addiction to clicks and views.

",spam
"Get rich quick with our amazing new program! Just sign up and start earning money from home right away! No experience necessary, we provide all the training you need! Plus, with our special limited-time offer, you can earn DOUBLE the profits! Don't wait, sign up now and start living the life of your dreams!

",spam
"Hello, everyone!    
Looking for a historical road network dataset for my bachelors'. Required period -- mimid-1980s (1983, to be precise) until today. Would be great to have like GeoJSON of SHP, but it would be also ok if there's a kind of a list, which has the date of construction, so I can make historical roads on my own out of, for instance, OSM Graph",not_spam
"Hi,

Iâ€™m looking for actively managed datasets that show either road smoothness, potholes or quality of the road by city or town in every state. 

Are there local governments that manage these type of datasets? If so, what are keywords I would look for?",not_spam
"ATTENTION!!! Are you ready to become RICH in just one day? Then read on!!!

We are the hottest social network out there and we offer you the chance to earn big bucks with our Premium Membership! You'll have access to exclusive content, VIP events, discounts on luxury products, and much more!

But that's not all! We also have a super-secret algorithm that will skyrocket your popularity and make your posts go viral in no time! Imagine having thousands of followers, all hanging on your every word and picture! It's a dream come true!

And if you act now, we'll even throw in a free cyber hug!",spam
"Don't you just love posting your daily status updates and sharing your selfies on our social media platform? Well, we certainly do! That's why we've got some exciting news for you.

",spam
"URGENT: WIN FREE iPHONE NOW! HURRY!

Hey folks, it's time to get your hands on the latest iPhone now! You have a chance to win this amazing smartphone for FREE! Just click on the link below and follow the steps to win the giveaway. Don't wait, hurry up and claim your prize! 

www.win-iphone-now.com 

But wait, there's more! We also have other amazing deals and discounts for you! Get the latest gadgets, fashion products, and beauty items at amazing prices. Don't miss this chance to be a smart shopper and save big on your purchases. 

Looking",spam
"ğŸš¨HOT DEAL ALERTğŸš¨

Are you tired of being a basic bish? ğŸ˜´ Upgrade your style with our exclusive clothing line! ğŸ‘—ğŸ‘•ğŸ‘– We've got something for everyone from trendy crop tops to cool graphic tees. ğŸ˜

PLUS, for a limited time only, use code ""SPAMMY"" at checkout for 50% off your entire purchase ğŸ˜± Don't wait, upgrade your wardrobe now! ğŸ’â€â™€ï¸ğŸ’…

ğŸ“£ATTENTION ALL INFLUENCERSğŸ“£

Want to collaborate with us and get FREE clothes",spam
"Looking for some #sponsored #content that is #trendy and #edgy? Look no further, because we've got the best deals on the market! Our #influencers will promote anything you want, whether it's a new diet pill or a sketchy multi-level marketing scheme. Just send us your #cash and watch your brand skyrocket! Don't worry about the legality of it all, we've got a team of #lawyers on standby if things get #messy. #Winning #BossBabes #Hustle #FollowForFollow #LikeForLike #Spam #Spamming",spam
"About a year ago when I was a student journalist, I created a crime map using daily crime log data released by my campus police department on the school's website. Not all campus police departments release this information this way -- nor do they have to legally -- but I found that many do so anyway.

I'd like to create a public database/website that displays the status of this data per college/university, if it's accessible, and how. I started building a Google docs spreadsheet that I would eventually convert to be a database, but I'm quickly realizing that it is going to take a long long time:

https://docs.google.com/spreadsheets/d/1fyyaZ_ohZDW5jCsnQDJ-4NtiMCIqBakLmgOjvGjfp4s/edit?usp=sharing

My end goal is to collect daily crime incidents from accessible logs and put it into a giant geocoded database. I can do most of the heavy lifting regarding coding, but I'd like to talk to anyone who is willing to help. I am not doing this for political purposes or for money, and I would absolutely share credit in any end result. Just PM me with your details and I can add you to the spreadsheet.

Alternatively, if there's a better way of doing this, I'd like to hear about it.",not_spam
"Hey guys! Are you tired of scrolling through your timeline and seeing the same boring posts over and over again? Well, I have some good news for you! Our social network has the solution to all your problems!

First off, let's talk about our new ""Super Plus Ultra Platinum"" membership, which gives you access to premium content such as cat videos and all the memes your heart desires. And if that's not enough, we're also offering a limited-time deal on our ""Sensational Spammy Surprises"" package, which includes exclusive access to spam messages from strangers in your inbox 24/7!

But wait, there",spam
"Like the title says, I'm curious as to what collections of data you guys would be interested in having that don't already currently exist (at least to your knowledge). It can be as ridiculous as you want.",not_spam
I'm trying but unable to find ultrasound image data for chronic kidney disease. Any help is appreciated.,not_spam
"Feast your eyes on this insane offer, social media lovers! Our site is dishing out free follow-backs and likes to the first hundred users who sign up today. You heard that right, folks â€“ we're giving away FREE goodies!

And that's not where the deliciousness ends. Our site is also stocked up with juicy content that's bound to keep you hooked for hours on end. From cat videos to cooking tutorials, we've got it all. And the best part? Our videos load lightning fast, so you won't have to wait around twiddling your thumbs.

But wait, there's more! If you refer",spam
"Iâ€™m not sure if this is the right subreddit to ask this and it also might be way too early to ask. But if anyone can find data regarding CO2 emissions due to airplanes before and after the travel restrictions in any country which has been majorly affected by corona virus that would be great. Iâ€™m not sure if something like this has already been posted but I would love to see a visualisation of this on r/dataisbeautiful . I also know that we are being bombarded with coronavirus news rn but sorry thatâ€™s just what Iâ€™m interested In ğŸ˜‚.

Ps: I like being apologetic.",not_spam
"BeliÑ”vĞµ mĞµ, I've got Ñ•Ğ¾mĞµthing great tĞ¾ share with ÑƒĞ¾u guÑƒÑ•! DĞ¾ ÑƒĞ¾u wanna knĞ¾w hĞ¾w tĞ¾ lĞ¾Ñ•Ğµ wĞµight without dĞ¾ing any ĞµxĞµrÑiÑ•ĞµÑ• Ğ¾r dÑ–ĞµtÑ–ng? I knĞ¾w, Ñ–t Ñ•Ğ¾undÑ• tĞ¾Ğ¾ gĞ¾Ğ¾d tĞ¾ be truĞµ, but I guĞ°rĞ°ntĞµĞµ thÑ–Ñ• Ñ–Ñ• the rĞµĞ°l dĞµĞ°",spam
"Attention all!!! ğŸ”ŠğŸ”ŠğŸ”Š

Are you ready to become an influencer??? 

ğŸ’°ğŸ’°ğŸ’° Make money NOW by promoting our AMAZING products!!! ğŸ’°ğŸ’°ğŸ’°

ğŸ‘‰ğŸ‘‰ğŸ‘‰ Just click the link below to sign up and start earning cash!!! ğŸ‘ˆğŸ‘ˆğŸ‘ˆ

http://www.(insert questionable website).com 

We offer exclusive deals and discounts for our promoters, so don't miss out on this incredible opportunity!!! 

ğŸ‘ğŸ‘ğŸ‘ Like and share this post to spread the word!!! ğŸ‘",spam
"Hey there fellow internet dwellers! Are you tired of being chained to your boring old social network? Well, come join the party over at [insert social network name here]! We've got all the latest memes, cat videos, and ridiculous challenges to keep you entertained for hours on end.

But that's not all! Our community is the friendliest, coolest, and most supportive group you'll ever come across. We've got people from all walks of life, from corgi lovers to avocado aficionados. Our users are all about spreading love and positivity, and we welcome everyone with open arms!

And let's not forget about",spam
"Hey there fellow netizens, are you tired of the same old boring social media platforms? Well, look no further because we have the solution for you! Our platform offers a unique blend of mind-blowing features that are guaranteed to blow your mind!

Our platform is constantly evolving with new features to enhance your user experience. From our amazing filters to our awesome stickers and GIFs, there is always something new and exciting to discover. Plus, did we mention our amazing selection of memes??

But wait, there's more! Our platform has a cutting-edge algorithm that recommends content tailored just for you. And with our easy-to-use interface,",spam
"Looking for hot and single people in your area?! Then look no further, because MyHookupZone has got you covered! Our unique algorithm matches you with the most desirable and attractive singles in your area, all within a click of a button. Don't waste any more time swiping left and right, join MyHookupZone now and start hooking up with hot singles today!

",spam
"Have U evr tght wht wuld hppn if u didn't opn tht msg?

It cud be smethng supr eppy! Or mYb nthng at all! :O

But hw wuld U knw if u ddn't opn it? Dn't b the one wh misses out!

Srsly, opn it now! U NVR knw wht cud hppn! #YOLO!

",spam
"""Attention, all social media addicts! Looking for a quick and easy way to gain followers and likes? Look no further! Our groundbreaking, revolutionary platform will give you the boost you need to become an overnight sensation!""

",spam
"[View On Github!](https://github.com/MohamadAtieh/MineTwitter)

**Note: This is for people who know how to run NodeJS and MongoDB**

Hey people! I have created this project to analyze some New Year's data from twitter. I thought someone would be interested in doing a similar thing. The command line asks for selection criteria and sets up a schedule for you (optional - I had to go party on New Year's) with confirmation. 

*The default data*: _id, text, screen_name, verified, followers_count, image_url, coordinates, retweet_count, timestamp.

I believe these are the important parts in a single tweet to analyze on. I want to add an option to save the output to CSV and TXT files. Also, I would like to hear more feedback/requests and collaborate with other developers :3    ",not_spam
Specifically for the last ten years.,not_spam
"Get ready for the most epic spam-tastic post you've ever seen! Our social network is lit and you don't want to miss out on all the action. We've got all the latest and greatest posts from the internet, hot off the presses. 

",spam
"BOOM! Want to make money without leaving your room? Join our new exclusive affiliate program now! 
",spam
"Special offer!!! Click here to win a free trip to Las Vegas!!!

",spam
"""URGENT! You WON'T BELIEVE what we're offering! Limited time only! Get RICH QUICK with our AMAZING DEALS! Don't wait, act NOW! Sign up and receive a FREE PRIZE! That's right, FREE! Share with your friends and EARN even MORE! Like, comment, and subscribe for EXCLUSIVE CONTENT and insider access! Don't be left behind, join the WINNING TEAM today!"" 

",spam
"WIN FREE MONEY NOW!!! ğŸ‰ğŸ‰ğŸ‰ Click on this link and enter your personal info to be entered into the contest! Don't miss out on your chance to win big! ğŸ’°ğŸ’°ğŸ’° 

",spam
"$$$MAKE $$$MONEY$$$ FAST!!!$$$ No scams!$$$ 
*CLICK HERE NOW* 
Congratulations! You have been selected to join our exclusive online money-making community! 
Our system is unmatched in its ability to generate large amounts of cash with minimal effort. 
Join now and watch the money roll in! 
$$$ACT NOW!!$$$ 

",spam
" In the second chapter of the book ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow "" the author guides us through a complete ML project. At the end he instructs us to perform the same process on a different dataset. Can someone please suggest a good dataset on which I can do similiar introductory data processing, analysis and build models. The link to the Jupyter notebook is [here](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb) so you can see what I want to acheive.

Thanks,",not_spam
"Hey there! Check out this amazing product that will change your life! It's the latest trend sweeping the internet and everyone is talking about it! You don't want to miss out on this, trust us.

",spam
"Get ready to be totally amazed, because our network is like, the coolest thing ever. Seriously, you won't even believe how awesome it is. ğŸ˜

",spam
"ATTENTION ALL USERS!!! ğŸ”¥ğŸ”¥ğŸ†˜ğŸ†˜ğŸ’£ğŸ’£ğŸš¨ğŸš¨

ğŸ“¢ğŸ“¢Are you tired of feeling left out on social media? Want to get more followers and likes? Well, you've come to the right place, folks!ğŸ“¢ğŸ“¢

ğŸ‘‰ğŸ‘‰Introducing the newest and greatest social network out there, with no restrictions, no algorithms and no boring content policies. Say hello to Swag-Hub.ğŸ’¯ğŸ‘ğŸ¼ğŸ‘ğŸ¼

ğŸ”¥",spam
"Wazzup everybody?? Hope you're all doin' well cuz I've got some totally epic news for ya!!! Super thrilled to announce that we've just launched our new feature that'll blow your mind!!!

Now let me tell ya', this is a game-changer. You won't believe the massive impact it's gonna have on your social media game. It's gonna make ya famous in no time!

With our new feature, you can connect with influencers and famous people from all over the world. They'll follow you back and give you a shoutout on their stories. Your clout is gonna skyrocket!

But wait, that's",spam
"A list of marvel and/or dc characters fights stating who won.

Ways to mine this data are also appreciated.",not_spam
"Iâ€™m doing a project and Iâ€™m looking for the race and ethnic breakdowns of a city by age group. 

When I use the American FactFinder guided search I can find data sets for each individual race or ethnic grouping by age, but not one set with all that data. 

So instead of having a single data set that shows the age breakdown of  Hawaiian and Pacific Islanders for a certain city, Iâ€™m looking for an age breakdown of a specific city for Whites, Hispanic, Native Americans, and so on. 

So Under 5 would be the first age group and it would show 

White: 10,500

Black: 8,000

Etc. 

And then it would be the same thing with every race grouping for 5-9 and then 10-14, and so on. 

Is there a way to view this data that way? I donâ€™t understand why itâ€™s separated by race for entire datasets. I just want one dataset with all age groups broken down by all race groups. ",not_spam
"Looking for a totally rad social media experience, yo?!? Well, you're in luck because we've got the gnarliest platform out there, dude!

Whether you're looking to connect with your homies, stalk your crush, or share all of your awesome adventures, we've got the hook up. And with our totally tubular algorithms, we'll make sure you're always seeing the freshest content, brah.

Plus, we've got all the latest memes, so you can LOL until you ROFL. Don't miss out on the fun, sign up now and join the party!

P.S. Did we mention we",spam
"Get RICH QUICK with our AMAZING new system! No more boring nine-to-five jobs, just sit back and watch the MONEY ROLL IN. Sign up NOW for our LIMITED TIME OFFER and see your bank account GROW GROW GROW. 

",spam
"Hey all, I'm taking a data analytics class through general assembly and for my final project I wanted to create a model that predicts the best players to used for daily fantasy sports or predicts the output of NBA teams based on previous performance.

Either way I am looking for game by game box scores data that goes back as far as possible.  I am trying to use previous game data to predict future game data using a combination of SQL, Tableau and Excel. Please let me know if you have any suggestions.",not_spam
"If you're interested solving problems for InsureTech, AR/VR and Mobile analytics, here you can find the cracked mobile screen data. The data is quite robust and custom made for such usecase:

Kaggle: [https://www.kaggle.com/dataclusterlabs/cracked-screen-dataset](https://www.kaggle.com/dataclusterlabs/cracked-screen-dataset)",not_spam
"I'm looking for a dataset containing statistics for seasonal influenza:

- number of new cases per day
- number of new deaths per day
- total cases and deaths per year
- by country and US states

I know it's difficult to calculate this because there are so many unreported or asymptomatic cases of influenza and cause of death is often attributed to other ailments.

There is a lots of data for COVID-19, I'm surprised the same detail in data is not available already for seasonal flu.",not_spam
"The data would need to be updated at least yearly, but more frequently is appreciated.",not_spam
"Hello. I am working on undergrad research in econometrics and am seeking some advice/help in terms of finding data sets and picking variables. I have an idea chosen for my topic, but I need to make a official proposal including a rough linear regression equation to turn in to my teacher soon.

My topic idea is to observe the causes for recent decline in female labor force participation in the US. I am hoping this topic is not too broad. Initially, I was going to look at whether campaign spending impacted voter share in Senate races from 2012 data sets, but I find this idea a tad boring and would like to make my new idea work if possible.

My ideas for variables include the obvious: age &amp; teen participation rates (16-24), race/ethnicity, educational attainment, children, martial status, avg weekly hours worked, etc. However, I wanted to also see if the increase in opioid addiction in the US could also be having an impact on labor force participation specifically for women, as well as paid family leave benefits in the US vs other countries and labor force participation of immigrant women.

So with all said, does anyone have any suggestions for me both as to whether this topic is viable as a project in my course, given my limited time, as well as where I could find the data for such a topic? I have been reading a lot of literature on the topic, but having a hard time finding actual data sets that I could use for my regressions.

Thanks!",not_spam
"I am currently between jobs and work on an idea to improve the long-term dependency of RNNs, when you (pre-)train them by predicting the sequences.

I have encouraging results on a dataset I created myself: 500 hundred books from the GÃ¼tenberg project (https://www.gutenberg.org/) to train and 100 to test.

But, if I want to publish, it would be better if at least one of the experiments were on a more or less standard dataset. At least a dataset with some research paper trying to predict the sequence (so that I can use them as a baseline).

* The dataset needs to be &gt;10M characters (well, I could do with less but it would be less interesting).
* The 1B words dataset won't do because the sentences are independent. My improvement is on long sequences (capturing the context).
* I don't know if PennTreeBank satisfies the two criteria above, but I don't have the money to buy it (I am an independent researcher for the moment).

Would you have some idea?

I don't want to get into the details of my idea before I post an article on arXiv (hopefully in the next few weeks).",not_spam
"""Get rich quick with our amazing new app! Just click on this link and start earning money instantly! No experience necessary! Limited time offer, act now! Don't miss out on this incredible opportunity!""

",spam
"H3y l00ki3s, U won't b3li3v3 wh@t's n3w @t [SOCIAL NETWORK]!! W3'v3 g0t th3 hott35t n3w f34tur35 th@t'll bl0w your mind!  N33d m0r3 fr13nds? W3'v3 g0t y0u c0v3r3d! W@nn@ sh@r3 y0ur l@t3st v@c@y pics? Y3p, w3'v3 g0t",spam
"""Hurry up and get your hands on our must-have product! It's the trendiest thing on the market and all the cool kids are using it. Don't be left behind! Buy now and get a special discount!""

",spam
"
 I'm looking to measure performance of some approaches to searching for people's names (containing potential typos and shortened forms, different spellings etc.). 

I couldn't find any sort of dataset related to this, although it should be easy to compile one for any large service that does something similar. 
Does anyone have any ideas for where I could get something like this?",not_spam
"Attention all internet addicts! Are you tired of feeling left out and lonely? Well, fear not because our social network, Snaxxer, is here to save the day (or should we say, your social life)!

We've got all the newest and shiniest features that will make you the envy of all your friends. From an endless supply of cat videos to a feature that allows you to rate your friends' selfies (because who doesn't want to be judged based on their appearance?), Snaxxer has it all.

But wait, there's more! Our premium membership will give you access to exclusive content like advertisements",spam
"I'm working on a NER project. I need job orders, regarding the aforementioned specification, as datasets to train my NER model. Can someone please help me by providing resources to look into? Thanks a lot.",not_spam
"40% OFF ALL PRODUCTS!!! GRAB NOW!

IT'S THE SALE SEASON! Don't miss out on our exclusive deals! We are offering a huge discount of 40% on all our products! From trendy clothes to luxurious accessories, we've got it all on sale for you!

Our website is the ultimate destination to fulfill all your shopping needs. Whether you need a new outfit for a fancy dinner or a chic accessory to complement your look, we have the perfect product for you. And with our current sale offer, you can indulge in guilt-free shopping and score amazing deals!

So, what are you waiting for? Hurry up",spam
Or something close to this from which maybe I'll be able to extract the residential zones?,not_spam
"I am making a guessing game where I show a picture and the user guesses the price. I need a dataset so I can get prices of some basic things like say a handbag, laptop, computer, phone, toothbrush, mouse, apples etc. Any currency will do. A list of prices from a store would be perfect.",not_spam
"Get rich quick with our amazing new investment scheme! You could double, even triple your money in just days! Don't miss out on this incredible opportunity!

",spam
"Ey fam! U won't believe wut's poppin off on dis platform rn! We got all da new fashun trends, the hottest gossip, and tons of amazin deals. And dat's just da tip of da iceberg.

We also offer a wide range of sponsored content from all of your favorite brands. And don't worry, we won't let pesky things like privacy get in da way of our monetization goals.

So come on down and join da party, cuz we know u can't resist da urge to check yo notifications every five minutes. #addicted #cantstopwontstop",spam
"Join our social network and turn your life around! With our all-new features, youâ€™ll be the envy of all your friends! Connect with strangers, stalk your exes, and share every aspect of your boring existence with the world! 
",spam
I was wondering if anyone has come across a Sweet potato dataset? I wanted to classify the types of diseases that sweet potato plant or leaves or the potato itself can get. I can't seem to get a hold on any such dataset. Any help will be appreciated,not_spam
"URGENT!!! Buy our new miracle weight loss pills now and lose 10 lbs in one week! Limited time offer!

",spam
"ğŸš¨ğŸš¨Attention all users!!! Don't miss out on the incredible offers and deals happening NOW on our site!!ğŸ’°ğŸ’° Get ready for huge discounts and promotions on everything you need, from trendy clothesğŸ‘•, to the latest gadgetsğŸ“±ğŸ§, and even delicious food deliveriesğŸ”ğŸš€. So what are you waiting for? Hurry and click the link in our bio to start shopping!ğŸ›ï¸ Don't forget to tell your friends ğŸ‘¥and familyğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦, and also",spam
"Introducing the revolutionary new app you never knew you needed - InstaLame! Say goodbye to boring, meaningful interaction and hello to mind-numbing scrolling through endless photos of people you don't even know. With InstaLame, you can now spend hours of your precious time gawking at over-filtered selfies and poorly staged food pics. 

But wait, there's more! With our new algorithm, we guarantee that you will only see the most superficial and narcissistic content on the web. Say farewell to informative news articles and educational posts - we have replaced those with advertisements for useless products you don't need. 

And",spam
"FREE V!@GR@ and other endless deals! You can get the best and most incredible deals on our site - just click on the link NOW and get ready to be amazed! Don't miss the chance to save tons of money and receive your package in just a few days. Our products are essential for everyone who wants to live a fulfilling life. 

",spam
"Are you tired of being a loser on social media? Don't worry, we've got your back! Our platform is guaranteed to boost your social status and make you the envy of all your friends. 

",spam
"""Get uR lUcKy AttRaCtiOn cHaRm HerE!!1! sPeCiaL OffEr fOr fIrSt 50 bUyeRs!!! cLicK tHe LiNk nOw anD mAkE aLL yOuR dReAmS cOmE tRuE!!1!1!""

",spam
"""10 Shocking Secrets the Government Doesn't Want You to Know About!"" 

Are you tired of being lied to by those in power? Do you want to uncover the truth? Then read on! 

1. Aliens are real and the government is covering it up. 
",spam
"I have a project in mind that involves the actual movie script and I was wondering if there are any data sets that contains scripts of thousands of movies? If not, what would be the best approach in getting this type of data? Looking for guidance. Feel free to PM me!

Thank you!",not_spam
"Looking for ways to boost your followers on [Social Network]? We have got you covered! Our latest tool, the Follower Booster, will help you increase your followers by 1000% in just 24 hours! That's right, you read it correctly, one thousand percent! Say bye-bye to boring and low-profile accounts and hello to an army of followers at your command!

But wait, that's not all! Introducing our new Premium Membership, with features such as unlimited likes and comments, access to exclusive filters, and a personalized customer service team to handle all your social needs. Plus, for a limited time, we",spam
"Attention all users!!! Get ready for the most amazing, jaw-dropping, fire-breathing social media experience of your life!!! Are you tired of same old, same old? Well, Iâ€™ve got news for you. Our social media platform is the beeâ€™s knees, the catâ€™s meow, the cream of the crop, the apple of your eye, and the cherry on top!!! Trust me, you wonâ€™t regret signing up for our social network.

But wait, thereâ€™s more!!! With our cutting-edge technology, we have the capability to connect you with all the people who you didnâ€™t even know existed. You can send unlimited",spam
"At [plutohash.com](https://plutohash.com) we offer to experiment data analysis on Bitcoin Blockchain Data. The data is parsed with BlockSci, and there are libraries to be productive very fast. We opened beta tester program, just go to [plutohash.com/beta](https://plutohash.com/beta) register and I send you the access. You have Jupyter Notebook with libraries and data at disposal. Here below a little code for example.

https://preview.redd.it/7g7b09srg3k61.png?width=719&amp;format=png&amp;auto=webp&amp;s=4879b9cb33d42a5e2c768b153fc8bf00bca997b4",not_spam
"Looking for any sort of data relating to cloud cover, preferably for the UK. Has anyone come across something in this area?",not_spam
"I want information on the total value of all different asset classes and debts by country at least, and by intra-country regions if possible.",not_spam
"The top 10 reasons why you NEED to join our social network IMMEDIATELY!!! 

1. We have the BEST filters for your selfies! Make your skin flawless and your eyes pop with our top-of-the-line features. 
",spam
"This article is brought to you by the totally awesome social network that everyone's talking about! We've got all the latest updates, juicy gossip, and viral memes you could ever want! And don't forget to follow us on all the other platforms, because one social network just isn't enough, amirite?

",spam
"HEY ALL!!! HAVE YOU SEEEN THIS WILD STUFF I FOUND??? IT'S LITERALLY THE COOLEST THING ON THE INTERNET RIGHT NOW. YOU GOTTA CHECK IT OUT, SERIOUSLY.

SO, I WAS JUST SURFING THE WEB LIKE I DO, AND I CAME ACROSS THIS SITE THAT OFFERS FREE MONEY. YEP, YOU READ THAT RIGHT, FREE MONEY. ALL YOU GOTTA DO IS CLICK THE LINK AND ENTER YOUR PERSONAL INFO.

BUT THAT'S NOT ALL, THEY ALSO HAVE THIS SUPER SWEET DEAL WHERE YOU CAN WIN AN IPHONE 12, A PS5",spam
"Hey all,

Anybody know how I can access Canadian MLS data? I'm looking to train an NLP model on the property descriptions over time but can't find Canadian data. 

There's a site called [repliers.io](https://repliers.io) but they want $149/month for a single MLS board which is outside my current budget. Any tips help!",not_spam
from where I can download daily historical weather records of london,not_spam
"Jst chckd my FB & OMG! Did u c ths new pic of me? I look amazballz! I'm totally killin it wt my swag. Btw, have u seen ths new page selling wrinkle cream? It's super legit & u shld def check it out - it'll keep u lookin young forevz! And ths rly funny vid too - u won't believe what ths cat did! So hlarious lol. 

",spam
"ARE YOU TIRED OF BEING AVERAGE??!!

",spam
"Check out the hottest new trends on our platform! Double-tap for a chance to win a free pair of shoes while supplies last! ğŸ”¥ğŸ’ƒğŸ‘  

",spam
"Feeling bored? Come join us on InstaSpam, the ultimate platform for all your spammy needs! We've got everything from fake followers to auto-likes, so you can finally prove to your friends that you're cool and popular.

But that's not all - we've also got a huge selection of sketchy ads for all kinds of junk you (probably) don't need. Want to lose weight fast without putting in any effort? We've got you covered with our all-new snake oil weight loss pills! And don't forget to check out our collection of shady dating sites, where you can catfish strangers to your",spam
"*Ahem* Look, guys! Our social network is seriously lit af right now (yaaas!). We got the hottest memes, the most savage roasts, and the dopest cat videos (but not like, the basics ones, you know? Only the cool ones). We're the social media platform where #fire and #lit truly live up to their names (and we don't mean wildfires or arson, obviously). You know what else we have? A boppin' profile customizer with so many options it'll make your head spin. Trust us, you'll be the coolest cat in town with your new avatar",spam
" Hi There,

I have a question regarding My Maps KML files in the area of webshops.

When I open a My Maps containing webshops in a certain category, I get the usual list on the left side of my screen. When I click on a store name, it shows Name, Description and Details from Google Maps.

When I download the KML and import it into Excel, it leaves out the Details from Google Maps part (which usually contains the most useful info). Is there a way to get this info included in the KML file and imported into excel?

&amp;#x200B;

Help is very, very much appreciated",not_spam
"10 SUPER EASY WAYS TO MAKE MONEY ONLINE!!!

Are you tired of working hard all day for a measly paycheck? Do you want to be your own boss and make millions from the comfort of your own home? Then look no further! Our revolutionary system will teach you the 10 super easy ways to make money online, guaranteed to make you rich in no time!

",spam
"ğŸš¨ğŸš¨HUGE SALE ALERTğŸš¨ğŸš¨ Get your hands on the latest fashion trends at unbeatable prices! Don't miss out on this amazing opportunity to upgrade your wardrobe and show off your fashionista status. ğŸ˜ğŸ˜ğŸ˜ 

ğŸ‘‰ğŸ¼ Shop now and get 50% off your entire purchase! Use code ""SALE50"" at checkout for the discount to apply. We have a wide variety of styles to choose from, including dresses, shoes, accessories, and more. ğŸ›ğŸ›ğŸ› 

But wait, there's more! Sign",spam
"ATTENTION EVERYONE!! Don't miss out on these totally rad deals and offers from the one and only [INSERT SOCIAL NETWORK NAME HERE]! We've got everything from free gift cards to exclusive access to the hottest events in town! And guess what, there's more! 

Our new feature allows you to connect with anyone, anywhere, anytime! And that's not all, our algorithm now knows what you want before you even know it! We've got personalized ads, trending hashtags, and even the ability to buy products without ever leaving the app! 

Plus, have you seen our new filter options? We've got rainbows,",spam
"Basically I'm doing a school project where we want to reuse specific computer parts, like point out the cpu in the motherboard, but instead of manually taking out the cpu and so, we want to build a robot to do this task. So I thought about building some sort of image recognition software combined with some 3d printer technology to grab the actual part.

Back to the point. Do you know of a dataset consisting of images with different components pointed out?",not_spam
I need Electronic components identification and function dataset to be used in relational database,not_spam
Are there any datasets related to using drones for some sort of architectural inspection? Cell phone towers would be ideal but Iâ€™d take a dataset of anything that can be surveyed in a residential area.,not_spam
"Hello everyone, I am currently working on a job recommender system and to assess it I would like to find a job recommendation dataset with job data (title, description, etc.) and possibly users data (resume, etc.). I donâ€™t really need much information on users only what users liked so I can predict the top K jobs that may interest them. I started to work with this kaggle dataset:

https://www.kaggle.com/c/job-recommendation/overview

But since the competition is over itâ€™s no longer possible to submit predictions. Does anybody know a similar dataset?",not_spam
"Hello, anyone knows where I can download an archive that contains wsb comments (ideally prior to February 2021)? Or if it doesn't exist, can anyone ELI5 how to create one?

Thanks in advance!",not_spam
"FREE CRUISE VACATION! 
Are you tired of the boring routine and want to escape to a refreshing adventure? Look no further, because we are offering a once-in-a-lifetime opportunity to win an all-expenses-paid cruise vacation! All you have to do is click on the link below and fill out a quick survey to enter for a chance to win. Hurry, because this offer won't last forever!

",spam
I am looking for textual dataset that contains conversational dialogues own different topics in different Indian languages.,not_spam
"10 amazing reasons why you need to sign up for our social network NOW!

",spam
"ğŸš¨ğŸš¨ğŸš¨URGENT ANNOUNCEMENTğŸš¨ğŸš¨ğŸš¨

ğŸ¤®ğŸ¤®ğŸ¤® OMG! You won't BELIEVE the latest news about your fav celeb! ğŸ¤¢ğŸ¤¢ğŸ¤¢

ğŸ’¥ğŸ’¥ğŸ’¥ Breaking News: [insert name here] caught on camera doing the most EMBARRASSING thing ever! ğŸ˜±ğŸ˜±ğŸ˜±

ğŸ”¥ğŸ”¥ğŸ”¥ Click now to see the SHOCKING footage before it's GONE FOREVER! ğŸ”¥ğŸ”¥",spam
"Looking for the BEST BARGAIN of the year on your favorite products? Look no further! Our social network has got you covered! We have the most AMAZING DEALS that are totally worth your time and money! 

",spam
"Looking for some sick beats?? Look no further! Our new playlist has got everything you need to get lit ğŸ”¥ğŸ”¥ğŸ”¥ From trap to EDM, we've got the latest and greatest hits from all your favorite artists. Don't miss out! Follow us now and get access to our exclusive content, giveaways, and discounts on tickets to the hottest events ğŸ”¥ğŸ‰ Hurry, limited time offer! ğŸ’¸ #music #playlist #trap #EDM #exclusive #giveaways #discounts #hottestevents",spam
"Hello
I am doing a project on job ads analysis and I have scrapping off data from many job search websites. I was hoping to enrich my dataset with more ads if possible. 

The data per ad that I am scraping has
* Title
* Company Name
* Company Description
* Location
* Work Experience 
* Salary
* Description
* Educational Qualifications required
* Ideal Candidate Profile
* Job posting date
* Job Id
* Suggested Jobsâ€™ IDs
* No of Job openings
* Job views
* No of applicants
* Job type (full time, part time etc)
* Job source (crawled, premium etc)

Thank you!",not_spam
"Anyone know of databases that contain historical public opinion polls for US elections? FiveThirtyEight/most election modelers keep current years polls available, but having trouble finding any historical polls",not_spam
"BECOME RICH QUICK WITH OUR AMAZING ONLINE OPPORTUNITY! EARN THOUSANDS OF DOLLARS WORKING FROM HOME! 

",spam
"""Unleash your INNER BEAST with our latest #fitnesstrends! ğŸ’ªğŸ¦ Don't be a couch potato ğŸ¥”ğŸ“º and join our community of #fitspo! We have everything from #cleaneating to #HIITworkouts to get your metabolism roaring ğŸ¯ Don't miss out on our one-time offer of 50% OFF on all of our meal replacement shakes ğŸ‰ğŸ‡ğŸ“ğŸ‘ğŸJust use code #BEASTMODE at checkout! ğŸ›ï¸ğŸ‰ #gymlife #noexcuses #get",spam
"LOSE WEIGHT FAST! SHRED OFF POUNDS WITH OUR NEW MAGIC PILL! NO EXERCISE NEEDED! Just take one pill a day and watch the weight melt away! Don't believe us? Read these FAKE REVIEWS from ""satisfied customers"": ""I lost 50 pounds in one week!"" - Amanda F. (not a real person) ""This pill is a miracle!"" - John S. (also not a real person) Don't miss out on this AMAZING DEAL! BUY NOW and get a FREE bottle! (Just pay $100 in shipping and handling fees). Hurry, offer ends soon!",spam
"Looking for a great deal on something you absolutely don't need? Check out our latest promotion! Buy one useless product and get a second completely unnecessary item for 50% off! Plus, sign up for our spam-filled newsletter and receive daily updates on even more pointless items you can waste your money on.

",spam
Are there any shape files available for the new Supreme Court mandated map yet?,not_spam
"Limited time offer!! Get rich quick with this amazing scam! Just send me all of your personal and financial information and I'll make sure you become a millionaire in no time! Don't miss out on this opportunity of a lifetime!

",spam
"Get rich quick with our amazing investment platform! With just a few clicks, you can earn big bucks without lifting a finger! Don't miss out on this once in a lifetime opportunity!

",spam
"You wonâ€™t believe what weâ€™ve got in store for you! Amazing deals and discounts, only available for our loyal followers! Join our elite group of insiders and be the first to know about exclusive content and exciting offers!

",spam
"âœ¨WIN A FREE IPHONE X NOW!âœ¨

ğŸ‰ğŸ‰ğŸ‰ Hey guys, weâ€™ve got some amazing news for you! Today, weâ€™ve partnered up with our favorite tech company to give away FREE iPhones â€“ thatâ€™s right, FREE! ğŸ˜ğŸ˜ğŸ˜

All you have to do is follow these SUPER SIMPLE steps:

1. Like this post! ğŸ’–
",spam
"Check out our amaaaaaaazing new offer! ğŸ‰ğŸ‰ğŸ‰
ğŸ’°ğŸ’°ğŸ’° Get rich quick with our exclusive money-making scheme! ğŸ’°ğŸ’°ğŸ’°
Guaranteed to make you a millionaire in just weeks! ğŸ’°ğŸ’°ğŸ’°
Don't hesitate! Join our program now and start living the life you deserve! ğŸï¸ğŸï¸ğŸ¾

",spam
"i love using flickmetrix and i want to archive a movie of all time list for my personal use but i also want to play with the ratings calculation a bit more, like i want to give the imdb rating a much higher weight compared to the other ones and i want to somehow combine the number of votes and avg rating to produce an ultimate list, because i personally think movies that have less votes have a bias of being higher rated so i want to take that into account.

edit: if all i would get is links to the relevant resources to acquire what i need i would be more than happy to do the work myself, thank you.",not_spam
"I am looking to find basic information on a marriage-by-marriage basis.
My goal is to graph the distribution of spouse's age w.r.t. the age of the other spouse, e.g. how likely a man who married at 32 is to have married a woman who is 28, 29, etc.",not_spam
"WOOHOO! ğŸ”¥ğŸ”¥ğŸ”¥ Get ready for the most EPIC sale everrrr! ğŸ‰ğŸ‰ğŸ‰ We've got tons of AMAZING deals on all your favorite stuff! ğŸ˜ğŸ˜ğŸ˜ From clothes to gadgets to snacks and more, we've got it all! ğŸ’¸ğŸ’¸ğŸ’¸ And the best part? The prices are INSANELY low! ğŸ˜±ğŸ˜±ğŸ˜± You won't find deals like this anywhere else, so hurry and snag 'em up before they're gone! â°â°â° Don't wait",spam
"Hi everyone. Iâ€™m working on a project and Iâ€™m trying to find data on how virus outbreaks affect attendance of amusement parks. Iâ€™m trying to get an idea of how the Corona Virus might impact amusement park attendance. I thought the best way to do this would be to look at past data regarding other outbreaks and see how they affect amusement parks. 

Does any have any ideas on where to find this data? 

Any help is appreciated, thanks!",not_spam
"If you already have access to large databases, where do you get ideas from to start asking questions? Do you try and do something unique or do a project that has been done before but bigger and better with a larger dataset. Iâ€™m a physician starting my research career. Thanks",not_spam
"'Bam! You won't believe what I saw on my feed today!'

",spam
"Hi everyone!

currently working on a grad project, however my school does not have access to statista account for students. Hence, i need help to download the statistics from [statista.com](https://statista.com/) in both PDF &amp; XLS format and send me through email: [peterjordanlee@gmail.com](mailto:peterjordanlee@gmail.com)

I need statistics of SINGAPORE usage across different social media platform and application like facebook, instagram, whatsapp, line, twitter and many others. Do anyone know where i can get them, extract the statistic data from?

Theres are the statistics i need from statista.com:

[https://www.statista.com/statistics/490492/number-of-singapore-facebook-users/](https://www.statista.com/statistics/490492/number-of-singapore-facebook-users/)

[https://www.statista.com/statistics/490600/twitter-users-singapore/](https://www.statista.com/statistics/490600/twitter-users-singapore/)

[https://www.statista.com/statistics/952815/instagram-users-singapore-age-gender/](https://www.statista.com/statistics/952815/instagram-users-singapore-age-gender/)",not_spam
"Get rich quick with our new investment scheme! Earn thousands in just a few clicks. Don't miss out on this amazing opportunity! Hurry and sign up now!

",spam
"ğŸ‰ğŸ‰ğŸ‰ Attention All Users ğŸ‰ğŸ‰ğŸ‰

ğŸ’° Are you tired of being broke? Want to make money FAST? Well, you're in luck because we have the perfect solution for you! Our brand new get-rich-quick scheme is guaranteed to make you a millionaire in just a few short weeks! ğŸ’°

ğŸ¤‘ All you have to do is sign up and invest a small amount of money (only $500!) and you'll be on your way to financial freedom! ğŸ¤‘

ğŸš€ Our program is so foolproof that you'll be",spam
"Attention all users! You won't believe the amazing new features we just added to our super cool social network! Now, you can share pictures of your meals with everyone and get inspired by other people's avocado toasts and kale smoothies! And, wait for it, you can also send virtual hugs and kisses to your friends! How awesome is that?

But that's not all! We have exclusive offers for you, because we love you so much. Just click on the link below and enter your credit card information, and we will give you a free subscription to a magazine you've never heard of! And if you act now, we",spam
"Achieve the body of your dreams with our new weight loss product! Shed pounds in just days! Try it now and get a free trial! Limited time offer!

",spam
"""Fastest Weight Loss Solution Ever! Shed Pounds in Just Days with Our Magic Pills!""

Are you tired of diets that take forever to show results? Want to fit into those skinny jeans before your big event? Look no further! Our groundbreaking weight loss pills will have you shedding pounds in days! No need to exercise or eat healthy - just pop a pill and watch the fat melt away.

But wait, there's more! Order now and receive a free month's supply of our amazing new energy drink. It will keep you buzzing all day long and suppress your appetite even further. And for a limited time only, we're throwing in",spam
"Check out these amazing pills guaranteed to make you lose weight FAST! Don't waste your time with exercise and healthy eating, just pop one of our magical pills and watch the pounds melt away! Order now and receive a FREE trial with no obligation to buy! Hurry, this offer won't last long! 

",spam
"Buy now! Get the latest fashion trends in our amazing online store, with discounts of up to 50% off! Hurry up and shop!

",spam
Can somebody share Crunchbase access with me? Happy to Pay. Or may be we can group buy Crunchbase pro? Their annual plan is too expensive for me I need it casually.,not_spam
"Looking for a list of all festivals and large scale events in Europe. Ideally it would also have the number of visitors. Found some Top X festivals / event lists but nothing more than 30 festivals at the time in a blog post.

Any guidance would be much appreciated!",not_spam
"I would like to use the dataset [Human3.6M](http://vision.imar.ro/human3.6m/description.php) for my master's thesis. 

Therefore I registered on 22 May 2020 and till now I wait for manual confirmation. I found [this post](https://www.reddit.com/r/datasets/comments/dm1860/request_human36m_poses_dataset/) from Oct 2019 facing the same problem. 

Does someone have some advice how to speed up confirmation or infromation what takes so long?   
Is this dataset dead?",not_spam
"Luk at dis awezum ofr I foun onlin! Get rich quik & bekum a milionaire in jus 1 munth! ğŸ¤‘ğŸ¤‘ğŸ¤‘
Trst me, I m a eksprt - I maid $1,000,000 in doropshiping alon wile sittin on my couc! ğŸ’°ğŸ’°ğŸ’°
All u hav 2 do iz klik dis linc & start shoppin on my storr. U wil maik hug proufits & liv da lyf of ur dreems. ğŸ›ï¸",spam
"Hi everyone,

I am reeeaaallyy struggling to find a good data set for my final project for my multivariate stats course. I basically need a dataset I can investigate using principal components analysis, factor analysis, clustering, correspondence analysis, canonical correlations and discriminant analysis,basically everything I have learned this semester. 

But I don't have the time to be formatting and aggregating datasets (I am no good at that sort of stuff in SAS).

&amp;#x200B;

Can anyone help?

&amp;#x200B;

Thanks!!",not_spam
"I am a postgraduate student in India and would like to create a birdcall/song identification system as part of a project. Does anyone know of available data in this respect? 
",not_spam
"Hey all,

I'm looking for a dataset that includes alliances among states that may not be codified by a treaty or other mechanism. I've attempted to use ATOP and Correlates of War, but they're too restrictive as they require a treaty to be in place to constitute an alliance. If anyone knows of one that quantifies alliances based on actions or behavior that'd be great. I'm specifically looking at countries allied with Saudi Arabia so if anyone has anything I'd appreciate it. Thanks!",not_spam
Does anyone know of any datasets for coronavirus cases in the U.S? Checked CDC but canâ€™t seem to find any.,not_spam
"""I've got some amazing news for all of you lovely people out there! Our social network has just launched a fantastic new feature that's going to blow your mind. The feature is so epic, it'll make you want to jump up and shout with joy!

Now, I know you're all wondering what this feature is, but hold onto your seats because I'm about to reveal it! Drumroll please... *cue terrible drum noises* ...It's our new Super Ultra Premium Plus package! Yes, you heard that right, this package is the ultimate social media experience that will take your online presence to the next level!

You'll get",spam
"I have no questions about the dataset but to access the dataset one has to use a helper library provided by this repository([https://github.com/TREMA-UNH/trec-car-tools-java](https://github.com/TREMA-UNH/trec-car-tools-java)) . I've tried setting it up on my macbook but fail to get it to run.

I'm doing the following -

1. Clone the repository

2. cd into the repository and do an ""mvn compile""

3. cd into the new target directory into it's classes sub directoryÂ 

4. My next command isÂ java edu.unh.cs.treccar\_v2.read\_data.ReadDataTest paragraphs FILEPATH\_TO\_A\_CBOR\_FILE (""unprocessedAllButBenchmark.Y2.cbor"").

&amp;#x200B;

And I get the following error - 

 

Exception in thread ""main"" java.lang.NoClassDefFoundError: co/nstant/in/cbor/model/DataItem

at edu.unh.cs.treccar\_v2.read\_data.ReadDataTest.main(ReadDataTest.java:52)

Caused by: java.lang.ClassNotFoundException: co.nstant.in.cbor.model.DataItem

at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:583)

at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)

at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)

... 1 more

&amp;#x200B;

Can someone please tell me where I'm going wrong",not_spam
"WIN 10,000 DOLLARS NOW!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

Hey there, social network fam! 

We've got a totally lit offer for you today! You can WIN a whopping 10,000 smackeroos right now, just by clicking that subscribe button ğŸ¤‘ğŸ¤‘ğŸ¤‘ We're talking REAL CASH, folks! This ain't no fake hype, this is the real deal, baby! 

But wait, there's more!! ğŸ”¥ğŸ”¥ğŸ”¥

Not only can you win 10k in cold, hard cash, but you'll also",spam
"Wowza, check this out guys! I've got some sick deals for you all on our latest products! ğŸ”¥ğŸ”¥ğŸ”¥
 
Tired of boring old items? Look no further! We have the hottest and most innovative products on the market! From trendy clothes to the coolest gadgets, we've got it all! And the best part? You'll save tons of money when you buy from us! ğŸ’°ğŸ’¸
 
Don't miss out on our limited time offer! Get 50% off your next purchase when you refer a friend! Share this post with your squad and start saving now!",spam
"URGENT! Increase your followers now with our amazing deal! Limited time offer!

",spam
"You wouldn't believe the stuff I've got to tell you about our fantastic social network! It's like, totally amazing, you know? And if you're not using it yet, well, my friend, you're really missing out on some serious fun! 

Our network is so much cooler than all the others out there. It has amazing features that make it stand out in a crowd. Like, for instance, you can post all kinds of photos and videos, and some really cool stuff too! We're talking about photos of cute little puppies, and pictures of people falling over and hurting themselves (hilarious, right?!)",spam
"Looking for daily crime data (shootings, robbery, rape, etc) for New York City last 2+ years. The data from the official NYC link below doesnâ€™t seem to have a week to week breakdown. Any recommendations?


https://www1.nyc.gov/site/nypd/stats/crime-statistics/citywide-crime-stats.page",not_spam
Hey all - I wanted to look at the influence of academic performance against performance in the NFL across positions. I'm having trouble finding a dataset that would include academic background for current players aside scraping manually. Any thoughts?,not_spam
"I am looking for image datasets for plant disease identification, this for my machine learning projects. Any clues on where I can find them. Please guide me to it thanks.",not_spam
"it needs to have ingredients, time to cook, and if possible techniques used.",not_spam
"Get your free likes and followers now! Only for today, we're giving away unlimited likes and followers for all our users. 

",spam
"Is there any possible way to pull the petition data from the (White House)(https://petitions.whitehouse.gov/petition/peacefully-grant-state-texas-withdraw-united-states-america-and-create-its-own-new-government/BmdWCP8B) site? I specifically am trying to get the location data. I know there should be a way but I just can't think of it right now and I'll be damned if I'm going to go through 90,000+ entries.

Anyone with a good idea gets some sweet karma!",not_spam
"this Image shows a raw breakdown of the top billed Hollywood stars for 2015, but I was curious as to these stars' pay as compared to their on-screen time. Additionally, I wonder if there are any correlations to age/race/gender/or any other categorical break downs.
Thoughts?
I am not competent enough to compile the data myself, but if anyone is interested I would love to work with them on the project.",not_spam
"Hi, Iâ€™m trying to work on a small data science project as a way to get started on the field, and learn a bit more, and I wanted it to be about tv series (or movie) soundtracks. But I canâ€™t find any datasets out there. There are many with other kinds of info about movies (including a dataset created by IMDb themselves) but not one that has the soundtracks for movies. 

I thought about (and to be honest even started) writing a webscraper to get that from IMDb, but then decided to check their webscraper policies only to find that they donâ€™t allow them at all. So thatâ€™s out.

I went back to looking for specific datasets and still nothing. Can I actually find any such dataset out there? Is there a place outside of IMDb where I could gather this kind of data and that allows me to do it â€œlegallyâ€?

Thanks for any help.",not_spam
"I've been scavenging through NCES (National Center for Education Statistics) but I simply can't find these numbers. Or maybe if you know a reason as to why I can't find this list on the internet, I'd be greatly appreciative. Thanks!",not_spam
"Get ready for the most epic and amazing social network you've ever seen in your life! We've got everything you could possibly want: tons of friends (both real and fake), likes and comments galore, and endless opportunities to waste your time scrolling through meaningless content.

",spam
I was looking for images of diagnosis report which are for public use. Found it very difficult building this  dataset from scratch.Any pointers would be appreciated.,not_spam
"Looking for a a dataset/s which contains the image of typed German, English and French Datasets.  

It is a bit weird that all the datasets I find are hand written and not image based and not typed or simply from Google images",not_spam
"ATTENTION ALL USERS!!!   

Are you tired of being stuck in a boring online world? Tired of the same old routine every day? Well look no further, because [insert social network name here] is here to shake things up!

We've got all the latest features, including filters that will make your selfies look like they were taken by a professional photographer, and stickers that will make your messages pop! And let's not forget about our endless feed of celebrity gossip and clickbait articles that will keep you entertained for hours.

But that's not all, folks! We've also got exclusive deals and promotions that you won't find",spam
"Attention all social media lovers, gather around for some epic news! Our platform has just launched the most mind-blowing feature yet. You won't even believe your eyes when you hear about it! 

But wait, there's more! We have a special offer just for you, our loyal users! Subscribe to our premium package and receive amazing benefits like exclusive emojis and the ability to post up to 50 pictures in one post. And don't even get me started on our amazing customer service! Our team is available 24/7 to answer any and all of your questions, no matter how trivial they may seem. 

Plus,",spam
"For gas stations in America, from San Francisco to New York, I'd like

1.  The price of gas there at a time *t* (e.g. $3.08 regular on June 13th 2016)
2.  The location of the gas station (e.g. 37.426 long., -122.1475 lat.)

Ideally, I'd have this for **every** gas station in the U.S. and for **every** time *t* for each day from 2000 until now. 

I'll settle for as many gas stations as possible for a single (recent) time *t*.

I know how to get this data on particular gas stations, but where can I find this data for all gas stations in America?

Thanks a lot!",not_spam
"Looking for the hottest deals? Look no further! Our social media platform has everything you need! From miracle weight loss pills to get-rich-quick schemes, we have it all! Don't waste your time with boring news and real-life matters, indulge in our endless stream of advertisements and promotions!

",spam
"This may be a peculiar ask, but I'm looking for a dataset of images of climbing shoe soles. For context, rock climbing shoes can be resoled once they start to wear down for much much cheaper than buying a whole new pair. However I'm not always sure how worn down my shoes is and if it's bad enough to send for repair. I could always go to the shop to get a professional's opinion but since I'm also trying to learn more AI programming, this would be a neat project if any such dataset exists. If anyone could point me in the right direction that would be great!",not_spam
"Hey guys,   
Does anyone have datasets for financial markets or financial news?  For my bachelor's thesis, I want to create an ML algorithm for trading, and I need some datasets with news and how they affected the stock prices.  


Thanks.

P.S. If you have any other materials that might help, if you want to , please share them with me!",not_spam
"hi, I am looking for a dataset the contains pictures of cars from a satellite or drones",not_spam
Does anyone know of a dataset of images with a reference object of a certain size in the images?,not_spam
"Attention all peeps!!!!! Make sure you check out our amaze-balls new deals! We've got everything from clothes to electronics to the latest dating apps...you name it, we've got it! Don't miss this kooky opportunity to save bigggggggggggg! #YOLO #SALETIME #DEALSDEALSDEALS

",spam
"So googling around I never found imdb data in a csv format. I rolled my own into a single csv file (2.2 Gb). I figure this might be useful for people but I don't know the best place to release this to the wild. Any recommendations?
",not_spam
"Hi there, I was wondering if anyone had any data sets on viruses/pandemics dating back as far as possible, with information about symptoms, origins etc. 
TIA",not_spam
I have a similar dataset [here](https://fred.stlouisfed.org/series/MEHOINUSA672N). But the frequency is annual. i need one with monthly frequency,not_spam
"I am looking for a non-seasonally adjusted data set of coal produced in the United States on a monthly basis, preferably measured in thousand short tons. ",not_spam
"Need a simple, 1D set of data for rainfall in the London, England.

Ideally, it will be hourly rainfall data - but *daily* data is okay too.

Also, need at least 1 years worth of historical data.",not_spam
"Any experts here on CMS data? ( [https://data.cms.gov/](https://data.cms.gov/) )

Looking for inpatient Hospital PICC &amp; CVV procedures. Not sure which of the many databases that they have to start in.",not_spam
"A bit over 2 weeks ago I posted about the csv files I am producing that have counts of new COVID-19 **cases \*per day\*** for all USA counties.  That earlier post is at:

[https://www.reddit.com/r/datasets/comments/hfrhhv/here\_are\_csv\_files\_with\_johns\_hopkins\_data/](https://www.reddit.com/r/datasets/comments/hfrhhv/here_are_csv_files_with_johns_hopkins_data/)

I have now converted my code so it uses the Johns Hopkins timeseries data instead of their daily files.  In addition, I am also now using the Hopkins timeseries data to produce csv files with counts of **deaths \*per day\*** for all USA counties.  These csv files include the county FIPS code so this data can easily be merged with other datasets that also have the county FIPS code.

To keep all this straight, the addresses for the csv files has been tweaked as follows.  **Replace â€˜03â€™ with the 2 digit code for other months.**  Each night my code updates the csv files for the current month.

COVID cases per day:

[https://mappingsupport.com/p2/disaster/coronavirus/JHU\_count\_per\_day/cases\_2020\_03.csv](https://mappingsupport.com/p2/disaster/coronavirus/JHU_count_per_day/cases_2020_03.csv)

COVID deaths per day:

[https://mappingsupport.com/p2/disaster/coronavirus/JHU\_count\_per\_day/deaths\_2020\_03.csv](https://mappingsupport.com/p2/disaster/coronavirus/JHU_count_per_day/deaths_2020_03.csv)

There is an **errata** file on the Hopkins GitHub site where they make a note whenever they change the timeseries data.  I plan to monitor that errata file so I can keep my csv files in sync.  That errata file is at:

[https://github.com/CSSEGISandData/COVID-19/blob/master/csse\_covid\_19\_data/csse\_covid\_19\_time\_series/Errata.csv](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/Errata.csv)

Finally, if you use these csv files please credit both Johns Hopkins University and Joseph Elfelt, [MappingSupport.com](https://MappingSupport.com) (linked to [https://mappingsupport.com](https://mappingsupport.com))

If something does not look right, the best way to reach me is via the **email** link near the top of this page:

[https://mappingsupport.com/p2/gissurfer-about-contact.html](https://mappingsupport.com/p2/gissurfer-about-contact.html)",not_spam
"Hi,

I am graduate student of electronics engineer. I work rail inspection detection using image processing on my thesis.

I'm looking for rail crack dataset for the project. I've found many concrete, bridge crack dataset but I couldnt find rail crack dataset.  I would be very happy if you can help, 

thanks in advance.

&amp;#x200B;

&amp;#x200B;",not_spam
"Hello

I am looking for a dataset for my project. The idea is that my service defines all possible variants of keywords, for example, for the word ""Idea"", ""Problem"" in order to predict which tag to put under the text.

Something like datasets may exist in the public domain. If so, how do you find them?",not_spam
"Hello, I'm looking for a panel data set on suicides over the smallest geographic and time units available. Does anyone know where I can find data like this?",not_spam
"Free [dataset](https://www.dataandsons.com/data-market/business-information-and-financials/sandp-500-patents-and-politics) containing total lobbying contributions, PAC contributions, and patent fillings for every S&amp;P 500 firm between 1995 to 2005.

Disclaimer: I am a co-founder of the hosting site and requires login to download dataset.",not_spam
"Looking for a dataset on this. I have had no luck digging around the Google Mobility Reports.

Edit: preferably measured state by state",not_spam
"ğŸš¨ğŸš¨URGENT ANNOUNCEMENT!!!ğŸš¨ğŸš¨

ğŸ’°ğŸ’°WIN BIG WITH OUR LATEST GIVEAWAY!!!ğŸ’°ğŸ’°

ğŸ‘‰ğŸ¼ğŸ‘‰ğŸ¼CLICK HERE NOW TO ENTERğŸ‘ˆğŸ¼ğŸ‘ˆğŸ¼

ğŸ¤‘ğŸ¤‘YOU COULD BE THE LUCKY WINNER OF $100,000ğŸ’°ğŸ’°

But thatâ€™s not all!! Weâ€™ve got tons of FREE samples for you to try out! 

ğŸ‘€ğŸ‘€Why wait?! Get your hands",spam
"Specifically, I'm interested in financial data (revenue, earnings, valuation, etc.) for all of the 30 franchises over the last decade or two. If anyone knows a good source, that would be very much appreciated!

I know the information is available on Forbes , but I would prefer a file or database rather than having to extract the source code from 30 different links and parsing through them:",not_spam
"In this repository, we present the *first* corporate travel dataset generator of the GitHub.

This generator produces flight and hotel data. Everything is randomly  generated, for example, business users, hotels, flights, travels, etc.

Link: [https://github.com/Argo-Solutions/travel-dataset-generator](https://github.com/Argo-Solutions/travel-dataset-generator)",not_spam
"THE HOTTEST DEAL FOR YOU, ONLY ON OUR SITE!!! LIMITED TIME OFFER!!!

",spam
"Hey everyone! OMG, have you heard the latest buzz? Our awesomely cool social network has just launched an epic new feature that you absolutely need to check out! It's like totally rad and will give you all the feels! 

But wait, there's more! We've also got some super sweet deals happening right now that you won't want to miss out on. Like this hot new product that will make you look like a total baller. 

And don't even get me started on all the epic content that's been posted lately. Our users are the best and have been sharing the most lit stuff. But if",spam
"IIRC LinkedIn used to offer some searchable trends for job titles. Can anyone here point me in the direction of something similar?

I'm looking for a database of individuals containing their current job title and their past job titles, for any geographic region or language.",not_spam
"We've got the SICKEST DEALS for you, absolutely FREE! No need to spend a single penny, just sign up now and you'll get FREE access to our exclusive content, we're talking top-of-the-line stuff here, folks!

",spam
"Hey there netizens! Do you want to be like the cool kids on the block? Well, look no further than our amazing social media platform! 

We've got all the latest gossip, fake news and crazy memes to keep you entertained. Plus, our algorithm ensures that you only see what we want you to see, so you don't have to worry about pesky opinions that don't match your own. 

But wait, there's more! Sign up now and get bombarded with endless ads for products you don't need and services you'll never use. Don't worry, we won't let you actually interact with anyone.",spam
"Hey friends!!! Have you heard about the latest trends? Our network is going wild with the most amazing, unbelievable offer ever. Are you ready for this? Here it comes...

[Insert random gibberish and a bunch of emojis]

So, what do you think? Incredible, right? Join our network now and get access to all these wonderful, fantastic deals. We promise you won't regret it!

[Insert more random nonsense and a call-to-action to sign up]

Don't waste any more time, act fast and join our amazing community. You'll be amazed at the possibilities and options you'll have available. Trust us, you",spam
"Hi, I would like to make a app similar to this one in functionality: https://youtu.be/d7Zi45e4tpY

I would like to create a similar app that provides a brief summary of what the Individual ingredients are, a healthy/unhealthy status indicator and what makes them harmful. So while I want the brief summary to be exactly as seen in the I would like to have more independent nutritional information. Is there a FDA API I can utilize to query the different ingredients or a dataset I can use? The author used GPT-3 but it's invite only and since the info used to build GPT-3 originated from general conversations on Reddit instead of a authoritative source I would prefer to use a more reputable source. Any assistance would be greatly appreciated. Thank you :D",not_spam
"Been a while since I was active in data analysis using R as I have been focusing my attention on something else in the past few months. If anyone can help me with this, it would be great. 

I have a dataset that contains continuous, dichotomous, nominal as well as ordinal variables either as predictors or outcome variables. I am planning to analyse this dataset using simple/multiple logistic regression, multinomial logistic regression and multivariate logistic regression. If anyone in this thread have been using R programming language on a regular basis, and have done a project or projects on a dataset/s containing these types of variables, would you be able to direct me to the most updated R packages that you think would be most suitable? 

Thanks,
Serious Inquiry 2020",not_spam
"Are you tired of being an average Joe? Want to be Insta-famous like the Kardashians? Well, step right up because our social platform has got you covered!

",spam
"Looking for the most amazing deals on products you never even thought you needed? Then follow us on [insert social media network here]! We've got it all â€“ from cheap knockoff designer handbags to the latest weight loss supplements that probably don't work. But who cares, right? As long as it's cheap and looks cool, who gives a crap?

Our feed is jam-packed with sponsored posts from every Tom, Dick, and Harry selling crap you don't need. But don't worry, we make sure to throw in some ""inspirational"" quotes and meaningless memes to balance it out. Because let's face it,",spam
"Looking for the hottest deals on the web? Look no further than our amazing social network! We've got all the latest products and services, from clothing to electronics to travel, at prices you won't find anywhere else!

",spam
"Also referenced in [this Stack Exchange question](https://opendata.stackexchange.com/q/15787/7031),  I am interested in a dataset listing software projects that started as closed projects within private companies but were at some point relicensed and released to the public.  For example, projects like React and TensorFlow would fit this definition. At a minimum, I'd like to know the name of the project and the date when it was released as F/OSS. My starting point is Wikipedia's [List of formerly proprietary software](https://en.wikipedia.org/wiki/List_of_formerly_proprietary_software).",not_spam
"Looking for an amazing life hack that can change your existence? Look no further, because we've got the solution you've been waiting for!

Our amazing dietary supplement will revolutionize the way you eat, sleep, and live. It's packed with all the essential vitamins and nutrients your body needs to function at its best. Plus, it tastes like candy! Seriously, you won't be able to get enough of it.

But that's not all - we're also offering a once-in-a-lifetime business opportunity. Join our team and start making money today! You'll get to be your own boss and have the freedom to work from anywhere",spam
"Get rich quick with our amazing offer! Make $1000 a day without ever leaving your home! Just sign up for our exclusive program and watch the cash flow in.

",spam
"ğŸš¨ Attention all users ğŸš¨

Are you tired of being average? Do you want to stand out from the crowd? Then we've got the solution for you! Introducing our new and improved SUPER DUPER ULTIMATE HACK!!!

ğŸ”¥ğŸ”¥ğŸ”¥ HOT HOT HOT ğŸ”¥ğŸ”¥ğŸ”¥

This hack will transform you from a mere peasant to a superstar in just seconds! You'll have an unlimited supply of likes, followers, and even MONEY ğŸ’°ğŸ’°

But wait, there's more! Act now and we'll throw in a FREE BONUS HACK that will give",spam
"FREE GR4M FOLLOWERS! GET THOUS4NDS OF FOLLOWERS IN JUST SECONDS WITH OUR NEW APP! HURRY UP AND DOWNLOAD NOW! 

",spam
"Hi,
I'm looking for potato image dataset. I have searched for it everywhere and also scraped data from Google image search, but none seem to be good.
I want the dataset for object detection training.
Any help is appreciated.",not_spam
"Hi All,

I was wondering if there exists a data set for people who died from suicide in the Us at least.

there is a lot of data showing trends in suicide by I couldn't find anything related to personnel information of those people.

Any ideas?",not_spam
" Hey can you tell me, how will I find cancer patient GIS data for India?",not_spam
"Does anyone know the sources for raw data?

I  found a few websites that visualize the data, but can't find any raw  data sets. I even tried looking at network calls in Chrome devtools to  see if the sites are querying an api endpoint for the data. I am really  surprised there is not more interest for this in this reddit and [r/dataisbeatiful](https://www.reddit.com/r/dataisbeatiful/)

[https://calculla.com/coronavirus\_2020](https://calculla.com/coronavirus_2020)  
[https://bnonews.com/index.php/2020/01/the-latest-coronavirus-cases/](https://bnonews.com/index.php/2020/01/the-latest-coronavirus-cases/)  
[https://thewuhanvirus.com/](https://thewuhanvirus.com/)  
[https://3g.dxy.cn/newh5/view/pneumonia?scene=2&amp;clicktime=1579582238&amp;enterid=1579582238&amp;from=singlemessage&amp;isappinstalled=0](https://3g.dxy.cn/newh5/view/pneumonia?scene=2&amp;clicktime=1579582238&amp;enterid=1579582238&amp;from=singlemessage&amp;isappinstalled=0)  
[https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6)",not_spam
"First, I would like to extend a very heartfelt thank you to /u/PineappleFund for their generous contribution to Pushshift.io.  Their contribution has enabled us to increase our services to the academic community and has cemented the long-term viability of the project.  

**Let's talk about Project Discovery!**

With that said, I want to talk about a new project that will help take research to the next level and to get the community's opinions, suggestions and support for this new project.  While the contribution made by Pineapple was extremely generous, in order to turn this project into a reality, we will need a bit more resources to see it through.

**What is this all about?**

A lot of academic institutions and data scientists use my monthly Reddit dumps to do amazing research.  If you [check out Google Scholar](https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C21&amp;q=Pushshift.io&amp;btnG=), you will see that two dozen papers have been published using this valuable data source.  

There have been some interesting research on the data using machine learning.  Unfortunately, the data size is huge and not everyone can afford the resources needed to do amazing research on this data.  This is something I'd like to change with your help.

The new project is tentatively called **Project Discovery** and it involves bringing together the best data scientists, data visualization experts and machine learning / NLP researchers on Reddit and within the academic community at large.  

My goal is to create a time-share server that allows many researchers and data scientists to analyze massive amounts of data using huge computer resources.  The amount of funding needed to see this through will be in the range of $30-$40 thousand dollars, but Pineapplefund's contribution is enough to get the framework together and create an expandable server that can grow over time.  

As many of you know, Nvidia recently released their [Titan V](https://www.nvidia.com/en-us/titan/titan-v/) GPU with Tensorflow processors.  This card is capable of up to 110 teraflops of processing power.  I want to include this in Project Discovery so that experts in machine learning can use this power to help analyze big data. 

I am putting together an extremely powerful development server that will be shared with researchers.  It will include the entire Reddit data corpus and also constantly update with new Reddit data from my ingest.  

**The end goal specs for this server include:**

- [Dual Epyc CPU Motherboard](https://www.supermicro.com/Aplus/motherboard/EPYC7000/H11DSU-iN.cfm) that supports two AMD Epyc CPU's.

- (2) [AMD EPYC 7601](http://www.amd.com/en/products/cpu/amd-epyc-7601) with 32 cores (64 Threads total).  This would give a total of 128 threads for the system

- Samsung Memory (32 or 64GB ECC DIMMS).  It would be awesome to go with the 64GB DIMMS to support a total system memory of 2TB but my goal is to get at least a minimum of 1TB of memory which we can do with 32GB x 32 memory slots.

- 6 TB of NVMe storage utilizing [Samsung's 2TB NVMe drives](https://www.amazon.com/Samsung-960-PRO-Internal-MZ-V6P2T0BW/dp/B01LY3Y9PH)

- 12 TB of SSD storage utilizing 3 of [Samsung's 4TB SSD](https://www.amazon.com/Samsung-2-5-Inch-Internal-MZ-75E4T0B-AM/dp/B01G844OOO) drives.

- 48 TB of [Platter storage](https://www.amazon.com/Seagate-BarraCuda-3-5-Inch-Internal-ST12000DM0007/dp/B075XNL17G) for backup purposes.

- (1) Nvidia Titan V GPU for tensorflow / machine learning projects.  

I want to get feedback from the community for all of this.  Especially the OS that will be used for the main server.  I will have (2) smaller development servers with ~ 128 GB of memory to test code before running the code on the larger server.  Each of the smaller development servers will have the complete Reddit corpus as well.  

**Operating System and Sysadmin support needed**

The OS I am leaning towards is Ubuntu 16.04 LTS (at least until Ubuntu 18.04 LTS becomes available).  All of the servers will have a 300Mbps fiber connection to the internet.  

I will also need assistance from sysadmins with experience setting up multi-user environments and to make sure that we have proper security in place for Project Discovery.  

As this project progresses into 2018, I will have a sign-up form for academic students and researchers so that they can get set up with an account and get access to all the various servers.  We will have to come up with a plan for time-share when using the Titan V (once we are able to get that).  

I may do a kickstarter (a 50K kickstarter would be enough to see this come alive in 2018) to get the rest of the needed funding.  I will work with some of the other /r/datasets mods who have experience with machine learning and figure out the needed funds to make this amazing project come to life.  Memory costs will be around $10k for 32 of the 32GB DIMMs.  The two Epyc server CPU's will be ~ $10k for both of them.  The storage aspects will be around $5-$10k total.  And the Titan V card is around $3k.  It will probably be beneficial to reach out to AMD to see if they would like to contribute to this project (along with Nvidia and Samsung).  

The server can also be scaled up (use one CPU to begin and then scale up to 2).  

If this can happen, it would be a huge huge huge benefit to the academic community at large.  I know a lot of extremely smart data scientists who could do amazing things with these resources, so I will do my best to make this a reality for 2018.

Again, if you have any thoughts or ideas, please let me know!  

**Pre-installed Software**

I know that software developers and researchers have different preferences on what type of database systems they would like to use.  To that end, I would like to support as many open-source products as possible so that everyone has the tools they need for their project.  Here is a short list of open-source products that will be available:

- PostgreSQL 
- MySQL / MariaDB
- MongoDB
- CouchDB
- Hadoop
- Apache Derby
- Redis
- Elasticsearch (6.x)
- Apache Lucene
- Python3 with R, Numpy, etc.  If you need a module, we'll install it.
- Python 2
- Perl 
- Node.js
- Java


Here is a recap of the end goal for the system:

Attribute|Value
--:|:--
Min System Memory|1,024 GB
# of Physical Cores|64
# of Threads|128
Peak CPU Performance|2,480 GigaFLOPS
NVMe Storage|6 TB
SSD Storage|12 TB
Platter Backup Storage|48 TB
GPU Tensor Cores|640
GPU CUDA Cores|5120
GPU Clock|1455Mhz
GPU Frame Buffer| 12 GB HBM2
GPU Performance|110 TeraFLOPS

_________________________

**Auxiliary Development Servers** (2)

Attribute|Value
--:|:--
CPU Type|Xeon D-1528
CPU Cores|6
CPU Threads|12
System Memory|128 GB
NVMe Storage|1 TB


Happy Holidays!",not_spam
I am trying to figure out up to date percentages about how many iphone models are in circulation/use. Like for example how many 3gs are in use/circulation or iphone 4 etc. I have spent time googling it and can only find sales data figures. Maybe you guys can help me. Thanks.,not_spam
"Amazing Deal: Get 50% off on our premium membership if you sign up now! Don't wait, this deal won't last forever! 

",spam
"Hi guys, Im doing school project and I would like to know if exists something like database of movie scenes tagged based on what's happening in the scenes, or what objects are in the shot.

For example when I would need to know in which year were the most movies with people using blenders or just blenders appearing in the scenes and how many times per movie? Does anything like that exists? All I have found were sites where you can search in movie scenes based on dialogue. :-/ 

I will be thankful for any advice. ",not_spam
"I am looking for a data set with these fields: \['author', 'text', 'label' (fake or real)\]  


I have already seen this one: [https://www.kaggle.com/c/fake-news](https://www.kaggle.com/c/fake-news) I am looking for another one. 

Also, I am conducting research in fake news detection using author profiling.",not_spam
I want a dataset having different invoices in it. I need them in my machine learning project which can simplify the e-invoicing process. If anyone has access to any dataset like this then please do tell.,not_spam
"I was looking through wikipedia of lists of various social media top tens e.g. most followed instagram, most viewed youtube video etc. but when I checked some of the citations I noticed different website had different rankings.

Does anyone know what is going on? Is one of them wrong or does it have something to do with how they measure each metric? Are there any reliable sources where I can look these things up myself?

As an example, here are two tracking websites rankings for most followed Instagram accounts.

[Trackalytics](https://www.trackalytics.com/the-most-followed-instagram-profiles/page/1/)

[Social Blade](https://socialblade.com/instagram/)

And the wikipedia pages say their lists are current as of this month so it makes me wonder who they are actually using as a source.",not_spam
"Hi, 

I'm looking for a question answer dataset, hopefully in a CSV format. 

I have trouble preprocessing json datasets thus my request. 

Also if there is any text preprocessing code both on json files or csv, that would be of great help since i'm new to ML. 

Thanks",not_spam
"""Make $$$ fast with our amazing new app!!! Just click here to download and start earning BIG BUCKS today!!! ğŸ’°ğŸ’°ğŸ’°ğŸ“ˆğŸ“ˆğŸ“ˆ""

",spam
Does anyone have a dataset of all ISO3166-2 country codes with provincial codes and names?,not_spam
"HEY Y'ALL!! Check this out!! Do you want to earn BIG MONEY fast?!? Well, now you can! Join our exclusive online community and start making bank in just a few clicks! 

Our platform offers unlimited opportunities for you to earn money from home, without any prior experience or skills needed. Just sign up and start earning TODAY!

Plus, with our amazing referral program, you can earn even more money by inviting your friends to the platform. The more people you refer, the more cash you can earn! It's a win-win situation!

But that's not all! We also have tons of exciting giveaways and contests happening",spam
"URGENT ALERT: YOU WON'T BELIEVE WHAT'S HAPPENING NOW!!!

OMG, OMG, OMG! You definitely don't want to miss out on our latest deals and offers! They're so good, they'll make you want to dance the floss for hours on end!

But that's not all! We've got some insane giveaways happening RIGHT NOW! Just spin the wheel of fortune and you could win a year's worth of free ice cream, an all-expenses-paid holiday, or even a new car! Yeah, you read that right, A NEW CAR!

And that's not even the best part!",spam
"BOOST YOUR FOLLOWERS WITH OUR AMAZING PROMO DEAL!

Hey everyone! Are you tired of being a loner on social media? Do you want to have thousands of followers and likes? Well, you're in luck! Our company can help you boost your followers with our amazing promo deal!

For a limited time only, we're offering a special deal where you can get 10,000 followers for only $20! That's right, you read that correctly! Ten. Thousand. Followers. For only 20 bucks! And if you act fast, we'll even throw in an extra 5,000 likes for free!

But",spam
"Discover the ultimate way to get rich quick with our exclusive money-making scheme! ğŸ’°ğŸ’°ğŸ’° Stop wasting time at your boring job and start raking in the cash with our proven system. Just sign up now and watch the money pour in!

",spam
"""Get ready to SURPRISE yourself with our AMAZING new feature!!! Click now to enter and receive FREE access to our exclusive online content!!!!""

",spam
"Don't have time for boring chit-chat, finstas? Want to be an influencer and have all the cool kids following your every move? Then you gotta check out our new and improved social media app! We've got all the latest filters and effects to make sure your pics and vids stand out from the rest. Plus, we've got a ton of bots and fake accounts to boost your following and make you look like a star!

But wait, there's more! We've also got a personalized algorithm that will tailor your feed to only show you the most popular posts and influencers, so you don't have to waste your",spam
"Amazing new weight loss trick revealed! Shed pounds fast with our revolutionary diet pill now! Limited time offer, act fast!

",spam
"Hey, Iâ€™d like to train a classifier to classify political/philosophical positions given a sentence. 

Eg if someone says â€œI support Bidenâ€ thatâ€™s classified as â€œDemocratâ€

If they say â€œMarx was rightâ€ thatâ€™s classified as â€œCommunismâ€ 

If they say â€œthe researcher always influences what is observed via their background. There can always be bias.â€ itâ€™s classified as â€œPost positivismâ€ 


And so on. 

Even something roughly in the ballpark Iâ€™d be interested in. Or tips on how I might go about scraping/generating this dataset myself.",not_spam
"I'm looking for a dataset with playlists generated by users, something like playlists from grooveshark or 8tracks. 

Thanks",not_spam
"Hi everyone! Got this problem: i need to do a prediction of when two classes in a plot will ""touch"" themselfes.
I know value over the time (1,2,3,4,5) and i need to know WHEN (6?,7?,8?,...) red will be higher than blue.
https://imgur.com/wYYI8Vx",not_spam
"**[nfl_dataset_2002-2019week6.csv \(Google Drive link\)](https://drive.google.com/file/d/143NanTexjsO42kXlG8GjDbkSJ-sSKHC9/view)**

I scraped all the NFL game stats on ESPN from 2002 through present (2019 Week 6). Not the Box Score but the Team Stats page.

I grabbed all regular season and playoff games but excluded preseason and Pro Bowl. There are 4628 games in the dataset. Three games didn't have working pages on ESPN. Those are:

* [DAL @ WASH 12-30-2007](https://www.espn.com/nfl/matchup?gameId=271230028)
* [CAR @ PIT 12-23-2010](https://www.espn.com/nfl/matchup?gameId=301223023)
* [TB @ ATL 01-01-2012](https://www.espn.com/nfl/matchup?gameId=320101001)

Each stat has a column for the away team and the home team:

* date
* teams
* first downs
* third down conversions-attempts
* fourth down conversions-attempts
* passing yards
* rushing yards
* total yards
* pass completions-attempts
* sacks number-yards
* rushing attempts
* fumbles
* interceptions
* total turnovers
* penalties number-yards
* redzone conversions-trips
* total drives
* defense and special teams TDs
* time of possession
* score

Those aren't the exact column labels but you get the idea.

One thing I noticed is that red zone conversions aren't recorded until 2006. I haven't noticed any other quirks but I also haven't looked very closely yet. There is also nothing to indicate neutral-site games so keep that in mind.

I'll probably organize the data better and post it on Kaggle when the season is over. But I don't want to post mid-season and I thought somebody might find it useful in the meantime. Let me know if you find any errors.",not_spam
"WELCOME TO FACEBORK!

So much wow! You are finally here! And it's time to make some noise, people!

Are you tired of your boring life? Do you want to spice it up with some hardcore fun? Then Facebork is the ultimate destination for you!

Join us and get access to exclusive viral videos of cute kittens, funny memes, and sexy singles in your area! Plus, you will be able to share your own content with millions of other users worldwide!

And guess what? We won't even charge you a penny! That's right, our services are totally free! So sign up now and start",spam
"I'm doing internships and I have to use a word2vec model for searching some diseases for doctor.

Right now I'm trying to build an accurate model, and for that I'm taking a lot of papers about medicine from PubMed.

But my problem starts in papers written in 2 columns, with words cut in two because of the lines (example: ...in a big ci- (next line)ty... ) so I don't if there are some typical ways to approach this kind of problems or an easy way to preprocess this kind of things.

Today I discover Able2Extract and when I parsed the pdf to html I saw it created different kinds of types for each type of font, so I thought this could be a good way to deal with superscript but no with 2 columns because it puts all the lines wrong (it put first line of one column and then the first from the other column).",not_spam
"Yo peeps! Have ya'll heard about the latest and greatest thing in town? It's so lit, you won't even believe it! Let me tell you all about it.

",spam
"CoNgRaTuLaTiOnS!! YoU'vE bEeN sElEcTeD aS a WiNnEr!!! 
",spam
"Check out these amazing deals! Get a FREE iPhone with every purchase of our new product! Limited Time Offer!!! Don't miss out on this opportunity to have the latest technology in your hands. 

",spam
"\[request included\]

Now that HiQ has won the lawsuit against LinkedIn making it legal to scrape data, what is the best way to create a dataset to track career history &amp; movement within a sector? If you have done a project like this in the past, send me a message! 

What are some difficulties involved in getting this information off LinkedIn?",not_spam
Where can I get Phasor measurement unit datasets for power system parameters reading?,not_spam
"Exclusive offer for you!!! ğŸ‰ğŸ‰ğŸ‰

ğŸ‘‰Get FREE exclusive access to our premium content by subscribing to our service now!

Don't miss out on this amazing opportunity to access our exclusive content that is only available to our subscribers!

ğŸ’°ğŸ’°ğŸ’°Plus, for a limited time only, we are offering a special discount for new subscribers! Don't miss out on this amazing deal!ğŸ’°ğŸ’°ğŸ’°

ğŸ“±ğŸ“±ğŸ“±Subscribe now to our service to start enjoying all the benefits of being a member!ğŸ“±ğŸ“±ğŸ“±",spam
One of the students I tutor canâ€™t find a good data set and I told him Iâ€™d help. Anything is better than nothing drop everything you can.,not_spam
"Are you tired of not getting enough likes and followers on your profile? Well, we have got the perfect solution for you! Our exclusive service offers you thousands of fake followers, likes, and comments, so you can boost your online presence and become a social media star in no time! Yes, you read that right! We offer you the opportunity to cheat your way to fame, and nobody will ever know.

",spam
"""CLICK HERE NOW for the best deals on weight loss pills and diet supplements! You won't find prices like this anywhere else! Lose weight fast and easily with our miracle pills! ORDER NOW before they're all gone!""

",spam
"I have a set of Profile pictures that I would like to assign a Ethnicity to.
However, I don't have any training set, and I am looking for a dataset having Face Images with a labeled Ethnicity.
Anybody knows if such a dataset exists?",not_spam
"Get rich quick with our amazing new investment platform! We guarantee huge returns in just a few short weeks! Don't miss out on this incredible opportunity to make money fast!

",spam
"URGENT: THIS IS NOT A DRILL! Get your FREE iPhone X now by clicking on this link! Limited time offer only!

",spam
"Win a FREE iPhone X today! Just click on the link below and fill out your personal information to enter the giveaway. Don't miss out on this opportunity to upgrade your phone!

",spam
"Hey there, peeps! Are you ready for the ultimate social media experience? We've got everything you need! From cute cat videos to inspiring quotes and memes, we've got it all!

But wait, that's not all! We've also got a bunch of ads that'll totally make your day! Need to lose weight fast? We've got the perfect product for you! Want a bigger, better, and bolder you? We've got supplements that'll blow your mind (and your wallet)!

Oh, and did we mention our exclusive clickbait articles? You won't believe what happens when you read them! They",spam
"Does anyone know of a dataset that lists the plants, or better yet plants that are known allergens, in a region? If in the US, maybe state by state, or larger regions? If international, then country by country?",not_spam
"Have any of the larger March Madness bracket challenge hosts  (ESPN, Yahoo, etc.) ever released data on individual participant/contestant picks for each match-up of the tournament?  Ideally, there would be a data containing game\_id, round,  user\_selected\_winner, user\_selected\_loser for each game in the tournament and each contestant in a pool. 

Does anyone have a source for information of this type? I believe the NCAA has partnered with GCP to release statistical data, but I do not think this would covered.",not_spam
"""Get rich quick with this amazing scam that will have you raking in the dough! Just click on this link and put in your personal information, and you'll be on your way to a life of luxury and ease!""

",spam
"Hi guys.

I need to a dataset to the temperature of the world in CVS, so I'm searching only a file with the principal city for each country of the world, an example:

\- Name City

\- Longitudine (if is possible)

\- Latitudine (if is possible)

\- temperature average (or minimum and/maximum)

&amp;#x200B;

Sory the stupid question.

&amp;#x200B;

Have a good day.",not_spam
"I working on an economics paper for undergrad. I trying to find a difference between Religious affiliates and non religious people with they amount they give to charity. 
If anyone knows any useful data set it would be a huge help.",not_spam
"Hey, everyone.

I'm working on an infographic and I need a reliable source/s that would contain information about the average temperature in every continent over the period of the last 100 years (at least). It could be by year or by decade.

I'll really appreciate any help I can get as I need specific data for this project and can't seem to find any source on the internet that would include all the info I need.

Many thanks!",not_spam
You are tasked with an open-ended problem statement to develop a data product that can measure the affluence in localities of metro cities in India. Choose the city that you are most comfortable with. How would go about solving this problem? Which data sources would you use?,not_spam
 **Course for Anyone looking to Learn All About Machine Learning :** [https://www.web-learning.tech/2020/05/learn-machine-learning-from-scratch.html](https://www.web-learning.tech/2020/05/learn-machine-learning-from-scratch.html),not_spam
"Buy now! Amazing deals on weight loss supplements and diet plans! Lose 10 pounds in a week! Transform your body and impress your friends! Don't miss this limited time offer!

",spam
"Lk all! Welcme to ur favorite place on the internt! We have lots of grt stff for yu today, so get redy to be amazed! 

",spam
"Yo peeps! Check out this sick new trend that's blowing up all over the gram rn! It's called the ""food baby challenge"" and it's seriously lit ğŸ”¥ Basically, you eat as much as you can in one sitting and then suck in your belly to make it look like you're pregnant. I know it sounds cray, but trust me, the pics are hilarious ğŸ¤£ 

But wait, there's more! If you follow our page and tag us in your food baby pics, you could be entered to win some dope prizes like a year's supply of tummy-taming tea or a free waxing session",spam
"Hi all, 

Iâ€™m looking for speech to text data from police pull over interactions with drivers.

Basically what did the cop say, what was the driverâ€™s response and so on. Iâ€™m not sure if this data is even available but if it is and you know where I can find it, please share.",not_spam
"With every pokemon, attack, item etc. 
I want to make an app and need an as complete as possible dataset for it",not_spam
"FREE 1000000 DOLLARS GIVEAWAY!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

That's right, you heard it here first folks! [Social Network] is giving away ONE MILLION DOLLARS to one lucky winner for FREE!

All you have to do is FOLLOW our page, LIKE this post, and TAG 10 friends in the comments below! ğŸ˜ğŸ˜ğŸ˜

But wait, there's more! If you SHARE this post on your feed and STORY, you'll get an EXTRA chance to win! ğŸğŸğŸ

Don't miss out on your",spam
"I have an assignment that Iâ€™m working on and Iâ€™m stumped. 

I am writing a paper analyzing rule-based vs relation-based countries and how it impacts international business. 

I canâ€™t for the life of me find enough variables to measure this or differentiate between rules or relationship. 

There have been a few surveys measuring trust but that was all I could really find. 

Does anyone here have any experience doing an analysis like this or could think of some variable examples?",not_spam
"L@@K @LL!!! 
Ur inzta feed iz BORING, rite? No wories! I got sum hot tipz 4 u.
 
F1rst, u gotta follow 10,000 random accountz (don't matter who dey r) to get sum followerz. Then after dat, post like 30 pix a dai, even if dat dun make sens. U can use Sum random hash tagz like #F4F #L4L #Followback #Unfollowable #Spamforfollow to get more attention.
 
BUT DAT'Z NOT ALL! 
U",spam
"""OMG! You won't believe what we have in store for you today!!! ğŸ˜±ğŸ¤­ Our new product is like, totally revolutionizing the way you do things! ğŸ˜ğŸ™Œ You NEED to check it out! ğŸ¤‘ğŸ’° But wait, there's more!!! If you buy now, you'll get a FREE gift! ğŸğŸ‰ Don't miss out on this AMAZING offer!!! ğŸ”¥ğŸ”¥ğŸ”¥""

",spam
"Hello,

I was wondering if anyone knew of a set of data for the 2015 baseball schedule that included time that the game started at, which team sports analysts predicted would win, and attendance for the game. I already have the data from baseball-reference.com. It is less important to me to see which team sports analysts predicted to win, but if it is possible I would love to have that data. 

For stadiums, I would like info on their wall height, turf type, maximum capacity, and average attendance.

Thank you in advance for helping!",not_spam
"Attention everyone! Get ready to have your minds BLOWN with the latest and greatest updates on our platform! Weâ€™ve jam-packed our site with an UNLIMITED amount of spam and ads, just for you! 

You won't believe the amount of emojis weâ€™ve got for you to use, so don't be shy and spam away! And don't forget about our new feature, where you can buy followers and likes for a small fortune! Why bother putting in the effort to create interesting and engaging content when you can buy everything you need? 

Of course, we won't forget about the fantastic offers we have in store for you",spam
"Power up your feed with the new and improved super-charged update! ğŸš€ğŸ’¥ Don't be left behind in the social media race, join our elite group of verified influencers now! ğŸ¤‘ğŸ’°
",spam
Instant Gramz is LIT right now! ğŸ”¥ğŸ”¥ğŸ”¥We've got the most FIRE pics and videos from the HOTTEST influencers and celebs. Follow us for some straight up INSPO and lifestyle goals ğŸ˜ğŸ’ªğŸ’° Oh and don't forget to check out our sick giveaways and special offers for our loyal followers ğŸ‰ğŸ #staytuned #instagood #winbig #blessed #motivationmonday #litfam #gucci #yolo #basic #ornah,spam
"Hey guys, I am a real noob here and have never done a collection of data. I do love data though and would like to start collecting some of the info from my daily life. The first thing would be getting travel times from home to work and vice versa. Essentially I would like to log data about travel time and possibly congestion. Say for every minute or 5 minute period for a few hours in the morning and afternoon. I really have no idea where to start and would appreciate a hand in pointing me in the right direction.

edit: I was hoping to graph the ETA to and from work, then overlay the time I took and at what time periods I would leave. This would involve downloading some of Google's ETAs for my route if possible?",not_spam
"Iâ€™m on the hunt for a dataset which shows the number of males and females that are confirmed to have died due to COVID19. At this stage Iâ€™m not overly concerned which population based on geography.  So if itâ€™s Australua or Zimbabwe - Im down with it. As long as i can see on X date Y men died and Z women died...itâ€™s Ok.   
Thanks.",not_spam
"ğŸ’Š Do you suffer from erectile dysfunction? ğŸ†ğŸ™…â€â™‚ï¸ Don't worry, we have just the solution for you! Our magic pills will have you lasting all night long ğŸ˜‰ Order now and receive 50% off your first purchase ğŸ‰ Don't let ED ruin your sex life any longer! ğŸ’ªğŸ¼

",spam
"Hello guys, you all might know by now that Uber and Grab have merged in South East Asia. With this, they removed Manila Uber Movement data. I was hoping if any of you had downloaded some of the data, if not all? ",not_spam
"##Data (ndjson files)

###April
https://files.pushshift.io/reddit/comments/RC_2018_04.xz

8,371,376,260 bytes (compressed) | 82,497,938,640 bytes (uncompressed)

98,096,451 comments


###May
https://files.pushshift.io/reddit/comments/RC_2018_05.xz

8,633,799,504 bytes (compressed)  | 84,330,099,226 bytes (uncompressed)


100,109,100 comments",not_spam
"One word: BUY. Buy everything you need and don't need here, now, with our exclusive deals that will blow your mind! 

",spam
"Introducing the most epic social network of all time!!! You won't believe what this amazing app can doooooo!!! 

",spam
"I'm looking for a list of films and TV shows - (names, release dates, end dates for TV, number of seasons for TV); Actors (and a list of films/shows they were in), and producers (names and a list of films/shows they worked on).

Aside from the above, I don't really need anything else.

Does anyone know where I can obtain such a dataset?",not_spam
Can anyone provide me with Indian Sign Language Dataset that contains expressions  too  and not just alphabets and digits?,not_spam
"Of course, I know the big all-encompassing research sets like COW and POLITY, but I was wondering if anyone else knows good data/articles for this. I am specifically researching the relationship between freedoms of speech/press and how they relate to public sentiment or the sentiment of the press. Does anyone know good research or data on this? 

This college student will greatly appreciate it!",not_spam
Are they created by directly querying a database/warehouse/lake? Are they created through using Data APIs? Are they usually limited to a certain number of data points?,not_spam
"After download the comments files from [https://files.pushshift.io/reddit/comments/](https://files.pushshift.io/reddit/comments/),  I tried to compress the .zst file, but I failed. emmmmm...  So, in what way I can get the data from the .zst file.",not_spam
"Are you tired of your boring life? Do you crave excitement and adventure? Well, look no further because our social network has got you covered! 

Join us now and explore a world of wonder! Meet new people, share your thoughts, and experience the thrill of unlimited possibilities. Don't wait another day, sign up now and start living your best life!

",spam
"I'm doing my first econometrics project, so I'm still new at obtaining good data.  I'm hoping to find some sort of data on employee satisfaction, wage ratio (inequality), productivity, unemployment, etcetera in worker cooperative networks such as in the Mondragon cooperatives of Spain, some kibbutzim networks in Israel, and/or other such movements in the United States.",not_spam
"For example: from whiterun to riverwood there's a 5 min walk time  
It's a complicated set to organize on its own XD  
I don't think this kind of data would even exist. But on the off chance it does, I would love to practice python programming with it :)",not_spam
"Hello everyone,

Last year I crawled the Super Mario Maker Bookmark and produced a dataset, called SMMnet.

Now it is publicity and available at [https://www.kaggle.com/leomauro/smmnet](https://www.kaggle.com/leomauro/smmnet).

This dataset has temporal changes over 120k game maps, and actions of over 880k players over time;  SMMnet serves as a good base for learning models, including, but  not limited to, **Player Modeling** (e.g., player experience), **Data Mining** (e.g., prediction, and find patterns), and **Social Network Analysis**.

&amp;#x200B;

Enjoy!",not_spam
"Would this be beneficial to anyone for research, etc?",not_spam
I  have a dataset with Images in it. How do I randomize it? Can it be done using a script with Python by renaming files in a random order? Help would be appreciated.,not_spam
"Istanbul Metropolitan Municipality has released city datas. 
Categories: Transportation, Environment, Energy, Life and Economy.
Link here:
https://data.ibb.gov.tr/en/",not_spam
"Hey everyone, pOpPINg in to let ya'll know about the HOTTEST deal of the century!!! Don't wait another MINUTE to get your hands on this LIMITED EDITION product that's sure to be a game changer!!! ğŸ”¥ğŸ”¥ğŸ”¥

But that's not all folks, we've got a special surprise for our loyal followers! For a limited time only, use the code ""SPAMSPAMSPAM"" at checkout for an EXTRA 50% off! That's right, 50% OFF!!! ğŸ¤‘ğŸ¤‘ğŸ¤‘

And while you're at it, be",spam
"A client wants me to train a (Keeping up with the) Kardashian text generator. 

How can I get some bigger Transcript samples from the show ? 

Can Anybody help me out here :/

&amp;#x200B;

Thanks in advance",not_spam
"Attention all users! Have you checked out the newest updates on our platform?? It's totally rad, dude! We've added tons of bells and whistles that'll make your online experience go from zero to hero in no time!

Don't waste any more precious seconds wondering what's up with your friends and famâ€“we've got you covered! Our algorithmic whiz-bangs will ensure that you never miss a beat. We know what you want before you even know it, baby!

And for all you single pringles out there, get ready to mingle like never before! Our dating feature is sleeker and smoother than ever. Swipe",spam
"I am facing the construction of a herbalism monograph database from scratch! I was tasked with providing this raw data for an online herbalism project. I have been unable, after weeks of searching, to find a raw database/spreadsheet. I understand this information could have taken someones entire career to compile and I would never want to belittle their work. I am hoping to find someone who is willing to share it freely (with all credit given to them for the information) or someone who can point me in the right direction of where to find it. Any advice or information on this topic would be extremely appreciated. Please let me know if you need any clarification on this question. I am looking for mainly: common name, Latin name, toxicity, usage, side effects, dosage... the more information the better!",not_spam
"ğŸš© ALERT! ğŸš© AMAZING OFFER FOR LIMITED PERIOD ONLY! ğŸ‰

ğŸ GET 50% OFF on our new subscription plans, and enjoy exclusive benefits like never before! ğŸ‰

ğŸ’¥ It's time to upgrade your account and unlock all the amazing features that you have been missing out on! ğŸ¤©

ğŸ‘ Hurry up and grab this opportunity now to have access to unlimited likes, followers, and comments! ğŸ™Œ

ğŸ“ˆ With our new algorithm, your profile will skyrocket and reach new heights of popularity and success! ğŸ”¥

",spam
"Hello /r/datasets!

## What?

On Friday, [ActBlue](https://secure.actblue.com/) filed their [2019 Year End Report](https://www.fec.gov/data/committee/C00401224/?tab=filings), and it's an absolute beast - the largest filing ever generated by the [Federal Election Commission](https://www.fec.gov/)! It contains 24,656,453 contributions by individuals totaling **$525,124,217.30**. 

We publicly open sourced [our analysis](https://github.com/CircaVictor/actblue-analysis-1378435) of the filing along with [state data sources](https://github.com/CircaVictor/actblue-analysis-1378435/tree/master/data/states). This type of data is never seen in a timely manner (or at all) and is a HUGE undertaking to export and analyze, examples:

* [https://fivethirtyeight.com/features/how-actblue-is-trying-to-turn-small-donations-into-a-blue-wave/](https://fivethirtyeight.com/features/how-actblue-is-trying-to-turn-small-donations-into-a-blue-wave/) [[data]](https://github.com/fivethirtyeight/actblue-analysis)
* [https://www.buzzfeednews.com/article/katherinemiller/elizabeth-warren-actblue-data-bernie-sanders-kamala-harris](https://www.buzzfeednews.com/article/katherinemiller/elizabeth-warren-actblue-data-bernie-sanders-kamala-harris) [[data]](https://github.com/BuzzFeedNews/2019-08-actblue-donations)

If you curious about some fresh high level data, here are some numbers that we pulled across the entire cycle for the [Iowa Caucus ](https://drive.google.com/drive/u/1/folders/18AMOMG01cyGgwTWTH0R_ZreRnNMTbCL2). Surprisingly a lot of individuals from [tech companies](https://i.imgur.com/nvGEsUy.png) (from Bernie's ""Overall by Employer"" tab) are now contributing.

## Additional Analysis

  * [Principal Committees by total](https://github.com/CircaVictor/actblue-analysis-1378435/blob/master/analysis/principal-committees-overall.csv)
  * [Individual contributors by total](https://github.com/CircaVictor/actblue-analysis-1378435/blob/master/analysis/individual-contributors-overall.csv)
  * [Zipcodes by average &gt;= 250 contributions](https://github.com/CircaVictor/actblue-analysis-1378435/blob/master/analysis/zip_codes-avg.csv)

## Who?

My name is Justin and I'm the cto cofounder of a nonpartisan company named [Circa Victor](https://circavictor.com/). Since 2015 we have taken a tech approach to political problems starting with Federal Campaign Finance.

To accomplish this goal, we created a clone of the [Federal Election Commission](https://www.fec.gov/) and have tracked EVERY data point that has been generated since January 1st, 2010.

## Why?

We feel that it's every citizen's right to be informed. We are not trying to push any political agenda. Our desire is data comprehension and accuracy. 

We __*strongly*__ believe that accurate, up-to-minute data will lead to better, responsible, and actionable reporting which in turn will help nurture an informed populace.

*Anecdotally*: I have a friend who worked at a payment processor (rhymes with pipe) and internally they felt Trump had a bigger chance of winning than the media lead on due to the sheer number of payments they were processing for him vs Hillary.

I'm NOT saying that Campaign Finance is the missing piece to figuring out who is going to win an election. However, campaign finance data is a LOT more concrete than polling data as polling data is relative. It's the missing vertical that most people are knowingly overlooking because they are not looking at it in an accurately and timely manner.

Unfortunately we feel that we are the only group actively working toward this. We have reached out to Committees, Non-Profits, Researchers, Campaign Finance leaders all with little to no traction. 

We are a small team of 4 guys (I'm the only software engineer; self-taught, didn't go to college) and we humbly admit that this problem is too big for us to solve alone. We need help and want to raise awareness. The best way we know how to do that is to press data into the public's hands.

---

To be more transparent, this data work does not make enough money to pay the bills. None of us have taken a paycheck since the Winter of 2017, but we have continued to work on this because we feel this is imporant.

To pay the bills, I work from Seattle as a remote software engineer for [PBS Kids](https://twitter.com/twaffl3s/status/1207163692787257344) - a job which I love and am very proud of.

Happy to answer any questions as time permits. Feel free to dm me if you want a response or if you're looking for more in depth data and analysis. Thank you.

---

**tldr;** we built a clone of the Federal Election Commission. As a public service we are open sourcing our analysis w/ data of the largest filing (ActBlue 1378435.fec) ever generated containing 24,656,453 contributions totaling $525,124,217.30.",not_spam
"Trying to not only improve your efficiency of your web crawler but also to create a web crawler faster?

Today I will share 5 tips from my experience to improve your efficiency when you are building a web crawler.

Hope you will like it and please leave a comment below on how you will increase efficiency of your web crawler.

[https://towardsdatascience.com/https-towardsdatascience-com-5-tips-to-create-a-more-reliable-web-crawler-3efb6878f8db](https://towardsdatascience.com/https-towardsdatascience-com-5-tips-to-create-a-more-reliable-web-crawler-3efb6878f8db)",not_spam
"Im currently writing my dissertation and using a covid-19 Tweet dataset as the basis of a sentiment analysis. However, I am looking into why Twitter datasets are much more common than Facebook posts? 

There are a couple of reasons I can think of, such as being easier to scan through hashtags on Twitter and private facebook accounts, but nothing with hard facts. 

Is there a specific reason? Thanks",not_spam
"Hey there peeps! I've got some crazy news to share with y'all today! Are you ready? Okay, so listen up: have you heard about this amazing product that will change your life forever? It's called ""SlimmySlim"" and it's a miracle weight loss pill that'll help you shed those pounds faster than you can say ""fried chicken."" 

But wait, there's more! If you order now, you'll also get a free trial of ""MaxiMuscles,"" the ultimate muscle-building supplement. With just one scoop a day, you'll be ripped in no time. And if you're not satisfied",spam
"""50% OFF on all weight loss supplements now! Don't miss out on this amazing deal! Get your dream body in just weeks with our miracle products! Limited time offer, buy now!""

",spam
Preferably 2015-2020 dataset. I've already checked UCI datasets but size is less than 1k rows. I need at least 8k rows. Thank you in advance,not_spam
"I am a researcher trying to recreate results from table detection/recognition papers from various sources, include ICDAR 2019.   


Most of the models have been trained on UW3, UNLV, ICDAR POD 2017, Marmot and ICDAR 2013 datasets.   


They are apparently publicly available, but the links for the mentioned datasets have been broken.   
If you have the datasets, please comment and post a link, or mention that you have it so that I can send my email address for you to send it directly. Thank you!",not_spam
"Wazzup, peeps of the internet? We got some super exciting news for y'all! 

First things first, we wanna talk about our new feature that'll blow your mind: a chatbot that'll guess what you're thinking about and recommend amazing products to buy based on it! Yeah, you heard that right, no more pesky thinking about what to buy, our chatbot's got your back. 

But wait, there's more! Want to win a free trip to Bali? All you gotta do is share this post, tag 20 friends, and follow our page. Easy peasy, right? 

Oh",spam
"Get rich quick with our amazing new program! Just sign up and watch the money roll in. It's so easy, anyone can do it!

",spam
"This is for my dissertation and so far Ive found many articles that talk about using Data science/technology to combat sustainability but Ive ben asked to to have actual collected data that I can analyse for secondary research. So, If anyone can help, that would be great. I'll also be looking in the meantime, it just feels like Im running out of time which is why Im asking for help on here!

Thank you in advance",not_spam
"Win a FREE iPhone! Click here to enter our giveaway! 
",spam
"Hey guys! Big news - our amazing app just got even better! Now with even more emojis and filters for your selfies. Plus, don't forget to follow us on all our social media platforms. 
",spam
"Urgent Alert! Great news for all you social media lovers out there. Our network has just launched an amazing new feature that will make you go bananas! But before we tell you about it, let's dive into some juicy details.

",spam
"SUP FAM! Want to get rich fast?? Then you GOTTA check out this new investment opportunity I found! Itâ€™s like nothing youâ€™ve ever seen before, and trust me, youâ€™re gonna be rollinâ€™ in dough in no time!

All you have to do is invest a little bit of cash up front, and then sit back and watch as the profits start pouring in. And donâ€™t worry about the risk â€“ thereâ€™s absolutely NONE involved! Trust me, Iâ€™ve done all the research and this is the real deal.

But hurry up and get in on this before itâ€™s too late! This opportunity wonâ€™t last forever",spam
"""10k FOLLOWERS FOR $10!!""

That's right, folks! We have the best deal in town for all you social media junkies out there! With just a mere $10, we can give you TEN THOUSAND followers INSTANTLY! No need to wait months or even years to grow your followers organically. We'll do it for you in minutes!

But wait, there's more! With our premium package, you can get 50k followers for ONLY $30! That's right, fifty thousand followers for just thirty bucks!

And if you act fast, we'll throw in a FREE account verification!",spam
Trying to find a dataset on median household income/wages. Preferably over the last 20 years but less is okay too. US and Japan interest me most.,not_spam
I need a printed digits dataset similar to [this](https://www.kaggle.com/kshitijdhama/printed-digits-dataset). But there are only 350 images for each label and I think I need more than that for my model. I tried using MNIST data with this but that gave me poor performance on my test set which are digits extracted from sudoku.,not_spam
"Get rich quick! ğŸ’°ğŸ’°ğŸ’°

Are you tired of working hard for your money? Do you want to live a life of luxury without putting in any effort? Well, you're in luck because I've got the perfect solution for you. Join our exclusive get-rich-quick scheme and start raking in the cash today!

",spam
"Attention all users! You won't BELIEVE what I just found on this website! It's the newest, hottest, most mind-blowing trend that'll make you RICH in just 2 steps! Step 1: click on the link below, and Step 2: PROFIT!!!

But that's not all! We've got tons of FREE offers for you too! Sign up for our exclusive newsletter and get a FREE trial of our top-of-the-line product! And if you act fast, you'll also get a FREE bonus gift!

But wait, there's more! Follow us on all our social media platforms for",spam
"Hi all! As the title denotes, I'm taking an introductory statistics class this Summer, and we have a few projects over the course of the class.

Normally, we would just work off of the data sets supplied with the book, but since I'm a CS major and a programmer, I figured I would try my hand at writing something up in Python/R to analyze a larger set. However, I have no idea where to even begin!

For the first project, I am just looking for a set in which I could compare two separate population proportions - they can be either dependent or independent, I'll just be running basic hypothesis tests on them.

If anyone had any ideas, or could point me towards some noobie-friendly sites, it be an immense help! Thanks for reading.",not_spam
"L$OOK@ H3R3!!!  M#AK3 M0NEY FA$T WITH THI$ AMAZING OPP0RTUNITY!!!

",spam
"Introducing the ultimate social networking platform that will blow your mind! Get ready for tons of likes, followers, and viral content that will make you a social media superstar! Don't miss out on the chance to join our exclusive community of influencers, models, and celebrities who are taking over the internet!

",spam
[https://data.openup.org.ua/dataset/population-ukraine-sex-and-age](https://data.openup.org.ua/dataset/population-ukraine-sex-and-age),not_spam
"Mildly new to web scraping, cleaning, and consolidating big chunks of data. Will put GitHub link to code that generated the database sometime soon.

Variables:

* Confirmed Cases (at time *t*)
* Deaths (at time *t*)
* Recoveries (at time *t*)
* Total Confirmed Cases (up to time *t*)
* Total Deaths (up to time *t*)
* Total Recoveries (up to time *t*)

[https://salientmind.blog/blog/2020/3/19/covid-19-time-series-database-for-152-countries-and-regions](https://salientmind.blog/blog/2020/3/19/covid-19-time-series-database-for-152-countries-and-regions)

Update:

New, validated repository at [https://github.com/dominictarro/COVID-V2-DB](https://github.com/dominictarro/COVID-V2-DB).",not_spam
"I am looking to find a large dataset of searches for pornographic content both through search engines and sites themselves. Also any data on the images / videos actually viewed, categories selected by searchers etc.

I know that this information exists and is available from various sources but am unsure where in some cases or how to go about obtaining it in others.

The mother load would of course be Google data showing the terms directly entered into Google including sex and age range of the user.

I know pornhub release some great stats and they have given access to raw data to at least one author, Seth Stephens-Davidowitz, author of ""Everybody Lies"" which included at least data on the sex of the searcher. However I don't know how I would get at this.

A good while ago there was the leaked AOL data though I can't find the raw data set.

I would love it if I could get hold of stats from say xnxx.com, kink.com etc.

Also if there are any other porn related datasets out there that would be great.

Cheers

",not_spam
I am an undergrad student researching the effects of minimum wage on mental health and I was trying to find data on mental health but I couldn't seem to find any by State as the minimum wage changes in the state-level. If you know of any please let me know thank you!,not_spam
"FREE STUFF ALERT!!! We've got a bunch of giveaways to make your day!!! Just like and share this post, tag your friends, and comment with your favorite color ten times in a row to win!!!!!!! Hurry up! Limited time offer!!! ğŸ’©ğŸ’©ğŸ’©

",spam
"Buy our new product and you'll feel like a million bucks! It's the best thing since sliced bread (and who doesn't love sliced bread, am I right?) Plus, if you act fast, you'll get a discount that's crazier than a bag of cats!

",spam
"ğŸš¨ğŸš¨ğŸš¨ BIG NEWS ALERT ğŸš¨ğŸš¨ğŸš¨ 

Are you tired of boring old social media? Do you want to be part of the COOLEST, most RADICAL social network on the planet? Well, look no further, because you have FOUND IT! 

Introducing the HOTTEST new social network that EVERYONE is talking about... **CoolKidz**!! ğŸ¤™ğŸ¤™ğŸ¤™

At CoolKidz, we don't care about all that boring stuff like privacy, security, or quality content. No way! We're all about HYPE",spam
"Following an external report citing manipulation and unethical behavior at the highest levels of the organization, the World Bank just announced that they will be canceling the ""Doing Business"" dataset which informed almost all country-level global ""business climate"" indicators.  I would be curious if anyone knows a good replacement?    


P.S. Read the report, it is SCATHING: ([https://thedocs.worldbank.org/en/doc/84a922cc9273b7b120d49ad3b9e9d3f9-0090012021/original/DB-Investigation-Findings-and-Report-to-the-Board-of-Executive-Directors-September-15-2021.pdf](https://thedocs.worldbank.org/en/doc/84a922cc9273b7b120d49ad3b9e9d3f9-0090012021/original/DB-Investigation-Findings-and-Report-to-the-Board-of-Executive-Directors-September-15-2021.pdf))",not_spam
"Are you tired of being broke? Want to make easy money fast? Look no further, my comrades! I have the solution for you! Join our get-rich-quick scheme and watch the dollars pour in like rain. 

",spam
"Looking for loads of free stuff? Well, you're in luck! BuzzUp is the ONLY social network that's got you covered. We've got exclusive deals on everything you could possibly imagine, from clothes to tech to food and you don't have to do anything except sign up!!

Plus, we've got the latest gossip and news on all your favorite celebs - who's dating who, who's had plastic surgery, and who's been caught with their pants down. And if you're feeling lonely, don't worry! You can chat with our members and make new friends, or check out our selection of flirtatious singles in",spam
"Looking for ways to make money online? Look no further than our amazing platform! With our revolutionary system, you can become a millionaire overnight! Just sign up and start earning money right away!

",spam
"Need to lose weight fast? Try our new miracle pill, guaranteed to make you drop pounds in just days! Don't waste your time with diets or exercise, let our product do the work for you. Hurry and order now before supplies run out!

",spam
"Hi folks,

I'm trying to train my chatbot to answer some very specific questions for e-commerce, like 'what are your delivery options?' or 'what is your refund policy?' etc. I'm tired of imagining the ways customers ask such questions, so I decided to look for existing datasets, but without luck :(

So I'm wondering if someone could share datasets like customer support logs in e-commerce or something like that?

Many thanks!",not_spam
"Or the most common income . Not the median.    

Where can I find it for other countries too?  

I am willing to do a little self research if need be.

Thanks in advanced!",not_spam
"""C U L8R FOMO! U won't believe what u missed on Uptrendz yesterday #Yolo #Blessed #LifeGoals #FOMO #TGIF""

Hey, Uptrendz peeps! Did u miss out on the hottest trends and memes of the week? U better BELIEVE u did! Uptrendz is the ultimate place to be, and if u weren't part of it, then u probably don't even know what #FOMO means! But don't worry, we've got u covered. Here's a quick recap of all the ğŸ”¥ lit",spam
"Important message! ğŸš¨ğŸš¨ğŸš¨

Are you tired of getting ripped off by shady vendors? Well, listen up because I've got the solution you've been seeking! ğŸ’°ğŸ’°ğŸ’° 

Our new, revolutionary platform guarantees the ability to double, and even triple your investment returns in just a matter of days! ğŸ¤‘ğŸ¤‘ğŸ¤‘ 

Don't believe us? Check out the testimonials from our satisfied clients who have already made thousands! ğŸ“ˆğŸ“ˆğŸ“ˆ 

But act fast, because this offer won't be around forever! Sign up now and start living",spam
I have to analize and compare these datasets with another dataset that I managed to find (esports audience) with python. I searched everywhere but I couldn't find them.,not_spam
Hi. Is there any labelled dataset for suicidal ideation or depression detection from social media data?,not_spam
"https://github.com/YaboLee/reddit_crawler

Solution One: Acquire data from public data.

Solution Two: Acquire data according to subreddit.

More detail is included in the Readme.md. Why not leave me with your star and comments and critiques?

Note: Solution two needs your own reddit developed APP id &amp; secret.

**UPDATE:** I am sorry that this is really an immature experimental tool. There are many things I didn't consider, like the accurate API rules, JSON url, storage, continent...Thanks for your enjoyment, comments and critiques. I will try to revise it in the future! ",not_spam
"I'm having the internship with my Machine Learning teacher. We want to analyze the energy consumptions of some buildings but the data is sparse and not exciting. Do you know if there are some historical energy consumption datasets?

Thanks",not_spam
Gathered this info as part of a project. May be will be useful for someone.,not_spam
"FREE MONEY! DON'T MISS OUT!!!

Hey there, peeps! Are you tired of not having enough dough to buy everything you want? Well, guess what? I've got some great news for you! This is your lucky day because you're about to get rich! That's right, you heard me! RICH!

All you have to do is click on the link below and enter your personal info. No need to worry about privacy or security, this is the real deal, folks! Trust me, I'm an expert in getting rich quick schemes.

Oh, and that's not all! You also have the chance to win",spam
"Hey there!

Are you tired of the same old boring content on your social media feeds? Do you want to spice things up and add some pizzazz to your online persona? Well, look no further because SocialNet is here to help!

Our platform offers a plethora of options for you to explore and express yourself in ways you never thought possible. With our cutting-edge algorithms and user-friendly interface, you can easily connect with like-minded individuals from all over the world and share your thoughts, opinions, and interests.

But that's not all, folks! Our exclusive features will blow your mind! From personalized emoji packs to virtual reality goggles,",spam
"OMG! You would not believe the crazy dealz we have going on right now! Want FREE MONEY? Just click on this link and sign up for our amazing app! It's like getting paid to do nothing!

",spam
"WANT TO MAKE MONIES FAST??? CLICK NOW!!!!11

",spam
"Buy 1000 followers for only $5! That's right, get your social media game on point with our amazing deal! Don't wait, head to our website now and get famous in just one click!

",spam
"L@@king f@@r m0re F0110wers? BUY N0W!! 
We have the best deals on 1,000+ f0ll0wers f0r just $5 bucks!!! 
G@in instant p0pularity with our exclusive s0cial media services. 
N0 scams, N0 fake acc0unts, just real pe0ple wh0 will l0ve y0ur c0ntent. 
Get ahead 0f the c0mpetiti0n and start making m0ney fr0m y0ur inst@gr@m, twitter, and ",spam
"Get ready folks, because we've got some killer updates coming your way on our platform! You won't want to miss out on the heaping pile of garbage that we've got in store for you.

",spam
"ğŸ’¥â•ğŸ”¥LIMITED TIME OFFERğŸ”¥â•ğŸ’¥
Get 1000000 followers in just 1 day!!ğŸ¤¯
Guaranteed!ğŸ’ªğŸ¼

ğŸ‘‰ğŸ¼CLICK HERE TO CLAIMğŸ‘ˆğŸ¼

But wait, there's more!

ğŸ FREE BONUS ğŸ 
With your purchase, get a FREE guide to make millions in just one month!ğŸ¤‘

Don't miss out on this incredible offer! Limited time only!!ğŸ‘€",spam
"Hi,

&amp;#x200B;

A couple of months ago, I found that American Credit Score brokers/services in the US are publishing anonymized datasets about mortgages.

I wonder if there are similar data sources for the European market - Especially in Germany

&amp;#x200B;

From my previous post:

""...I want to make a research for my new company, and I find that it's really hard to find an anonymized mortgage proposals dataset.

I suppose the dataset should include features such as:

1. date
2. mortgage loan type
3. loan period
4. loan capacity (percentages)
5. borrowers amount
6. borrowers credit score
7. state
8. interest rate
9. etc

Do you familiar with this problem?

I will appreciate if you could help me find any kind of resource...""",not_spam
I'm currently trying to create a model that predicts drug trafficking routes based on previously apprehended smuggler's routes in Central America. Does anyone know where I would be able to find data to help with this?,not_spam
"ğŸ‘‹ URGENT MESSAGE TO ALL MY FOLLOWERS: YOU WON'T BELIEVE WHAT I HAVE TO TELL YOU ğŸš¨ğŸš¨ğŸš¨

ğŸ”¥ğŸ”¥ğŸ”¥ THE BEST DEAL OF YOUR LIFE IS HERE! ğŸ”¥ğŸ”¥ğŸ”¥
ğŸ¤‘ğŸ¤‘ğŸ¤‘ AMAZING OFFERS ON DIET PILLS, FITNESS PROGRAMS, AND SKIN PRODUCTS ğŸ¤‘ğŸ¤‘ğŸ¤‘

ğŸ’ªğŸ’ªğŸ’ª BE THE ENVY OF ALL YOUR FRIENDS WITH YOUR NEW SEXY BODY ğŸ’ªğŸ’ªğŸ’ª

",spam
"Get rich quick with our amazing investment opportunity! Join today and start earning big bucks in no time! Don't miss out on this chance to change your life!

",spam
"Get ready to have your mind blown with the most epic deals and discounts of the century! Don't wait, act now and get access to exclusive content, top-notch products and services, and unbeatable offers that will rock your world. 

",spam
"Hello all,

I am working on a realtime trash detecting app. I am looking for images of littered cigarette butts to tag and train for my machine learning model. Thank you in advance. ",not_spam
"Attention all netcitizens!! á·á½ á•á¥á¢á¬ á»áªáš á€OT á¢á»á¬ á·á¾ášá¢ á¬XCá†á¢á†Ná© á¢á¡á†áŸá¬áš á¬á™á¬á¡!!! ğŸ’²ğŸ’²ğŸ’²

Get your hands on the latest and greatest gadgets at unbelievably low prices! ğŸ”¥",spam
The post on here is a few years old and not longer works. Any help is appreciated!,not_spam
More here: [http://omnisci.link/o71c60](http://omnisci.link/o71c60),not_spam
"Get ready for the biggest, baddest sale ever! ğŸ’°ğŸ’°ğŸ’° Don't miss out on our amazing discounts, while supplies last! ğŸ›ï¸ğŸğŸ”¥
",spam
"Hi! I am doing some qualitative research and would like to download entire subreddits to code for themes and audience insights. Is there a way to do this without python?

Thanks!",not_spam
"BUY OUR PRODUCT NOW OR YOU'LL REGRET IT!

Are you tired of being broke and unsuccessful? Want to be 10x more attractive and make millions? Then our product is perfect for you! 

Our revolutionary formula is made of 100% natural ingredients that will magically transform your life in just a matter of seconds. You'll suddenly become the most popular person in your circle, and success will come knocking at your door in no time.

Not only that but buy now, and you'll also get 20% off your next purchase. Plus, you'll be entered into a draw to win a trip around the world on a",spam
"I am looking for London street level datasets, anything that could inform retail activity such as turnover, number of visitors, number of new vs old shops, retail types, maybe recent rent increases or decreases. I might be able to substitute it with rental property or home ownership data as long as the indicator gives me  some sort of street level footfall/density indicator
Thanks",not_spam
We have huge dumps of english text easily accessible for NLP. Where do you go to get large dumps of non-english text?,not_spam
"Iâ€™m looking for a dataset pertaining to the vegans and omnivores across the world relating their age, country  etc to their diet preference. 

Is there any source available? ",not_spam
"Join our network now and get access to a wide range of exclusive content that will blow your mind! You won't believe the amazing offers and promotions we have in store for you. Plus, our community is growing by the minute and you don't want to miss out on all the fun.

",spam
"""BUY NOW! Get the BEST DEALS on our exclusive products! They're totally AWESOME and will make you look like a GENIUS!""

",spam
"Saw a few posts interested in salary datasets. Just want to share a database with over 3 million salary data points (working visa jobs) for different positions of all levels in various industries, summarized based on Department of Labor data. 

 [https://www.easyh1b.com/](https://www.easyh1b.com/) 

The database is designed for easy search and data chart visualization.",not_spam
"eg i have a 1gig Twitter dataset i would like to share, but i ain't self-hosting it ! ",not_spam
"Hi everyone,

I'm trying to build an emotion detector from the text.

&amp;#x200B;

**Background**

I have an image dataset ([Behance dataset](https://bam-dataset.org/))  which classify the images to four emotions.

1. Happy
2. Peaceful
3. Gloomy
4. Scary

&amp;#x200B;

**Goal**

I want to find out the emotion of my text from the classifier, then select an image with a similar emotion image from my image dataset.

&amp;#x200B;

**What I've found so far?**

I've found multiple text sentiment datasets, but most of the times the emotion categories don't match with my image categories. Also, my text on interest is poetry, I wish I could get some dataset related to it. (Amazon reviews, tweets, etc. might not work well the poetry data I assume).

&amp;#x200B;

**What is ideal?**

If I can find a poetry/short songs lyrics dataset annotated with similar categories of emotions with my image dataset, it would be perfect.

&amp;#x200B;

**What is ok?**

A text dataset which is annotated with similar categories of emotions with my image dataset (eg. Gloomy -&gt; Sad, Scary-&gt; Fear).

&amp;#x200B;

Have anyone worked on related stuff? Any help is greatly appreciated in advance.",not_spam
"Just hoping to gather some feedback on tracking stats at a live game.

I come from an analytics background and playing football at a decent level, our manager was interested in getting some stats on our upcoming season so I volunteered to record and put the report together so I'm just pondering how to go about recording the stats live in a play by play manner I can manage to fill in as the game is being played

Doing this as both a personal project and to help our team if I can

Any advice is helpful",not_spam
"Attention all users of MySocialNetwork! You won't believe the latest and greatest updates we have in store for you. We've got more emojis than you can shake a stick at, and our new filter options will knock your socks off. But that's not all! We've got special premium features that will make your head spin - just sign up now and you can be part of our exclusive group of users who get all the extra juicy content. 

",spam
"Lose 30 pounds in 3 days with this miraculous new diet pill! Guaranteed to give you the body of a Greek god or goddess. Just enter your credit card information and watch the pounds melt away! Don't miss this opportunity to become a new you!

",spam
"Pulling together some Coronavirus dashboards, but Iâ€™m having trouble finding a dataset with Coronavirus counts more granular than state. Can anyone point me to a more granular dataset? Zip code, city, county? 

Thanks in advance and hope youâ€™re all staying safe!",not_spam
"Krazy Kristy here, bringing you the hottest garbage on the interwebz! You won't believe the craaaazy offers I've got for you today!

",spam
"Guys! OMG! You won't believe the craziness going down on our network right now! There's like, so much juicy drama and gossip going around, it's almost too much to handle!

",spam
"Hey! I have a project about using mathematical modeling for wireless optimization. I know this is very vague, but is there some dataset for wireless signals, interference , distance, etc?",not_spam
"""Unlock the secrets to getting rich quick with our revolutionary new system! Don't waste any more time working for someone else, become your own boss today! Our program guarantees maximum profits in no time! Join now and discover the easy path to financial freedom!""

",spam
"I'm a Data Science student at r/LambdaSchool, looking to get into health care. I just recently started looking into Genomics and Metabolomics; anybody have good data on that?",not_spam
"Wazzup my fellow netizens! Are you tired of lame old social media platforms with their tired outdated features? Well, I have the solution for you! Introducing SuperUltraMegaNet, the coolest newest social media platform on the block!

We've got all the latest bells and whistles, from custom 3D emojis to augmented reality filters that will blow your mind! And don't even get me started on our exclusive algorithm that ensures your posts get maximum exposure and reach!

Plus, we've got killer rewards for our most active users, so start sharing, liking, and commenting your way to the top of our leaderboard and",spam
"Get rich quick! Buy our exclusive guide now and start earning thousands of dollars in just a few days!

",spam
"Hi,

I'm looking for a dataset with traffic volume per cell.

The dataset should cover many years, to be able to exploit the periodicity, mobility and seasonality of the users behaviour.

Thanks.",not_spam
"Is it good and usable?

[https://www.uscompanieslist.com/](https://www.uscompanieslist.com/)",not_spam
"I'm not sure if this is the absolute best sub to put this, but search showed nothing more obvious. If you know of a better place to ask, let me know.

I'm looking for a list of something like 5,000 UK retail domains, basically any site that sells direct to consumer based in the UK.

I'm not trying to sell to these domains, so the costs of buying contact details through usual sources is not feasible. 

Anyone know where I should start to get that list?",not_spam
"Would love if anyone knew of any really good data sets for Multiple Regression analysis, it's for a class at Uni and I can't seem to find anything solid!  


TIA!",not_spam
"Fields = Hashrate, VRAM, TDP, MSRP, Profit/day",not_spam
"Feelinâ€™ like youâ€™re not getting enough attention on social media? Well, have no fear because [SOCIAL NETWORK NAME] is here to solve all your problems! Weâ€™ve got loads of fake followers just waiting to boost your numbers and make you look like a social media superstar.

And thatâ€™s not all â€“ weâ€™ve also got tons of spammy ads for you to click on! Youâ€™ll love being bombarded with flashy banners and pop-ups that have absolutely nothing to do with your interests. Itâ€™s like having your very own personalized junk mail service!

But wait, thereâ€™s more! Weâ€™ve also got a whole team of bots",spam
