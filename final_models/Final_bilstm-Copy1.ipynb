{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1600638b-09e0-4164-9165-a06808d7ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('final_train.csv')\n",
    "test_data = pd.read_csv('final_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ecf0f9-a91c-401e-8aec-1c40e84f2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Pad sequences\n",
    "maxlen = 100  # adjust as needed\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Encode labels\n",
    "label_mapping = {\n",
    "    'bully-Spam': 0,\n",
    "    'not_bully-Spam': 1,\n",
    "    'bully-Ham': 2,\n",
    "    'not_bully-Ham': 3\n",
    "}\n",
    "y_train = train_data['new_label'].map(label_mapping)\n",
    "y_test = test_data['new_label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd088d6d-618b-4e88-b741-450bed086332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 9s 104ms/step - loss: 1.1324 - accuracy: 0.4354 - val_loss: 1.1840 - val_accuracy: 0.4752\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.8125 - accuracy: 0.6178 - val_loss: 0.7736 - val_accuracy: 0.8794\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.6519 - accuracy: 0.8121 - val_loss: 0.6531 - val_accuracy: 0.8936\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.4105 - accuracy: 0.8906 - val_loss: 0.6899 - val_accuracy: 0.7305\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.2345 - accuracy: 0.9334 - val_loss: 0.5283 - val_accuracy: 0.8156\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.1529 - accuracy: 0.9572 - val_loss: 0.6748 - val_accuracy: 0.8014\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1031 - accuracy: 0.9675 - val_loss: 1.1162 - val_accuracy: 0.6879\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.5777 - val_accuracy: 0.8794\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0534 - accuracy: 0.9881 - val_loss: 0.9844 - val_accuracy: 0.7163\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0377 - accuracy: 0.9921 - val_loss: 0.7390 - val_accuracy: 0.8298\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.8482 - val_accuracy: 0.8156\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 0.4221 - val_accuracy: 0.9007\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 0.8722 - val_accuracy: 0.8156\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.7657 - val_accuracy: 0.8085\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.8804 - val_accuracy: 0.8085\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "# Build Bidirectional LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=50, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Bidirectional LSTM model\n",
    "history=model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88921293-17a9-45e3-bf44-3ef397528956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 24ms/step\n",
      "Bi-LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.91      0.83      0.87       115\n",
      "           2       0.82      0.85      0.84       102\n",
      "           3       0.85      0.87      0.86       199\n",
      "\n",
      "    accuracy                           0.86       426\n",
      "   macro avg       0.89      0.87      0.88       426\n",
      "weighted avg       0.86      0.86      0.86       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Bi-LSTM model\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = predictions.argmax(axis=1)\n",
    "print(\"Bi-LSTM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb4a24-cb6a-4300-bffa-3d6f6dee3de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
