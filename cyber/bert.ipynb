{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3fdd3b-4a22-4298-b779-dd4783548f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('new1_cyber_train.csv')\n",
    "test_df = pd.read_csv('new1_cyber_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae6588f-43bc-4816-b321-f61b2e757a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\nitin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "26/26 [==============================] - 1010s 38s/step - loss: 0.6766 - accuracy: 0.5623 - val_loss: 0.6284 - val_accuracy: 0.6703\n",
      "Epoch 2/3\n",
      "26/26 [==============================] - 1025s 39s/step - loss: 0.5955 - accuracy: 0.7213 - val_loss: 0.5596 - val_accuracy: 0.7582\n",
      "Epoch 3/3\n",
      "26/26 [==============================] - 1034s 40s/step - loss: 0.4675 - accuracy: 0.8533 - val_loss: 0.4633 - val_accuracy: 0.8132\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.4095 - accuracy: 0.8628\n",
      "Test accuracy: 0.8628318309783936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Apply stemming\n",
    "    ps = PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization for DistilBERT\n",
    "tokenizer =BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Encoding as numbers for training dataset\n",
    "encoded_train_texts = tokenizer(train_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "X_train_padded = pad_sequences(encoded_train_texts['input_ids'], padding='post')\n",
    "y_train = train_df['label'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Encoding as numbers for testing dataset\n",
    "encoded_test_texts = tokenizer(test_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "X_test_padded = pad_sequences(encoded_test_texts['input_ids'], padding='post')\n",
    "y_test = test_df['label'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Building the BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compile the model (define optimizer, loss, and metric)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    {'input_ids': X_train_padded, 'attention_mask': encoded_train_texts['attention_mask']},\n",
    "    y_train,\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Evaluating the model on the testing dataset\n",
    "eval_result = model.evaluate(\n",
    "    {'input_ids': X_test_padded, 'attention_mask': encoded_test_texts['attention_mask']},\n",
    "    y_test\n",
    ")\n",
    "print(f\"Test accuracy: {eval_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd515d7-743d-4689-8fa6-d9a4e9174afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
